{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ae902532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /opt/homebrew/anaconda3/lib/python3.12/site-packages (1.32.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (8.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (20.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (13.3.5)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (4.13.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
      "Requirement already satisfied: toolz in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet feedparser langchain_community langgraph duckduckgo-search\n",
    "!pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "35f2cb84-6abf-4a6c-8d1f-cdc6474b77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying final output format\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import feedparser\n",
    "from langchain.tools import BaseTool\n",
    "from urllib.parse import urlencode \n",
    "\n",
    "# LangChain Dependencies\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "from langgraph.graph import END, StateGraph\n",
    "# For State Graph \n",
    "from typing_extensions import TypedDict\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d39b8539-1bfe-4001-b7b2-6752a77846d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variables\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"L3 Research Agent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9b341d1d-0a59-4c03-8558-759ea00171bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining LLM\n",
    "local_llm = 'llama3.2'\n",
    "llama3 = ChatOllama(model=local_llm, temperature=0)\n",
    "llama3_json = ChatOllama(model=local_llm, format='json', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4c7813ac-791f-4035-a5ec-04810d5de5f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=4aaf83fc-be7f-4b34-a295-37b8bab5de60,id=4aaf83fc-be7f-4b34-a295-37b8bab5de60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Pei Min\\'s swordsmanship is like his personality, unrestrained and uninhibited. He traveled around the world, doing justice and left countless moving stories. Some people say that Pei Min\\'s swordsmanship is like the wind, changing rapidly, just like his unruly heart. He danced with a sword on the streets of Chang\\'an, attracting countless people ... Pei Min, on the other hand, was a famous swordsman of the Tang Dynasty, skilled in swordsmanship, and known as the \"Sage of Sword\". Although they lived in the same era and had different identities, they were both outstanding in their respective fields. Their relationship has become a much-talked-about tale among later generations. Pei Min took off his filial piety and danced with a sword, which amazed the onlookers. When Pei Min\\'s sword fell, Wu Daozi painted the picture \"for the magnificence of the world\". The sword is one of the four famous ancient weapons. It can not only be used to kill the enemy, but also ancient scholars and scholars like to carry the saber. Pei Min was a native of Wenxi, Hedong (now Wenxi, Shanxi). He was a general during the Kaiyuan period of the Tang Dynasty. He was promoted to the rank of General of the Left Jinwu Guard, and was famous for his extraordinary swordsmanship. It can even be said that if people mentioned the word \"sword\", they would definitely think of Pei Min first ... Cheng Pei Ming says he had part of his lung and liver cut out in a Chinese prison after being jailed for practising the Falun Gong religion. Owen Leonard - The Sun. 5 min read. August 9, 2024 - 6 ... Therefore, in order to learn swordsmanship, Li Bai came to Shandong and worshiped as his teacher Pei Min, the well-known defender of Beiping at that time, and Pei Min was recognized as the number one swordsman in the world in the Tang Dynasty at that time. Li Bai studied hard under his disciples. Li Bai came to Shandong and worshipped Pei Min, who was known as the \"Swordsman of the Tang Dynasty\", as his teacher. \"The sword comes to Shandong\", at that time Pei Min had the title of swordsman of the Great Tang Dynasty. According to the \"Du Yi Zhi\" record, it \"throws a sword into the cloud, tens of meters high, if the electric light is shot ... The world-renowned Chinese-American architect Ieoh Ming Pei, known as I. M. Pei, passed away on May 16, 2019, at the age of 102.The acclaimed architect is known for his bold designs and explicit geometries in his projects, spanning his career over six decades. 裴旻（拼音：péimín，注音：ㄆㄟˊㄇㄧㄣˊ），东鲁（今山东兖州）人，后迁居任城（今属山东），祖籍河东闻喜（今山西闻喜），唐朝开元年间人士。他曾镇守北平郡（治今河北卢龙），曾先后参与对奚人、契丹和吐蕃的战事。据《新唐书》记载，裴旻官至\"左金吾大将军\"。 MIRI (Dec 16): A student of SM Pei Min, Constanz Lim, has brought home three gold and two silver medals from the World Scholar\\'s Cup (WSC) Tournament of Champions, which took place at Yale ... （3日訊）美里培民中學華樂團將於5月4日（星期日） 晚上7時，在校內林木增暨黃秀英大禮堂舉行\"春夏秋冬\"音樂會， 作為其首個\"年度樂季\"計劃的開幕演出。 此次音樂會不僅為團員提供展示成果的舞台， 也象徵著該團在邁向系統化、專業化發展的道路上開啟全新篇章。 (( 詩華日報 (剪报)) （8日訊）培民中學董事會茲欣然宣佈， 該校第一副校長貝美嬌老師將於2025年1月1日擢升為校長， 以接替因個人原因而辭職的楊友和代校長。 貝美嬌校友早期在培民中學接受六年的高、初中教育， 高中畢業後負笈澳洲留學， 從澳大利亞回國後就返回母校執起了教鞭， 一晃眼就是 ... Mengenai permintaan bantuan kewangan bagi membina trek dan bangunan baharu di Sekolah Menengah Pei Min, Abang Johari setuju untuk memberi peruntukan sebanyak RM2.5 juta dan Lembaga Pengurusan Persatuan Sekolah Menengah Swasta Cina Bersatu Sarawak dan alumni sekolah menyediakan RM2.5 juta lagi bagi menjadikan jumlah RM5 juta dapat digunakan bagi ... (( 詩華日報 (剪报)) （8日訊）2025年美里省19歲以下匹克球錦標賽， 培中球手黃以柔在女子組單打奪得第一名。 這項由美里省匹克球協會主辦的賽事4月26日至27日在百樂城匹 克球中心舉行。 培民中學球手黃以柔在女子組單打奪得第一名， 其他學生在女子雙打、混雙、男子組都有不俗的表現。 美里培民中學校友會 Pei Min Middle School Alumni Association (1993) www.peimin.net 美里培民中學校友會 Pei Min Middle School Alumni Association (1993) www.peimin.net （24日訊）大馬教育文憑（spm）考試今日放榜， 培中成績佳，各科獲得100%及格率， 其中林欣恩和黃允和考獲9a，為理科生最佳； 李嘉琪考獲全科7a，成為文科\"狀元\"。 何春梅、劉恩馨考獲8a；余尚義、郭詠翔考獲7a；許新杰、 劉靖苧、周麗穎考獲6a；蔡頌慧考獲5a。 數理生考獲a者多 Sagu hati - SM Chung Hua No. 1, Kuching dan SM Min Lit, Batu Kawa, Kuching. Kategori Konduktor Terbaik. Lau Ting Yuan dari SM Katholik, Sibu. Pertandingan Klip Video Pendek . Johan - SM Kai Dee, Bintulu. Naib johan - SM Chung Hua No. 3, Kuching. Tempat ketiga - SM Katholik, Sibu. Sagu hati - SM Chung Hua No. 1, Kuching dan SM Pei Min ... School code Location Name of school in Malay Name of school in Chinese Postcode Area Urban/ Rural No. of students Coordinates ABC1046 Pangkor: SJK(C) Hwa Lian (1) SJKC Pei Min Segari 昔加里培民华小 added a new photo. SJK(C) Poi Min - New Chinese Primary School in Puchong Now Open for Enrollment! Located at 4091, Jalan Perindustrian Puchong, 47100 Puchong, Selangor, SJK(C) Poi Min is now welcoming students to its newly opened school.This Chinese primary school offers an educational experience with a strong focus on language and cultural studies, providing families in the Puchong area with a new option for ... Touching on SM Pei Min new building block, Abang Johari said it reflects unity among all races and those in need of government assistance. 美里培民中學校友會 Pei Min Middle School Alumni Association (1993) www.peimin.net Canada\\'s 2025 minimum wage updates reflect a strong commitment to supporting workers and ensuring fair pay. With changes happening across multiple provinces and federally regulated sectors, both employees and employers must stay informed. SJKC Pei Min Segari 昔加里培民华小. 813 likes · 121 talking about this. Education'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Web Search Tool\n",
    "\n",
    "wrapper = DuckDuckGoSearchAPIWrapper(max_results=25)\n",
    "web_search_tool = DuckDuckGoSearchRun(api_wrapper=wrapper)\n",
    "\n",
    "# Test Run\n",
    "resp = web_search_tool.invoke(\"pei min\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c12f9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "def get_top_hf_papers(n: int):\n",
    "    url = \"https://huggingface.co/papers\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to retrieve papers: {response.status_code}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    papers = soup.find_all(\"article\")\n",
    "\n",
    "    paper_info = []\n",
    "    for paper in papers:\n",
    "        title = paper.find(\"h3\").text.strip() if paper.find(\"h3\") else \"No Title\"\n",
    "        link = paper.find(\"a\")[\"href\"] if paper.find(\"a\") else \"#\"\n",
    "        vote_info = paper.find(\"div\", {\"class\": \"flex flex-wrap items-center gap-2.5 pt-1\"})\n",
    "        vote_count = 0\n",
    "        if vote_info:\n",
    "            vote_text = vote_info.find(\"div\", {\"class\": \"leading-none\"})\n",
    "            vote_count = int(vote_text.text.strip()) if vote_text and vote_text.text.strip().isdigit() else 0\n",
    "        thumbnail = paper.find(\"img\")[\"src\"] if paper.find(\"img\") else \"\"\n",
    "        author_list = paper.find(\"ul\", {\"class\": \"flex items-center flex-row-reverse text-sm\"})\n",
    "\n",
    "        authors = []\n",
    "        if author_list:\n",
    "            for author in author_list.find_all(\"li\"):\n",
    "                if author.has_attr(\"title\"):\n",
    "                    authors.append(author[\"title\"])\n",
    "\n",
    "        paper_info.append({\n",
    "            \"title\": title,\n",
    "            \"link\": link,\n",
    "            \"votes\": vote_count,\n",
    "            \"thumbnail\": thumbnail,\n",
    "            \"authors\": \", \".join(authors) if authors else \"Unknown\",\n",
    "        })\n",
    "\n",
    "    paper_info.sort(key=lambda x: x[\"votes\"], reverse=True)\n",
    "    top_papers = paper_info[:n]\n",
    "\n",
    "    for i, paper in enumerate(top_papers):\n",
    "        paper_url = f\"https://huggingface.co{paper['link']}\"\n",
    "        paper_response = requests.get(paper_url)\n",
    "        if paper_response.status_code != 200:\n",
    "            continue\n",
    "        paper_soup = BeautifulSoup(paper_response.text, \"html.parser\")\n",
    "        date_div = paper_soup.find(\"div\", {\"class\": \"mb-6 flex flex-wrap gap-2 text-sm text-gray-500 max-sm:flex-col sm:items-center sm:text-base md:mb-8\"})\n",
    "        published_date = \"\"\n",
    "        if date_div and date_div.find(\"div\"):\n",
    "            published_date = date_div.find(\"div\").text.split(\"Published on \")[-1].strip()\n",
    "        abstract_div = paper_soup.find(\"div\", {\"class\": \"pb-8 pr-4 md:pr-16\"})\n",
    "        abstract = abstract_div.find(\"p\").text.strip() if abstract_div and abstract_div.find(\"p\") else \"No abstract available\"\n",
    "\n",
    "        top_papers[i][\"published_date\"] = published_date\n",
    "        top_papers[i][\"abstract\"] = abstract\n",
    "\n",
    "    return json.dumps(top_papers, indent=2)\n",
    "\n",
    "\n",
    "class HuggingFacePapersAPIWrapper(BaseTool):\n",
    "    name: str = \"huggingface\"\n",
    "    description: str = \"Fetch top-voted Hugging Face papers\"\n",
    "\n",
    "    def _run(self, n: int):\n",
    "        raw = get_top_hf_papers(n)\n",
    "        return {\"source\": \"huggingface\", \"results\": json.loads(raw)}\n",
    "\n",
    "\n",
    "hf_tool = HuggingFacePapersAPIWrapper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1a2adc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arxiv_search(query: str, max_results: int = 5):\n",
    "    \"\"\"\n",
    "    Query arXiv’s API and return the top N most recent papers.\n",
    "    \"\"\"\n",
    "    base_url = \"http://export.arxiv.org/api/query\"\n",
    "    params = {\n",
    "        \"search_query\": query,\n",
    "        \"start\":        0,\n",
    "        \"max_results\":  max_results,\n",
    "        \"sortBy\":       \"submittedDate\",\n",
    "        \"sortOrder\":    \"descending\",\n",
    "    }\n",
    "    url = f\"{base_url}?{urlencode(params)}\"\n",
    "    feed = feedparser.parse(url)\n",
    "\n",
    "    results = []\n",
    "    for entry in feed.entries:\n",
    "        results.append({\n",
    "            \"title\": entry.title,\n",
    "            \"summary\": entry.summary,\n",
    "            \"authors\": [a.name for a in entry.authors],\n",
    "            \"published\": entry.published,\n",
    "            \"pdf_url\": next((l.href for l in entry.links if l.type==\"application/pdf\"), None)\n",
    "        })\n",
    "    return results\n",
    "\n",
    "class ArxivAPIWrapper(BaseTool):\n",
    "    name: str = \"research-search\"\n",
    "    description: str = \"Use this to fetch the latest arXiv papers on a topic.\"\n",
    "\n",
    "    def _run(self, query: str):\n",
    "        papers = arxiv_search(query, max_results=5)\n",
    "        return \"\\n\\n\".join(\n",
    "            f\"{p['title']} ({p['published']})\\n\"\n",
    "            f\"{p['summary'][:300]}…\\nPDF: {p['pdf_url']}\"\n",
    "            for p in papers\n",
    "        )\n",
    "\n",
    "    async def _arun(self, query: str):\n",
    "        return self._run(query)\n",
    "\n",
    "# instantiate\n",
    "research_tool = ArxivAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "    web_search_tool,\n",
    "    research_tool,     \n",
    "    hf_tool\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2d798a81-6ed6-4a4f-a1d9-93b4e3059fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation Prompt\n",
    "\n",
    "generate_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    \n",
    "    <|begin_of_text|>\n",
    "    \n",
    "    <|start_header_id|>system<|end_header_id|> \n",
    "    \n",
    "    You are an AI assistant for Research Question Tasks, that synthesizes web search results. \n",
    "    Strictly use the following pieces of web search context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    keep the answer concise, but provide all of the details you can in the form of a research report. \n",
    "    Only make direct references to material if provided in the context.\n",
    "    \n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    \n",
    "    Question: {question} \n",
    "    Web Search Context: {context} \n",
    "    Answer: \n",
    "    \n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "# Chain\n",
    "generate_chain = generate_prompt | llama3 | StrOutputParser()\n",
    "\n",
    "# Test Run\n",
    "# question = \"How are you?\"\n",
    "# context = \"\"\n",
    "# generation = generate_chain.invoke({\"context\": context, \"question\": question})\n",
    "# print(generation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "49fa1965-6bd4-4dfc-9eb8-96c6cff7b639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=4aaf83fc-be7f-4b34-a295-37b8bab5de60,id=4aaf83fc-be7f-4b34-a295-37b8bab5de60; trace=ae3fa61a-f24f-48fe-8ae3-3dc297a30a00,id=ae3fa61a-f24f-48fe-8ae3-3dc297a30a00; trace=ae3fa61a-f24f-48fe-8ae3-3dc297a30a00,id=c0aad389-0ad3-4873-aef2-e1ad25ea7930; trace=ae3fa61a-f24f-48fe-8ae3-3dc297a30a00,id=c0aad389-0ad3-4873-aef2-e1ad25ea7930; trace=ae3fa61a-f24f-48fe-8ae3-3dc297a30a00,id=671d36ad-663b-405c-9e7a-ee65d99f3a07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice': 'GENERAL'}\n"
     ]
    }
   ],
   "source": [
    "# Router\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    <|begin_of_text|>\n",
    "    <|start_header_id|>system<|end_header_id|>\n",
    "    You are an expert at routing a user question into one of four categories:\n",
    "    1. RESEARCH     – user needs the latest peer-reviewed papers (scholarly queries).\n",
    "    2. NEWS         – user is asking about current events or recent news.\n",
    "    3. GENERAL      – user should get a direct answer from the LLM without external lookups.\n",
    "    4. HUGGINGFACE  – user wants trending models or papers on Hugging Face.\n",
    "\n",
    "    Return JSON with a single key \"choice\" whose value is exactly one of RESEARCH, NEWS, GENERAL, or HUGGINGFACE.\n",
    "\n",
    "    Question to route: {question}\n",
    "    <|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# Chain\n",
    "question_router = router_prompt | llama3_json | JsonOutputParser()\n",
    "\n",
    "# Test Run\n",
    "question = \"top ai model\"\n",
    "print(question_router.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "33ab4128-e0b0-4f49-9f36-1d3bf5636715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=ae3fa61a-f24f-48fe-8ae3-3dc297a30a00,id=671d36ad-663b-405c-9e7a-ee65d99f3a07; trace=ae3fa61a-f24f-48fe-8ae3-3dc297a30a00,id=5bce9145-61cc-40a4-9f5d-bae8f8585c04; trace=ae3fa61a-f24f-48fe-8ae3-3dc297a30a00,id=5bce9145-61cc-40a4-9f5d-bae8f8585c04; trace=ae3fa61a-f24f-48fe-8ae3-3dc297a30a00,id=ae3fa61a-f24f-48fe-8ae3-3dc297a30a00; trace=473809a4-1c47-4926-9929-065bba110d52,id=473809a4-1c47-4926-9929-065bba110d52; trace=473809a4-1c47-4926-9929-065bba110d52,id=ad76a04d-ec8d-462a-91ed-5e25ed2ce06f; trace=473809a4-1c47-4926-9929-065bba110d52,id=ad76a04d-ec8d-462a-91ed-5e25ed2ce06f; trace=473809a4-1c47-4926-9929-065bba110d52,id=81f823f7-143d-4a56-a9ea-9ee011f0c7b7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'recent developments in ChatGPT'}\n"
     ]
    }
   ],
   "source": [
    "# Query Transformation\n",
    "\n",
    "query_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    \n",
    "    <|begin_of_text|>\n",
    "    \n",
    "    <|start_header_id|>system<|end_header_id|> \n",
    "    \n",
    "    You are an expert at crafting web search queries for research questions.\n",
    "    More often than not, a user will ask a basic question that they wish to learn more about, however it might not be in the best format. \n",
    "    Reword their query to be the most effective web search string possible.\n",
    "    Return the JSON with a single key 'query' with no premable or explanation. \n",
    "    \n",
    "    Question to transform: {question} \n",
    "    \n",
    "    <|eot_id|>\n",
    "    \n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "# Chain\n",
    "query_chain = query_prompt | llama3_json | JsonOutputParser()\n",
    "\n",
    "# Test Run\n",
    "question = \"What's happened recently with chatgpt?\"\n",
    "print(query_chain.invoke({\"question\": question}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a1c8e922-3f00-48d6-83cb-cc78a2292838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph State\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        search_query: revised question for web search\n",
    "        context: web_search result\n",
    "        n: optional number of top HF papers to fetch\n",
    "    \"\"\"\n",
    "    question : str\n",
    "    generation : str\n",
    "    search_query : str\n",
    "    context : str\n",
    "    n : int\n",
    "\n",
    "# Node - Generate\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        dict: New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"Step: Generating Final Response\")\n",
    "    question = state[\"question\"]\n",
    "    # Safely grab context (empty if none)\n",
    "    context = state.get(\"context\", \"\")\n",
    "\n",
    "    # Answer Generation\n",
    "    generation = generate_chain.invoke({\"context\": context, \"question\": question})\n",
    "    return {\"generation\": generation}\n",
    "\n",
    "# Node – Hugging Face\n",
    "hf_tool = HuggingFacePapersAPIWrapper()\n",
    "\n",
    "def huggingface_node(state):\n",
    "    question = state[\"question\"]\n",
    "    import re\n",
    "    match = re.search(r\"top\\s+(\\d+)\", question.lower())\n",
    "    n = int(match.group(1)) if match else 5\n",
    "    hf_result = hf_tool.invoke({\"n\": n})\n",
    "    return {\"context\": hf_result}\n",
    "\n",
    "# Node - Query Transformation\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform user question to web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended search query\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Step: Optimizing Query for Web Search\")\n",
    "    question = state['question']\n",
    "    gen_query = query_chain.invoke({\"question\": question})\n",
    "    search_query = gen_query[\"query\"]\n",
    "    return {\"search_query\": search_query}\n",
    "\n",
    "\n",
    "# Node - Web Search\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to context\n",
    "    \"\"\"\n",
    "\n",
    "    search_query = state['search_query']\n",
    "    print(f'Step: Searching the Web for: \"{search_query}\"')\n",
    "    \n",
    "    # Web search tool call\n",
    "    search_result = web_search_tool.invoke(search_query)\n",
    "    return {\"context\": search_result}\n",
    "\n",
    "def research_node(state):\n",
    "    \"\"\"\n",
    "    Call the ArXiv tool and stash results in state['context'].\n",
    "    \"\"\"\n",
    "    print(\"Step: Running Research Tool\")\n",
    "    q = state.get(\"query\") or state.get(\"question\")\n",
    "    papers = research_tool.invoke(q)\n",
    "    # research_tool.invoke returns a single string; if it were a list you'd join it\n",
    "    return {\"context\": papers}\n",
    "\n",
    "\n",
    "\n",
    "# Conditional Edge, Routing\n",
    "\n",
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to one of the tags: RESEARCH, NEWS, or GENERAL.\n",
    "    \"\"\"\n",
    "    print(\"Step: Routing Query\")\n",
    "    q = state.get(\"query\") or state.get(\"question\")\n",
    "    choice = question_router.invoke({\"question\": q})[\"choice\"]\n",
    "\n",
    "    # Just return the tag\n",
    "    if choice == \"RESEARCH\":\n",
    "        print(\"Tag: RESEARCH\")\n",
    "        return \"RESEARCH\"\n",
    "    elif choice == \"HUGGINGFACE\":\n",
    "        print(\"Tag: HUGGINGFACE\")\n",
    "        return \"huggingface\"\n",
    "    elif choice == \"NEWS\":\n",
    "        print(\"Tag: NEWS\")\n",
    "        return \"NEWS\"\n",
    "    else:\n",
    "        print(\"Tag: GENERAL\")\n",
    "        return \"GENERAL\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8f665713-e80b-4d86-8015-77ba55506004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the nodes\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"websearch\",       web_search)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"research\",        research_node)\n",
    "workflow.add_node(\"huggingface\",     huggingface_node)\n",
    "workflow.add_node(\"generate\",        generate)\n",
    "\n",
    "# Build the edges\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"RESEARCH\":     \"research\",\n",
    "        \"huggingface\":  \"huggingface\", \n",
    "        \"NEWS\":         \"transform_query\",\n",
    "        \"GENERAL\":      \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"transform_query\", \"websearch\")\n",
    "workflow.add_edge(\"websearch\",       \"generate\")\n",
    "\n",
    "workflow.add_edge(\"research\",        \"generate\")\n",
    "workflow.add_edge(\"huggingface\",     \"generate\") \n",
    "workflow.add_edge(\"generate\",        END)\n",
    "\n",
    "# Compile the workflow\n",
    "local_agent = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "4f53aa05-20b2-420e-9a8f-bf12b1e547ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(query):\n",
    "    output = local_agent.invoke({\"question\": query})\n",
    "    print(\"=======\")\n",
    "    display(Markdown(output[\"generation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "6a1b135d-131e-4276-b40c-12ea8b78c39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Routing Query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=473809a4-1c47-4926-9929-065bba110d52,id=81f823f7-143d-4a56-a9ea-9ee011f0c7b7; trace=473809a4-1c47-4926-9929-065bba110d52,id=453f6f99-ce28-4875-8959-308fbde62b27; trace=473809a4-1c47-4926-9929-065bba110d52,id=453f6f99-ce28-4875-8959-308fbde62b27; trace=473809a4-1c47-4926-9929-065bba110d52,id=473809a4-1c47-4926-9929-065bba110d52; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=e24a3e43-d4bf-41c1-9263-9540a98a68d3; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=87642dc6-0a0c-4e43-a3f8-9b092e3ce937; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=90922678-f667-4fa5-a97c-13d359a460f6; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=58144b04-4490-4937-99df-0bfabbc79973; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=141b07a6-b632-4bfb-8c34-cd5e29b87452; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=141b07a6-b632-4bfb-8c34-cd5e29b87452; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=cf5e14a7-2d7f-4675-9436-ff5e53c87831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag: HUGGINGFACE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=cf5e14a7-2d7f-4675-9436-ff5e53c87831; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=37ed08af-bdeb-4bf7-a450-1f844679061b; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=37ed08af-bdeb-4bf7-a450-1f844679061b; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=58144b04-4490-4937-99df-0bfabbc79973; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=90922678-f667-4fa5-a97c-13d359a460f6; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=87642dc6-0a0c-4e43-a3f8-9b092e3ce937; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=537d064f-dce4-4476-8dc7-933b54f67376; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=dc294d97-9a04-4a71-a0db-d7c21c108db1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Generating Final Response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=dc294d97-9a04-4a71-a0db-d7c21c108db1; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=537d064f-dce4-4476-8dc7-933b54f67376; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=857ff5c2-5c74-4cfc-aeb5-b589dd7762f5; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=c3d35d8b-36c3-4135-81b2-4779003af747; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=818fa854-88b4-449c-8bbd-9d37afd32ade; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=818fa854-88b4-449c-8bbd-9d37afd32ade; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=54ca3905-8b25-4d2a-b0bc-77a9efaffa48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Top 5 Papers on HF (Hugging Face) as of Today**\n",
       "\n",
       "Based on the provided web search context from Hugging Face, here are the top 5 papers in a clear format:\n",
       "\n",
       "1. **Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective**\n",
       "\t* Title: Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective\n",
       "\t* Link: <https://huggingface.co/papers/2506.14965>\n",
       "\t* Authors: Shibo Hao, Zhoujun Cheng, fengyao1909, koalazf99, tianyang\n",
       "\t* Published Date: June 17\n",
       "\t* Thumbnail: ![thumbnail](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14965.png)\n",
       "\t* Abstract: Guru, a diverse RL reasoning corpus, highlights domain-specific training needs and demonstrates improved performance in complex tasks for RL-enhanced LLMs.\n",
       "2. **EmoNet-Voice: A Fine-Grained, Expert-Verified Benchmark for Speech Emotion Detection**\n",
       "\t* Title: EmoNet-Voice: A Fine-Grained, Expert-Verified Benchmark for Speech Emotion Detection\n",
       "\t* Link: <https://huggingface.co/papers/2506.09827>\n",
       "\t* Authors: Robert Kaczmarczyk, soeren1611, felfri, tourist800, ChristophSchuhmann\n",
       "\t* Published Date: June 11\n",
       "\t* Thumbnail: ![thumbnail](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.09827.png)\n",
       "\t* Abstract: EmoNet-Voice, a new resource with large pre-training and benchmark datasets, advances speech emotion recognition by offering fine-grained emotion evaluation with synthetic, privacy-preserving audio.\n",
       "3. **Show-o2: Improved Native Unified Multimodal Models**\n",
       "\t* Title: Show-o2: Improved Native Unified Multimodal Models\n",
       "\t* Link: <https://huggingface.co/papers/2506.15564>\n",
       "\t* Authors: Mike Zheng Shou, Zhenheng Yang, Jinheng Xie\n",
       "\t* Published Date: June 18\n",
       "\t* Thumbnail: ![thumbnail](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.15564.png)\n",
       "\t* Abstract: Show-o2 leverages autoregressive modeling and flow matching within a 3D causal variational autoencoder to create unified visual representations for multimodal understanding and generation tasks.\n",
       "4. **Improved Iterative Refinement for Chart-to-Code Generation via Structured Instruction**\n",
       "\t* Title: Improved Iterative Refinement for Chart-to-Code Generation via Structured Instruction\n",
       "\t* Link: <https://huggingface.co/papers/2506.14837>\n",
       "\t* Authors: Yuyang Wang, weiranhuang, sunlichao137, WaltonFuture, dazhiga\n",
       "\t* Published Date: June 15\n",
       "\t* Thumbnail: ![thumbnail](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14837.png)\n",
       "\t* Abstract: ChartIR uses structured instruction and iterative refinement to improve MLLM performance in chart-to-code generation by separating visual understanding and code translation tasks.\n",
       "5. **SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning**\n",
       "\t* Title: SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning\n",
       "\t* Link: <https://huggingface.co/papers/2506.15154>\n",
       "\t* Authors: Abhinaba Roy, dorienh, annabeth97c\n",
       "\t* Published Date: June 18\n",
       "\t* Thumbnail: ![thumbnail](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.15154.png)\n",
       "\t* Abstract: SonicVerse, a multi-task music captioning model, integrates audio feature detection to enhance caption quality and enable detailed descriptions of music pieces.\n",
       "\n",
       "Note: The thumbnail images are displayed using Markdown syntax (`![thumbnail](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2506.14965.png)`) if available in the web search context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send compressed multipart ingest: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"error\":\"Unauthorized\"}\\n')trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=54ca3905-8b25-4d2a-b0bc-77a9efaffa48; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=e1bed48c-00ed-4eba-ba94-285b2ecd3bd5; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=e1bed48c-00ed-4eba-ba94-285b2ecd3bd5; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=c3d35d8b-36c3-4135-81b2-4779003af747; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=857ff5c2-5c74-4cfc-aeb5-b589dd7762f5; trace=e24a3e43-d4bf-41c1-9263-9540a98a68d3,id=e24a3e43-d4bf-41c1-9263-9540a98a68d3\n"
     ]
    }
   ],
   "source": [
    "# Test it out!\n",
    "# run_agent(\"What's up with lope recently?\")\n",
    "#run_agent(\"How are you?\")\n",
    "#run_agent(\"Find me the latest arXiv papers on graph neural networks?\")\n",
    "run_agent(\"What are the top 5 papers on HF today? Please organize them in a clear format and include any available details, thumbnails, etc. Display the images in markdown if they exist. use function call\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
