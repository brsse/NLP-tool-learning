{"doi": "10.48550/arXiv.2405.03423", "date": "2024-05-06", "title": "Generalized Baer and Generalized Quasi-Baer Rings of Skew Generalized Power Series", "authors": "M. M. Hamam, R. E. Abdel-Khalek, R. M. Salem", "abstract": "Let $R$ be a ring with identity, $(S,\\leq)$ an ordered monoid, $\\omega:S \\to\nEnd(R)$ a monoid homomorphism, and $A= R\\left[\\left[S,\\omega \\right]\\right]$\nthe ring of skew generalized power series. The concepts of generalized Baer and\ngeneralized quasi-Baer rings are generalization of Baer and quasi-Baer rings,\nrespectively. A ring $R$ is called generalized right Baer (generalized right\nquasi-Baer) if for any non-empty subset $S$ (right ideal $I$) of $R$, the right\nannihilator of $S^n \\space{0.1cm}(I^n)$ is generated by an idempotent for some\npositive integer $n$. Left cases may be defined analogously. A ring $R$ is\ncalled generalized Baer (generalized quasi-Baer) if it is both generalized\nright and left Baer (generalized right and left quasi-Baer) ring. In this\npaper, we examine the behavior of a skew generalized power series ring over a\ngeneralized right Baer (generalized right quasi-Baer) ring and prove that,\nunder specific conditions, the ring $A$ is generalized right Baer (generalized\nright quasi-Baer) if and only if $R$ is a generalized right Baer (generalized\nright quasi-Baer) ring.", "journal": ""}
{"doi": "10.48550/arXiv.1205.3915", "date": "2012-05-17", "title": "On generalized topological groups", "authors": "Murad Hussain, Moiz Ud Din Khan, Cenap \u007f\u00d6zel", "abstract": "In this work, we will introduce the notion of generalized topological groups\nusing generalized topological structure and generalized continuity defined by\n?A. Cs?asz?ar [2]. We will discuss some basic properties of this kind of\nstructures and connectedness properties of this structures are given. Keywords:\nGeneralized topology; generalized continuity; generalized topological groups;\ngeneralized connectedness.", "journal": ""}
{"doi": "10.48550/arXiv.1703.06340", "date": "2017-03-18", "title": "Weighted spherical means generated by generalized translation and general Euler-Poisson-Darboux equation", "authors": "Elina Shishkina", "abstract": "We consider the spherical mean generated by a multidimensional generalized\ntranslation and general Euler-Poisson-Darboux equation corresponding to this\nmean. The Asgeirsson property of solutions of the ultrahyperbolic equation that\nincludes singular differential Bessel operators acting by each variable is\nprovided.", "journal": ""}
{"doi": "10.48550/arXiv.2010.05756", "date": "2020-10-09", "title": "Generalized groups and module groupoids", "authors": "P. G. Romeo, Sneha K K", "abstract": "In this paper we discuss generalized group, provides some interesting\nexamples. Further we introduce a generalized module as a module like structure\nobtained from a generalized group and discuss some of its properties and we\nalso describes generalized module groupoids.", "journal": ""}
{"doi": "10.48550/arXiv.1111.2567", "date": "2011-11-10", "title": "Generalized Lucas Numbers and Relations with Generalized Fibonacci Numbers", "authors": "Kenan Kaygisiz, Adem Sahin", "abstract": "In this paper, we present a new generalization of the Lucas numbers by matrix\nrepresentation using Genaralized Lucas Polynomials. We give some properties of\nthis new generalization and some relations between the generalized order-k\nLucas numbers and generalized order-k Fibonacci numbers. In addition, we obtain\nBinet formula and combinatorial representation for generalized order-k Lucas\nnumbers by using properties of generalized Fibonacci numbers.", "journal": ""}
{"doi": "10.48550/arXiv.1111.4065", "date": "2011-11-17", "title": "k Sequences of Generalized Van der Laan and Generalized Perrin Polynomials", "authors": "Kenan Kaygisiz, Adem Sahin", "abstract": "In this paper, we present k sequences of Generalized Van der Laan Polynomials\nand Generalized Perrin Polynomials using Genaralized Fibonacci and Lucas\nPolynomials. We give some properties of these polynomials. We also obtain\ngeneralized order-k Van der Laan Numbers, k sequences of generalized order-k\nVan der Laan Numbers, generalized order-k Perrin Numbers and k sequences of\ngeneralized order-k Perrin Numbers. In addition, we examine the relationship\nbetween them.", "journal": ""}
{"doi": "10.48550/arXiv.2301.00649", "date": "2023-01-02", "title": "On Some Characterizations of General s-Convex Functions", "authors": "Musavvir Ali, Ehtesham Akhter", "abstract": "It is established that general s-convex functions are a new class of\ngeneralized convex functions. In a similar vein, a new class of general\ns-convex sets is introduced, which are generalizations of s-convex sets.\nAdditionally, certain fundamental characteristics of general s-convex functions\nare discussed for both general cases and differentiable situations. Aside from\nthat, the general s-convexity is used to define and demonstrate the sufficient\ncriteria for optimality for both unconstrained and inequality-constrained\nprogramming.", "journal": ""}
{"doi": "10.48550/arXiv.2411.18783", "date": "2024-11-27", "title": "Quasitoric representation of generalized braids", "authors": "Neha Nanda, Manpreet Singh", "abstract": "In this paper, we define generalized braid theories in alignment with the\nlanguage of Fenn and Bartholomew for knot theories, and compute a generating\nset for the pure generalized braid theories. Using this, we prove that every\noriented normal generalized knot is the closure of a quasitoric normal\ngeneralized braid. Further, we prove that the set of quasitoric normal\ngeneralized braids forms a subgroup of normal generalized braid group.", "journal": ""}
{"doi": "10.48550/arXiv.2111.02716", "date": "2021-11-04", "title": "General Fractional Vector Calculus", "authors": "Vasily E. Tarasov", "abstract": "A generalization of fractional vector calculus as a self-consistent\nmathematical theory is proposed to take into account a general form of\nnon-locality in kernels of fractional vector differential and integral\noperators. Self-consistency involves proving generalizations of all fundamental\ntheorems of vector calculus for generalized kernels of operators. In the\ngeneralization of FVC from power-law nonlocality to the general form of\nnonlocality in space, we use the general fractional calculus in the Luchko\napproach. This paper proposed the following: (1) Self-consistent definitions of\ngeneral fractional differential vector operators: the regional and line general\nfractional gradients, the regional and surface general fractional curl\noperators, the general fractional divergence are proposed. (2) Self-consistent\ndefinitions of general fractional integral vector operators: the general\nfractional circulation, general fractional flux and general fractional volume\nintegral are proposed. (3) The general fractional gradient, Green, Stokes and\nGauss theorems as fundamental theorems of general fractional vector calculus\nare proved for simple and complex regions. The fundamental theorems (Gradient,\nGreen, Stokes, Gauss theorems) of the proposed general FVC are proved for a\nwider class of domains, surfaces and curves. Therefore we can state that we\nproposed a calculus, which is a general fractional vector calculus. The\ndifficulties and problems of defining general fractional integral and\ndifferential vector operators are discussed to the nonlocal case, caused by the\nviolation of standard product (Leibniz) rule, chain rule, and semigroup\nproperty. General FVC for orthogonal curvilinear coordinates, which includes\ngeneral fractional vector operators for the spherical and cylindrical\ncoordinates, is also proposed.", "journal": "Mathematics. 2021. Vol.9. No.21/ Article number: 2816"}
{"doi": "10.48550/arXiv.9908033", "date": "1999-08-11", "title": "A Simple Formula for Generating Chern Characters by Repeated Exterior Differentiation", "authors": "C. C. Briggs", "abstract": "A simple formula is given for generating Chern characters by repeated\nexterior differentiation for n-dimensional differentiable manifolds having a\ngeneral linear connection.", "journal": ""}
{"doi": "10.48550/arXiv.9908034", "date": "1999-08-11", "title": "A Sequence of Generalizations of Cartan's Conservation of Torsion Theorem", "authors": "C. C. Briggs", "abstract": "A sequence of generalizations of Cartan's conservation of torsion theorem is\ngiven for n-dimensional differentiable manifolds having a general linear\nconnection.", "journal": ""}
{"doi": "10.48550/arXiv.0503179", "date": "2005-03-09", "title": "On a Possible Generalization of Fermats Last Theorem", "authors": "Dhananjay P. Mehendale", "abstract": "This paper proposes a generalized ABC conjecture and assuming its validity\nsettles a generalized version of Fermats last theorem.", "journal": ""}
{"doi": "10.48550/arXiv.0609831", "date": "2006-09-29", "title": "Generalized subresultants and generalized subresultant algorithm", "authors": "Petr Glotov", "abstract": "In this paper we present the notions of trail (pseudo-)division, generalized\nsubresultants and generalized subresultant algorithm.", "journal": ""}
{"doi": "10.48550/arXiv.1709.07668", "date": "2017-09-22", "title": "On The Generalized Binomial Edge Ideals of Generalized Block Graphs", "authors": "Faryal Chaudhry, Rida Irfan", "abstract": "We compute the depth and (give bounds for) the regularity of generalized\nbinomial edge ideals associated with generalized block graphs.", "journal": ""}
{"doi": "10.48550/arXiv.1906.05160", "date": "2019-06-12", "title": "General Video Game Rule Generation", "authors": "Ahmed Khalifa, Michael Cerny Green, Diego Perez-Liebana, Julian Togelius", "abstract": "We introduce the General Video Game Rule Generation problem, and the\neponymous software framework which will be used in a new track of the General\nVideo Game AI (GVGAI) competition. The problem is, given a game level as input,\nto generate the rules of a game that fits that level. This can be seen as the\ninverse of the General Video Game Level Generation problem. Conceptualizing\nthese two problems as separate helps breaking the very hard problem of\ngenerating complete games into smaller, more manageable subproblems. The\nproposed framework builds on the GVGAI software and thus asks the rule\ngenerator for rules defined in the Video Game Description Language. We describe\nthe API, and three different rule generators: a random, a constructive and a\nsearch-based generator. Early results indicate that the constructive generator\ngenerates playable and somewhat interesting game rules but has a limited\nexpressive range, whereas the search-based generator generates remarkably\ndiverse rulesets, but with an uneven quality.", "journal": ""}
{"doi": "10.48550/arXiv.2303.17122", "date": "2023-03-30", "title": "The general definition of Kahler angle", "authors": "Yongpin Zhu", "abstract": "In this paper, we give a general definition of Kahler angle. There are many\nresults about Kahler angle one can try to generalize to the general case.", "journal": ""}
{"doi": "10.48550/arXiv.1202.0949", "date": "2012-02-05", "title": "Bayesian filtering for multi-object systems with independently generated observations", "authors": "Daniel Edward Clark", "abstract": "A general approach for Bayesian filtering of multi-object systems is studied,\nwith particular emphasis on the model where each object generates observations\nindependently of other objects. The approach is based on variational calculus\napplied to generating functionals, using the general version of Faa di Bruno's\nformula for Gateaux differentials. This result enables us to determine some\ngeneral formulae for the updated generating functional after the application of\na multi-object analogue of Bayes' rule.", "journal": ""}
{"doi": "10.48550/arXiv.1612.00970", "date": "2016-12-03", "title": "Fractal generalized Pascal matrices", "authors": "E. Burlachenko", "abstract": "Set of generalized Pascal matrices whose elements are generalized binomial\ncoefficients is considered as an integral object. The special system of\ngeneralized Pascal matrices, based on which we are building fractal generalized\nPascal matrices, is introduced. Pascal matrix (Pascal triangle) is the Hadamard\nproduct of the fractal generalized Pascal matrices. The concept of zero\ngeneralized Pascal matrices, an example of which is the Pascal triangle modulo\n2, arise in connection with the system of matrices introduced.", "journal": ""}
{"doi": "10.48550/arXiv.1802.00079", "date": "2018-01-28", "title": "Generalizations of Banach and Kannan Fixed point theorems in b_{v}(s) metric spaces", "authors": "Ibrahim Karahan", "abstract": "Generalizations of a metric space is one of the most important research areas\nin mathematics. In literature ,there are several generalized metric spaces. The\nlatest generalized metric space is b_{v}(s) metric space which is introduced by\nMitrovic and Radenovic in 2017. In this paper, we prove Kannan fixed point\ntheorem and generalize Banach fixed point theorem for weakly contractive\nmappings in b_{v}(s) metric spaces. Our results extend and generalize some\ncorresponding result.", "journal": ""}
{"doi": "10.48550/arXiv.1905.01599", "date": "2019-05-05", "title": "A new characterization of generalized Browder's theorem and a Cline's formula for generalized Drazin-meromorphic inverses", "authors": "Anuradha Gupta, Ankit Kumar", "abstract": "In this paper, we give a new characterization of generalized Browder's\ntheorem by considering equality between the generalized Drazin-meromorphic Weyl\nspectrum and the generalized Drazin-meromorphic spectrum. Also, we generalize\nCline's formula to the case of generalized Drazin-meromorphic invertibility\nunder the assumption that $A^kB^kA^k=A^{k+1}$ for some positive integer $k$.", "journal": ""}
{"doi": "10.48550/arXiv.2306.07431", "date": "2023-06-12", "title": "Deformed Newton's $(s,t)$-Binomial Series and Generating Functions of Generalized Central Binomial Coefficients and Generalized Catalan Numbers", "authors": "Ronald Orozco L\u00f3pez", "abstract": "We define the deformed $(s,t)$-binomial formula and the deformed Newton\n$(s,t)$-binomial series, and we will use it to establish the generating\nfunctions of the generalized central binomial coefficients and the generalized\nCatalan numbers.", "journal": ""}
{"doi": "10.48550/arXiv.2406.02937", "date": "2024-06-05", "title": "Identities and Generating Functions of Products of Generalized Fibonacci numbers, Catalan and Harmonic Numbers", "authors": "Vladimir V. Kruchinin, Maria Y. Perminova", "abstract": "We considered the properties of generalized Fibonacci and Lucas numbers\nclass. The analogues of well-known Fibonacci identities for generalized numbers\nare obtained. We gained a new identity of product convolution of generalized\nFibonacci and Lucas numbers. We wrote down generating functions of generalized\nFibonacci and Lucas numbers products, their multisections, harmonic numbers and\nCatalan numbers.", "journal": ""}
{"doi": "10.48550/arXiv.2408.01832", "date": "2024-08-03", "title": "Lattice paths and quiver generating series with higher level generators", "authors": "Du\u0161an \u0110or\u0111evi\u0107, Marko Sto\u0161i\u0107", "abstract": "The generalized knots-quivers correspondence extends the original\nknots-quivers correspondence, by allowing higher level generators of quiver\ngenerating series. In this paper we explore the underlined combinatorics of\nsuch generating series, relationship with the BPS numbers of a corresponding\nknot, and new combinatorial interpretations of the coefficients of generating\nseries.", "journal": ""}
{"doi": "10.48550/arXiv.1701.03870", "date": "2017-01-14", "title": "A representation theorem for generators of BSDEs with general growth generators in $y$ and its applications", "authors": "Lishun Xiao, Shengjun Fan", "abstract": "In this paper we first prove a general representation theorem for generators\nof backward stochastic differential equations (BSDEs for short) by utilizing a\nlocalization method involved with stopping time tools and approximation\ntechniques, where the generators only need to satisfy a weak monotonicity\ncondition and a general growth condition in $y$ and a Lipschitz condition in\n$z$. This result basically solves the problem of representation theorems for\ngenerators of BSDEs with general growth generators in $y$. Then, such\nrepresentation theorem is adopted to prove a probabilistic formula, in\nviscosity sense, of semilinear parabolic PDEs of second order. The\nrepresentation theorem approach seems to be a potential tool to the research of\nviscosity solutions of PDEs.", "journal": ""}
{"doi": "10.48550/arXiv.2101.04283", "date": "2021-01-12", "title": "A Brief Survey of Associations Between Meta-Learning and General AI", "authors": "Huimin Peng", "abstract": "This paper briefly reviews the history of meta-learning and describes its\ncontribution to general AI. Meta-learning improves model generalization\ncapacity and devises general algorithms applicable to both in-distribution and\nout-of-distribution tasks potentially. General AI replaces task-specific models\nwith general algorithmic systems introducing higher level of automation in\nsolving diverse tasks using AI. We summarize main contributions of\nmeta-learning to the developments in general AI, including memory module,\nmeta-learner, coevolution, curiosity, forgetting and AI-generating algorithm.\nWe present connections between meta-learning and general AI and discuss how\nmeta-learning can be used to formulate general AI algorithms.", "journal": ""}
{"doi": "10.48550/arXiv.2304.12895", "date": "2023-04-25", "title": "Discovering Graph Generation Algorithms", "authors": "Mihai Babiac, Karolis Martinkus, Roger Wattenhofer", "abstract": "We provide a novel approach to construct generative models for graphs.\nInstead of using the traditional probabilistic models or deep generative\nmodels, we propose to instead find an algorithm that generates the data. We\nachieve this using evolutionary search and a powerful fitness function,\nimplemented by a randomly initialized graph neural network. This brings certain\nadvantages over current deep generative models, for instance, a higher\npotential for out-of-training-distribution generalization and direct\ninterpretability, as the final graph generative process is expressed as a\nPython function. We show that this approach can be competitive with deep\ngenerative models and under some circumstances can even find the true graph\ngenerative process, and as such perfectly generalize.", "journal": ""}
{"doi": "10.48550/arXiv.2403.09711", "date": "2024-03-10", "title": "Two-dimensional generalized gamma function and its applications", "authors": "Artem M. Ponomarenko", "abstract": "In this article, we present a new two-dimensional generalization of the gamma\nfunction based on the product of the one-dimensional generalized beta function\nand the one-dimensional generalized gamma function. As will become clear later,\nthis generalization is also a generalization the famous formula that gives the\nconnection between the classical gamma and beta functions. Next we present\nproperties of this generalization, some series for the generalized beta\nfunction. As a practical application of the two-dimensional generalized gamma\nfunction, we will show how it can be used to represent a fairly wide class of\ndouble integrals in the form of functional series.", "journal": ""}
{"doi": "10.48550/arXiv.2411.00443", "date": "2024-11-01", "title": "Spinor bilinears and Killing-Yano forms in generalized geometry", "authors": "\u00d6zg\u00fcr A\u00e7\u0131k, \u00dcmit Ertem, \u00d6zg\u00fcr Kelek\u00e7i", "abstract": "Spinor bilinears of generalized spinors and their properties are\ninvestigated. Generalized Killing and twistor spinor equations are considered\nand their relations to the equations satisfied by special types of differential\nforms are found. Killing equation in generalized geometry is written in terms\nof the generalized covariant derivative and Killing-Yano forms are described in\nthe framework of generalized geometry. Construction of generalized Killing-Yano\nforms and generalized closed conformal Killing-Yano forms in terms of the\nspinor bilinears of generalized Killing spinors are determined.", "journal": ""}
{"doi": "10.48550/arXiv.0404126", "date": "2004-04-06", "title": "Simply Generated Trees, B-series and Wigner Processes", "authors": "Christian Mazza", "abstract": "We consider simply generated trees and study multiplicative functions on\nrooted plane trees. We show that the associated generating functions satisfy\ndifferential equations or difference equations. Our approach considers B-series\nfrom Butcher's theory, the generating functions are seen as generalized\nRunge-Kutta methods", "journal": ""}
{"doi": "10.48550/arXiv.0704.3744", "date": "2007-04-27", "title": "The General Form Of Cyclic Orthonormal Generators In R^N", "authors": "Kerry M. Soileau", "abstract": "In this paper we give a definition of cyclic orthonormal generators (cogs) in\nR^N. We give a general canonical form for their expression. Further, we give an\nexplicit formula for computing the canonical form of any given cog.", "journal": ""}
{"doi": "10.48550/arXiv.1611.01435", "date": "2016-11-04", "title": "A modified Belinfante/Rosenfeld Procedure for Testing the Compatibility of General-Covariant Continuum Physics and General Relativity Theory", "authors": "Wolfgang Muschik", "abstract": "Creating a modified Belinfante/Rosenfeld procedure, Mathisson-Papapetrou-like\nequations are derived by which a comparison of General-Covariant Continuum\nPhysics with General Relativity Theory becomes possible.", "journal": ""}
{"doi": "10.48550/arXiv.1909.06577", "date": "2019-09-14", "title": "On Generalization of Some Inequalities of Chebyshevs Functional Using Generalized Katugampola Fractional Integral", "authors": "Tariq A. Al-Jaaidi, Deepak B. Pachpatte", "abstract": "In this paper we obtain a generalization of some integral inequalities\nrelated to Chebyshev`s functional by using a generalized Katugampola fractional\nintegral.", "journal": ""}
{"doi": "10.48550/arXiv.2003.11530", "date": "2020-03-12", "title": "Meta-CoTGAN: A Meta Cooperative Training Paradigm for Improving Adversarial Text Generation", "authors": "Haiyan Yin, Dingcheng Li, Xu Li, Ping Li", "abstract": "Training generative models that can generate high-quality text with\nsufficient diversity is an important open problem for Natural Language\nGeneration (NLG) community. Recently, generative adversarial models have been\napplied extensively on text generation tasks, where the adversarially trained\ngenerators alleviate the exposure bias experienced by conventional maximum\nlikelihood approaches and result in promising generation quality. However, due\nto the notorious defect of mode collapse for adversarial training, the\nadversarially trained generators face a quality-diversity trade-off, i.e., the\ngenerator models tend to sacrifice generation diversity severely for increasing\ngeneration quality. In this paper, we propose a novel approach which aims to\nimprove the performance of adversarial text generation via efficiently\ndecelerating mode collapse of the adversarial training. To this end, we\nintroduce a cooperative training paradigm, where a language model is\ncooperatively trained with the generator and we utilize the language model to\nefficiently shape the data distribution of the generator against mode collapse.\nMoreover, instead of engaging the cooperative update for the generator in a\nprincipled way, we formulate a meta learning mechanism, where the cooperative\nupdate to the generator serves as a high level meta task, with an intuition of\nensuring the parameters of the generator after the adversarial update would\nstay resistant against mode collapse. In the experiment, we demonstrate our\nproposed approach can efficiently slow down the pace of mode collapse for the\nadversarial text generators. Overall, our proposed method is able to outperform\nthe baseline approaches with significant margins in terms of both generation\nquality and diversity in the testified domains.", "journal": ""}
{"doi": "10.48550/arXiv.2208.12575", "date": "2022-08-20", "title": "Perov type T-contractive Mappings on Cone b-Metric Spaces with Generalized c-Distance", "authors": "Talat Nazir, Mujahid Abbas, Sergei Silvestrov", "abstract": "Fixed point results of Perov type mapping which satisfy generalized\nTcontractive conditions in the setup of cone b-metric spaces associated with\ngeneralized c-distance are proved and illustrated by nontrivial examples.", "journal": ""}
{"doi": "10.48550/arXiv.2303.14777", "date": "2023-03-26", "title": "Query Generation based on Generative Adversarial Networks", "authors": "Weihua Sun, Run-An Wang, Zhaonian Zou", "abstract": "Many problems in database systems, such as cardinality estimation, database\ntesting and optimizer tuning, require a large query load as data. However, it\nis often difficult to obtain a large number of real queries from users due to\nuser privacy restrictions or low frequency of database access. Query generation\nis one of the approaches to solve this problem. Existing query generation\nmethods, such as random generation and template-based generation, do not\nconsider the relationship between the generated queries and existing queries,\nor even generate semantically incorrect queries. In this paper, we propose a\nquery generation framework based on generative adversarial networks (GAN) to\ngenerate query load that is similar to the given query load. In our framework,\nwe use a syntax parser to transform the query into a parse tree and traverse\nthe tree to obtain the sequence of production rules corresponding to the query.\nThe generator of GAN takes a fixed distribution prior as input and outputs the\nquery sequence, and the discriminator takes the real query and the fake query\ngenerated by the generator as input and outputs a gradient to guide the\ngenerator learning. In addition, we add context-free grammar and semantic rules\nto the generation process, which ensures that the generated queries are\nsyntactically and semantically correct. We conduct experiments to evaluate our\napproach on real-world dataset, which show that our approach can generate new\nquery loads with a similar distribution to a given query load, and that the\ngenerated queries are syntactically correct with no semantic errors. The\ngenerated query loads are used in downstream task, and the results show a\nsignificant improvement in the models trained with the expanded query loads\nusing our approach.", "journal": ""}
{"doi": "10.48550/arXiv.2310.02577", "date": "2023-10-04", "title": "Generalized torsion orders of generalized torsion elements", "authors": "Tetsuya Ito", "abstract": "A non-trivial element of a group is a generalized torsion element if some\nproducts of its conjugates is the identity. The minimum number of such\nconjugates is called a generalized torsion order. We provide several\nrestrictions for generalized torsion orders by using $G$-invariant norm and\nAlexander polynomials.", "journal": ""}
{"doi": "10.48550/arXiv.2311.05805", "date": "2023-11-10", "title": "Ideals of generic forms", "authors": "Ralf Froberg", "abstract": "We determine the Hilbert series of some classes of ideals generated by\ngeneric forms of degree two and three, and investigate the difference to the\nHilbert series of ideals generated by powers of linear generic forms of the\ncorresponding degrees.", "journal": ""}
{"doi": "10.48550/arXiv.2501.17426", "date": "2025-01-29", "title": "On finite generating sets of infinitely generated ideals", "authors": "Takafumi Shibuta", "abstract": "This paper presents a novel approach to constructing finite generating sets\nfor infinitely generated ideals. By integrating algebraic and computational\ntechniques, we provide a method to identify finite generators, demonstrated\nthrough illustrative examples.", "journal": ""}
{"doi": "10.48550/arXiv.1607.05387", "date": "2016-07-19", "title": "Generating Images Part by Part with Composite Generative Adversarial Networks", "authors": "Hanock Kwak, Byoung-Tak Zhang", "abstract": "Image generation remains a fundamental problem in artificial intelligence in\ngeneral and deep learning in specific. The generative adversarial network (GAN)\nwas successful in generating high quality samples of natural images. We propose\na model called composite generative adversarial network, that reveals the\ncomplex structure of images with multiple generators in which each generator\ngenerates some part of the image. Those parts are combined by alpha blending\nprocess to create a new single image. It can generate, for example, background\nand face sequentially with two generators, after training on face dataset.\nTraining was done in an unsupervised way without any labels about what each\ngenerator should generate. We found possibilities of learning the structure by\nusing this generative model empirically.", "journal": ""}
{"doi": "10.48550/arXiv.2407.04493", "date": "2024-07-05", "title": "PROUD: PaRetO-gUided Diffusion Model for Multi-objective Generation", "authors": "Yinghua Yao, Yuangang Pan, Jing Li, Ivor Tsang, Xin Yao", "abstract": "Recent advancements in the realm of deep generative models focus on\ngenerating samples that satisfy multiple desired properties. However, prevalent\napproaches optimize these property functions independently, thus omitting the\ntrade-offs among them. In addition, the property optimization is often\nimproperly integrated into the generative models, resulting in an unnecessary\ncompromise on generation quality (i.e., the quality of generated samples). To\naddress these issues, we formulate a constrained optimization problem. It seeks\nto optimize generation quality while ensuring that generated samples reside at\nthe Pareto front of multiple property objectives. Such a formulation enables\nthe generation of samples that cannot be further improved simultaneously on the\nconflicting property functions and preserves good quality of generated samples.\nBuilding upon this formulation, we introduce the PaRetO-gUided Diffusion model\n(PROUD), wherein the gradients in the denoising process are dynamically\nadjusted to enhance generation quality while the generated samples adhere to\nPareto optimality. Experimental evaluations on image generation and protein\ngeneration tasks demonstrate that our PROUD consistently maintains superior\ngeneration quality while approaching Pareto optimality across multiple property\nfunctions compared to various baselines.", "journal": "Machine Learning 2024"}
{"doi": "10.48550/arXiv.2410.20587", "date": "2024-10-27", "title": "Generator Matching: Generative modeling with arbitrary Markov processes", "authors": "Peter Holderrieth, Marton Havasi, Jason Yim, Neta Shaul, Itai Gat, Tommi Jaakkola, Brian Karrer, Ricky T. Q. Chen, Yaron Lipman", "abstract": "We introduce Generator Matching, a modality-agnostic framework for generative\nmodeling using arbitrary Markov processes. Generators characterize the\ninfinitesimal evolution of a Markov process, which we leverage for generative\nmodeling in a similar vein to flow matching: we construct conditional\ngenerators which generate single data points, then learn to approximate the\nmarginal generator which generates the full data distribution. We show that\nGenerator Matching unifies various generative modeling methods, including\ndiffusion models, flow matching and discrete diffusion models. Furthermore, it\nexpands the design space to new and unexplored Markov processes such as jump\nprocesses. Finally, Generator Matching enables the construction of\nsuperpositions of Markov generative models and enables the construction of\nmultimodal models in a rigorous manner. We empirically validate our method on\nimage and multimodal generation, e.g. showing that superposition with a jump\nprocess improves performance.", "journal": ""}
{"doi": "10.48550/arXiv.2106.03102", "date": "2021-06-06", "title": "On the Dual of Generalized Bent Functions", "authors": "Jiaxin Wang, Fang-Wei Fu", "abstract": "In this paper, we study the dual of generalized bent functions $f:\nV_{n}\\rightarrow \\mathbb{Z}_{p^k}$ where $V_{n}$ is an $n$-dimensional vector\nspace over $\\mathbb{F}_{p}$ and $p$ is an odd prime, $k$ is a positive integer.\nIt is known that weakly regular generalized bent functions always appear in\npairs since the dual of a weakly regular generalized bent function is also a\nweakly regular generalized bent function. The dual of non-weakly regular\ngeneralized bent functions can be generalized bent or not generalized bent. By\ngeneralizing the construction of \\cite{Cesmelioglu5}, we obtain an explicit\nconstruction of generalized bent functions for which the dual can be\ngeneralized bent or not generalized bent. We show that the generalized indirect\nsum construction method given in \\cite{Wang} can provide a secondary\nconstruction of generalized bent functions for which the dual can be\ngeneralized bent or not generalized bent. By using the knowledge on ideal\ndecomposition in cyclotomic field, we prove that $f^{**}(x)=f(-x)$ if $f$ is a\ngeneralized bent function and its dual $f^{*}$ is also a generalized bent\nfunction. For any non-weakly regular generalized bent function $f$ which\nsatisfies that $f(x)=f(-x)$ and its dual $f^{*}$ is generalized bent, we give a\nproperty and as a consequence, we prove that there is no self-dual generalized\nbent function $f: V_{n}\\rightarrow \\mathbb{Z}_{p^k}$ if $p\\equiv 3 \\ (mod \\ 4)$\nand $n$ is odd. For $p \\equiv 1 \\ (mod \\ 4)$ or $p\\equiv 3 \\ (mod \\ 4)$ and $n$\nis even, we give a secondary construction of self-dual generalized bent\nfunctions. In the end, we characterize the relations between the generalized\nbentness of the dual of generalized bent functions and the bentness of the dual\nof bent functions, as well as the self-duality relations between generalized\nbent functions and bent functions by the decomposition of generalized bent\nfunctions.", "journal": ""}
{"doi": "10.48550/arXiv.9912217", "date": "1999-12-28", "title": "Group analysis of differential equations and generalized functions", "authors": "Michael Kunzinger, Michael Oberguggenberger", "abstract": "We present an extension of the methods of classical Lie group analysis of\ndifferential equations to equations involving generalized functions (in\nparticular: distributions). A suitable framework for such a generalization is\nprovided by Colombeau's theory of algebras of generalized functions. We show\nthat under some mild conditions on the differential equations, symmetries of\nclassical solutions remain symmetries for generalized solutions. Moreover, we\nintroduce a generalization of the infinitesimal methods of group analysis that\nallows to compute symmetries of linear and nonlinear differential equations\ncontaining generalized function terms. Thereby, the group generators and group\nactions may be given by generalized functions themselves.", "journal": "SIAM J. Math. Anal. 31 (2000) no. 6, 1192-1213."}
{"doi": "10.48550/arXiv.0008105", "date": "2000-08-15", "title": "Generalized Lie bialgebroids and Jacobi structures", "authors": "David Iglesias, Juan C. Marrero", "abstract": "The notion of a generalized Lie bialgebroid (a generalization of the notion\nof a Lie bialgebroid) is introduced in such a way that a Jacobi manifold has\nassociated a canonical generalized Lie bialgebroid. As a kind of converse, we\nprove that a Jacobi structure can be defined on the base space of a generalized\nLie bialgebroid. We also show that it is possible to construct a Lie\nbialgebroid from a generalized Lie bialgebroid and, as a consequence, we deduce\na duality theorem. Finally, some special classes of generalized Lie\nbialgebroids are considered: triangular generalized Lie bialgebroids and\ngeneralized Lie bialgebras.", "journal": ""}
{"doi": "10.48550/arXiv.0107057", "date": "2001-07-07", "title": "Generalized pseudo-Riemannian geometry", "authors": "Michael Kunzinger, Roland Steinbauer", "abstract": "Generalized tensor analysis in the sense of Colombeau's construction is\nemployed to introduce a nonlinear distributional pseudo-Riemannian geometry. In\nparticular, after deriving several characterizations of invertibility in the\nalgebra of generalized functions we define the notions of generalized\npseudo-Riemannian metric, generalized connection and generalized curvature\ntensor. We prove a ``Fundamental Lemma of (pseudo-)Riemannian geometry'' in\nthis setting and define the notion of geodesics of a generalized metric.\nFinally, we present applications of the resulting theory to general relativity.", "journal": "Trans. Amer. Math. Soc. 354 (2002), no. 10, 4179-4199"}
{"doi": "10.48550/arXiv.0606386", "date": "2006-06-16", "title": "Pieri's Formula for Generalized Schur Polynomials", "authors": "Yasuhide Numata", "abstract": "Young's lattice, the lattice of all Young diagrams, has the\nRobinson-Schensted-Knuth correspondence, the correspondence between certain\nmatrices and pairs of semi-standard Young tableaux with the same shape. Fomin\nintroduced generalized Schur operators to generalize the\nRobinson-Schensted-Knuth correspondence. In this sense, generalized Schur\noperators are generalizations of semi-standard Young tableaux. We define a\ngeneralization of Schur polynomials as expansion coefficients of generalized\nSchur operators. We show that the commutating relation of generalized Schur\noperators implies Pieri's formula to generalized Schur polynomials.", "journal": "J. Algebraic Combin. 26 (2007), no. 1, 27-45"}
{"doi": "10.48550/arXiv.0604060", "date": "2006-04-25", "title": "Generalized forms and vector fields", "authors": "Saikat Chatterjee, Amitabha Lahiri, Partha Guha", "abstract": "The generalized vector is defined on an $n$ dimensional manifold. Interior\nproduct, Lie derivative acting on generalized $p$-forms, $-1\\le p\\le n$ are\nintroduced. Generalized commutator of two generalized vectors are defined.\nAdding a correction term to Cartan's formula the generalized Lie derivative's\naction on a generalized vector field is defined. We explore various identities\nof the generalized Lie derivative with respect to generalized vector fields,\nand discuss an application.", "journal": "J. Phys. A: Math. Gen. 39 (2006) 15435"}
{"doi": "10.48550/arXiv.0804.2908", "date": "2008-04-17", "title": "On Finitely Generated Models of Theories with at Most Countably Many Nonisomorphic Finitely Generated Models", "authors": "Abderezak Ould Houcine", "abstract": "We study finitely generated models of countable theories, having at most\ncountably many nonisomorphic finitely generated models. We intro- duce a notion\nof rank of finitely generated models and we prove, when T has at most countably\nmany nonisomorphic finitely generated models, that every finitely generated\nmodel has an ordinal rank. This rank is used to give a prop- erty of finitely\ngenerated models analogue to the Hopf property of groups and also to give a\nnecessary and sufficient condition for a finitely generated model to be prime\nof its complete theory. We investigate some properties of limit groups of\nequationally noetherian groups, in respect to their ranks.", "journal": ""}
{"doi": "10.48550/arXiv.0909.2720", "date": "2009-09-15", "title": "Generalized fractional hybrid Hamilton Pontryagin equations", "authors": "Chis Oana, Opris Dumitru", "abstract": "In this work we present a new approach on studying dynamical systems.\nCombining the two ways of expressing the uncertainty, using probabilistic\ntheory and credibility theory, we have research the generalized fractional\nhybrid equations. We have introduced the concepts of generalized fractional\nWiener process, generalized fractional Liu process and the combination between\nthose two, generalized fractional hybrid process. Corresponding generalized\nfractional stochastic, respectively fuzzy, respectively hybrid dynamical\nsystems were defined. We applied the theory for generalized fractional hybrid\nHamilton-Pontryagin (HP) equation, generalized fractional Hamiltonian\nequations. From the general fractional hybrid Hamiltonian equations, fractional\nLangevin equations were found and numerical simulations were done.", "journal": ""}
{"doi": "10.48550/arXiv.1701.04032", "date": "2017-01-15", "title": "Generalized metrics and generalized twistor spaces", "authors": "Johann Davidov", "abstract": "The twistor construction for Riemannian manifolds is extended to the case of\nmanifolds endowed with generalized metrics (in the sense of generalized\ngeometry \\`a la Hitchin). The generalized twistor space associated to such a\nmanifold is defined as the bundle of generalized complex structures on the\ntangent spaces of the manifold compatible with the given generalized metric.\nThis space admits natural generalized almost complex structures whose\nintegrability conditions are found in the paper. An interesting feature of the\ngeneralized twistor spaces discussed in it is the existence of intrinsic\nisomorphisms.", "journal": ""}
{"doi": "10.48550/arXiv.1210.0039", "date": "2012-09-28", "title": "Generalizations and specializations of generating functions for Jacobi, Gegenbauer, Chebyshev and Legendre polynomials with definite integrals", "authors": "Howard Cohl, Connor MacKenzie", "abstract": "In this paper we generalize and specialize generating functions for classical\northogonal polynomials, namely Jacobi, Gegenbauer, Chebyshev and Legendre\npolynomials. We derive a generalization of the generating function for\nGegenbauer polynomials through extension a two element sequence of generating\nfunctions for Jacobi polynomials. Specializations of generating functions are\naccomplished through the re-expression of Gauss hypergeometric functions in\nterms of less general functions. Definite integrals which correspond to the\npresented orthogonal polynomial series expansions are also given.", "journal": ""}
{"doi": "10.48550/arXiv.2202.01110", "date": "2022-02-02", "title": "A Survey on Retrieval-Augmented Text Generation", "authors": "Huayang Li, Yixuan Su, Deng Cai, Yan Wang, Lemao Liu", "abstract": "Recently, retrieval-augmented text generation attracted increasing attention\nof the computational linguistics community. Compared with conventional\ngeneration models, retrieval-augmented text generation has remarkable\nadvantages and particularly has achieved state-of-the-art performance in many\nNLP tasks. This paper aims to conduct a survey about retrieval-augmented text\ngeneration. It firstly highlights the generic paradigm of retrieval-augmented\ngeneration, and then it reviews notable approaches according to different tasks\nincluding dialogue response generation, machine translation, and other\ngeneration tasks. Finally, it points out some important directions on top of\nrecent methods to facilitate future research.", "journal": ""}
{"doi": "10.48550/arXiv.1609.09219", "date": "2016-09-29", "title": "Time/memory/data trade-off attack to a psuedo-random generator", "authors": "Behrooz Khadem, Ali Madadi", "abstract": "Time, data and memory trade off attack is one of the most important threats\nagainst pseudo- random generators and resisting against it, is considered as a\nmain criteria of designing such generators. In this research, the pseudo-random\nGMGK generator will be addressed and analyzed in details. Having indicated\nvarious weaknesses of this generator, we performed three different versions of\nstructural attack on this generator and showed that proposed TMDTO attacks to\nthis generator can discover blocks of plaintext with lower complexity than\nexhaustive search of space of key generator. Results indicated that the\nmentioned generator is lack of the security claimed by authors.", "journal": "Journal of Computational and Theoretical Nanoscience (2018)"}
{"doi": "10.48550/arXiv.2005.05101", "date": "2020-05-11", "title": "Generalized Univariate Distributions and a New Asymmetric Laplace Model", "authors": "Palash Sharma", "abstract": "This work provides a survey of the general class of distributions generated\nfrom the mixture of the beta random variables. We provide an extensive review\nof the literature, concerning generating new distributions via the inverse CDF\ntransformation. In particular, we accounted for beta generated and Kumaraswamy\ngenerated families of distributions. We provide a brief summary of each of\ntheir families of distributions. We also propose a new asymmetric mixture\ndistribution, which is an alternative to beta generated distributions. We\nprovide basic properties of this new class of distributions generated from the\nLaplace model. We also address the issue of parameter estimation of this new\nskew generalized Laplace model.", "journal": ""}
{"doi": "10.48550/arXiv.2110.02061", "date": "2021-09-29", "title": "General Canonical Quantum Gravity Theory and that of the Universe and General Black Hole", "authors": "C. Huang, Yong-Chang Huang, Xinfei Li", "abstract": "This paper gives both a general canonical quantum gravity theory and the\ngeneral canonical quantum gravity theories of the Universe and general black\nhole, and discovers the relations reflecting symmetric properties of the\nstandard nonlinear gravitational Lagrangian, which are not relevant to any\nconcrete metric models. This paper concretely shows the general commutation\nrelations of the general gravitational field operators and their zeroth, first,\nsecond and third style, respectively, of high order canonical momentum\noperators for the general nonlinear system of the standard gravitational\nLagrangian, and then has finished all the four styles of the canonical\nquantization of the standard gravity.", "journal": ""}
{"doi": "10.48550/arXiv.2112.12075", "date": "2021-12-17", "title": "Generalized q-difference equations for general q-polynomials with double q-binomial coefficients", "authors": "Jian Cao, Sama Arjika, Mahouton Norbert Hounkonnou", "abstract": "In this paper, we use the generalized q-polynomials with double q-binomial\ncoefficients and homogeneous q-operators [J. Difference Equ. Appl. 20 (2014),\n837--851.] to construct q-difference equations with seven variables, which\ngeneralize recent works of Jia et al [Symmetry 2021, 13, 1222.]. In addition,\nwe derive Rogers formulas, extended Rogers formulas and Srivastava--Agarwal\ntype bilinear generating functions for generalized q-polynomials, which\ngeneralize generating functions for Cigler's polynomials [J. Difference Equ.\nAppl. 24 (2018), 479--502.]. Finally, we also derive mixed generating functions\nusing q-difference equations.", "journal": ""}
{"doi": "10.48550/arXiv.2206.11219", "date": "2022-06-22", "title": "Understanding the Properties of Generated Corpora", "authors": "Naama Zwerdling, Segev Shlomov, Esther Goldbraich, George Kour, Boaz Carmeli, Naama Tepper, Inbal Ronen, Vitaly Zabershinsky, Ateret Anaby-Tavor", "abstract": "Models for text generation have become focal for many research tasks and\nespecially for the generation of sentence corpora. However, understanding the\nproperties of an automatically generated text corpus remains challenging. We\npropose a set of tools that examine the properties of generated text corpora.\nApplying these tools on various generated corpora allowed us to gain new\ninsights into the properties of the generative models. As part of our\ncharacterization process, we found remarkable differences in the corpora\ngenerated by two leading generative technologies.", "journal": ""}
{"doi": "10.48550/arXiv.2207.09317", "date": "2022-07-19", "title": "Generalized projections on general Banach spaces", "authors": "Akhtar A. Khan, Jinlu Li, Simeon Reich", "abstract": "In general Banach spaces, the metric projection map lacks the powerful\nproperties it enjoys in Hilbert spaces. There are a few generalized projections\nthat have been proposed in order to resolve many of the deficiencies of the\nmetric projection. However, such notions are predominantly studied in Banach\nspaces with rich topological structures, such as uniformly convex Banach\nspaces. In this paper, we investigate two notions of generalized projection in\ngeneral Banach spaces. Various examples are provided to demonstrate the\nproposed notions and the loss of structure in the generalized projections after\nmigrating from specially structured Banach spaces to general Banach spaces.\nConnections between the generalized projection and the metric projection are\nthoroughly explored.", "journal": ""}
{"doi": "10.48550/arXiv.2303.17153", "date": "2023-03-30", "title": "Understanding the limit sets generated by general iterated function systems on unbounded spaces", "authors": "Kanji Inui", "abstract": "In this paper, we reformulate the definition of the iterated function systems\n(denoted by general IFSs in this paper) and show the existence and uniqueness\n(in some sense) of the limit sets generated by the general IFSs, to unify the\ndefinitions of the limit sets introduced before. Note that the general IFSs are\ndefined on (possibly unbounded) complete metric spaces and we instead assume a\n``natural\" condition of general IFSs to show the main result. To obtain the\nmain result, we apply techniques in the Banach fixed point theorem to the\ngeneral IFSs with the ``natural\" condition. Besides, we consider an example of\ngeneral IFSs.", "journal": ""}
{"doi": "10.48550/arXiv.2305.00372", "date": "2023-04-30", "title": "The core compactly generated topology", "authors": "Qingguo Li, Hualin Miao", "abstract": "M. Escard\\'o et al. asked whether the core compactly generated topology of a\nsober space is again sober and the sobrification of a core compactly generated\nspace again core compactly generated. In this note, we answer the problem by\ndisplaying a counterexample, which reveals that the core compactly generated\nspaces are not closed under sobrifications. Meantime, we obtain that the core\ncompactly generated spaces are closed under {\\omega}-well-filterifications and\nD-completions. Furthermore, we find that the core compactly generated topology\nof the Smyth power space of a well-filtered space coincides with the Scott\ntopology. Finally, we provide a characterization for the core-compactness of\ncore compactly generated spaces.", "journal": ""}
{"doi": "10.48550/arXiv.2401.11477", "date": "2024-01-21", "title": "Some properties of generalized cluster algebras of geometric types", "authors": "Junyuan Huang, Xueqing Chen, Fan Xu, Ming Ding", "abstract": "We study the lower bound algebras generated by the generalized projective\ncluster variables of acyclic generalized cluster algebras of geometric types.\nWe prove that this lower bound algebra coincides with the corresponding\ngeneralized cluster algebra under the coprimality condition. As a corollary, we\nobtain the dual PBW bases of these generalized cluster algebras. Moreover, we\nshow that if the standard monomials of a generalized cluster algebra of\ngeometric type are linearly independent, then the directed graph associated to\nthe initial generalized seed of this generalized cluster algebra does not have\n3-cycles.", "journal": ""}
{"doi": "10.48550/arXiv.2411.05495", "date": "2024-11-08", "title": "Generating Cofaces in Vietoris--Rips Filtration Order", "authors": "Ulrich Bauer, Jordan Matuszewski, Mikael Vejdemo-Johansson", "abstract": "Cofaces -- simplices that contain a given simplex -- have multiple important\nuses in generating and using a Vietoris-Rips filtration: both in creating the\ncoboundary matrix for computing persistent cohomology, and for generating the\nordered sequence of simplices in the first place. Traditionally, most methods\nhave generated simplices first, and then sorted them in filtration order after\nthe generation step. In this paper, we propose fast algorithms for generating\nthe sequence of simplices by generating cofaces of a given simplex with the\nsame diameter, which by construction produces simplices in filtration order,\nand for generating additional cofaces in filtration order using sorted\nneighborhood lists in order to generate coboundaries directly in filtration\norder.", "journal": ""}
{"doi": "10.48550/arXiv.1502.07046", "date": "2015-02-25", "title": "Generalized CoK\u00e4hler Geometry and an Application to Generalized K\u00e4hler Structures", "authors": "Ralph R. Gomez, Janet Talvacchia", "abstract": "In this paper we define the notion of a generalized coK\\\"ahler structure and\nprove that the product $M_{1}\\times M_{2}$ of generalized contact metric\nmanifolds $(M_i, \\Phi_i,E_{\\pm,i}, G_i)$, $ i=1, 2$, where $M_{1}\\times M_{2}$\nis endowed with the product generalized complex structure induced from $\\Phi_1$\nand $\\Phi_2$, is generalized K\\\"ahler if and only if $(M_i, \\Phi_i, E_{\\pm,i},\nG_i) ,\\ \\ i=1,2$ are generalized coK\\\"ahler structures. We also prove that\nproducts of generalized coK\\\"ahler and generalized K\\\"ahler manifolds admit a\ngeneralized coK\\\"ahler structure. We use these product constructions to give\nnontrivial examples of generalized coK\\\"ahler structures. Finally, we show the\nanalogs of these theorems hold in the setting of twisted generalized\ngeometries. We use these theorems to construct new examples of twisted\ngeneralized K\\\"ahler structures on manifolds that do not admit a classical\nK\\\"ahler structure and we give examples of twisted generalized coK\\\"ahler\nstructures on manifolds which do not admit a classical coK\\\"ahler structure.", "journal": ""}
{"doi": "10.48550/arXiv.1612.08190", "date": "2016-12-24", "title": "Scalar curvature as moment map in generalized Kahler geometry", "authors": "Ryushi Goto", "abstract": "It is known that the scalar curvature arises as the moment map in Kahler\ngeometry. In pursuit of this analogy, we introduce the notion of a moment map\nin generalized Kahler geometry which gives the definition of a generalized\nscalar curvature on a generalized Kahler manifold. From the viewpoint of the\nmoment map, we obtain the generalized Ricci form which is a representative of\nthe first Chern class of the anticanonical line bundle. It turns out that\ninfinitesimal deformations of generalized Kahler structures with constant\ngeneralized scalar curvature are finite dimensional on a compact manifold.\nExplicit descriptions of the generalized Ricci form and the generalized scalar\ncurvature are given on a generalized Kahler manifold of type $(0,0)$. Poisson\nstructures constructed from a Kahler action of $T^m$ on a Kahler-Einstein\nmanifold give intriguing deformations of generalized Kahler-Einstein\nstructures. In particular, the anticanical divisor consists of three lines on\n$C P^2$ in general position yields nontrivial examples of generalized\nKahler-Einsein structures", "journal": "J. Symplectic Geom. 18 (2020), no. 1, 147-190"}
{"doi": "10.48550/arXiv.1705.02887", "date": "2017-05-08", "title": "Generative Cooperative Net for Image Generation and Data Augmentation", "authors": "Qiangeng Xu, Zengchang Qin, Tao Wan", "abstract": "How to build a good model for image generation given an abstract concept is a\nfundamental problem in computer vision. In this paper, we explore a generative\nmodel for the task of generating unseen images with desired features. We\npropose the Generative Cooperative Net (GCN) for image generation. The idea is\nsimilar to generative adversarial networks except that the generators and\ndiscriminators are trained to work accordingly. Our experiments on hand-written\ndigit generation and facial expression generation show that GCN's two\ncooperative counterparts (the generator and the classifier) can work together\nnicely and achieve promising results. We also discovered a usage of such\ngenerative model as an data-augmentation tool. Our experiment of applying this\nmethod on a recognition task shows that it is very effective comparing to other\nexisting methods. It is easy to set up and could help generate a very large\nsynthesized dataset.", "journal": "The International Symposium on Integrated Uncertainty in Knowledge\n  Modelling and Decision Making (IUKM) 2019"}
{"doi": "10.48550/arXiv.1809.05296", "date": "2018-09-14", "title": "Skeleton-to-Response: Dialogue Generation Guided by Retrieval Memory", "authors": "Deng Cai, Yan Wang, Victoria Bi, Zhaopeng Tu, Xiaojiang Liu, Wai Lam, Shuming Shi", "abstract": "For dialogue response generation, traditional generative models generate\nresponses solely from input queries. Such models rely on insufficient\ninformation for generating a specific response since a certain query could be\nanswered in multiple ways. Consequentially, those models tend to output generic\nand dull responses, impeding the generation of informative utterances.\nRecently, researchers have attempted to fill the information gap by exploiting\ninformation retrieval techniques. When generating a response for a current\nquery, similar dialogues retrieved from the entire training data are considered\nas an additional knowledge source. While this may harvest massive information,\nthe generative models could be overwhelmed, leading to undesirable performance.\nIn this paper, we propose a new framework which exploits retrieval results via\na skeleton-then-response paradigm. At first, a skeleton is generated by\nrevising the retrieved responses. Then, a novel generative model uses both the\ngenerated skeleton and the original query for response generation. Experimental\nresults show that our approaches significantly improve the diversity and\ninformativeness of the generated responses.", "journal": ""}
{"doi": "10.48550/arXiv.2105.02544", "date": "2021-05-06", "title": "SGG: Learning to Select, Guide, and Generate for Keyphrase Generation", "authors": "Jing Zhao, Junwei Bao, Yifan Wang, Youzheng Wu, Xiaodong He, Bowen Zhou", "abstract": "Keyphrases, that concisely summarize the high-level topics discussed in a\ndocument, can be categorized into present keyphrase which explicitly appears in\nthe source text, and absent keyphrase which does not match any contiguous\nsubsequence but is highly semantically related to the source. Most existing\nkeyphrase generation approaches synchronously generate present and absent\nkeyphrases without explicitly distinguishing these two categories. In this\npaper, a Select-Guide-Generate (SGG) approach is proposed to deal with present\nand absent keyphrase generation separately with different mechanisms.\nSpecifically, SGG is a hierarchical neural network which consists of a\npointing-based selector at low layer concentrated on present keyphrase\ngeneration, a selection-guided generator at high layer dedicated to absent\nkeyphrase generation, and a guider in the middle to transfer information from\nselector to generator. Experimental results on four keyphrase generation\nbenchmarks demonstrate the effectiveness of our model, which significantly\noutperforms the strong baselines for both present and absent keyphrases\ngeneration. Furthermore, we extend SGG to a title generation task which\nindicates its extensibility in natural language generation tasks.", "journal": ""}
{"doi": "10.48550/arXiv.2106.07117", "date": "2021-06-14", "title": "Toward Diverse Precondition Generation", "authors": "Heeyoung Kwon, Nathanael Chambers, Niranjan Balasubramanian", "abstract": "Language understanding must identify the logical connections between events\nin a discourse, but core events are often unstated due to their commonsense\nnature. This paper fills in these missing events by generating precondition\nevents. Precondition generation can be framed as a sequence-to-sequence\nproblem: given a target event, generate a possible precondition. However, in\nmost real-world scenarios, an event can have several preconditions, requiring\ndiverse generation -- a challenge for standard seq2seq approaches. We propose\nDiP, a Diverse Precondition generation system that can generate unique and\ndiverse preconditions. DiP uses a generative process with three components --\nan event sampler, a candidate generator, and a post-processor. The event\nsampler provides control codes (precondition triggers) which the candidate\ngenerator uses to focus its generation. Unlike other conditional generation\nsystems, DiP automatically generates control codes without training on diverse\nexamples. Analysis against baselines reveals that DiP improves the diversity of\npreconditions significantly while also generating more preconditions.", "journal": ""}
{"doi": "10.48550/arXiv.2304.07483", "date": "2023-04-15", "title": "Video Generation Beyond a Single Clip", "authors": "Hsin-Ping Huang, Yu-Chuan Su, Ming-Hsuan Yang", "abstract": "We tackle the long video generation problem, i.e.~generating videos beyond\nthe output length of video generation models. Due to the computation resource\nconstraints, video generation models can only generate video clips that are\nrelatively short compared with the length of real videos. Existing works apply\na sliding window approach to generate long videos at inference time, which is\noften limited to generating recurrent events or homogeneous content. To\ngenerate long videos covering diverse content and multiple events, we propose\nto use additional guidance to control the video generation process. We further\npresent a two-stage approach to the problem, which allows us to utilize\nexisting video generation models to generate high-quality videos within a small\ntime window while modeling the video holistically based on the input guidance.\nThe proposed approach is complementary to existing efforts on video generation,\nwhich focus on generating realistic video within a fixed time window. Extensive\nexperiments on challenging real-world videos validate the benefit of the\nproposed method, which improves over state-of-the-art by up to 9.5% in\nobjective metrics and is preferred by users more than 80% of time.", "journal": ""}
{"doi": "10.48550/arXiv.2305.14712", "date": "2023-05-24", "title": "On the Generalization of Diffusion Model", "authors": "Mingyang Yi, Jiacheng Sun, Zhenguo Li", "abstract": "The diffusion probabilistic generative models are widely used to generate\nhigh-quality data. Though they can synthetic data that does not exist in the\ntraining set, the rationale behind such generalization is still unexplored. In\nthis paper, we formally define the generalization of the generative model,\nwhich is measured by the mutual information between the generated data and the\ntraining set. The definition originates from the intuition that the model which\ngenerates data with less correlation to the training set exhibits better\ngeneralization ability. Meanwhile, we show that for the empirical optimal\ndiffusion model, the data generated by a deterministic sampler are all highly\nrelated to the training set, thus poor generalization. This result contradicts\nthe observation of the trained diffusion model's (approximating empirical\noptima) extrapolation ability (generating unseen data). To understand this\ncontradiction, we empirically verify the difference between the sufficiently\ntrained diffusion model and the empirical optima. We found, though obtained\nthrough sufficient training, there still exists a slight difference between\nthem, which is critical to making the diffusion model generalizable. Moreover,\nwe propose another training objective whose empirical optimal solution has no\npotential generalization problem. We empirically show that the proposed\ntraining objective returns a similar model to the original one, which further\nverifies the generalization ability of the trained diffusion model.", "journal": ""}
{"doi": "10.48550/arXiv.2308.09931", "date": "2023-08-19", "title": "TDG: Text-guided Domain Generalization", "authors": "Geng Liu, Yuxi Wang", "abstract": "Domain generalization (DG) attempts to generalize a model trained on single\nor multiple source domains to the unseen target domain. Benefiting from the\nsuccess of Visual-and-Language Pre-trained models in recent years, we argue\nthat it is crucial for domain generalization by introducing extra text\ninformation. In this paper, we develop a novel Text-guided Domain\nGeneralization (TDG) paradigm for domain generalization, which includes three\nfollowing aspects. Specifically, we first devise an automatic words generation\nmethod to extend the description of current domains with novel domain-relevant\nwords. Then, we embed the generated domain information into the text feature\nspace, by the proposed prompt learning-based text feature generation method,\nwhich shares a common representation space with the image feature. Finally, we\nutilize both input image features and generated text features to train a\nspecially designed classifier that generalizes well on unseen target domains,\nwhile the image encoder is also updated under the supervision of gradients back\npropagated from the classifier. Our experimental results show that the\ntechniques incorporated by TDG contribute to the performance in an easy\nimplementation manner. Experimental results on several domain generalization\nbenchmarks show that our proposed framework achieves superior performance by\neffectively leveraging generated text information in domain generalization.", "journal": ""}
{"doi": "10.48550/arXiv.2402.07395", "date": "2024-02-12", "title": "Comparing the willingness to share for human-generated vs. AI-generated fake news", "authors": "Amirsiavosh Bashardoust, Stefan Feuerriegel, Yash Raj Shrestha", "abstract": "Generative artificial intelligence (AI) presents large risks for society when\nit is used to create fake news. A crucial factor for fake news to go viral on\nsocial media is that users share such content. Here, we aim to shed light on\nthe sharing behavior of users across human-generated vs. AI-generated fake\nnews. Specifically, we study: (1) What is the perceived veracity of\nhuman-generated fake news vs. AI-generated fake news? (2) What is the user's\nwillingness to share human-generated fake news vs. AI-generated fake news on\nsocial media? (3) What socio-economic characteristics let users fall for\nAI-generated fake news? To this end, we conducted a pre-registered, online\nexperiment with $N=$ 988 subjects and 20 fake news from the COVID-19 pandemic\ngenerated by GPT-4 vs. humans. Our findings show that AI-generated fake news is\nperceived as less accurate than human-generated fake news, but both tend to be\nshared equally. Further, several socio-economic factors explain who falls for\nAI-generated fake news.", "journal": ""}
{"doi": "10.48550/arXiv.2402.17338", "date": "2024-02-27", "title": "Variety of general position problems in graphs", "authors": "Jing Tian, Sandi Klav\u017ear", "abstract": "Let $X$ be a vertex subset of a graph $G$. Then $u, v\\in V(G)$ are\n$X$-positionable if $V(P)\\cap X \\subseteq \\{u,v\\}$ holds for any shortest\n$u,v$-path $P$. If each two vertices from $X$ are $X$-positionable, then $X$ is\na general position set. The general position number of $G$ is the cardinality\nof a largest general position set of $G$ and has been already well\ninvestigated. In this paper a variety of general position problems is\nintroduced based on which natural pairs of vertices are required to be\n$X$-positionable. This yields the total (resp.\\ dual, outer) general position\nnumber. It is proved that the total general position sets coincide with sets of\nsimplicial vertices, and that the outer general position sets coincide with\nsets of mutually maximally distant vertices. It is shown that a general\nposition set is a dual general position set if and only if its complement is\nconvex. Several sufficient conditions are presented that guarantee that a given\ngraph has no dual general position set. The total general position number, the\nouter general position number, and the dual general position number of\narbitrary Cartesian products are determined.", "journal": ""}
{"doi": "10.48550/arXiv.2404.17018", "date": "2024-04-25", "title": "Leveraging AI to Generate Audio for User-generated Content in Video Games", "authors": "Thomas Marrinan, Pakeeza Akram, Oli Gurmessa, Anthony Shishkin", "abstract": "In video game design, audio (both environmental background music and object\nsound effects) play a critical role. Sounds are typically pre-created assets\ndesigned for specific locations or objects in a game. However, user-generated\ncontent is becoming increasingly popular in modern games (e.g. building custom\nenvironments or crafting unique objects). Since the possibilities are virtually\nlimitless, it is impossible for game creators to pre-create audio for\nuser-generated content. We explore the use of generative artificial\nintelligence to create music and sound effects on-the-fly based on\nuser-generated content. We investigate two avenues for audio generation: 1)\ntext-to-audio: using a text description of user-generated content as input to\nthe audio generator, and 2) image-to-audio: using a rendering of the created\nenvironment or object as input to an image-to-text generator, then piping the\nresulting text description into the audio generator. In this paper we discuss\nethical implications of using generative artificial intelligence for\nuser-generated content and highlight two prototype games where audio is\ngenerated for user-created environments and objects.", "journal": ""}
{"doi": "10.48550/arXiv.2411.13237", "date": "2024-11-20", "title": "BIPro: Zero-shot Chinese Poem Generation via Block Inverse Prompting Constrained Generation Framework", "authors": "Xu Zou", "abstract": "Recently, generative pre-trained models have made significant strides,\nparticularly highlighted by the release of ChatGPT and GPT-4, which exhibit\nsuperior cross-domain capabilities. However, these models still face challenges\non constrained writing tasks like poem generation under open-domain titles. In\nresponse to this challenge, we introduce Block Inverse Prompting (BIPro)\nconstrained generation framework. BIPro leverages two block inverse prompting\nmethods, revise and rewrite, that mimic the process of human text writing using\nblock generative models. It significantly improves the zero-shot generation\nquality on the formidable constrained generation task of open-domain\ntraditional-form Chinese poem generation. Based on a less powerful block\ngenerative model GLM-10B-Chinese, poems composed via BIPro without priming or\nadditional training outperform both most advanced direct generative systems\nlike GPT-4 or GLM-4 and best domain-specific systems such as Yusheng,\nShisanbai, or Baidu Poetry Helper in human evaluation by proficient poets.\nFinally, BIPro considerably narrows the gap between AI-generated works and\nshort-listed human literary arts in another human evaluation, unveiling the\npromising potential of block generative models in improving the quality of\nconstrained generation.", "journal": ""}
{"doi": "10.48550/arXiv.2501.00868", "date": "2025-01-01", "title": "Large Language Models Are Read/Write Policy-Makers for Simultaneous Generation", "authors": "Shoutao Guo, Shaolei Zhang, Zhengrui Ma, Yang Feng", "abstract": "Simultaneous generation models write generation results while reading\nstreaming inputs, necessitating a policy-maker to determine the appropriate\noutput timing. Existing simultaneous generation methods generally adopt the\ntraditional encoder-decoder architecture and learn the generation and\npolicy-making capabilities through complex dynamic programming techniques.\nAlthough LLMs excel at text generation, they face challenges in taking on the\nrole of policy-makers through traditional training methods, limiting their\nexploration in simultaneous generation. To overcome these limitations, we\npropose a novel LLM-driven Simultaneous Generation (LSG) framework, which\nallows the off-the-shelf LLM to decide the generation timing and produce output\nconcurrently. Specifically, LSG selects the generation policy that minimizes\nlatency as the baseline policy. Referring to the baseline policy, LSG enables\nthe LLM to devise an improved generation policy that better balances latency\nand generation quality, and writes generation results accordingly. Experiments\non simultaneous translation and streaming automatic speech recognition tasks\nshow that our method can achieve state-of-the-art performance utilizing the\nopen-source LLMs and demonstrate practicality in real-world scenarios.", "journal": ""}
{"doi": "10.48550/arXiv.2506.01370", "date": "2025-06-02", "title": "PointT2I: LLM-based text-to-image generation via keypoints", "authors": "Taekyung Lee, Donggyu Lee, Myungjoo Kang", "abstract": "Text-to-image (T2I) generation model has made significant advancements,\nresulting in high-quality images aligned with an input prompt. However, despite\nT2I generation's ability to generate fine-grained images, it still faces\nchallenges in accurately generating images when the input prompt contains\ncomplex concepts, especially human pose. In this paper, we propose PointT2I, a\nframework that effectively generates images that accurately correspond to the\nhuman pose described in the prompt by using a large language model (LLM).\nPointT2I consists of three components: Keypoint generation, Image generation,\nand Feedback system. The keypoint generation uses an LLM to directly generate\nkeypoints corresponding to a human pose, solely based on the input prompt,\nwithout external references. Subsequently, the image generation produces images\nbased on both the text prompt and the generated keypoints to accurately reflect\nthe target pose. To refine the outputs of the preceding stages, we incorporate\nan LLM-based feedback system that assesses the semantic consistency between the\ngenerated contents and the given prompts. Our framework is the first approach\nto leveraging LLM for keypoints-guided image generation without any\nfine-tuning, producing accurate pose-aligned images based solely on textual\nprompts.", "journal": ""}
{"doi": "10.48550/arXiv.9711086", "date": "1997-11-28", "title": "Cosmological structures in generalized gravity", "authors": "J. Hwang", "abstract": "In a class of generalized gravity theories with general couplings between the\nscalar field and the scalar curvature in the Lagrangian, we describe the\nquantum generation and the classical evolution processes of both the scalar and\ntensor structures in a simple and unified manner.", "journal": ""}
{"doi": "10.48550/arXiv.9307222", "date": "1993-07-14", "title": "Applications of generalized special functions in stellar astrophysics", "authors": "Hans J. Haubold, Arak Mathai Mathai", "abstract": "This article gives an brief outline of the applications of generalized\nspecial functions such as generalized hypergeometric functions, G-functions and\nH-functions into the general area of nuclear energy generation and reaction\nrate theory such as the energy generation in a simple stellar model and nuclear\nreaction rates in non-resonant and resonant as well as screened non-resonant", "journal": ""}
{"doi": "10.48550/arXiv.9307224", "date": "1993-07-25", "title": "Generalized Hermite polynomials and the Bose-like oscillator calculus", "authors": "Marvin Rosenblum", "abstract": "This paper studies a suitably normalized set of generalized Hermite\npolynomials and sets down a relevant Mehler formula, Rodrigues formula, and\ngeneralized translation operator. Weighted generalized Hermite polynomials are\nthe eigenfunctions of a generalized Fourier transform which satisfies an F. and\nM. Riesz theorem on the absolute continuity of analytic measures. The Bose-like\noscillator calculus, which generalizes the calculus associated with the quantum\nmechanical simple harmonic oscillator, is studied in terms of these\npolynomials.", "journal": ""}
{"doi": "10.48550/arXiv.0006104", "date": "2000-06-14", "title": "Generalized vertex algebras generated by parafermion-like vertex operators", "authors": "Yongcun Gao, Haisheng Li", "abstract": "It is proved that for a vector space W, any set of parafermion-like vertex\noperators on W in a certain canonical way generates a generalized vertex\nalgebra in the sense of [DL2] with W as a natural module. This result\ngeneralizes a result of [Li2]. As an application, generalized vertex algebras\nare constructed from Lepowsky-Wilson's Z-algebras of any nonzero level.", "journal": ""}
{"doi": "10.48550/arXiv.0107051", "date": "2001-07-06", "title": "Generalized functions valued in a smooth manifold", "authors": "Michael Kunzinger", "abstract": "Based on Colombeau's theory of algebras of generalized functions we introduce\nthe concepts of generalized functions taking values in differentiable manifolds\nas well as of generalized vector bundle homomorphisms. We study their basic\nproperties, in particular with respect to some new point value concepts for\ngeneralized functions and indicate applications of the resulting theory in\ngeneral relativity.", "journal": "Monatsh. Math., 137, 31-49, 2002."}
{"doi": "10.48550/arXiv.0502053", "date": "2005-02-02", "title": "Some results in Generalized \u0160erstnev spaces", "authors": "M. Alimohammady, R. Saadati", "abstract": "In this paper, we show that D-compactness in Generalized \\v{S}erstnev spaces\nimplies D-boundedness and as in the classical case, a D-bounded and closed\nsubset of a characteristic Generalized \\v{S}erstnev is not D-compact in\ngeneral. Finally, in the finite dimensional Generalized \\v{S}erstnev spaces a\nsubset is D-compact if and only if is D-bounded and closed.", "journal": ""}
{"doi": "10.48550/arXiv.0605483", "date": "2006-05-17", "title": "Non-genericity of infinitesimal variations of Hodge structures arising in some geometric contexts", "authors": "Emmanuel Allaud, Javier Fernandez", "abstract": "We prove that the infinitesimal variations of Hodge structure arising in a\nnumber of geometric situations are non-generic. In particular, we consider the\ncase of generic hypersurfaces in complete smooth projective toric varieties,\ngeneric hypersurfaces in weighted projective spaces and generic complete\nintersections in projective space and show that, for sufficiently high degrees,\nthe corresponding infinitesimal variations are non-generic.", "journal": "Proc. Edinb. Math. Soc., 53, 13-29 (2010)"}
{"doi": "10.48550/arXiv.0707.3289", "date": "2007-07-22", "title": "A Further Generalized Lagrangian Density and Its Special Cases", "authors": "Fang-Pei Chen", "abstract": "By summarizing and extending the Lagrangian densities of the general\nrelativity and the Kibble's gauge theory of gravitation,a further generalized\nLagrangian density for a gravitational system is obtained and analyzed in\ngreater detail, which can be used for studying more extensive range of\ngravitation. Many special cases can be derived from this generalized Lagrangian\ndensity, their general characters and peculiarities will be briefly described.", "journal": ""}
{"doi": "10.48550/arXiv.0802.0156", "date": "2008-02-01", "title": "Generic separable metric structures", "authors": "Alexander Usvyatsov", "abstract": "We compare three notions of genericity of separable metric structures. Our\nanalysis provides a general model theoretic technique of showing that\nstructures are generic in descriptive set theoretic (topological) sense and in\nmeasure theoretic sense.\n  In particular, it gives a new perspective on Vershik's theorems on genericity\nand randomness of Urysohn's space among separable metric spaces.", "journal": ""}
{"doi": "10.48550/arXiv.1004.0800", "date": "2010-04-06", "title": "From generalized Kaehler to generalized Sasakian structures", "authors": "Izu Vaisman", "abstract": "This is an expository paper, which provides a first introduction to geometric\nstructures on $TM\\oplus T^*M$. The paper contains definitions and\ncharacteristic properties of generalized complex, generalized Kaehler,\ngeneralized (normal, almost) contact and generalized Sasakian structures. A few\nof these properties are new.", "journal": "Journal of Geometry and Symmetry in Physics, 18 (2010), 63-86"}
{"doi": "10.48550/arXiv.1006.2764", "date": "2010-06-14", "title": "General form of quantum evolution", "authors": "Dariusz Chruscinski, Andrzej Kossakowski", "abstract": "We propose a complete treatment of a local in time dynamics of open quantum\nsystems. In this approach Markovian evolution turns out to be a special case of\na general non-Markovian one. We provide a general representation of the local\ngenerator which generalizes well known Lindblad representation for the\nMarkovian dynamics. It shows that the structure of non-Markovian generators is\nhighly intricate and the problem of their classification is still open. Simple\nexamples illustrate our approach.", "journal": ""}
{"doi": "10.48550/arXiv.1109.3273", "date": "2011-09-15", "title": "Generating functions for plateaus in Motzkin paths", "authors": "Dan Drake, Ryan Gantner", "abstract": "A plateau in a Motzkin path is a sequence of three steps: an up step, a\nhorizontal step, then a down step. We find three different forms for the\nbivariate generating function for plateaus in Motzkin paths, then generalize to\nlonger plateaus. We conclude by describing a further generalization: a\ncontinued fraction form from which one can easily derive new multivariate\ngenerating functions for various kinds of path statistics. Several examples of\ngenerating functions are given using this technique.", "journal": ""}
{"doi": "10.48550/arXiv.1302.2474", "date": "2013-02-11", "title": "Generalizations of generating functions for hypergeometric orthogonal polynomials with definite integrals", "authors": "Howard S. Cohl, Connor MacKenzie, Hans Volkmer", "abstract": "We generalize generating functions for hypergeometric orthogonal polynomials,\nnamely Jacobi, Gegenbauer, Laguerre, and Wilson polynomials. These\ngeneralizations of generating functions are accomplished through series\nrearrangement using connection relations with one free parameter for these\northogonal polynomials. We also use orthogonality relations to determine\ncorresponding definite integrals.", "journal": ""}
{"doi": "10.48550/arXiv.1312.0846", "date": "2013-12-03", "title": "Generalized forms and gravitation", "authors": "D. C. Robinson", "abstract": "The algebra and calculus of generalized differential forms are reviewed and\nemployed to construct a class of generalized connections and to investigate\ntheir properties. The class includes generalized connections which are flat\nwhen Einstein's vacuum field equations are satisfied. Generalized Chern-Simons\naction principles are formulated and it is shown that certain of these have\nEinstein's vacuum field equations as Euler-Lagrange equations.", "journal": ""}
{"doi": "10.48550/arXiv.1412.3631", "date": "2014-12-11", "title": "Local-global principle for General Quadratic and General Hermitian groups and the nilpotence of KH_1", "authors": "Rabeya Basu", "abstract": "In this article we establish an analog of the Quillen---Suslin's local-global\nprinciple for the elementary subgroup of the general quadratic group and the\ngeneral Hermitian group. We show that unstable ${\\k}$-groups of general\nHermitian groups over module finite rings are nilpotent-by-abelian. This\ngeneralizes earlier results of A. Bak, R. Hazrat, and N. Vavilov.", "journal": ""}
{"doi": "10.48550/arXiv.1501.00754", "date": "2015-01-05", "title": "On generalized K\u00e4hler geometry on compact Lie groups", "authors": "Shengda Hu", "abstract": "We present some fundamental facts about a class of generalized K\\\"ahler\nstructures defined by invariant complex structures on compact Lie groups. The\nmain computational tool is the BH-to-GK spectral sequences that relate the\nbi-Hermitian data to generalized geometry data. The relationship between\ngeneralized Hodge decomposition and generalized canonical bundles for\ngeneralized K\\\"ahler manifolds is also clarified.", "journal": ""}
{"doi": "10.48550/arXiv.1502.05276", "date": "2015-02-18", "title": "The Free Generalized Vertex Algebras and Generalized Principal Subspaces", "authors": "Kazuya Kawasetsu", "abstract": "The notion of {\\it free} generalized vertex algebras is introduced. It is\nequivalent to the notion of {\\it generalized principal subspaces} associated\nwith lattices which are not necessarily integral. Combinatorial bases and the\ncharacters of the free generalized vertex algebras are given. As an\napplication, the commutants of principal subspaces are described by using\ngeneralized principal subspaces.", "journal": ""}
{"doi": "10.48550/arXiv.1510.01264", "date": "2015-09-30", "title": "Gama and beta approximations via general ordered topological spaces", "authors": "M. Abo-Elhamayel", "abstract": "In this paper, we introduce the concepts of gamma and beta approximations via\ngeneral ordered topological approximation spaces. Also, increasing (decreasing)\ngamma and beta boundary, positive and negative regions are given in general\nordered topological approximation spaces (GOTAS, for short). Some important\nproperties of them were investigated. From this study, we can say that studying\nany properties of rough set concepts via GOTAS is a generalization of Pawlak\napproximation spaces and general approximation spaces.", "journal": ""}
{"doi": "10.48550/arXiv.1602.08279", "date": "2016-02-26", "title": "Iterations of the generalized Gram-Schmidt procedure for generating Parseval frames", "authors": "Tomislav Beri\u0107", "abstract": "In this paper we describe some properties of the generalized Gram-Schmidt\nprocedure (GGSP) for generating Parseval frames which was first introduced by\nCasazza and Kutyniok [A generalization of Gram-Schmidt orthogonalization\ngenerating all Parseval frames, Adv. Comput. Math. 27 (2007), pp. 65-78]. Next\nwe investigate the iterations of the procedure and its limit. In the end we\ngive some examples of the iterated procedure.", "journal": ""}
{"doi": "10.48550/arXiv.1610.02880", "date": "2016-10-10", "title": "Preservation of immersed or injective properties by composing generic generalized distance-squared mappings", "authors": "Shunsuke Ichiki, Takashi Nishimura", "abstract": "Any generalized distance-squared mapping of equidimensional case has\nsingularities, and their singularity types are wrapped into mystery in higher\ndimensional cases. Any generalized distance-squared mapping of equidimensional\ncase is not injective. Nevertheless, in this paper, it is shown that the\nnon-singular property or the injective property of a mapping is preserved by\ncomposing a generic generalized distance-squared mapping of equidimensional\ncase.", "journal": ""}
{"doi": "10.48550/arXiv.1612.08812", "date": "2016-12-28", "title": "Stability and Genericity Aspects of Properties of Space-times in General Relativity", "authors": "R. V. Saraykar", "abstract": "In this article, we review and discuss different aspects of stability and\ngenericity of some properties of space-times which occur in various contexts in\nthe General Theory of Relativity. We also give argument supporting the\nconclusion that Linearization Stability is a generic property if we restrict\nspace-times to the class of those which admit compact spacelike constant mean\ncurvature hypersurfaces.", "journal": ""}
{"doi": "10.48550/arXiv.1701.07199", "date": "2017-01-25", "title": "Generic metrics satisfy the generic condition", "authors": "Eric Larsson", "abstract": "We prove that the \"generic condition\" used in singularity theorems of general\nrelativity is generic in the space of Lorentzian metrics on a given manifold,\nin the sense that it is satisfied for all metrics in a residual set in the\nWhitney $C^k$-topology, for $k$ depending on the dimension of the manifold.", "journal": ""}
{"doi": "10.48550/arXiv.2111.06125", "date": "2021-11-11", "title": "Invariant representation for generators of general time interval quadratic BSDEs under stochastic growth conditions", "authors": "Guangshuo Zhou, Fengjiao Du, Shengjun Fan", "abstract": "This paper is devoted to proving a general invariant representation theorem\nfor generators of general time interval backward stochastic differential\nequations, where the generator $g$ has a quadratic growth in the unknown\nvariable $z$ and satisfies some stochastic growth conditions in the unknown\nvariable $y$. This unifies and strengthens some known results. And, a natural\nand innovative idea is used to prove the representation theorem.", "journal": ""}
{"doi": "10.48550/arXiv.1703.09489", "date": "2017-03-28", "title": "Generalized connected sum formula for the Arnold invariants of generic plane curves", "authors": "Keiichi Sakai, Ryutaro Sugiyama", "abstract": "We define the generalized connected sum for generic closed plane curves,\ngeneralizing the strange sum defined by Arnold, and completely describe how the\nArnold invariants $J^{\\pm}$ and $\\mathit{St}$ behave under the generalized\nconnected sums.", "journal": "Topology and its Applications, volume 255 (2019), pages 86-108"}
{"doi": "10.48550/arXiv.2201.09155", "date": "2022-01-23", "title": "Pairs of Generators for Matrix Groups. I", "authors": "Donald E. Taylor", "abstract": "Matrix generators for the general and special linear groups, the symplectic\ngroups and the general and special unitary groups over finite fields. For the\nmost part the generators have been obtained by translating Steinberg's\ngenerators for groups of Lie type into matrix form.", "journal": "The Cayley Bulletin No. 3 (1987) 76--85"}
{"doi": "10.48550/arXiv.1609.08453", "date": "2016-09-23", "title": "Generalized Weyl Conformal Curvature Tensor of a Generalized Riemannian Space", "authors": "Nenad O. Vesic", "abstract": "It is generalized Weyl conformal curvature tensor in the case of a conformal\nmappings of a generalized Riemannian space in this paper. Moreover, it is found\nuniversal generalizations of it without any additional assumption. A method\nused in this paper may help different scientists in their researching.", "journal": ""}
{"doi": "10.48550/arXiv.1811.06622", "date": "2018-11-15", "title": "Concept-Oriented Deep Learning: Generative Concept Representations", "authors": "Daniel T. Chang", "abstract": "Generative concept representations have three major advantages over\ndiscriminative ones: they can represent uncertainty, they support integration\nof learning and reasoning, and they are good for unsupervised and\nsemi-supervised learning. We discuss probabilistic and generative deep\nlearning, which generative concept representations are based on, and the use of\nvariational autoencoders and generative adversarial networks for learning\ngenerative concept representations, particularly for concepts whose data are\nsequences, structured data or graphs.", "journal": ""}
{"doi": "10.48550/arXiv.2007.06300", "date": "2020-07-13", "title": "Synthetic Dataset Generation with Itemset-Based Generative Models", "authors": "Christian Lezcano, Marta Arias", "abstract": "This paper proposes three different data generators, tailored to\ntransactional datasets, based on existing itemset-based generative models. All\nthese generators are intuitive and easy to implement and show satisfactory\nperformance. The quality of each generator is assessed by means of three\ndifferent methods that capture how well the original dataset structure is\npreserved.", "journal": ""}
{"doi": "10.48550/arXiv.2106.14129", "date": "2021-06-27", "title": "The first-order definability of generic large cardinals", "authors": "Saka\u00e9 Fuchino, Hiroshi Sakai", "abstract": "We show that the notions of generic and Laver-generic supercompactness are\nfirst-order definable in the language of ZFC. This also holds for generic and\nLaver-generic (almost) hugeness as well as for generic versions of other large\ncardinals.", "journal": ""}
{"doi": "10.48550/arXiv.2110.03225", "date": "2021-10-07", "title": "On general Sombor index", "authors": "Chinglensana Phanjoubam, Sainkupar Mn Mawiong", "abstract": "We present the bounds in terms of other important graph parameters for\ngeneral Sombor index which generalises both the forgotten index and the Sombor\nindex. We also explore the Nordhaus-Gaddum-type result for the general Sombor\nindex. We present further the relations between general Sombor index and other\ngeneralised indices: general Randi\\'c index and general sum-connectivity index.", "journal": "Asian-European Journal of Mathematics, 2022"}
{"doi": "10.48550/arXiv.2203.00726", "date": "2022-03-01", "title": "Minimal invariable generating sets", "authors": "Daniele Garzoni, Andrea Lucchini", "abstract": "A subset $S$ of a group $G$ invariably generates $G$ if, when each element of\n$S$ is replaced by an arbitrary conjugate, the resulting set generates $G.$ An\ninvariable generating set $X$ of $G$ is called minimal if no proper subset of\n$X$ invariably generates $G.$ We will address several questions related to the\nbehaviour of minimal invariable generating sets of a finite group.", "journal": ""}
{"doi": "10.48550/arXiv.2304.08462", "date": "2023-04-17", "title": "A Formula for Derived Sets in General Topology", "authors": "Eugene Zhang", "abstract": "In this paper, we present a general formula for derived sets in general\ntopology. Consequently, more results can be proved in general topology\ninvolving derived sets and isolated point sets. More specifically, we can prove\nthat isolated point sets are nowhere dense in general topological space.", "journal": ""}
{"doi": "10.48550/arXiv.2404.05738", "date": "2024-03-30", "title": "On Generalized Bihyperbolic Third-order Jacobsthal Polynomials", "authors": "Gamaliel Cerda-Morales", "abstract": "In this paper, a new generalization of third-order Jacobsthal bihyperbolic\npolynomials is introduced. Some of the properties of presented polynomials are\ngiven. A Vadja formula for the generalized bihyperbolic third-order Jacobsthal\npolynomials is obtained. This result implies the Catalan, Cassini and d'Ocagne\nidentities. Moreover, generating function and matrix generators for these\npolynomials are presented.", "journal": "Mathematica Bohemica, first online, pp. 1-11, 2024"}
{"doi": "10.48550/arXiv.2408.13835", "date": "2024-08-25", "title": "CR structures, k-contact structures, and generalized Sasakian structures", "authors": "Janet Talvacchia", "abstract": "In previous work (arXiv:2205.12067), we defined a notion of a generalized\nSasakian structure in the context of generalized contact geometry, the odd\ndimensional analogue of generalized complex geometry introduced by Hitchin and\nGualtieri. We show here that k-contact manifolds are generalized Sasakian if\nand only if they are classically Sasakian. We show also that strictly\npseudo-convex CR manifolds are always generalized Sasakian.", "journal": ""}
{"doi": "10.48550/arXiv.2409.08535", "date": "2024-09-13", "title": "Demailly's Conjecture for general and very general points", "authors": "Sankhaneel Bisui, Dipendranath Mahato", "abstract": "We prove that at least $\\left( \\dfrac{(1+\\epsilon)2m}{N-1}+1+\\epsilon\n\\right)^N$, where $0\\leqslant \\epsilon <1$, many general points, satisfy\nDemailly's conjecture. Previously, it was known to be true for at least\n$(2m+2)^N$ many general points in arxiv.org/abs/2009.05022. We also study\nDemailly's conjecture for $m=3$ for ideal defining general and very general\npoints.", "journal": ""}
{"doi": "10.48550/arXiv.1305.6215", "date": "2013-05-27", "title": "On some interrelations of generalized $q$-entropies and a generalized Fisher information, including a Cram\u00e9r-Rao inequality", "authors": "Jean-Fran\u00e7ois Bercher", "abstract": "In this communication, we describe some interrelations between generalized\n$q$-entropies and a generalized version of Fisher information. In information\ntheory, the de Bruijn identity links the Fisher information and the derivative\nof the entropy. We show that this identity can be extended to generalized\nversions of entropy and Fisher information. More precisely, a generalized\nFisher information naturally pops up in the expression of the derivative of the\nTsallis entropy. This generalized Fisher information also appears as a special\ncase of a generalized Fisher information for estimation problems. Indeed, we\nderive here a new Cram\\'er-Rao inequality for the estimation of a parameter,\nwhich involves a generalized form of Fisher information. This generalized\nFisher information reduces to the standard Fisher information as a particular\ncase. In the case of a translation parameter, the general Cram\\'er-Rao\ninequality leads to an inequality for distributions which is saturated by\ngeneralized $q$-Gaussian distributions. These generalized $q$-Gaussians are\nimportant in several areas of physics and mathematics. They are known to\nmaximize the $q$-entropies subject to a moment constraint. The Cram\\'er-Rao\ninequality shows that the generalized $q$-Gaussians also minimize the\ngeneralized Fisher information among distributions with a fixed moment.\nSimilarly, the generalized $q$-Gaussians also minimize the generalized Fisher\ninformation among distributions with a given $q$-entropy.", "journal": "Applied Stochastic Models and Data Analysis, Mataro (Barcelona) :\n  Spain (2013)"}
{"doi": "10.48550/arXiv.1510.03650", "date": "2015-10-13", "title": "Long Period Sequences Generated by the Logistic Map over Finite Fields with Control Parameter Four", "authors": "Kazuyoshi Tsuchiya, Yasuyuki Nogami", "abstract": "Pseudorandom number generators have been widely used in Monte Carlo methods,\ncommunication systems, cryptography and so on. For cryptographic applications,\npseudorandom number generators are required to generate sequences which have\ngood statistical properties, long period and unpredictability. A Dickson\ngenerator is a nonlinear congruential generator whose recurrence function is\nthe Dickson polynomial. Aly and Winterhof obtained a lower bound on the linear\ncomplexity profile of a Dickson generator. Moreover Vasiga and Shallit studied\nthe state diagram given by the Dickson polynomial of degree two. However, they\ndo not specify sets of initial values which generate a long period sequence. In\nthis paper, we show conditions for parameters and initial values to generate\nlong period sequences, and asymptotic properties for periods by numerical\nexperiments. We specify sets of initial values which generate a long period\nsequence. For suitable parameters, every element of this set occurs exactly\nonce as a component of generating sequence in one period. In order to obtain\nsets of initial values, we consider a logistic generator proposed by Miyazaki,\nAraki, Uehara and Nogami, which is obtained from a Dickson generator of degree\ntwo with a linear transformation. Moreover, we remark on the linear complexity\nprofile of the logistic generator. The sets of initial values are described by\nvalues of the Legendre symbol. The main idea is to introduce a structure of a\nhyperbola to the sets of initial values. Our results ensure that generating\nsequences of Dickson generator of degree two have long period. As a\nconsequence, the Dickson generator of degree two has some good properties for\ncryptographic applications.", "journal": ""}
{"doi": "10.48550/arXiv.1905.07136", "date": "2019-05-17", "title": "Biosignal Generation and Latent Variable Analysis with Recurrent Generative Adversarial Networks", "authors": "Shota Harada, Hideaki Hayashi, Seiichi Uchida", "abstract": "The effectiveness of biosignal generation and data augmentation with\nbiosignal generative models based on generative adversarial networks (GANs),\nwhich are a type of deep learning technique, was demonstrated in our previous\npaper. GAN-based generative models only learn the projection between a random\ndistribution as input data and the distribution of training data.Therefore, the\nrelationship between input and generated data is unclear, and the\ncharacteristics of the data generated from this model cannot be controlled.\nThis study proposes a method for generating time-series data based on GANs and\nexplores their ability to generate biosignals with certain classes and\ncharacteristics. Moreover, in the proposed method, latent variables are\nanalyzed using canonical correlation analysis (CCA) to represent the\nrelationship between input and generated data as canonical loadings. Using\nthese loadings, we can control the characteristics of the data generated by the\nproposed method. The influence of class labels on generated data is analyzed by\nfeeding the data interpolated between two class labels into the generator of\nthe proposed GANs. The CCA of the latent variables is shown to be an effective\nmethod of controlling the generated data characteristics. We are able to model\nthe distribution of the time-series data without requiring domain-dependent\nknowledge using the proposed method. Furthermore, it is possible to control the\ncharacteristics of these data by analyzing the model trained using the proposed\nmethod. To the best of our knowledge, this work is the first to generate\nbiosignals using GANs while controlling the characteristics of the generated\ndata.", "journal": ""}
{"doi": "10.48550/arXiv.2402.08540", "date": "2024-02-13", "title": "Generative VS non-Generative Models in Engineering Shape Optimization", "authors": "Muhammad Usama, Zahid Masood, Shahroz Khan, Konstantinos Kostas, Panagiotis Kaklis", "abstract": "In this work, we perform a systematic comparison of the effectiveness and\nefficiency of generative and non-generative models in constructing design\nspaces for novel and efficient design exploration and shape optimization. We\napply these models in the case of airfoil/hydrofoil design and conduct the\ncomparison on the resulting design spaces. A conventional Generative\nAdversarial Network (GAN) and a state-of-the-art generative model, the\nPerformance-Augmented Diverse Generative Adversarial Network (PaDGAN), are\njuxtaposed with a linear non-generative model based on the coupling of the\nKarhunen-Lo\\`eve Expansion and a physics-informed Shape Signature Vector\n(SSV-KLE). The comparison demonstrates that, with an appropriate shape encoding\nand a physics-augmented design space, non-generative models have the potential\nto cost-effectively generate high-performing valid designs with enhanced\ncoverage of the design space. In this work, both approaches are applied to two\nlarge foil profile datasets comprising real-world and artificial designs\ngenerated through either a profile-generating parametric model or deep-learning\napproach. These datasets are further enriched with integral properties of their\nmembers' shapes as well as physics-informed parameters. Our results illustrate\nthat the design spaces constructed by the non-generative model outperform the\ngenerative model in terms of design validity, generating robust latent spaces\nwith none or significantly fewer invalid designs when compared to generative\nmodels. We aspire that these findings will aid the engineering design community\nin making informed decisions when constructing designs spaces for shape\noptimization, as we have show that under certain conditions computationally\ninexpensive approaches can closely match or even outperform state-of-the art\ngenerative models.", "journal": ""}
{"doi": "10.48550/arXiv.2506.06821", "date": "2025-06-07", "title": "Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems", "authors": "Yuhan Cao, Zian Chen, Kun Quan, Ziliang Zhang, Yu Wang, Xiaoning Dong, Yeqi Feng, Guanzhong He, Jingcheng Huang, Jianhao Li, Yixuan Tan, Jiafu Tang, Yilin Tang, Junlei Wu, Qianyu Xiao, Can Zheng, Shouchen Zhou, Yuxiang Zhu, Yiming Huang, Tian Xie, Tianxing He", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncode generation, capable of tackling complex tasks during inference. However,\nthe extent to which LLMs can be utilized for code checking or debugging through\ntest case generation remains largely unexplored. We investigate this problem\nfrom the perspective of competition-level programming (CP) programs and propose\nTCGBench, a Benchmark for (LLM generation of) Test Case Generators. This\nbenchmark comprises two tasks, aimed at studying the capabilities of LLMs in\n(1) generating valid test case generators for a given CP problem, and further\n(2) generating targeted test case generators that expose bugs in human-written\ncode. Experimental results indicate that while state-of-the-art LLMs can\ngenerate valid test case generators in most cases, most LLMs struggle to\ngenerate targeted test cases that reveal flaws in human code effectively.\nEspecially, even advanced reasoning models (e.g., o3-mini) fall significantly\nshort of human performance in the task of generating targeted generators.\nFurthermore, we construct a high-quality, manually curated dataset of\ninstructions for generating targeted generators. Analysis demonstrates that the\nperformance of LLMs can be enhanced with the aid of this dataset, by both\nprompting and fine-tuning.", "journal": ""}
{"doi": "10.48550/arXiv.0805.1872", "date": "2008-05-13", "title": "Avoidance of Partially Ordered Generalized Patterns of the form $k$-$\u03c3$-$k$", "authors": "Marteinn T. Hardarson", "abstract": "Sergey Kitaev has shown that the exponential generating function for\npermutations avoiding the generalized pattern $\\sigma$-$k$, where $\\sigma$ is a\npattern without dashes and $k$ is one greater than the biggest element in\n$\\sigma$, is determined by the exponential generating function for permutations\navoiding $\\sigma$.\n  We show that this also holds for permutations avoiding all the generalized\npatterns $\\sigma_1$-$k_1$, $...$, $\\sigma_n$-$k_n$, where $\\sigma_1$, $...$,\n$\\sigma_n$ are patterns without dashes and $k_i$ is one greater than the\nbiggest element in $\\sigma_i$. Similarly the exponential generating function\nfor permutations avoiding the partially ordered generalized patterns\n$k_1$-$\\sigma_1$-$k_1$, $...$, $k_n$-$\\sigma_n$-$k_n$ can be determined from\nthe exponential generating function for permutations avoiding the generalized\npatterns $\\sigma_1$, $...$, $\\sigma_n$, where $\\sigma_1$, $...$, $\\sigma_n$ are\npatterns without dashes and $k_i$ is one greater than the largest element in\n$\\sigma_i$.\n  Using this we construct a bijection between bicolored set partitions and\npermutations avoiding the partially ordered generalized pattern 3-12-3 (that\nis, permutations avoiding both the patterns 3-12-4 and 4-12-3). By using this\nmethod twice, we find a closed formula for the exponential generating function\nfor permutations avoiding the partially ordered generalized pattern 3-121-3.\n  Finally, we give a complete classification of when single partially ordered\ngeneralized patterns have the same set of avoiders.", "journal": ""}
{"doi": "10.48550/arXiv.1808.03082", "date": "2018-08-09", "title": "Paired 3D Model Generation with Conditional Generative Adversarial Networks", "authors": "Cihan \u00d6ng\u00fcn, Alptekin Temizel", "abstract": "Generative Adversarial Networks (GANs) are shown to be successful at\ngenerating new and realistic samples including 3D object models. Conditional\nGAN, a variant of GANs, allows generating samples in given conditions. However,\nobjects generated for each condition are different and it does not allow\ngeneration of the same object in different conditions. In this paper, we first\nadapt conditional GAN, which is originally designed for 2D image generation, to\nthe problem of generating 3D models in different rotations. We then propose a\nnew approach to guide the network to generate the same 3D sample in different\nand controllable rotation angles (sample pairs). Unlike previous studies, the\nproposed method does not require modification of the standard conditional GAN\narchitecture and it can be integrated into the training step of any conditional\nGAN. Experimental results and visual comparison of 3D models show that the\nproposed method is successful at generating model pairs in different\nconditions.", "journal": ""}
{"doi": "10.48550/arXiv.2006.10137", "date": "2020-06-17", "title": "MoFlow: An Invertible Flow Model for Generating Molecular Graphs", "authors": "Chengxi Zang, Fei Wang", "abstract": "Generating molecular graphs with desired chemical properties driven by deep\ngraph generative models provides a very promising way to accelerate drug\ndiscovery process. Such graph generative models usually consist of two steps:\nlearning latent representations and generation of molecular graphs. However, to\ngenerate novel and chemically-valid molecular graphs from latent\nrepresentations is very challenging because of the chemical constraints and\ncombinatorial complexity of molecular graphs. In this paper, we propose MoFlow,\na flow-based graph generative model to learn invertible mappings between\nmolecular graphs and their latent representations. To generate molecular\ngraphs, our MoFlow first generates bonds (edges) through a Glow based model,\nthen generates atoms (nodes) given bonds by a novel graph conditional flow, and\nfinally assembles them into a chemically valid molecular graph with a posthoc\nvalidity correction. Our MoFlow has merits including exact and tractable\nlikelihood training, efficient one-pass embedding and generation, chemical\nvalidity guarantees, 100\\% reconstruction of training data, and good\ngeneralization ability. We validate our model by four tasks: molecular graph\ngeneration and reconstruction, visualization of the continuous latent space,\nproperty optimization, and constrained property optimization. Our MoFlow\nachieves state-of-the-art performance, which implies its potential efficiency\nand effectiveness to explore large chemical space for drug discovery.", "journal": ""}
{"doi": "10.48550/arXiv.2206.13974", "date": "2022-06-28", "title": "Joint Generator-Ranker Learning for Natural Language Generation", "authors": "Weizhou Shen, Yeyun Gong, Yelong Shen, Song Wang, Xiaojun Quan, Nan Duan, Weizhu Chen", "abstract": "Generate-then-rank is a widely used mechanism for text generation, where a\ngenerator produces multiple text candidates and a ranker chooses the best one\namong the text candidates. However, existing methods usually train the\ngenerator and the ranker individually, neglecting the mutual feedback that\ncould further enhance the generation quality. To tackle this limitation, we\npropose JGR, a novel joint training algorithm that integrates the generator and\nthe ranker in a single framework. JGR optimizes the generator with a hybrid\nobjective that combines data likelihood and ranker reward, and trains the\nranker with a contrastive loss that compares the generator outputs. By\niteratively updating the generator and the ranker, JGR can effectively\nharmonize their learning and enhance their quality jointly. We evaluate JGR on\nvarious text generation tasks and demonstrate that it surpasses existing\nmethods on four public datasets across three common generation scenarios. Our\ncode and models are publicly available at\nhttps://github.com/microsoft/ProphetNet/tree/master/JGR.", "journal": ""}
{"doi": "10.48550/arXiv.2206.15027", "date": "2022-06-30", "title": "Interpretable Melody Generation from Lyrics with Discrete-Valued Adversarial Training", "authors": "Wei Duan, Zhe Zhang, Yi Yu, Keizo Oyama", "abstract": "Generating melody from lyrics is an interesting yet challenging task in the\narea of artificial intelligence and music. However, the difficulty of keeping\nthe consistency between input lyrics and generated melody limits the generation\nquality of previous works. In our proposal, we demonstrate our proposed\ninterpretable lyrics-to-melody generation system which can interact with users\nto understand the generation process and recreate the desired songs. To improve\nthe reliability of melody generation that matches lyrics, mutual information is\nexploited to strengthen the consistency between lyrics and generated melodies.\nGumbel-Softmax is exploited to solve the non-differentiability problem of\ngenerating discrete music attributes by Generative Adversarial Networks (GANs).\nMoreover, the predicted probabilities output by the generator is utilized to\nrecommend music attributes. Interacting with our lyrics-to-melody generation\nsystem, users can listen to the generated AI song as well as recreate a new\nsong by selecting from recommended music attributes.", "journal": ""}
{"doi": "10.48550/arXiv.2211.08095", "date": "2022-11-15", "title": "Will Large-scale Generative Models Corrupt Future Datasets?", "authors": "Ryuichiro Hataya, Han Bao, Hiromi Arai", "abstract": "Recently proposed large-scale text-to-image generative models such as\nDALL$\\cdot$E 2, Midjourney, and StableDiffusion can generate high-quality and\nrealistic images from users' prompts. Not limited to the research community,\nordinary Internet users enjoy these generative models, and consequently, a\ntremendous amount of generated images have been shared on the Internet.\nMeanwhile, today's success of deep learning in the computer vision field owes a\nlot to images collected from the Internet. These trends lead us to a research\nquestion: \"\\textbf{will such generated images impact the quality of future\ndatasets and the performance of computer vision models positively or\nnegatively?}\" This paper empirically answers this question by simulating\ncontamination. Namely, we generate ImageNet-scale and COCO-scale datasets using\na state-of-the-art generative model and evaluate models trained with\n\"contaminated\" datasets on various tasks, including image classification and\nimage generation. Throughout experiments, we conclude that generated images\nnegatively affect downstream performance, while the significance depends on\ntasks and the amount of generated images. The generated datasets and the codes\nfor experiments will be publicly released for future research. Generated\ndatasets and source codes are available from\n\\url{https://github.com/moskomule/dataset-contamination}.", "journal": ""}
{"doi": "10.48550/arXiv.2311.15561", "date": "2023-11-27", "title": "ET3D: Efficient Text-to-3D Generation via Multi-View Distillation", "authors": "Yiming Chen, Zhiqi Li, Peidong Liu", "abstract": "Recent breakthroughs in text-to-image generation has shown encouraging\nresults via large generative models. Due to the scarcity of 3D assets, it is\nhardly to transfer the success of text-to-image generation to that of\ntext-to-3D generation. Existing text-to-3D generation methods usually adopt the\nparadigm of DreamFusion, which conducts per-asset optimization by distilling a\npretrained text-to-image diffusion model. The generation speed usually ranges\nfrom several minutes to tens of minutes per 3D asset, which degrades the user\nexperience and also imposes a burden to the service providers due to the high\ncomputational budget.\n  In this work, we present an efficient text-to-3D generation method, which\nrequires only around 8 $ms$ to generate a 3D asset given the text prompt on a\nconsumer graphic card. The main insight is that we exploit the images generated\nby a large pre-trained text-to-image diffusion model, to supervise the training\nof a text conditioned 3D generative adversarial network. Once the network is\ntrained, we are able to efficiently generate a 3D asset via a single forward\npass. Our method requires no 3D training data and provides an alternative\napproach for efficient text-to-3D generation by distilling pre-trained image\ndiffusion models.", "journal": ""}
{"doi": "10.48550/arXiv.2312.02625", "date": "2023-12-05", "title": "Diffusion Noise Feature: Accurate and Fast Generated Image Detection", "authors": "Yichi Zhang, Xiaogang Xu", "abstract": "Generative models have reached an advanced stage where they can produce\nremarkably realistic images. However, this remarkable generative capability\nalso introduces the risk of disseminating false or misleading information.\nNotably, existing image detectors for generated images encounter challenges\nsuch as low accuracy and limited generalization. This paper seeks to address\nthis issue by seeking a representation with strong generalization capabilities\nto enhance the detection of generated images. Our investigation has revealed\nthat real and generated images display distinct latent Gaussian representations\nwhen subjected to an inverse diffusion process within a pre-trained diffusion\nmodel. Exploiting this disparity, we can amplify subtle artifacts in generated\nimages. Building upon this insight, we introduce a novel image representation\nknown as Diffusion Noise Feature (DNF). DNF is extracted from the estimated\nnoise generated during the inverse diffusion process. A simple classifier,\ne.g., ResNet50, trained on DNF achieves high accuracy, robustness, and\ngeneralization capabilities for detecting generated images (even the\ncorresponding generator is built with datasets/structures that are not seen\nduring the classifier's training). We conducted experiments using four training\ndatasets and five testsets, achieving state-of-the-art detection performance.", "journal": ""}
{"doi": "10.48550/arXiv.2401.17626", "date": "2024-01-31", "title": "Generative AI to Generate Test Data Generators", "authors": "Benoit Baudry, Khashayar Etemadi, Sen Fang, Yogya Gamage, Yi Liu, Yuxin Liu, Martin Monperrus, Javier Ron, Andr\u00e9 Silva, Deepika Tiwari", "abstract": "Generating fake data is an essential dimension of modern software testing, as\ndemonstrated by the number and significance of data faking libraries. Yet,\ndevelopers of faking libraries cannot keep up with the wide range of data to be\ngenerated for different natural languages and domains. In this paper, we assess\nthe ability of generative AI for generating test data in different domains. We\ndesign three types of prompts for Large Language Models (LLMs), which perform\ntest data generation tasks at different levels of integrability: 1) raw test\ndata generation, 2) synthesizing programs in a specific language that generate\nuseful test data, and 3) producing programs that use state-of-the-art faker\nlibraries. We evaluate our approach by prompting LLMs to generate test data for\n11 domains. The results show that LLMs can successfully generate realistic test\ndata generators in a wide range of domains at all three levels of\nintegrability.", "journal": "IEEE Software, 2024"}
{"doi": "10.48550/arXiv.2401.17807", "date": "2024-01-31", "title": "Advances in 3D Generation: A Survey", "authors": "Xiaoyu Li, Qi Zhang, Di Kang, Weihao Cheng, Yiming Gao, Jingbo Zhang, Zhihao Liang, Jing Liao, Yan-Pei Cao, Ying Shan", "abstract": "Generating 3D models lies at the core of computer graphics and has been the\nfocus of decades of research. With the emergence of advanced neural\nrepresentations and generative models, the field of 3D content generation is\ndeveloping rapidly, enabling the creation of increasingly high-quality and\ndiverse 3D models. The rapid growth of this field makes it difficult to stay\nabreast of all recent developments. In this survey, we aim to introduce the\nfundamental methodologies of 3D generation methods and establish a structured\nroadmap, encompassing 3D representation, generation methods, datasets, and\ncorresponding applications. Specifically, we introduce the 3D representations\nthat serve as the backbone for 3D generation. Furthermore, we provide a\ncomprehensive overview of the rapidly growing literature on generation methods,\ncategorized by the type of algorithmic paradigms, including feedforward\ngeneration, optimization-based generation, procedural generation, and\ngenerative novel view synthesis. Lastly, we discuss available datasets,\napplications, and open challenges. We hope this survey will help readers\nexplore this exciting topic and foster further advancements in the field of 3D\ncontent generation.", "journal": ""}
{"doi": "10.48550/arXiv.2402.11843", "date": "2024-02-19", "title": "WildFake: A Large-scale Challenging Dataset for AI-Generated Images Detection", "authors": "Yan Hong, Jianfu Zhang", "abstract": "The extraordinary ability of generative models enabled the generation of\nimages with such high quality that human beings cannot distinguish Artificial\nIntelligence (AI) generated images from real-life photographs. The development\nof generation techniques opened up new opportunities but concurrently\nintroduced potential risks to privacy, authenticity, and security. Therefore,\nthe task of detecting AI-generated imagery is of paramount importance to\nprevent illegal activities. To assess the generalizability and robustness of\nAI-generated image detection, we present a large-scale dataset, referred to as\nWildFake, comprising state-of-the-art generators, diverse object categories,\nand real-world applications. WildFake dataset has the following advantages: 1)\nRich Content with Wild collection: WildFake collects fake images from the\nopen-source community, enriching its diversity with a broad range of image\nclasses and image styles. 2) Hierarchical structure: WildFake contains fake\nimages synthesized by different types of generators from GANs, diffusion\nmodels, to other generative models. These key strengths enhance the\ngeneralization and robustness of detectors trained on WildFake, thereby\ndemonstrating WildFake's considerable relevance and effectiveness for\nAI-generated detectors in real-world scenarios. Moreover, our extensive\nevaluation experiments are tailored to yield profound insights into the\ncapabilities of different levels of generative models, a distinctive advantage\nafforded by WildFake's unique hierarchical structure.", "journal": ""}
{"doi": "10.48550/arXiv.2403.01071", "date": "2024-03-02", "title": "GraphRCG: Self-Conditioned Graph Generation", "authors": "Song Wang, Zhen Tan, Xinyu Zhao, Tianlong Chen, Huan Liu, Jundong Li", "abstract": "Graph generation generally aims to create new graphs that closely align with\na specific graph distribution. Existing works often implicitly capture this\ndistribution through the optimization of generators, potentially overlooking\nthe intricacies of the distribution itself. Furthermore, these approaches\ngenerally neglect the insights offered by the learned distribution for graph\ngeneration. In contrast, in this work, we propose a novel self-conditioned\ngraph generation framework designed to explicitly model graph distributions and\nemploy these distributions to guide the generation process. We first perform\nself-conditioned modeling to capture the graph distributions by transforming\neach graph sample into a low-dimensional representation and optimizing a\nrepresentation generator to create new representations reflective of the\nlearned distribution. Subsequently, we leverage these bootstrapped\nrepresentations as self-conditioned guidance for the generation process,\nthereby facilitating the generation of graphs that more accurately reflect the\nlearned distributions. We conduct extensive experiments on generic and\nmolecular graph datasets across various fields. Our framework demonstrates\nsuperior performance over existing state-of-the-art graph generation methods in\nterms of graph quality and fidelity to training data.", "journal": ""}
{"doi": "10.48550/arXiv.2403.01535", "date": "2024-03-03", "title": "Neural Graph Generator: Feature-Conditioned Graph Generation using Latent Diffusion Models", "authors": "Iakovos Evdaimon, Giannis Nikolentzos, Christos Xypolopoulos, Ahmed Kammoun, Michail Chatzianastasis, Hadi Abdine, Michalis Vazirgiannis", "abstract": "Graph generation has emerged as a crucial task in machine learning, with\nsignificant challenges in generating graphs that accurately reflect specific\nproperties. Existing methods often fall short in efficiently addressing this\nneed as they struggle with the high-dimensional complexity and varied nature of\ngraph properties. In this paper, we introduce the Neural Graph Generator (NGG),\na novel approach which utilizes conditioned latent diffusion models for graph\ngeneration. NGG demonstrates a remarkable capacity to model complex graph\npatterns, offering control over the graph generation process. NGG employs a\nvariational graph autoencoder for graph compression and a diffusion process in\nthe latent vector space, guided by vectors summarizing graph statistics. We\ndemonstrate NGG's versatility across various graph generation tasks, showing\nits capability to capture desired graph properties and generalize to unseen\ngraphs. We also compare our generator to the graph generation capabilities of\ndifferent LLMs. This work signifies a shift in graph generation methodologies,\noffering a more practical and efficient solution for generating diverse graphs\nwith specific characteristics.", "journal": ""}
{"doi": "10.48550/arXiv.2403.15690", "date": "2024-03-23", "title": "EAGLE: A Domain Generalization Framework for AI-generated Text Detection", "authors": "Amrita Bhattacharjee, Raha Moraffah, Joshua Garland, Huan Liu", "abstract": "With the advancement in capabilities of Large Language Models (LLMs), one\nmajor step in the responsible and safe use of such LLMs is to be able to detect\ntext generated by these models. While supervised AI-generated text detectors\nperform well on text generated by older LLMs, with the frequent release of new\nLLMs, building supervised detectors for identifying text from such new models\nwould require new labeled training data, which is infeasible in practice. In\nthis work, we tackle this problem and propose a domain generalization framework\nfor the detection of AI-generated text from unseen target generators. Our\nproposed framework, EAGLE, leverages the labeled data that is available so far\nfrom older language models and learns features invariant across these\ngenerators, in order to detect text generated by an unknown target generator.\nEAGLE learns such domain-invariant features by combining the representational\npower of self-supervised contrastive learning with domain adversarial training.\nThrough our experiments we demonstrate how EAGLE effectively achieves\nimpressive performance in detecting text generated by unseen target generators,\nincluding recent state-of-the-art ones such as GPT-4 and Claude, reaching\ndetection scores of within 4.7% of a fully supervised detector.", "journal": ""}
{"doi": "10.48550/arXiv.2412.15278", "date": "2024-12-18", "title": "DreaMark: Rooting Watermark in Score Distillation Sampling Generated Neural Radiance Fields", "authors": "Xingyu Zhu, Xiapu Luo, Xuetao Wei", "abstract": "Recent advancements in text-to-3D generation can generate neural radiance\nfields (NeRFs) with score distillation sampling, enabling 3D asset creation\nwithout real-world data capture. With the rapid advancement in NeRF generation\nquality, protecting the copyright of the generated NeRF has become increasingly\nimportant. While prior works can watermark NeRFs in a post-generation way, they\nsuffer from two vulnerabilities. First, a delay lies between NeRF generation\nand watermarking because the secret message is embedded into the NeRF model\npost-generation through fine-tuning. Second, generating a non-watermarked NeRF\nas an intermediate creates a potential vulnerability for theft. To address both\nissues, we propose Dreamark to embed a secret message by backdooring the NeRF\nduring NeRF generation. In detail, we first pre-train a watermark decoder.\nThen, the Dreamark generates backdoored NeRFs in a way that the target secret\nmessage can be verified by the pre-trained watermark decoder on an arbitrary\ntrigger viewport. We evaluate the generation quality and watermark robustness\nagainst image- and model-level attacks. Extensive experiments show that the\nwatermarking process will not degrade the generation quality, and the watermark\nachieves 90+% accuracy among both image-level attacks (e.g., Gaussian noise)\nand model-level attacks (e.g., pruning attack).", "journal": ""}
{"doi": "10.48550/arXiv.2412.16672", "date": "2024-12-21", "title": "Optoelectronic generative adversarial networks", "authors": "Jumin Qiu, Ganqing Lu, Tingting Liu, Dejian Zhang, Shuyuan Xiao, Tianbao Yu", "abstract": "Artificial intelligence generative content technology has experienced\nremarkable breakthroughs in recent years and is quietly leading a profound\ntransformation. Diffractive optical networks provide a promising solution for\nimplementing generative model with high-speed and low-power consumption. In\nthis work, we present the implementation of a generative model on the\noptoelectronic computing architecture, based on generative adversarial network,\nwhich is called optoelectronic generative adversarial network. The network\nstrategically distributes the generator and discriminator across the optical\nand electronic components, which are seamlessly integrated to leverage the\nunique strengths of each computing paradigm and take advantage of transfer\nlearning. The network can efficiently and high-speed process the complex tasks\ninvolved in the training and inference of the generative model. The superior\nperformance of these networks is verified by engaging three types of generative\ntasks, image generation, conditional generation, and image restoration. By\nsynergistically combining the strengths of optical and electronic computing,\nthe optoelectronic generative adversarial network paves the way for the\ndevelopment of more powerful and accessible artificial intelligence generative\ncontent technology that can unlock new creative possibilities across a wide\nrange of applications.", "journal": "Communications Physics 8, 162 (2025)"}
{"doi": "10.48550/arXiv.2501.18726", "date": "2025-01-30", "title": "Strong and Controllable 3D Motion Generation", "authors": "Canxuan Gang", "abstract": "Human motion generation is a significant pursuit in generative computer\nvision with widespread applications in film-making, video games, AR/VR, and\nhuman-robot interaction. Current methods mainly utilize either diffusion-based\ngenerative models or autoregressive models for text-to-motion generation.\nHowever, they face two significant challenges: (1) The generation process is\ntime-consuming, posing a major obstacle for real-time applications such as\ngaming, robot manipulation, and other online settings. (2) These methods\ntypically learn a relative motion representation guided by text, making it\ndifficult to generate motion sequences with precise joint-level control. These\nchallenges significantly hinder progress and limit the real-world application\nof human motion generation techniques. To address this gap, we propose a simple\nyet effective architecture consisting of two key components. Firstly, we aim to\nimprove hardware efficiency and computational complexity in transformer-based\ndiffusion models for human motion generation. By customizing flash linear\nattention, we can optimize these models specifically for generating human\nmotion efficiently. Furthermore, we will customize the consistency model in the\nmotion latent space to further accelerate motion generation. Secondly, we\nintroduce Motion ControlNet, which enables more precise joint-level control of\nhuman motion compared to previous text-to-motion generation methods. These\ncontributions represent a significant advancement for text-to-motion\ngeneration, bringing it closer to real-world applications.", "journal": ""}
{"doi": "10.48550/arXiv.2502.00283", "date": "2025-02-01", "title": "How Generative AI supports human in conceptual design", "authors": "Liuging Chen, Yaxuan Song, Jia Guo, Lingyun Sun, Peter Childs, Yuan Yin", "abstract": "Generative Artificial Intelligence (Generative AI) is a collection of AI\ntechnologies that can generate new information such as texts and images. With\nits strong capabilities, Generative AI has been actively studied in creative\ndesign processes. However, limited studies have explored the roles of humans\nand Generative AI in conceptual design processes, leaving a gap for human-AI\ncollaboration investigation. To address this gap, this study uncovers the\ncontributions of different Generative AI technologies in assisting humans in\nthe conceptual design process. Novice designers completed two design tasks with\nor without the assistance of Generative AI. Results revealed that Generative AI\nprimarily assists humans in problem definition and idea generation stages,\nwhile idea selection and evaluation remain predominantly human-led.\nAdditionally, with Generative AI assistance, the idea selection and evaluation\nstages were further enhanced. Based on the findings, we discuss the role of\nGenerative AI in human-AI collaboration and implications for enhancing future\nconceptual design support with Generative AI assistance.", "journal": ""}
{"doi": "10.48550/arXiv.2504.05334", "date": "2025-04-04", "title": "Level Generation with Constrained Expressive Range", "authors": "Mahsa Bazzaz, Seth Cooper", "abstract": "Expressive range analysis is a visualization-based technique used to evaluate\nthe performance of generative models, particularly in game level generation. It\ntypically employs two quantifiable metrics to position generated artifacts on a\n2D plot, offering insight into how content is distributed within a defined\nmetric space. In this work, we use the expressive range of a generator as the\nconceptual space of possible creations. Inspired by the quality diversity\nparadigm, we explore this space to generate levels. To do so, we use a\nconstraint-based generator that systematically traverses and generates levels\nin this space. To train the constraint-based generator we use different tile\npatterns to learn from the initial example levels. We analyze how different\npatterns influence the exploration of the expressive range. Specifically, we\ncompare the exploration process based on time, the number of successful and\nfailed sample generations, and the overall interestingness of the generated\nlevels. Unlike typical quality diversity approaches that rely on random\ngeneration and hope to get good coverage of the expressive range, this approach\nsystematically traverses the grid ensuring more coverage. This helps create\nunique and interesting game levels while also improving our understanding of\nthe generator's strengths and limitations.", "journal": ""}
{"doi": "10.48550/arXiv.2505.03547", "date": "2025-05-06", "title": "STORY2GAME: Generating (Almost) Everything in an Interactive Fiction Game", "authors": "Eric Zhou, Shreyas Basavatia, Moontashir Siam, Zexin Chen, Mark O. Riedl", "abstract": "We introduce STORY2GAME, a novel approach to using Large Language Models to\ngenerate text-based interactive fiction games that starts by generating a\nstory, populates the world, and builds the code for actions in a game engine\nthat enables the story to play out interactively. Whereas a given set of\nhard-coded actions can artificially constrain story generation, the ability to\ngenerate actions means the story generation process can be more open-ended but\nstill allow for experiences that are grounded in a game state. The key to\nsuccessful action generation is to use LLM-generated preconditions and effects\nof actions in the stories as guides for what aspects of the game state must be\ntracked and changed by the game engine when a player performs an action. We\nalso introduce a technique for dynamically generating new actions to\naccommodate the player's desire to perform actions that they think of that are\nnot part of the story. Dynamic action generation may require on-the-fly updates\nto the game engine's state representation and revision of previously generated\nactions. We evaluate the success rate of action code generation with respect to\nwhether a player can interactively play through the entire generated story.", "journal": ""}
{"doi": "10.48550/arXiv.0106052", "date": "2001-06-15", "title": "Composition of Lorentz Transformations in Terms of Their Generators", "authors": "B. Coll, F. San Jose Martinez", "abstract": "Two-forms in Minkowski space-time may be considered as generators of Lorentz\ntransformations. Here, the covariant and general expression for the composition\nlaw (Baker-Campbell-Hausdorff formula) of two Lorentz transformations in terms\nof their generators is obtained. Every subalgebra of the Lorentz algebra of\nsuch generators, up to one, may be generated by a sole pair of generators. When\nthe subalgebra is known, the above BCH formula for the two two-forms\nsimplifies. Its simplified expressions for all such subalgebras are also given.", "journal": "Gen.Rel.Grav. 34 (2002) 1345-1356"}
{"doi": "10.48550/arXiv.0703015", "date": "2007-03-02", "title": "A New Formulation of General Relativity - Part III: GR as Scalar Field Theory", "authors": "Joachim Schr\u00f6ter", "abstract": "The aim of this paper (Part III) is formulating GR as a scalar field theory.\nThe basic structural elements of it are a generating function, a generalized\ndensity and a generalized temperature. One of the axioms of this theory is a\ngeneralized Einstein equation which determines the generating function\ndirectly. It is shown that basic concepts like orientation, time orientation\nand isometry are expressible in terms of generating functions. At the end of\nthe paper six problems are formulated which are still unsolved and can act as a\nstimulant for further research.", "journal": ""}
{"doi": "10.48550/arXiv.0803.0284", "date": "2008-03-03", "title": "Generalized Fourier Integral Operators on spaces of Colombeau type", "authors": "Claudia Garetto", "abstract": "Generalized Fourier integral operators (FIOs) acting on Colombeau algebras\nare defined. This is based on a theory of generalized oscillatory integrals\n(OIs) whose phase functions as well as amplitudes may be generalized functions\nof Colombeau type. The mapping properties of these FIOs are studied as the\ncomposition with a generalized pseudodifferential operator. Finally, the\nmicrolocal Colombeau regularity for OIs and the influence of the FIO action on\ngeneralized wave front sets are investigated. This theory of generalized FIOs\nis motivated by the need of a general framework for partial differential\noperators with non-smooth coefficients and distributional data.", "journal": ""}
{"doi": "10.48550/arXiv.0811.1521", "date": "2008-11-10", "title": "Generalized analytic functions on generalized domains", "authors": "Hans Vernaeve", "abstract": "We define the algebra of Colombeau generalized functions on a subset A of the\nspace of d-dimensional generalized points. If the domain A is open, such\ngeneralized functions can be identified with pointwise maps from A into the\nring of Colombeau generalized numbers. We study analyticity in these algebras,\nif the domain is an open subset of the complex generalized points. In\nparticular, if the domain is an open ball for the sharp norm, we characterize\nanalyticity and give a unicity theorem involving the values at generalized\npoints.", "journal": ""}
{"doi": "10.48550/arXiv.0904.1469", "date": "2009-04-09", "title": "Presentations of subgroups of the braid group generated by powers of band generators", "authors": "Michael L\u00f6nne", "abstract": "According to the Tits conjecture proved by Crisp and Paris, [CP], the\nsubgroups of the braid group generated by proper powers of the Artin elements\nare presented by the commutators of generators which are powers of commuting\nelements. Hence they are naturally presented as right-angled Artin groups.\n  The case of subgroups generated by powers of the band generators is more\ninvolved. We show that the groups are right-angled Artin groups again, if all\ngenerators are proper powers with exponent at least 3. We also give a\npresentation in cases at the other extreme, when all generators occur with\nexponent 1 or 2, which is far from being that of a right-angled Artin group.", "journal": ""}
{"doi": "10.48550/arXiv.0907.3254", "date": "2009-07-19", "title": "Generalized Chung-Feller Theorems for Lattice Paths (Thesis)", "authors": "Aminul Huq", "abstract": "In this thesis we develop generalized versions of the Chung-Feller theorem\nfor lattice paths constrained in the half plane. The beautiful cycle method\nwhich was developed by Devoretzky and Motzkin as a means to prove the ballot\nproblem is modified and applied to generalize the classical Chung-Feller\ntheorem. We use Lagrange inversion to derive the generalized formulas. For the\ngenerating function proof we study various ways of decomposing lattice paths.\nWe also show some results related to equidistribution properties in terms of\nNarayana and Catalan generating functions. We then develop generalized\nChung-Feller theorems for Motzkin and Schroeder paths. Finally we study\ngeneralized paths and the analogue of the Chung-Feller theorem for them.", "journal": ""}
{"doi": "10.48550/arXiv.1005.5658", "date": "2010-05-31", "title": "Generalized Calabi-Yau metric and Generalized Monge-Ampere equation", "authors": "Chris M. Hull, Ulf Lindstrom, Martin Rocek, Rikard von Unge, Maxim Zabzine", "abstract": "In the neighborhood of a regular point, generalized Kahler geometry admits a\ndescription in terms of a single real function, the generalized Kahler\npotential. We study the local conditions for a generalized Kahler manifold to\nbe a generalized Calabi-Yau manifold and we derive a non-linear PDE that the\ngeneralized Kahler potential has to satisfy for this to be true. This\nnon-linear PDE can be understood as a generalization of the complex\nMonge-Ampere equation and its solutions give supergravity solutions with\nmetric, dilaton and H-field.", "journal": "JHEP 1008:060,2010"}
{"doi": "10.48550/arXiv.1108.4268", "date": "2011-08-22", "title": "Generic Tropical Varieties on Subvarieties and in the Non-constant Coefficient Case", "authors": "Kirsten Schmitz", "abstract": "In earlier papers it was shown that the generic tropical variety of an ideal\ncan contain information on algebraic invariants as for example the depth in a\ndirect way. The existence of generic tropical varieties has so far been proved\nin the constant coefficient case for the usual notion of genericity. In this\npaper we generalize this existence result to include the case of non-constant\ncoefficients in certain settings. Moreover, we extend the notion of genericity\nto arbitrary closed subvarieties of the general linear group. In addition to\nincluding the concept of genericity on algebraic groups this yields structural\nresults on the tropical variety of an ideal under an arbitrary linear\ncoordinate change.", "journal": ""}
{"doi": "10.48550/arXiv.1206.0567", "date": "2012-06-04", "title": "On generalized Cram\u00e9r-Rao inequalities, generalized Fisher informations and characterizations of generalized q-Gaussian distributions", "authors": "J. -F. Bercher", "abstract": "This paper deals with Cram\\'er-Rao inequalities in the context of\nnonextensive statistics and in estimation theory. It gives characterizations of\ngeneralized q-Gaussian distributions, and introduces generalized versions of\nFisher information. The contributions of this paper are (i) the derivation of\nnew extended Cram\\'er-Rao inequalities for the estimation of a parameter,\ninvolving general q-moments of the estimation error, (ii) the derivation of\nCram\\'er-Rao inequalities saturated by generalized q-Gaussian distributions,\n(iii) the definition of generalized Fisher informations, (iv) the\nidentification and interpretation of some prior results, and finally, (v) the\nsuggestion of new estimation methods.", "journal": "J. Phys. A: Math. Theor. 45 255303 2012"}
{"doi": "10.48550/arXiv.1212.6064", "date": "2012-12-25", "title": "Generalized almost contact structures and generalized Sasakian structures", "authors": "Ken'ichi Sekiya", "abstract": "We introduce generalized almost contact structures which admit the $B$-field\ntransformations on odd dimensional manifolds. We provide definition of\ngeneralized Sasakain structures from the view point of the generalized almost\ncontact structures. We obtain a generalized Sasakian structure on a non-compact\nmanifold which does not arise as a pair of ordinary Sasakian structures.\nHowever we show that a generalized Sasakian structure on compact 3-dimensional\nmanifold is equivalent to a pair of Sasakian structures with the same metric.\nFinally we extend a definition of a generalized almost contact structure.", "journal": ""}
{"doi": "10.48550/arXiv.1309.3268", "date": "2013-09-11", "title": "Transmuted Generalized Inverse Weibull Distribution", "authors": "Faton Merovci, Ibrahim Elbatal, Alaa Ahmed", "abstract": "A generalization of the generalized inverse Weibull distribution so-called\ntransmuted generalized inverse Weibull dis- tribution is proposed and studied.\nWe will use the quadratic rank transmutation map (QRTM) in order to generate a\nflexible family of probability distributions taking generalized inverse Weibull\ndistribution as the base value distribution by introducing a new parameter that\nwould offer more distributional flexibility. Various structural properties\nincluding explicit expressions for the mo- ments, quantiles, and moment\ngenerating function of the new dis- tribution are derived.We proposed the\nmethod of maximum likelihood for estimating the model parameters and obtain the\nobserved information matrix. A real data set are used to compare the exibility\nof the transmuted version versus the generalized inverseWeibull distribution.", "journal": ""}
{"doi": "10.48550/arXiv.1309.4607", "date": "2013-09-18", "title": "Generalized forms, vector fields and superspace", "authors": "D. C. Robinson", "abstract": "Vector fields with components which are generalized zero-forms are\nconstructed. Inner products with generalized forms, Lie derivatives and Lie\nbrackets are computed. The results are shown to generalize previously reported\nresults for generalized vector fields. Hamiltonian vector fields are discussed.\nGeneralized affine connections and metrics are defined and the fundamental\ntheorem of metric differential geometry is extended. The global structure of\nthe exterior derivative of generalized forms is investigated.", "journal": ""}
{"doi": "10.48550/arXiv.1403.3683", "date": "2014-03-14", "title": "Removal and Contraction Operations in $n$D Generalized Maps for Efficient Homology Computation", "authors": "Guillaume Damiand, Rocio Gonzalez-Diaz, Samuel Peltier", "abstract": "In this paper, we show that contraction operations preserve the homology of\n$n$D generalized maps, under some conditions. Removal and contraction\noperations are used to propose an efficient algorithm that compute homology\ngenerators of $n$D generalized maps. Its principle consists in simplifying a\ngeneralized map as much as possible by using removal and contraction\noperations. We obtain a generalized map having the same homology than the\ninitial one, while the number of cells decreased significantly.\n  Keywords: $n$D Generalized Maps; Cellular Homology; Homology Generators;\nContraction and Removal Operations.", "journal": ""}
{"doi": "10.48550/arXiv.1502.06762", "date": "2015-02-24", "title": "On the Hilbert series of ideals generated by generic forms", "authors": "Lisa Nicklasson", "abstract": "There is a longstanding conjecture by Fr\\\"oberg about the Hilbert series of\nthe ring $R/I$, where $R$ is a polynomial ring, and $I$ an ideal generated by\ngeneric forms. We prove this conjecture true in the case when $I$ is generated\nby a large number of forms, all of the same degree. We also conjecture that an\nideal generated by $m$'th powers of forms of degree $d$ gives the same Hilbert\nseries as an ideal generated by generic forms of degree $md$. We verify this in\nseveral cases. This also gives a proof of the first conjecture in some new\ncases.", "journal": "Communications in Algebra (2017), vol. 45, no. 8, p. 3390-3395"}
{"doi": "10.48550/arXiv.1511.08465", "date": "2015-11-26", "title": "Generalized deviation equation and determination of the curvature in General Relativity", "authors": "Dirk Puetzfeld, Yuri N. Obukhov", "abstract": "We derive a generalized deviation equation -- analogous to the well-known\ngeodesic deviation equation -- for test bodies in General Relativity. Our\nresult encompasses and generalizes previous extensions of the standard geodesic\ndeviation equation. We show how the standard as well as a generalized deviation\nequation can be used to measure the curvature of spacetime by means of a set of\ntest bodies. In particular, we provide exact solutions for the curvature by\nusing the standard deviation equation as well as its next order generalization.", "journal": "Phys. Rev. D 93, 044073 (2016)"}
{"doi": "10.48550/arXiv.1601.03882", "date": "2016-01-15", "title": "Twistor space of a generalized quaternionic manifold", "authors": "Guillaume Deschamps", "abstract": "We first make a little survey of the twistor theory for hypercomplex,\ngeneralized hypercomplex, quaternionic or generalized quaternionic manifolds.\nThis last theory was iniated by Pantilie, who shows that any generalized almost\nquaternionic manifold equipped with an appropriate connection admit a twistor\nspace with an almost generalized complex structure.\n  The aim of this article is to give an integrability criterion for this\ngeneralized almost complex structure and to give some examples especially in\nthe case of generalized hyperk\\\"ahler manifolds using the generalized Bismut\nconnection, introduced by Gualtieri.", "journal": ""}
{"doi": "10.48550/arXiv.1607.04111", "date": "2016-07-14", "title": "General Rotational Surfaces in Pseudo-Euclidean 4-Space with Neutral Metric", "authors": "Yana Aleksieva, Velichka Milousheva, Nurettin Cenk Turgay", "abstract": "We define general rotational surfaces of elliptic and hyperbolic type in the\npseudo-Euclidean 4-space with neutral metric which are analogous to the general\nrotational surfaces of C. Moore in the Euclidean 4-space. We study Lorentz\ngeneral rotational surfaces with plane meridian curves and give the complete\nclassification of minimal general rotational surfaces of elliptic and\nhyperbolic type, general rotational surfaces with parallel normalized mean\ncurvature vector field, flat general rotational surfaces, and general\nrotational surfaces with flat normal connection.", "journal": "Bull. Malays. Math. Sci. Soc. 41, no. 4 (2018), 1773-1793"}
{"doi": "10.48550/arXiv.1705.08460", "date": "2017-05-23", "title": "Brill-Noether theorems and globally generated vector bundles on Hirzebruch surfaces", "authors": "Izzet Coskun, Jack Huizenga", "abstract": "In this paper, we show that the cohomology of a general stable bundle on a\nHirzebruch surface is determined by the Euler characteristic provided that the\nfirst Chern class satisfies necessary intersection conditions. More generally,\nwe compute the Betti numbers of a general stable bundle. We also show that a\ngeneral stable bundle on a Hirzebruch surface has a special resolution\ngeneralizing the Gaeta resolution on the projective plane. As a consequence of\nthese results, we classify Chern characters such that the general stable bundle\nis globally generated.", "journal": ""}
{"doi": "10.48550/arXiv.1808.04865", "date": "2018-08-14", "title": "Top-Down Tree Structured Text Generation", "authors": "Qipeng Guo, Xipeng Qiu, Xiangyang Xue, Zheng Zhang", "abstract": "Text generation is a fundamental building block in natural language\nprocessing tasks. Existing sequential models performs autoregression directly\nover the text sequence and have difficulty generating long sentences of complex\nstructures. This paper advocates a simple approach that treats sentence\ngeneration as a tree-generation task. By explicitly modelling syntactic\nstructures in a constituent syntactic tree and performing top-down,\nbreadth-first tree generation, our model fixes dependencies appropriately and\nperforms implicit global planning. This is in contrast to transition-based\ndepth-first generation process, which has difficulty dealing with incomplete\ntexts when parsing and also does not incorporate future contexts in planning.\nOur preliminary results on two generation tasks and one parsing task\ndemonstrate that this is an effective strategy.", "journal": ""}
{"doi": "10.48550/arXiv.1810.02833", "date": "2018-10-05", "title": "CanvasGAN: A simple baseline for text to image generation by incrementally patching a canvas", "authors": "Amanpreet Singh, Sharan Agrawal", "abstract": "We propose a new recurrent generative model for generating images from text\ncaptions while attending on specific parts of text captions. Our model creates\nimages by incrementally adding patches on a \"canvas\" while attending on words\nfrom text caption at each timestep. Finally, the canvas is passed through an\nupscaling network to generate images. We also introduce a new method for\ngenerating visual-semantic sentence embeddings based on self-attention over\ntext. We compare our model's generated images with those generated Reed et.\nal.'s model and show that our model is a stronger baseline for text to image\ngeneration tasks.", "journal": ""}
{"doi": "10.48550/arXiv.1908.04287", "date": "2019-08-12", "title": "Compactly generated spaces and quasi-spaces in topology", "authors": "Willian Ribeiro", "abstract": "The notions of compactness and Hausdorff separation for generalized enriched\ncategories allow us, as classically done for the category $\\mathsf{Top}$ of\ntopological spaces and continuous functions, to study $\\textit{compactly\ngenerated spaces}$ and $\\textit{quasi-spaces}$ in this setting. Moreover, for a\nclass $\\mathcal{C}$ of objects we generalize the notion of\n$\\textit{$\\mathcal{C}$-generated spaces}$, from which we derive, for instance,\na general concept of $\\textit{Alexandroff spaces}$. Furthermore, as done for\n$\\mathsf{Top}$, we also study, in our level of generality, the relationship\nbetween compactly generated spaces and quasi-spaces.", "journal": ""}
{"doi": "10.48550/arXiv.2006.03624", "date": "2020-06-05", "title": "The generator rank of subhomogeneous C*-algebras", "authors": "Hannes Thiel", "abstract": "We compute the generator rank of a subhomgeneous C*-algebra in terms of the\ncovering dimension of the pieces of its primitive ideal space corresponding to\nirreducible representations of a fixed dimension. We deduce that every Z-stable\nASH-algebra has generator rank one, which means that a generic element in such\nan algebra is a generator.\n  This leads to a strong solution of the generator problem for classifiable,\nsimple, nuclear C*-algebras: a generic element in each such algebra is a\ngenerator. Examples of Villadsen show that this is not the case for all\nseparable, simple, nuclear C*-algebras.", "journal": ""}
{"doi": "10.48550/arXiv.2111.04049", "date": "2021-11-07", "title": "Generalized Riordan groups and zero generalized Pascal matrices", "authors": "E. Burlachenko", "abstract": "The generalized Riordan group consists of infinite lower triangular matrices\nthat correspond to certain operators in the space of formal power series. Each\nsuch group contains the matrix (generalized Pascal matrix), elements of which\nare generalized binomial coefficients. Generalized Pascal matrices with\nnon-negative elements form an infinite-dimensional vector space. The paper\ngives an idea of groups similar to the generalized Riordan groups, but\nassociated with matrices, which in the space of generalized Pascal matrices\ncorrespond to the points at infinity; examples of such matrices are the matrix\nof $q$-binomial coefficients for $q=-1$ and the Pascal triangle modulo $2$. An\nanalog of the Lagrange inversion theorem for these groups is given and the\ncorresponding examples are considered.", "journal": ""}
{"doi": "10.48550/arXiv.1805.11202", "date": "2018-05-28", "title": "FairGAN: Fairness-aware Generative Adversarial Networks", "authors": "Depeng Xu, Shuhan Yuan, Lu Zhang, Xintao Wu", "abstract": "Fairness-aware learning is increasingly important in data mining.\nDiscrimination prevention aims to prevent discrimination in the training data\nbefore it is used to conduct predictive analysis. In this paper, we focus on\nfair data generation that ensures the generated data is discrimination free.\nInspired by generative adversarial networks (GAN), we present fairness-aware\ngenerative adversarial networks, called FairGAN, which are able to learn a\ngenerator producing fair data and also preserving good data utility. Compared\nwith the naive fair data generation models, FairGAN further ensures the\nclassifiers which are trained on generated data can achieve fair classification\non real data. Experiments on a real dataset show the effectiveness of FairGAN.", "journal": ""}
{"doi": "10.48550/arXiv.1809.00565", "date": "2018-09-03", "title": "Generalized metric $n$-Leibniz algebras and generalized orthogonal representation of metric Lie algebras", "authors": "Li-Na Song, Rong Tang", "abstract": "We introduce the notion of a generalized metric n-Leibniz algebra and show\nthat there is a one-to-one correspondence between generalized metric n-Leibniz\nalgebras and faithful generalized orthogonal representations of metric Lie\nalgebras (called Lie triple data). We further show that there is also a\none-to-one correspondence between generalized orthogonal derivations (resp.\ngeneralized orthogonal automorphisms) on generalized metric n-Leibniz algebras\nand Lie triple datas.", "journal": "Turkish J. Math. 42 (2018)"}
{"doi": "10.48550/arXiv.2202.01066", "date": "2022-02-01", "title": "Point-Set Topology", "authors": "Farzad Shahi", "abstract": "This is a review of the fundamental concepts of general topology.", "journal": ""}
{"doi": "10.48550/arXiv.1411.0270", "date": "2014-11-02", "title": "A simple characterization of generalized Robertson-Walker spacetimes", "authors": "Bang-Yen Chen", "abstract": "A generalized Robertson-Walker spacetime is the warped product with base an\nopen interval of the real line endowed with the opposite of its metric and base\nany Riemannian manifold. The family of generalized Robertson-Walker spacetimes\nwidely extends the one of classical Robertson-Walker spacetimes. In this\narticle we prove a very simple characterization of generalized Robertson-Walker\nspacetimes; namely, a Lorentzian manifold is a generalized Robertson-Walker\nspacetime if and only if it admits a timelike concircular vector field.", "journal": ""}
{"doi": "10.48550/arXiv.1708.01421", "date": "2017-08-04", "title": "On Generating functions of Diagonals Sequences of Sheffer and Riordan Number Triangles", "authors": "Wolfdieter Lang", "abstract": "The exponential generating function of ordinary generating functions of\ndiagonal sequences of general Sheffer triangles is computed by an application\nof Lagrange's theorem. For the special Jabotinsky type this is already known.\nAn analogous computation for general Riordan number triangles leads to a\nformula for the logarithmic generating function of the ordinary generating\nfunctions of the product of the entries of the diagonal sequence of Pascal's\ntriangle and those of the {Riordan triangle. For some examples these ordinary\ngenerating functions yield in both cases coefficient triangles of certain\nnumerator polynomials.", "journal": ""}
{"doi": "10.48550/arXiv.1804.07707", "date": "2018-04-20", "title": "Factorising AMR generation through syntax", "authors": "Kris Cao, Stephen Clark", "abstract": "Generating from Abstract Meaning Representation (AMR) is an underspecified\nproblem, as many syntactic decisions are not constrained by the semantic graph.\nTo explicitly account for this underspecification, we break down generating\nfrom AMR into two steps: first generate a syntactic structure, and then\ngenerate the surface form. We show that decomposing the generation process this\nway leads to state-of-the-art single model performance generating from AMR\nwithout additional unlabelled data. We also demonstrate that we can generate\nmeaning-preserving syntactic paraphrases of the same AMR graph, as judged by\nhumans.", "journal": ""}
{"doi": "10.48550/arXiv.1902.03984", "date": "2019-02-11", "title": "Improving Generalization and Stability of Generative Adversarial Networks", "authors": "Hoang Thanh-Tung, Truyen Tran, Svetha Venkatesh", "abstract": "Generative Adversarial Networks (GANs) are one of the most popular tools for\nlearning complex high dimensional distributions. However, generalization\nproperties of GANs have not been well understood. In this paper, we analyze the\ngeneralization of GANs in practical settings. We show that discriminators\ntrained on discrete datasets with the original GAN loss have poor\ngeneralization capability and do not approximate the theoretically optimal\ndiscriminator. We propose a zero-centered gradient penalty for improving the\ngeneralization of the discriminator by pushing it toward the optimal\ndiscriminator. The penalty guarantees the generalization and convergence of\nGANs. Experiments on synthetic and large scale datasets verify our theoretical\nanalysis.", "journal": ""}
{"doi": "10.48550/arXiv.1906.06275", "date": "2019-06-14", "title": "Extensions of Generic DOL for Generic Ontology Design Patterns", "authors": "Mihai Codescu, Bernd Krieg-Br\u00fcckner, Till Mossakowski", "abstract": "Generic ontologies were introduced as an extension (Generic DOL) of the\nDistributed Ontology, Modeling and Specification Language, DOL, with the aim to\nprovide a language for Generic Ontology Design Patterns. In this paper we\npresent a number of new language constructs that increase the expressivity and\nthe generality of Generic DOL, among them sequential and optional parameters,\nlist parameters with recursion, and local sub-patterns. These are illustrated\nwith non-trivial patterns: generic value sets and (nested) qualitatively graded\nrelations, demonstrated as definitional building blocks in an application\ndomain.", "journal": ""}
{"doi": "10.48550/arXiv.2002.04657", "date": "2020-02-11", "title": "Geometry of generalized Pauli channels", "authors": "Katarzyna Siudzi\u0144ska", "abstract": "We analyze the geometry of the generalized Pauli channels constructed from\nthe mutually unbiased bases. The Choi-Jamio{\\l}kowski isomorphism allows us to\nexpress the Hilbert-Schmidt line and volume elements in terms of the\neigenvalues of the generalized Pauli maps. After determining appropriate\nregions of integration, we analytically compute the volume of generalized Pauli\nchannels and their important subclasses. In particular, we obtain the volumes\nof the generalized Pauli channels that can be generated by a legitimate\ngenerator and are entanglement breaking. We also provide the upper bound for\nthe volume of positive, trace-preserving generalized Pauli maps.", "journal": "Phys. Rev. A 101, 062323 (2020)"}
{"doi": "10.48550/arXiv.2005.08368", "date": "2020-05-17", "title": "Multi-Objective level generator generation with Marahel", "authors": "Ahmed Khalifa, Julian Togelius", "abstract": "This paper introduces a new system to design constructive level generators by\nsearching the space of constructive level generators defined by Marahel\nlanguage. We use NSGA-II, a multi-objective optimization algorithm, to search\nfor generators for three different problems (Binary, Zelda, and Sokoban). We\nrestrict the representation to a subset of Marahel language to push the\nevolution to find more efficient generators. The results show that the\ngenerated generators were able to achieve good performance on most of the\nfitness functions over these three problems. However, on Zelda and Sokoban,\nthey tend to depend on the initial state than modifying the map.", "journal": ""}
{"doi": "10.48550/arXiv.2101.01443", "date": "2021-01-05", "title": "Unbounded generalization of logarithmic representation of infinitesimal generators", "authors": "Yoritaka Iwata", "abstract": "The logarithmic representation of infinitesimal generators is generalized to\nthe cases when the evolution operator is unbounded. The generalized result is\napplicable to the representation of infinitesimal generators of unbounded\nevolution operators, where unboundedness of evolution operator is an essential\ningredient of nonlinear analysis. In conclusion a general framework for the\nidentification between the infinitesimal generators with evolution operators is\nestablished. A mathematical framework for such an identification is\nindispensable to the rigorous treatment of nonlinear transforms: e.g.,\ntransforms appearing in the theory of integrable systems.", "journal": "Math. Meth. Appl. Sci.; 2023, 1-9"}
{"doi": "10.48550/arXiv.2102.01011", "date": "2020-12-28", "title": "Deep Evolutionary Learning for Molecular Design", "authors": "Yifeng Li, Hsu Kiang Ooi, Alain Tchagang", "abstract": "In this paper, we propose a deep evolutionary learning (DEL) process that\nintegrates fragment-based deep generative model and multi-objective\nevolutionary computation for molecular design. Our approach enables (1)\nevolutionary operations in the latent space of the generative model, rather\nthan the structural space, to generate novel promising molecular structures for\nthe next evolutionary generation, and (2) generative model fine-tuning using\nnewly generated high-quality samples. Thus, DEL implements a data-model\nco-evolution concept which improves both sample population and generative model\nlearning. Experiments on two public datasets indicate that sample population\nobtained by DEL exhibits improved property distributions, and dominates samples\ngenerated by multi-objective Bayesian optimization algorithms.", "journal": ""}
{"doi": "10.48550/arXiv.2103.14884", "date": "2021-03-27", "title": "Continuous Conditional Generative Adversarial Networks (cGAN) with Generator Regularization", "authors": "Yufeng Zheng, Yunkai Zhang, Zeyu Zheng", "abstract": "Conditional Generative Adversarial Networks are known to be difficult to\ntrain, especially when the conditions are continuous and high-dimensional. To\npartially alleviate this difficulty, we propose a simple generator\nregularization term on the GAN generator loss in the form of Lipschitz penalty.\nThus, when the generator is fed with neighboring conditions in the continuous\nspace, the regularization term will leverage the neighbor information and push\nthe generator to generate samples that have similar conditional distributions\nfor each neighboring condition. We analyze the effect of the proposed\nregularization term and demonstrate its robust performance on a range of\nsynthetic and real-world tasks.", "journal": ""}
{"doi": "10.48550/arXiv.2106.03394", "date": "2021-06-07", "title": "A generative model for molecule generation based on chemical reaction trees", "authors": "Dai Hai Nguyen, Koji Tsuda", "abstract": "Deep generative models have been shown powerful in generating novel molecules\nwith desired chemical properties via their representations such as strings,\ntrees or graphs. However, these models are limited in recommending synthetic\nroutes for the generated molecules in practice. We propose a generative model\nto generate molecules via multi-step chemical reaction trees. Specifically, our\nmodel first propose a chemical reaction tree with predicted reaction templates\nand commercially available molecules (starting molecules), and then perform\nforward synthetic steps to obtain product molecules. Experiments show that our\nmodel can generate chemical reactions whose product molecules are with desired\nchemical properties. Also, the complete synthetic routes for these product\nmolecules are provided.", "journal": ""}
{"doi": "10.48550/arXiv.2109.05864", "date": "2021-09-13", "title": "Conditional MoCoGAN for Zero-Shot Video Generation", "authors": "Shun Kimura, Kazuhiko Kawamoto", "abstract": "We propose a conditional generative adversarial network (GAN) model for\nzero-shot video generation. In this study, we have explored zero-shot\nconditional generation setting. In other words, we generate unseen videos from\ntraining samples with missing classes. The task is an extension of conditional\ndata generation. The key idea is to learn disentangled representations in the\nlatent space of a GAN. To realize this objective, we base our model on the\nmotion and content decomposed GAN and conditional GAN for image generation. We\nbuild the model to find better-disentangled representations and to generate\ngood-quality videos. We demonstrate the effectiveness of our proposed model\nthrough experiments on the Weizmann action database and the MUG facial\nexpression database.", "journal": ""}
{"doi": "10.48550/arXiv.2110.07784", "date": "2021-10-15", "title": "Subregularity in infinitely labeled generating trees of restricted permutations", "authors": "Toufik Mansour, Reza Rastegar, Mark Shattuck", "abstract": "In this paper, we revisit the application of generating trees to the pattern\navoidance problem for permutations. In particular, we study this problem for\ncertain general sets of patterns and propose a new procedure leveraging the\nFinLabel algorithm and exploiting the subregularities in the associated\ngenerating trees. We consider some general kinds of generating trees for which\nthe FinLabel algorithm fails to determine in a finite number of iterations the\ngenerating function that enumerates the underlying class of permutations. Our\nprocedure provides a unified approach in these cases leading to a system of\nequations satisfied by a certain finite set of generating functions which can\nbe readily solved with the aid of programming.", "journal": ""}
{"doi": "10.48550/arXiv.2203.06473", "date": "2022-03-12", "title": "On Some Inequalities-Equalities Concerning the continuous generalized Fusion Frame in Hilbert spaces", "authors": "Nadia Assila, Samir Kabbaj, Ouafaa Bouftouh, Chaimae Mezzat", "abstract": "Continuous generalized fusion frame theory was recently introduced by Rahimi\nand al. Several equalities and inequalities have been obtained for frame,\nfusion generalized fusion frame, among others. In the present paper, we\ncontinue and extend these results to obtain some important identities and\ninequalities in the case of continuous generalized fusion frame, Parceval\ncontinuous generalized fusion frame, $ \\lambda$-tight continuous generalized\nfusion frame. Moreover, we obtain some new inequalities for the alternate dual\ncontinuous generalized fusion frame. Finally, we obtain frame operator of a\npair of Bessel continuous generalized fusion mapping and we derive some results\nabout resolution of identity.", "journal": ""}
{"doi": "10.48550/arXiv.2205.11708", "date": "2022-05-24", "title": "A Proof-Generating C Code Generator for ACL2 Based on a Shallow Embedding of C in ACL2", "authors": "Alessandro Coglio", "abstract": "This paper describes a C code generator for ACL2 that recognizes ACL2\nrepresentations of C constructs, according to a shallow embedding of C in ACL2,\nand translates those representations to the represented C constructs. The code\ngenerator also generates ACL2 theorems asserting the correctness of the C code\nwith respect to the ACL2 code. The code generator currently supports a limited\nbut growing subset of C that already suffices for some interesting programs.\nThis paper also offers a general perspective on language embedding and code\ngeneration.", "journal": "EPTCS 359, 2022, pp. 185-201"}
{"doi": "10.48550/arXiv.2208.00534", "date": "2022-07-31", "title": "Generalized Luttinger surgery and other cut-and-paste constructions in generalized complex geometry", "authors": "Lorenzo Sillari", "abstract": "Exploiting the affinity between stable generalized complex structures and\nsymplectic structures, we explain how certain constructions coming from\nsymplectic geometry can be performed in the generalized complex setting. We\nintroduce generalized Luttinger surgery and generalized Gluck twist along\n$\\mathcal{J}$-symplectic submanifolds. We also export branched coverings to the\ngeneralized complex setting. As an application, stable generalized complex\nstructures are produced on a variety of high-dimensional manifolds. Remarkably,\nsome of them have non-homotopy-equivalent path-connected components of their\ntype change locus.", "journal": ""}
{"doi": "10.48550/arXiv.2211.07234", "date": "2022-11-14", "title": "Shared Loss between Generators of GANs", "authors": "Xin Wang", "abstract": "Generative adversarial networks are generative models that are capable of\nreplicating the implicit probability distribution of the input data with high\naccuracy. Traditionally, GANs consist of a Generator and a Discriminator which\ninteract with each other to produce highly realistic artificial data.\nTraditional GANs fall prey to the mode collapse problem, which means that they\nare unable to generate the different variations of data present in the input\ndataset. Recently, multiple generators have been used to produce more realistic\noutput by mitigating the mode collapse problem. We use this multiple generator\nframework. The novelty in this paper lies in making the generators compete\nagainst each other while interacting with the discriminator simultaneously. We\nshow that this causes a dramatic reduction in the training time for GANs\nwithout affecting its performance.", "journal": ""}
{"doi": "10.48550/arXiv.2212.14603", "date": "2022-12-30", "title": "Basic Classes of Timelike General Rotational Surfaces in the Four-dimensional Minkowski Space", "authors": "Victoria Bencheva, Velichka Milousheva", "abstract": "In the present paper, we consider timelike general rotational surfaces in the\nMinkowski 4-space which are analogous to the general rotational surfaces in the\nEuclidean 4-space introduced by C. Moore. We study two types of such surfaces\n(with timelike and spacelike meridian curve, respectively) and describe\nanalytically some of their basic geometric classes: flat timelike general\nrotational surfaces, timelike general rotational surfaces with flat normal\nconnection, and timelike general rotational surfaces with non-zero constant\nmean curvature. We give explicitly all minimal timelike general rotational\nsurfaces and all timelike general rotational surfaces with parallel normalized\nmean curvature vector field.", "journal": "Filomat, Vol. 37, No 25 (2023)"}
{"doi": "10.48550/arXiv.2303.03293", "date": "2023-03-06", "title": "On Hierarchical Multi-Resolution Graph Generative Models", "authors": "Mahdi Karami, Jun Luo", "abstract": "In real world domains, most graphs naturally exhibit a hierarchical\nstructure. However, data-driven graph generation is yet to effectively capture\nsuch structures. To address this, we propose a novel approach that recursively\ngenerates community structures at multiple resolutions, with the generated\nstructures conforming to training data distribution at each level of the\nhierarchy. The graphs generation is designed as a sequence of coarse-to-fine\ngenerative models allowing for parallel generation of all sub-structures,\nresulting in a high degree of scalability. Our method demonstrates generative\nperformance improvement on multiple graph datasets.", "journal": ""}
{"doi": "10.48550/arXiv.2303.10207", "date": "2023-02-10", "title": "Generalized Differential and Integral Calculus and Heisenberg Uncertainty Principle", "authors": "Fernando Marques de Almeida Nogueira", "abstract": "This paper presents a generalization for Differential and Integral Calculus.\nJust as the derivative is the instantaneous angular coefficient of the tangent\nline to a function, the generalized derivative is the instantaneous parameter\nvalue of a reference function (derivator function) tangent to the function. The\ngeneralized integral reverses the generalized derivative, and its calculation\nis presented without antiderivatives. Generalized derivatives and integrals are\npresented for polynomial, exponential and trigonometric derivators and\nintegrators functions. As an example of the application of Generalized\nCalculus, the concept of instantaneous value provided by the derivative is used\nto precisely determine time and frequency (or position and momentum) in a\nfunction (signal or wave function), opposing Heisenberg's Uncertainty\nPrinciple.", "journal": ""}
{"doi": "10.48550/arXiv.2307.00161", "date": "2023-06-30", "title": "FFPDG: Fast, Fair and Private Data Generation", "authors": "Weijie Xu, Jinjin Zhao, Francis Iannacci, Bo Wang", "abstract": "Generative modeling has been used frequently in synthetic data generation.\nFairness and privacy are two big concerns for synthetic data. Although Recent\nGAN [\\cite{goodfellow2014generative}] based methods show good results in\npreserving privacy, the generated data may be more biased. At the same time,\nthese methods require high computation resources. In this work, we design a\nfast, fair, flexible and private data generation method. We show the\neffectiveness of our method theoretically and empirically. We show that models\ntrained on data generated by the proposed method can perform well (in inference\nstage) on real application scenarios.", "journal": "ICLR 2021 Workshop on Synthetic Data Generation"}
{"doi": "10.48550/arXiv.2310.04616", "date": "2023-10-06", "title": "On the closed generalized Drazin-Riesz invertible operators and $C_{0}$-semigroups", "authors": "Othman Abad, Hassane Zguitti", "abstract": "This paper is a continuation of our paper [Med. J. Math 19, Article number:\n31 (2022)] in which we extended the notion of generalized Drazin-Riesz\ninvertible operators to closed operators. We establish here, results relating\nthe notion of closed generalized Drazin-Riesz invertibility with the theory of\n$C_{0}$-semigroups. Firstly, we generalize results obtained in the bounded case\n[1] to the context of closed operators. Secondly, we investigate when an\ninfinitesimal generator $A$ of a given $C_{0}$-semigroup is closed generalized\nDrazin-Riesz invertible. An application to $C_{0}$-groups and abstract second\norder differential equations is proposed, and an example of a $C_{0}$-group\nwith closed generalized Drazin-Riesz invertible infinitesimal generator is\ngiven.", "journal": ""}
{"doi": "10.48550/arXiv.2402.01629", "date": "2024-02-02", "title": "Position Paper: Generalized grammar rules and structure-based generalization beyond classical equivariance for lexical tasks and transduction", "authors": "Mircea Petrache, Shubhendu Trivedi", "abstract": "Compositional generalization is one of the main properties which\ndifferentiates lexical learning in humans from state-of-art neural networks. We\npropose a general framework for building models that can generalize\ncompositionally using the concept of Generalized Grammar Rules (GGRs), a class\nof symmetry-based compositional constraints for transduction tasks, which we\nview as a transduction analogue of equivariance constraints in physics-inspired\ntasks. Besides formalizing generalized notions of symmetry for language\ntransduction, our framework is general enough to contain many existing works as\nspecial cases. We present ideas on how GGRs might be implemented, and in the\nprocess draw connections to reinforcement learning and other areas of research.", "journal": ""}
{"doi": "10.48550/arXiv.2502.14390", "date": "2025-02-20", "title": "Hardy-Littlewood maximal, generalized Bessel-Riesz and generalized fractional integral operators in generalized Morrey and $BMO_\u03c6$ spaces associated with Dunkl operator on the real line", "authors": "Sumit Parashar, Saswata Adhikari", "abstract": "The analysis of Morrey spaces, generalized Morrey spaces and $BMO_\\phi$\nspaces related to the Dunkl operators on $\\mathbb{R}$ are covered in this\npaper. We prove the boundedness of the Hardy-Littlewood maximal operators,\nBessel-Riesz operators, generalized Bessel-Riesz operators, and generalized\nfractional integral operators associated with Dunkl operators on $\\mathbb{R}$\nin the generalized Dunkl-type Morrey spaces. Further, we derive the boundedness\nof the modified version of the generalized fractional integral operators\nassociated with the Dunkl operators on $\\mathbb{R}$ in Dunkl-type $BMO_\\phi$\nspaces.", "journal": ""}
{"doi": "10.48550/arXiv.2503.06987", "date": "2025-03-10", "title": "Social Bias Benchmark for Generation: A Comparison of Generation and QA-Based Evaluations", "authors": "Jiho Jin, Woosung Kang, Junho Myung, Alice Oh", "abstract": "Measuring social bias in large language models (LLMs) is crucial, but\nexisting bias evaluation methods struggle to assess bias in long-form\ngeneration. We propose a Bias Benchmark for Generation (BBG), an adaptation of\nthe Bias Benchmark for QA (BBQ), designed to evaluate social bias in long-form\ngeneration by having LLMs generate continuations of story prompts. Building our\nbenchmark in English and Korean, we measure the probability of neutral and\nbiased generations across ten LLMs. We also compare our long-form story\ngeneration evaluation results with multiple-choice BBQ evaluation, showing that\nthe two approaches produce inconsistent results.", "journal": ""}
{"doi": "10.48550/arXiv.2504.21097", "date": "2025-04-29", "title": "Nominal anti-unification", "authors": "Alexander Baumgartner, Temur Kutsia, Jordi Levy, Mateu Villaret", "abstract": "We study nominal anti-unification, which is concerned with computing least\ngeneral generalizations for given terms-in-context. In general, the problem\ndoes not have a least general solution, but if the set of atoms permitted in\ngeneralizations is finite, then there exists a least general generalization\nwhich is unique modulo variable renaming and $\\alpha$-equivalence. We present\nan algorithm that computes it. The algorithm relies on a subalgorithm that\nconstructively decides equivariance between two terms-in-context. We prove\nsoundness and completeness properties of both algorithms and analyze their\ncomplexity. Nominal anti-unification can be applied to problems were\ngeneralization of first-order terms is needed (inductive learning, clone\ndetection, etc.), but bindings are involved.", "journal": ""}
{"doi": "10.48550/arXiv.1808.07582", "date": "2018-08-22", "title": "TreeGAN: Syntax-Aware Sequence Generation with Generative Adversarial Networks", "authors": "Xinyue Liu, Xiangnan Kong, Lei Liu, Kuorong Chiang", "abstract": "Generative Adversarial Networks (GANs) have shown great capacity on image\ngeneration, in which a discriminative model guides the training of a generative\nmodel to construct images that resemble real images. Recently, GANs have been\nextended from generating images to generating sequences (e.g., poems, music and\ncodes). Existing GANs on sequence generation mainly focus on general sequences,\nwhich are grammar-free. In many real-world applications, however, we need to\ngenerate sequences in a formal language with the constraint of its\ncorresponding grammar. For example, to test the performance of a database, one\nmay want to generate a collection of SQL queries, which are not only similar to\nthe queries of real users, but also follow the SQL syntax of the target\ndatabase. Generating such sequences is highly challenging because both the\ngenerator and discriminator of GANs need to consider the structure of the\nsequences and the given grammar in the formal language. To address these\nissues, we study the problem of syntax-aware sequence generation with GANs, in\nwhich a collection of real sequences and a set of pre-defined grammatical rules\nare given to both discriminator and generator. We propose a novel GAN\nframework, namely TreeGAN, to incorporate a given Context-Free Grammar (CFG)\ninto the sequence generation process. In TreeGAN, the generator employs a\nrecurrent neural network (RNN) to construct a parse tree. Each generated parse\ntree can then be translated to a valid sequence of the given grammar. The\ndiscriminator uses a tree-structured RNN to distinguish the generated trees\nfrom real trees. We show that TreeGAN can generate sequences for any CFG and\nits generation fully conforms with the given syntax. Experiments on synthetic\nand real data sets demonstrated that TreeGAN significantly improves the quality\nof the sequence generation in context-free languages.", "journal": ""}
{"doi": "10.48550/arXiv.9810046", "date": "1998-10-14", "title": "Simple Formulas for Generating Chern-Simons Basic Invariant Polynomials by Repeated Exterior Differentiation", "authors": "C. C. Briggs", "abstract": "Simple formulas are given for generating Chern-Simons basic invariant\npolynomials by repeated exterior differentiation for n-dimensional\ndifferentiable manifolds having a general linear connection.", "journal": ""}
{"doi": "10.48550/arXiv.9810069", "date": "1998-10-21", "title": "Direct generation of spinning Einstein--Maxwell fields from static fields", "authors": "G\u00e9rard Cl\u00e9ment", "abstract": "I present a new method to generate rotating solutions of the\nEinstein--Maxwell equations from static solutions, and briefly discuss its\ngeneral properties.", "journal": ""}
{"doi": "10.48550/arXiv.9901007", "date": "1999-01-05", "title": "The Immortal Bel-Robinson Tensor", "authors": "S. Deser", "abstract": "We present some generalizations, and novel properties, of the Bel-Robinson\ntensor, in the context of constructing local invariants in D=11 supergravity.", "journal": "Gravitation and Relativity in general (World Pub 1999)"}
{"doi": "10.48550/arXiv.9905001", "date": "1999-05-03", "title": "Some General Expressions for the Coefficient of the 14th Chern Form", "authors": "C. C. Briggs", "abstract": "Some general expressions are given for the coefficient of the 14th Chern form\nin terms of the Riemann-Christoffel curvature tensor and some of its\nconcomitants (e.g., Pontrjagin's characteristic tensors) for n-dimensional\ndifferentiable manifolds having a general linear connection.", "journal": ""}
{"doi": "10.48550/arXiv.9905003", "date": "1999-05-01", "title": "A General Expression for the 14th Chern Form", "authors": "C. C. Briggs", "abstract": "A general expression is given for the 14th Chern form in terms of simple\npolynomial concomitants of the curvature 2-form for n-dimensional\ndifferentiable manifolds having a general linear connection.", "journal": ""}
{"doi": "10.48550/arXiv.9905004", "date": "1999-05-01", "title": "General Expressions for Chern Forms Up to the 13th Order in Curvature", "authors": "C. C. Briggs", "abstract": "General expressions are given for Chern forms up to the 13th order in\ncurvature in terms of simple polynomial concomitants of the curvature 2-form\nfor n-dimensional differentiable manifolds having a general linear connection.", "journal": ""}
{"doi": "10.48550/arXiv.0211073", "date": "2002-11-22", "title": "Two and Three parametric regular generalizations of spherically symmetric and axially symmetric metrics", "authors": "N. N. Popov", "abstract": "Regular generalizations of spherically and axially symmetric metrics and\ntheir properties are considered. Newton gravity law generalizations are reduced\nfor null geodesic.", "journal": ""}
{"doi": "10.48550/arXiv.0503087", "date": "2005-03-21", "title": "Energy Transport in the Vaidya System", "authors": "J. P. Krisch, E. N. Glass", "abstract": "Energy transport mechanisms can be generated by imposing relations between\nnull tetrad Ricci components. Several kinds of mass and density transport\ngenerated by these relations are studied for the generalized Vaidya system.", "journal": "J.Math.Phys. 46 (2005) 062501"}
{"doi": "10.48550/arXiv.0610219", "date": "2006-10-17", "title": "Comparison of Black Hole Generators for the LHC", "authors": "Douglas M. Gingrich", "abstract": "We compare Monte Carlo event generators dedicated to simulating the\nproduction and decay of extra-dimensional black holes at the Large Hadron\nCollider.", "journal": ""}
{"doi": "10.48550/arXiv.9901061", "date": "1999-01-15", "title": "On the Comultiplication in Quantum Affine Algebras", "authors": "Jesper Thoren", "abstract": "We express the comultiplication of the generators in Drinfelds second\nrealization of the quantum affine algebra U_q(sl_2^), induced by the\ncomultiplication of the generators in the Drinfeld-Jimbo realization of\nU_q(sl_2^) in terms of generating functions. Then we find explicit expressions\nfor the comultiplication of the generators.", "journal": ""}
{"doi": "10.48550/arXiv.0008114", "date": "2000-08-16", "title": "K-theory of C^*-algebras from one-dimensional generalized solenoids", "authors": "Inhyeop Yi", "abstract": "We compute the K-groups of C^*-algebras arising from one-dimensional\ngeneralized solenoids. The results show that Ruelle algebras from\none-dimensional generalized solenoids are one-dimensional generalizations of\nCuntz-Krieger algebras.", "journal": ""}
{"doi": "10.48550/arXiv.0404477", "date": "2004-04-27", "title": "C^*-algebras generated by scaling elements", "authors": "Takeshi Katsura", "abstract": "We investigate C^*-algebras generated by scaling elements. We generalize the\nWold decomposition and Coburn's theorem on isometries to scaling elements. We\nalso completely determine when the C^*-algebra generated by a scaling element\ncontains an infinite projection.", "journal": ""}
{"doi": "10.48550/arXiv.0406286", "date": "2004-06-15", "title": "A pure subalgebra of a finitely generated algebra is finitely generated", "authors": "Mitsuyasu Hashimoto", "abstract": "We prove the following. Let $R$ be a Noetherian ring, $B$ a finitely\ngenerated $R$-algebra, and $A$ a pure $R$-subalgebra of $B$. Then $A$ is\nfinitely generated over $R$.", "journal": "Proc. Amer. Math. Soc. 133 (2005), 2233--2235"}
{"doi": "10.48550/arXiv.0506109", "date": "2005-06-06", "title": "On o-minimality of extensions of $\\R$ by restricted generic smooth functions", "authors": "Alexei Grigoriev", "abstract": "It is shown that the extension of $\\R$ by a generic smooth function\nrestricted to the unit cube is o-minimal. The generalization to countably many\ngeneric smooth functions is indicated. Possible applications are sketched.", "journal": ""}
{"doi": "10.48550/arXiv.0509336", "date": "2005-09-15", "title": "Factors generated by $C^*$-finitely correlated states", "authors": "Hiromichi Ohno", "abstract": "We present several equivalent conditions for $C^*$-finitely correlated states\ndefined on the UHF algebras to be factor states and consider the types of\nfactors generated by them. Subfactors generated by generalized quantum Markov\nchains defined on the gauge-invariant parts of the UHF algebras are also\ndiscussed.", "journal": ""}
{"doi": "10.48550/arXiv.0510465", "date": "2005-10-21", "title": "On the residual solvability of generalized free products of finitely generated nilpotent groups", "authors": "D. Kahrobaei", "abstract": "In this paper we study the residual solvability of the generalized free\nproduct of finitely generated nilpotent groups. We show that these kinds of\nstructures are often residually solvable.", "journal": ""}
{"doi": "10.48550/arXiv.0511179", "date": "2005-11-07", "title": "On presentations of generalizations of braids with few generators", "authors": "Vladimir Vershinin", "abstract": "In his initial paper on braids E.Artin gave a presentation with two\ngenerators for an arbitrary braid group. We give analogues of this Artin's\npresentation for various generalizations of braids.", "journal": "Fundamental and Applied Mathematics. Vol. 11, No 4, 2005. 23-32"}
{"doi": "10.48550/arXiv.0703082", "date": "2007-03-03", "title": "Numerical Evaluation of Generalized Hypergeometric Functions for Degenerated Values of Parameters", "authors": "Yasushi Tamura", "abstract": "In this paper, we give an algorithm to generate connection formulas of\ngeneralized hypergeometric functions ${}_p F_{p-1}$ for degenerated values of\nparameters. We also show that these connection formulas give a fast method for\nnumerical evaluation of generalized hypergeometric functions near $\\infty$.", "journal": ""}
{"doi": "10.48550/arXiv.0606049", "date": "2006-06-20", "title": "Representations and Properties of Generalized $A_r$ Statistics", "authors": "Mohammed Daoud", "abstract": "A generalization of $A_r$ statistics is proposed and developed. The\ngeneralized $A_r$ quantum statistics is completely specified by a set of\nJacobson generators satisfying a set of triple algebraic relations.\nFock-Hilbert representations and Bargmann-Fock realizations are derived.", "journal": ""}
{"doi": "10.48550/arXiv.9703023", "date": "1997-03-19", "title": "Einstein's Violation of General Covariance", "authors": "Kenneth Dalton", "abstract": "Einstein rejected the differential law of energy-momentum conservation $\nT^{\\mu\\nu}_{;\\nu} = 0 $. In doing so, he violated the principle of general\ncovariance. Here, we prove the conservation law $ T^{\\mu\\nu}_{;\\nu} = 0 $ and\ndiscuss its significance for general relativity.", "journal": ""}
{"doi": "10.48550/arXiv.0007027", "date": "2000-07-11", "title": "It is the ambiguity. (But only three generations)", "authors": "A. Rivero", "abstract": "It is suggested that generations are linked to the need of calculating\ncurvature of space via a deformed or discrete calculus. Quantization would\nlimit the deformation, building three generations, and not four, as other\ninterpretation could imply.", "journal": ""}
{"doi": "10.48550/arXiv.0209107", "date": "2002-09-30", "title": "General Relativity Requires Absolute Space and Time", "authors": "Rainer W. Kuhne", "abstract": "We examine two far-reaching and somewhat heretic consequences of General\nRelativity. (i) It requires a cosmology which includes a preferred rest frame,\nabsolute space and time. (ii) A rotating universe and time travel are strict\nsolutions of General Relativity.", "journal": ""}
{"doi": "10.48550/arXiv.0710.3924", "date": "2007-10-21", "title": "Convexity properties for generalized moment maps I", "authors": "Yasufumi Nitta", "abstract": "We study generalized moment maps for a Hamiltonian action on a connected\ncompact $H$-twisted generalized complex manifold introduced by Lin and Tolman\nand prove the convexity and connectedness properties of the generalized moment\nmaps for a Hamiltonian torus action.", "journal": ""}
{"doi": "10.48550/arXiv.0805.1466", "date": "2008-05-10", "title": "The Iterative Simplicity of Basic Topological Operations", "authors": "Elemer E Rosinger", "abstract": "Semigroups generated by topological operations such as closure, interior or\nboundary are considered. It is noted that some of these semigroups are in\ngeneral finite and noncommutative. The problem is formulated whether they are\nalways finite.", "journal": ""}
{"doi": "10.48550/arXiv.0807.3706", "date": "2008-07-23", "title": "Book Review: The Genesis of General Relativity", "authors": "Donald Salisbury", "abstract": "This is a review of the four-volume set entitled The Genesis of General\nRelativity edited by Juergen Renn, Springer, Dordrecht (2007)", "journal": ""}
{"doi": "10.48550/arXiv.0809.4752", "date": "2008-09-27", "title": "Stability in Generalized Modified Gravity", "authors": "Sergio Zerbini", "abstract": "The stability issue of a large class of modified gravitational models is\ndiscussed with particular emphasis to de Sitter solutions. Three approaches are\nbriefly presented and the generalization to more general cases is mentioned.", "journal": "AIP Conf.Proc.1115:199-204,2009"}
{"doi": "10.48550/arXiv.0907.1201", "date": "2009-07-07", "title": "Generating Product Systems", "authors": "Nir Avni, Benjamin Weiss", "abstract": "Generalizing Krieger's finite generation theorem, we give conditions for an\nergodic system to be generated by a pair of partitions, each required to be\nmeasurable with respect to a given sub-algebra, and also required to have a\nfixed size.", "journal": ""}
{"doi": "10.48550/arXiv.0909.5250", "date": "2009-09-29", "title": "Genericity of Caustics and Wavefronts on an r-corner", "authors": "Takaharu Tsukada", "abstract": "We investigate genericities of reticular Lagrangian maps and reticular\nLegendrian maps in order to give generic classifications of caustics and\nwavefronts generated by a hypersurface germ without or with a boundary in a\nsmooth manifold.", "journal": ""}
{"doi": "10.48550/arXiv.0910.0987", "date": "2009-10-06", "title": "Symmetry properties of the generalized higher-order Euler polynomials", "authors": "Taekyun Kim", "abstract": "The purpose of this paper is to generalize this relation of symmetry between\nthe power sum polynomials and the generalized Euler polynomials to the relation\nbetween the power sum polynomials and the generalized higher-order Euler\npolynomials.", "journal": ""}
{"doi": "10.48550/arXiv.1006.1249", "date": "2010-06-07", "title": "Correction to \"Generalized Self-Shrinking Generator\"", "authors": "Amparo F\u00faster-Sabater", "abstract": "In this correspondence, it is given a correction to Theorem 4 in Y. Hu, and\nG. Xiao, \"Generalized Self-Shrinking Generator,\" IEEE Transactions on\nInformation Theory, vol. 50, No. 4, pp. 714-719, April 2004.", "journal": ""}
{"doi": "10.48550/arXiv.1008.0973", "date": "2010-08-05", "title": "Lectures on generalized geometry", "authors": "Nigel Hitchin", "abstract": "These are lecture notes mainly aimed at graduate students on selected aspects\nof generalized geometry: in particular generalized complex and Kaehler\nstructures and generalized holomorphic bundles. They are based on lectures\ngiven in March 2010 at the Chinese University of Hong Kong.", "journal": ""}
{"doi": "10.48550/arXiv.1103.4997", "date": "2011-03-25", "title": "A simple counterexample related to the Lie-Trotter product formula", "authors": "Claudia Canzi, Graziano Guerra", "abstract": "In this note a very simple example is given which shows that if the sum of\ntwo semigroup generators is itself a generator, the generated semigroup in\ngeneral can not be rapresented by the Lie-Trotter product formula.", "journal": ""}
{"doi": "10.48550/arXiv.1106.3737", "date": "2011-06-19", "title": "Minimal Diffeomorphisms cannot satisfy Generalized Dominated Splitting", "authors": "Xueting Tian", "abstract": "We introduce a new notion called generalized dominated splitting which is\nweaker than classical dominated splitting. We use this notion to generalize a\nresult of Zhang\\cite{Zh}: every diffeomorphism with nontrivial global\ngeneralized dominated splitting can not be minimal.", "journal": ""}
{"doi": "10.48550/arXiv.1109.5567", "date": "2011-09-26", "title": "Generalizations of Holder's and some related integral inequalities on fractal space", "authors": "Guang-Sheng Chen", "abstract": "Based on the local fractional calculus, we establish some new generalizations\nof H\\\"{o}lder's inequality. By using it, some results on the generalized\nintegral inequality in fractal space are investigated in detail.", "journal": ""}
{"doi": "10.48550/arXiv.1111.4066", "date": "2011-11-17", "title": "Determinantal and Permanental Representation of Generalized Fibonacci Polynomials", "authors": "Adem Sahin, Kenan Kaygisiz", "abstract": "In this paper, we give some determinantal and permanental representations of\nGeneralized Fibonacci Polynomials by using various Hessenberg matrices. These\nresults are general form of determinantal and permanental representations of k\nsequences of the generalized order-k Fibonacci and Pell numbers.", "journal": ""}
{"doi": "10.48550/arXiv.1212.6892", "date": "2012-12-31", "title": "Generic stability in dissipative generalized mechanics", "authors": "P. V\u00e1n", "abstract": "A theory of dissipative generalized continuum mechanics is presented in the\nframework of weakly nonlocal non-equilibrium thermodynamics. The evolution\nequation of microdeformation is obtained by thermodynamic principles.\nConditions of generic stability, the linear asymptotic stability of homogeneous\nequilibrium, is derived in a simple but representative case.", "journal": ""}
{"doi": "10.48550/arXiv.1407.5406", "date": "2014-07-21", "title": "Primely generated refinement monoids", "authors": "P. Ara, E. Pardo", "abstract": "We extend both Dobbertin's characterization of primely generated regular\nrefinement monoids and Pierce's characterization of primitive monoids to\ngeneral primely generated refinement monoids.", "journal": ""}
{"doi": "10.48550/arXiv.1508.03035", "date": "2015-08-10", "title": "Some properties of generalized $k$-Pell sequences", "authors": "Elijah Soria", "abstract": "The purpose of this paper is twofold; (1) to develop several identities for\nthe Generalized $k$-Pell sequence (including those of Binet, Catalan, Cassini,\nand d'Ocagne), and (2) to study applications of tridiagonal generating matrices\nfor the $k$-Pell and Generalized $k$-Pell sequences.", "journal": ""}
{"doi": "10.48550/arXiv.1508.04614", "date": "2015-08-19", "title": "Generalized Inheritance", "authors": "J. P. Krisch, E. N. Glass", "abstract": "Generalized inheritance is used with the almost-conformal Killing equation.\nExamples are the flat FRW, Kasner, and deSitter metrics. The volume changes in\nFRW while transitioning to a stiff fluid are discussed. An inheritance current\nis implicit in the generalized condition", "journal": ""}
{"doi": "10.48550/arXiv.1509.08675", "date": "2015-09-29", "title": "Fermionic quantum orthogonalizations I", "authors": "Gyula Lakos", "abstract": "We generalize classical orthogonalization procedures from real linear algebra\nto the setting of fermionic quantum (FQ) operations. In the case of the\nGram-Schmidt orthogonalization procedure, the generalization is easy. This,\nhowever, helps to obtain general information regarding FQ operations, and to\ngeneralize the symmetric orthogonalization procedure.", "journal": ""}
{"doi": "10.48550/arXiv.1511.07485", "date": "2015-11-23", "title": "An easy journey from Galilean to General Relativity", "authors": "Stephane Fay", "abstract": "We explain in a very concise way the basic principles that lead from Galilean\nto General Relativity to make them understandable to students or general\naudience, even with little knowledge in physics and mathematics.", "journal": ""}
{"doi": "10.48550/arXiv.1603.06739", "date": "2016-03-22", "title": "Some estimates for generalized commutators of rough fractional maximal and integral operators on generalized weighted Morrey spaces", "authors": "Ferit Gurbuz", "abstract": "In this paper, we establish BMO estimates for generalized commutators of\nrough fractional maximal and integral operators on generalized weighted Morrey\nspaces, respectively.", "journal": ""}
{"doi": "10.48550/arXiv.1605.01788", "date": "2016-05-05", "title": "Moduli of Linear Sections of a General Hypersurface", "authors": "Anand Patel", "abstract": "We investigate the global variation of moduli of linear sections of a general\nhypersurface. We prove a \"generic Torelli\" result for a large proportion of\ncases, and we obtain a complete picture of the global variation of moduli of\nline slices of a general hypersurface.", "journal": ""}
{"doi": "10.48550/arXiv.1605.02943", "date": "2016-05-10", "title": "Modified Stieltjes Transform and Generalized Convolutions", "authors": "Lev B Klebanov, Rasool Roozegar", "abstract": "Classical Stieltjes Transform is modified in a way to generalize both\nStieltjes and Fourier transforms. This transform allows to intro- duce new\nclasses of commutative and non-commutative generalized convolutions. Key words:\nStieltjes Transform; characteristic function; generalized convolution.", "journal": ""}
{"doi": "10.48550/arXiv.1606.01172", "date": "2016-05-13", "title": "Generic case completeness", "authors": "Alexei Miasnikov, Alexander Ushakov", "abstract": "In this note we introduce a notion of a generically (strongly generically)\nNP-complete problem and show that the randomized bounded version of the halting\nproblem is strongly generically NP-complete.", "journal": ""}
{"doi": "10.48550/arXiv.1701.03165", "date": "2017-01-11", "title": "A finitely generated group that does not satisfy the generalized Burghelea Conjecture", "authors": "A. Dranishnikov, M. Hull", "abstract": "We construct a finitely generated group that does not satisfy the generalized\nBurghelea conjecture.", "journal": ""}
{"doi": "10.48550/arXiv.1706.04565", "date": "2017-06-14", "title": "A Generalization of the Gauss-Kuzmin-Wirsing constant", "authors": "Peng Sun", "abstract": "We generalize the result of Wirsing on Gauss transformation to the\ngeneralized tranformation $T_p(x)=\\{\\cfrac{p}{x}\\}$ for any positive integer\n$p$. We give an estimate for the generalized Gauss-Kuzmin-Wirsing constant.", "journal": ""}
{"doi": "10.48550/arXiv.1709.08624", "date": "2017-09-24", "title": "Long Text Generation via Adversarial Training with Leaked Information", "authors": "Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, Jun Wang", "abstract": "Automatically generating coherent and semantically meaningful text has many\napplications in machine translation, dialogue systems, image captioning, etc.\nRecently, by combining with policy gradient, Generative Adversarial Nets (GAN)\nthat use a discriminative model to guide the training of the generative model\nas a reinforcement learning policy has shown promising results in text\ngeneration. However, the scalar guiding signal is only available after the\nentire text has been generated and lacks intermediate information about text\nstructure during the generative process. As such, it limits its success when\nthe length of the generated text samples is long (more than 20 words). In this\npaper, we propose a new framework, called LeakGAN, to address the problem for\nlong text generation. We allow the discriminative net to leak its own\nhigh-level extracted features to the generative net to further help the\nguidance. The generator incorporates such informative signals into all\ngeneration steps through an additional Manager module, which takes the\nextracted features of current generated words and outputs a latent vector to\nguide the Worker module for next-word generation. Our extensive experiments on\nsynthetic data and various real-world tasks with Turing test demonstrate that\nLeakGAN is highly effective in long text generation and also improves the\nperformance in short text generation scenarios. More importantly, without any\nsupervision, LeakGAN would be able to implicitly learn sentence structures only\nthrough the interaction between Manager and Worker.", "journal": ""}
{"doi": "10.48550/arXiv.1807.03923", "date": "2018-07-11", "title": "Generative Adversarial Networks with Decoder-Encoder Output Noise", "authors": "Guoqiang Zhong, Wei Gao, Yongbin Liu, Youzhao Yang", "abstract": "In recent years, research on image generation methods has been developing\nfast. The auto-encoding variational Bayes method (VAEs) was proposed in 2013,\nwhich uses variational inference to learn a latent space from the image\ndatabase and then generates images using the decoder. The generative\nadversarial networks (GANs) came out as a promising framework, which uses\nadversarial training to improve the generative ability of the generator.\nHowever, the generated pictures by GANs are generally blurry. The deep\nconvolutional generative adversarial networks (DCGANs) were then proposed to\nleverage the quality of generated images. Since the input noise vectors are\nrandomly sampled from a Gaussian distribution, the generator has to map from a\nwhole normal distribution to the images. This makes DCGANs unable to reflect\nthe inherent structure of the training data. In this paper, we propose a novel\ndeep model, called generative adversarial networks with decoder-encoder output\nnoise (DE-GANs), which takes advantage of both the adversarial training and the\nvariational Bayesain inference to improve the performance of image generation.\nDE-GANs use a pre-trained decoder-encoder architecture to map the random\nGaussian noise vectors to informative ones and pass them to the generator of\nthe adversarial networks. Since the decoder-encoder architecture is trained by\nthe same images as the generators, the output vectors could carry the intrinsic\ndistribution information of the original images. Moreover, the loss function of\nDE-GANs is different from GANs and DCGANs. A hidden-space loss function is\nadded to the adversarial loss function to enhance the robustness of the model.\nExtensive empirical results show that DE-GANs can accelerate the convergence of\nthe adversarial training process and improve the quality of the generated\nimages.", "journal": ""}
{"doi": "10.48550/arXiv.1808.04609", "date": "2018-08-14", "title": "The Optimal Constant in Generalized Hardy's Inequality", "authors": "Ying Li, Yong-hua Mao", "abstract": "We obtain the sharp factor of the two-sides estimates of the optimal constant\nin generalized Hardy's inequality with two general Borel measures on\n$\\mathbb{R}$, which generalizes and unifies the known continuous and discrete\ncases.", "journal": ""}
{"doi": "10.48550/arXiv.1810.07268", "date": "2018-10-16", "title": "On a closed form of rational generating functions for polynomials", "authors": "Goubi Mouloud", "abstract": "Our goal in this work is to found a closed form for rational generat- ing\nfunctions, these generate a various families of polynomials and generalized\npolynomials, in order to get the general recursive formula satisfied by these\npolynomials.", "journal": ""}
{"doi": "10.48550/arXiv.1908.10020", "date": "2019-08-26", "title": "Again, random numbers fall mainly in the planes: xorshift128+ generators", "authors": "Hiroshi Haramoto, Makoto Matsumoto", "abstract": "Xorshift128+ are pseudo random number generators with eight sets of\nparameters. Some of them are standard generators in many platforms, such as\nJavaScript V8 Engine. We show that in the 3D plots generated by this method,\npoints concentrate on planes, ruining the randomness.", "journal": ""}
{"doi": "10.48550/arXiv.2006.08074", "date": "2020-06-15", "title": "Generalized Jacobson's lemma for generalized Drazin inverses", "authors": "Huanyin Chen, Marjan Sheibani", "abstract": "We present new generalized Jacobson's lemma for generalized Drazin inverses.\nThis extend the main results on g-Drazin inverse of Yan, Zeng and Zhu (Linear\n$\\&$ Multilinear Algebra, {\\bf 68}(2020), 81--93).", "journal": ""}
{"doi": "10.48550/arXiv.1101.3686", "date": "2011-01-19", "title": "Generalized Timelike Mannheim Curves in Minkowski space-time $E_1^4$", "authors": "M. Akyi\u01e7it, S. Ersoy, i. \u00f6Zg\u00fcR, M. Tosun", "abstract": "We give a definition of generalized timelike Mannheim curve in Minkowski\nspace-time $E_1^4$. The necessary and sufficient conditions for the generalized\ntimelike Mannheim curve obtain. We show some characterizations of generalized\nMannheim curve.", "journal": ""}
{"doi": "10.48550/arXiv.1311.3813", "date": "2013-11-15", "title": "On Generating Permutations Under User-Defined Constraints", "authors": "Dhruvil Badani", "abstract": "In this paper, a method to generate permutations of a string under a set of\nconstraints decided by the user is presented. The required permutations are\ngenerated without generating all the permutations.", "journal": ""}
{"doi": "10.48550/arXiv.1604.02881", "date": "2016-04-11", "title": "Weak and strong structures and the $T_{3.5}$ property for generalized topological spaces", "authors": "E. Makai, Jr., E. Peyghan, B. Samadi", "abstract": "We investigate weak and strong structures for generalized topological spaces,\namong others products, sums, subspaces, quotients, and the complete lattice of\ngeneralized topologies on a given set. Also we introduce $T_{3.5}$ generalized\ntopological spaces and give a necessary and sufficient condition for a\ngeneralized topological space to be a $T_{3.5}$ space: they are exactly the\nsubspaces of powers of a certain natural generalized topology on $[0,1]$. For\nspaces with at least two points here we can have even dense subspaces. Also,\n$T_{3.5}$ generalized topological spaces are exactly the dense subspaces of\ncompact $T_4$ generalized topological spaces. We show that normality is\nproductive for generalized topological spaces. For compact generalized\ntopological spaces we prove the analogue of the Tychonoff product theorem. We\nprove that also Lindel\\\"ofness (and $\\kappa $-compactness) is productive for\ngeneralized topological spaces. On any ordered set we introduce a generalized\ntopology and determine the continuous maps between two such generalized\ntopological spaces: for $|X|, |Y| \\ge 2$ they are the monotonous maps\ncontinuous between the respective order topologies. We investigate the relation\nof sums and subspaces of generalized topological spaces to ways of defining\ngeneralized topological spaces.", "journal": ""}
{"doi": "10.48550/arXiv.1809.05989", "date": "2018-09-17", "title": "FermiNets: Learning generative machines to generate efficient neural networks via generative synthesis", "authors": "Alexander Wong, Mohammad Javad Shafiee, Brendan Chwyl, Francis Li", "abstract": "The tremendous potential exhibited by deep learning is often offset by\narchitectural and computational complexity, making widespread deployment a\nchallenge for edge scenarios such as mobile and other consumer devices. To\ntackle this challenge, we explore the following idea: Can we learn generative\nmachines to automatically generate deep neural networks with efficient network\narchitectures? In this study, we introduce the idea of generative synthesis,\nwhich is premised on the intricate interplay between a generator-inquisitor\npair that work in tandem to garner insights and learn to generate highly\nefficient deep neural networks that best satisfies operational requirements.\nWhat is most interesting is that, once a generator has been learned through\ngenerative synthesis, it can be used to generate not just one but a large\nvariety of different, unique highly efficient deep neural networks that satisfy\noperational requirements. Experimental results for image classification,\nsemantic segmentation, and object detection tasks illustrate the efficacy of\ngenerative synthesis in producing generators that automatically generate highly\nefficient deep neural networks (which we nickname FermiNets) with higher model\nefficiency and lower computational costs (reaching >10x more efficient and\nfewer multiply-accumulate operations than several tested state-of-the-art\nnetworks), as well as higher energy efficiency (reaching >4x improvements in\nimage inferences per joule consumed on a Nvidia Tegra X2 mobile processor). As\nsuch, generative synthesis can be a powerful, generalized approach for\naccelerating and improving the building of deep neural networks for on-device\nedge scenarios.", "journal": ""}
{"doi": "10.48550/arXiv.1910.11420", "date": "2019-10-24", "title": "Some Gruss-type Inequalities Using Generalized Katugampola Fractional Integral", "authors": "Tariq A. Aljaaidi, Deepak B. Pachpatte", "abstract": "The main objective of this paper is to obtain generalization of some\nGruss-type inequalities in case of functional bounds by using a generalized\nKatugampola fractional integral.", "journal": ""}
{"doi": "10.48550/arXiv.2105.00129", "date": "2021-05-01", "title": "WfChef: Automated Generation of Accurate Scientific Workflow Generators", "authors": "Tain\u00e3 Coleman, Henri Casanova, Rafael Ferreira da Silva", "abstract": "Scientific workflow applications have become mainstream and their automated\nand efficient execution on large-scale compute platforms is the object of\nextensive research and development. For these efforts to be successful, a solid\nexperimental methodology is needed to evaluate workflow algorithms and systems.\nA foundation for this methodology is the availability of realistic workflow\ninstances. Dozens of workflow instances for a few scientific applications are\navailable in public repositories. While these are invaluable, they are limited:\nworkflow instances are not available for all application scales of interest. To\naddress this limitation, previous work has developed generators of synthetic,\nbut representative, workflow instances of arbitrary scales. These generators\nare popular, but implementing them is a manual, labor-intensive process that\nrequires expert application knowledge. As a result, these generators only\ntarget a handful of applications, even though hundreds of applications use\nworkflows in production.\n  In this work, we present WfChef, a framework that fully automates the process\nof constructing a synthetic workflow generator for any scientific application.\nBased on an input set of workflow instances, WfChef automatically produces a\nsynthetic workflow generator. We define and evaluate several metrics for\nquantifying the realism of the generated workflows. Using these metrics, we\ncompare the realism of the workflows generated by WfChef generators to that of\nthe workflows generated by the previously available, hand-crafted generators.\nWe find that the WfChef generators not only require zero development effort\n(because it is automatically produced), but also generate workflows that are\nmore realistic than those generated by hand-crafted generators.", "journal": ""}
{"doi": "10.48550/arXiv.1402.6777", "date": "2014-02-27", "title": "A general existence and uniqueness result on multidimensional BSDEs", "authors": "ShaoYa Xu, ShengJun Fan", "abstract": "This paper establishes a new existence and uniqueness result of solutions for\nmultidimensional backward stochastic differential equations (BSDEs) whose\ngenerators satisfy a weak monotonicity condition and a general growth condition\nin $y$, which generalizes the corresponding results in [2], [3] and [5].", "journal": ""}
{"doi": "10.48550/arXiv.1707.01568", "date": "2017-07-05", "title": "Sheaves of nonlinear generalized function spaces", "authors": "Eduard A. Nigsch, Andreas Debrouwere", "abstract": "We provide a framework for the construction of diffeomorphism invariant\nsheaves of nonlinear generalized functions spaces. As an application, global\nalgebras of generalized functions for distributions on manifolds and\ndiffeomorphism invariant algebras of generalized functions for\nultradistributions are constructed.", "journal": ""}
{"doi": "10.48550/arXiv.2001.09323", "date": "2020-01-25", "title": "Identity for generalized Bernoulli polynomials", "authors": "Redha Chellal, Farid Bencherif, Mohamed Mehbali", "abstract": "In this paper, we establish an identity for Bernoulli's generalized\npolynomials. We deduce generalizations for many relations involving classical\nBernoulli numbers or polynomials. In particular, we generalize a recent Gessel\nidentity.", "journal": ""}
{"doi": "10.48550/arXiv.2002.04910", "date": "2020-02-12", "title": "Semigroups for which every right congruence of finite index is finitely generated", "authors": "Craig Miller", "abstract": "We call a semigroup $S$ f-noetherian if every right congruence of finite\nindex on $S$ is finitely generated. We prove that every finitely generated\nsemigroup is f-noetherian, and investigate whether the properties of being\nf-noetherian and being finitely generated coincide for various semigroup\nclasses.", "journal": ""}
{"doi": "10.48550/arXiv.2009.07734", "date": "2020-09-16", "title": "TreeGAN: Incorporating Class Hierarchy into Image Generation", "authors": "Ruisi Zhang, Luntian Mou, Pengtao Xie", "abstract": "Conditional image generation (CIG) is a widely studied problem in computer\nvision and machine learning. Given a class, CIG takes the name of this class as\ninput and generates a set of images that belong to this class. In existing CIG\nworks, for different classes, their corresponding images are generated\nindependently, without considering the relationship among classes. In\nreal-world applications, the classes are organized into a hierarchy and their\nhierarchical relationships are informative for generating high-fidelity images.\nIn this paper, we aim to leverage the class hierarchy for conditional image\ngeneration. We propose two ways of incorporating class hierarchy: prior control\nand post constraint. In prior control, we first encode the class hierarchy,\nthen feed it as a prior into the conditional generator to generate images. In\npost constraint, after the images are generated, we measure their consistency\nwith the class hierarchy and use the consistency score to guide the training of\nthe generator. Based on these two ideas, we propose a TreeGAN model which\nconsists of three modules: (1) a class hierarchy encoder (CHE) which takes the\nhierarchical structure of classes and their textual names as inputs and learns\nan embedding for each class; the embedding captures the hierarchical\nrelationship among classes; (2) a conditional image generator (CIG) which takes\nthe CHE-generated embedding of a class as input and generates a set of images\nbelonging to this class; (3) a consistency checker which performs hierarchical\nclassification on the generated images and checks whether the generated images\nare compatible with the class hierarchy; the consistency score is used to guide\nthe CIG to generate hierarchy-compatible images. Experiments on various\ndatasets demonstrate the effectiveness of our method.", "journal": ""}
{"doi": "10.48550/arXiv.2112.02126", "date": "2021-12-02", "title": "Quo Vadis, Mathematical General Relativity?", "authors": "Piotr T. Chrusciel", "abstract": "A review of selected topics in mathematical general relativity", "journal": ""}
{"doi": "10.48550/arXiv.2205.06722", "date": "2022-05-13", "title": "Proofs For Progressively Generalized Fibonacci Identities Using Maximal Independent Sets of Tree Graphs", "authors": "Connor Oxenhorn", "abstract": "This paper generalizes a graph theoretic proof technique for a Fibonacci\nidentity proposed by Lee Knisley Sanders, and explores characteristics of these\ngeneralized theorems ad infinitum.", "journal": ""}
{"doi": "10.48550/arXiv.2210.04178", "date": "2022-10-09", "title": "On generalized $\\unicode{x00A3}$-cotorsion LCA groups", "authors": "Aliakbar Alijani", "abstract": "A locally compact abelian group $G$ is called a generalized\n$\\unicode{x00A3}$-cotosion group if $G$ contains an open\n$\\unicode{x00A3}$-cotosion subgroup $H$ such that $G/H$ is a cotorsion group.\nIn this paper, we determine the generalized $\\unicode{x00A3}$-cotorsion LCA\ngroups.", "journal": ""}
{"doi": "10.48550/arXiv.2210.06998", "date": "2022-10-13", "title": "DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Generation Models", "authors": "Zeyang Sha, Zheng Li, Ning Yu, Yang Zhang", "abstract": "Text-to-image generation models that generate images based on prompt\ndescriptions have attracted an increasing amount of attention during the past\nfew months. Despite their encouraging performance, these models raise concerns\nabout the misuse of their generated fake images. To tackle this problem, we\npioneer a systematic study on the detection and attribution of fake images\ngenerated by text-to-image generation models. Concretely, we first build a\nmachine learning classifier to detect the fake images generated by various\ntext-to-image generation models. We then attribute these fake images to their\nsource models, such that model owners can be held responsible for their models'\nmisuse. We further investigate how prompts that generate fake images affect\ndetection and attribution. We conduct extensive experiments on four popular\ntext-to-image generation models, including DALL$\\cdot$E 2, Stable Diffusion,\nGLIDE, and Latent Diffusion, and two benchmark prompt-image datasets. Empirical\nresults show that (1) fake images generated by various models can be\ndistinguished from real ones, as there exists a common artifact shared by fake\nimages from different models; (2) fake images can be effectively attributed to\ntheir source models, as different models leave unique fingerprints in their\ngenerated images; (3) prompts with the ``person'' topic or a length between 25\nand 75 enable models to generate fake images with higher authenticity. All\nfindings contribute to the community's insight into the threats caused by\ntext-to-image generation models. We appeal to the community's consideration of\nthe counterpart solutions, like ours, against the rapidly-evolving fake image\ngeneration.", "journal": ""}
{"doi": "10.48550/arXiv.2302.02594", "date": "2023-02-06", "title": "Generating Subsurface Earth Models using Discrete Representation Learning and Deep Autoregressive Network", "authors": "Jungang Chen, Chung-Kan Huang, Jose F. Delgado, Siddharth Misra", "abstract": "Subsurface earth models (referred to as geo-models) are crucial for\ncharacterizing complex subsurface systems. Multiple-point statistics are\ncommonly used to generate geo-models. In this paper, a deep-learning-based\ngenerative method is developed as an alternative to the traditional Geomodel\ngeneration procedure. The generative method comprises two deep-learning models,\nnamely the hierarchical vector-quantized variational autoencoder (VQ-VAE-2) and\nPixelSNAIL autoregressive model. Based on the principle of neural discrete\nrepresentation learning, the VQ-VAE-2 learns to massively compress the\nGeomodels to extract the low-dimensional, discrete latent representation\ncorresponding to each Geomodel. Following that, PixelSNAIL uses the deep\nautoregressive network to learn the prior distribution of the latent codes. For\nthe purpose of Geomodel generation, PixelSNAIL samples from the newly learned\nprior distribution of latent codes, and then the decoder of the VQ-VAE-2\nconverts the newly sampled latent code to a newly constructed geo-model.\nPixelSNAIL can be used for unconditional or conditional geo-model generation.\nIn an unconditional generation, the generative workflow generates an ensemble\nof geo-models without any constraint. On the other hand, in the conditional\ngeo-model generation, the generative workflow generates an ensemble of\ngeo-models similar to a user-defined source image, which ultimately facilitates\nthe control and manipulation of the generated geo-models. To better construct\nthe fluvial channels in the geo-models, the perceptual loss is implemented in\nthe VQ-VAE-2 model instead of the traditional mean squared error loss. At a\nspecific compression ratio, the quality of multi-attribute geo-model generation\nis better than that of single-attribute geo-model generation.", "journal": ""}
{"doi": "10.48550/arXiv.2303.02906", "date": "2023-03-06", "title": "MotionVideoGAN: A Novel Video Generator Based on the Motion Space Learned from Image Pairs", "authors": "Jingyuan Zhu, Huimin Ma, Jiansheng Chen, Jian Yuan", "abstract": "Video generation has achieved rapid progress benefiting from high-quality\nrenderings provided by powerful image generators. We regard the video synthesis\ntask as generating a sequence of images sharing the same contents but varying\nin motions. However, most previous video synthesis frameworks based on\npre-trained image generators treat content and motion generation separately,\nleading to unrealistic generated videos. Therefore, we design a novel framework\nto build the motion space, aiming to achieve content consistency and fast\nconvergence for video generation. We present MotionVideoGAN, a novel video\ngenerator synthesizing videos based on the motion space learned by pre-trained\nimage pair generators. Firstly, we propose an image pair generator named\nMotionStyleGAN to generate image pairs sharing the same contents and producing\nvarious motions. Then we manage to acquire motion codes to edit one image in\nthe generated image pairs and keep the other unchanged. The motion codes help\nus edit images within the motion space since the edited image shares the same\ncontents with the other unchanged one in image pairs. Finally, we introduce a\nlatent code generator to produce latent code sequences using motion codes for\nvideo generation. Our approach achieves state-of-the-art performance on the\nmost complex video dataset ever used for unconditional video generation\nevaluation, UCF101.", "journal": ""}
{"doi": "10.48550/arXiv.2303.17126", "date": "2023-03-30", "title": "The $\u03b2$-symplectic critical surfaces in Hermite surfaces", "authors": "Yongpin Zhu", "abstract": "In \\cite{Zhu}, the authors give a general definition of K\\\"ahler angle. There\nare many results about K\\\"ahler angle one can try to generalize to the general\ncase. In this paper, we focus on the symplectic critical surfaces in Hermite\nsurfaces which is a generalization of \\cite{HL1} or \\cite{HLS1}.", "journal": ""}
{"doi": "10.48550/arXiv.2304.03516", "date": "2023-04-07", "title": "Generative Recommendation: Towards Next-generation Recommender Paradigm", "authors": "Wenjie Wang, Xinyu Lin, Fuli Feng, Xiangnan He, Tat-Seng Chua", "abstract": "Recommender systems typically retrieve items from an item corpus for\npersonalized recommendations. However, such a retrieval-based recommender\nparadigm faces two limitations: 1) the human-generated items in the corpus\nmight fail to satisfy the users' diverse information needs, and 2) users\nusually adjust the recommendations via inefficient passive feedback, e.g.,\nclicks. Nowadays, AI-Generated Content (AIGC) has revealed significant success,\noffering the potential to overcome these limitations: 1) generative AI can\nproduce personalized items to satisfy users' information needs, and 2) the\nnewly emerged large language models significantly reduce the efforts of users\nto precisely express information needs via natural language instructions. In\nthis light, the boom of AIGC points the way towards the next-generation\nrecommender paradigm with two new objectives: 1) generating personalized\ncontent through generative AI, and 2) integrating user instructions to guide\ncontent generation.\n  To this end, we propose a novel Generative Recommender paradigm named\nGeneRec, which adopts an AI generator to personalize content generation and\nleverages user instructions. Specifically, we pre-process users' instructions\nand traditional feedback via an instructor to output the generation guidance.\nGiven the guidance, we instantiate the AI generator through an AI editor and an\nAI creator to repurpose existing items and create new items. Eventually,\nGeneRec can perform content retrieval, repurposing, and creation to satisfy\nusers' information needs. Besides, to ensure the trustworthiness of the\ngenerated items, we emphasize various fidelity checks. Moreover, we provide a\nroadmap to envision future developments of GeneRec and several domain-specific\napplications of GeneRec with potential research tasks. Lastly, we study the\nfeasibility of implementing AI editor and AI creator on micro-video generation.", "journal": ""}
{"doi": "10.48550/arXiv.2310.04000", "date": "2023-10-06", "title": "Generalized Eta-Einstein and $(\u03ba,\u03bc)$-structures", "authors": "Philippe Rukimbira", "abstract": "Generalized $(\\kappa ,\\mu )$ structures occur in dimension 3 only. In this\ndimension 3, only K-contact structures can occur as generalized Eta-Einstein.\nOn closed manifolds, Eta-Einstein, K-contact structures which are not\nD-homothetic to Einstein structures are almost regular. We also construct\nexamples of compact, generalized Jacobi $(\\kappa ,\\mu )$-structures.", "journal": ""}
{"doi": "10.48550/arXiv.2311.05625", "date": "2023-08-28", "title": "Systems of functional equations, the generalized shift, and modelling pathological functions", "authors": "Symon Serbenyuk", "abstract": "The present article is devoted to one class of generalizations of the Salem\nfunctions. To construct such functions by systems of functional equations, the\ngeneralized shift operator is used.", "journal": ""}
{"doi": "10.48550/arXiv.2401.15030", "date": "2024-01-26", "title": "On the generalization capacity of neural networks during generic multimodal reasoning", "authors": "Takuya Ito, Soham Dan, Mattia Rigotti, James Kozloski, Murray Campbell", "abstract": "The advent of the Transformer has led to the development of large language\nmodels (LLM), which appear to demonstrate human-like capabilities. To assess\nthe generality of this class of models and a variety of other base neural\nnetwork architectures to multimodal domains, we evaluated and compared their\ncapacity for multimodal generalization. We introduce a multimodal\nquestion-answer benchmark to evaluate three specific types of\nout-of-distribution (OOD) generalization performance: distractor generalization\n(generalization in the presence of distractors), systematic compositional\ngeneralization (generalization to new task permutations), and productive\ncompositional generalization (generalization to more complex tasks structures).\nWe found that across model architectures (e.g., RNNs, Transformers, Perceivers,\netc.), models with multiple attention layers, or models that leveraged\ncross-attention mechanisms between input domains, fared better. Our positive\nresults demonstrate that for multimodal distractor and systematic\ngeneralization, either cross-modal attention or models with deeper attention\nlayers are key architectural features required to integrate multimodal inputs.\nOn the other hand, neither of these architectural features led to productive\ngeneralization, suggesting fundamental limitations of existing architectures\nfor specific types of multimodal generalization. These results demonstrate the\nstrengths and limitations of specific architectural components underlying\nmodern neural models for multimodal reasoning. Finally, we provide Generic COG\n(gCOG), a configurable benchmark with several multimodal generalization splits,\nfor future studies to explore.", "journal": ""}
{"doi": "10.48550/arXiv.2404.04203", "date": "2024-04-05", "title": "On a generalization of compact and connected spaces", "authors": "Nebojsa Elez, Ognjen Papaz", "abstract": "In this paper we will give two different natural generalizations of compact\nspaces and connected spaces simultaneously. We will show that these\ngeneralizations coincide for the subspaces of the real line and that they\ndiffer for subspaces of plane.", "journal": ""}
{"doi": "10.48550/arXiv.2404.08878", "date": "2024-04-13", "title": "Generative AI Agent for Next-Generation MIMO Design: Fundamentals, Challenges, and Vision", "authors": "Zhe Wang, Jiayi Zhang, Hongyang Du, Ruichen Zhang, Dusit Niyato, Bo Ai, Khaled B. Letaief", "abstract": "Next-generation multiple input multiple output (MIMO) is expected to be\nintelligent and scalable. In this paper, we study generative artificial\nintelligence (AI) agent-enabled next-generation MIMO design. Firstly, we\nprovide an overview of the development, fundamentals, and challenges of the\nnext-generation MIMO. Then, we propose the concept of the generative AI agent,\nwhich is capable of generating tailored and specialized contents with the aid\nof large language model (LLM) and retrieval augmented generation (RAG). Next,\nwe comprehensively discuss the features and advantages of the generative AI\nagent framework. More importantly, to tackle existing challenges of\nnext-generation MIMO, we discuss generative AI agent-enabled next-generation\nMIMO design, from the perspective of performance analysis, signal processing,\nand resource allocation. Furthermore, we present two compelling case studies\nthat demonstrate the effectiveness of leveraging the generative AI agent for\nperformance analysis in complex configuration scenarios. These examples\nhighlight how the integration of generative AI agents can significantly enhance\nthe analysis and design of next-generation MIMO systems. Finally, we discuss\nimportant potential research future directions.", "journal": ""}
{"doi": "10.48550/arXiv.2405.13360", "date": "2024-05-22", "title": "How to Trace Latent Generative Model Generated Images without Artificial Watermark?", "authors": "Zhenting Wang, Vikash Sehwag, Chen Chen, Lingjuan Lyu, Dimitris N. Metaxas, Shiqing Ma", "abstract": "Latent generative models (e.g., Stable Diffusion) have become more and more\npopular, but concerns have arisen regarding potential misuse related to images\ngenerated by these models. It is, therefore, necessary to analyze the origin of\nimages by inferring if a particular image was generated by a specific latent\ngenerative model. Most existing methods (e.g., image watermark and model\nfingerprinting) require extra steps during training or generation. These\nrequirements restrict their usage on the generated images without such extra\noperations, and the extra required operations might compromise the quality of\nthe generated images. In this work, we ask whether it is possible to\neffectively and efficiently trace the images generated by a specific latent\ngenerative model without the aforementioned requirements. To study this\nproblem, we design a latent inversion based method called LatentTracer to trace\nthe generated images of the inspected model by checking if the examined images\ncan be well-reconstructed with an inverted latent input. We leverage gradient\nbased latent inversion and identify a encoder-based initialization critical to\nthe success of our approach. Our experiments on the state-of-the-art latent\ngenerative models, such as Stable Diffusion, show that our method can\ndistinguish the images generated by the inspected model and other images with a\nhigh accuracy and efficiency. Our findings suggest the intriguing possibility\nthat today's latent generative generated images are naturally watermarked by\nthe decoder used in the source models. Code:\nhttps://github.com/ZhentingWang/LatentTracer.", "journal": ""}
{"doi": "10.48550/arXiv.2409.04835", "date": "2024-09-07", "title": "Generalized paracomplex structures on generalized reflector spaces", "authors": "Johann Davidov", "abstract": "Non-trivial examples of generalized paracomplex structures (in the sense of\nthe generalized geometry \\`a la Hitchin) are constructed applying the twistor\nspace construction scheme.", "journal": ""}
{"doi": "10.48550/arXiv.2410.03655", "date": "2024-10-04", "title": "Geometric Representation Condition Improves Equivariant Molecule Generation", "authors": "Zian Li, Cai Zhou, Xiyuan Wang, Xingang Peng, Muhan Zhang", "abstract": "Recent advances in molecular generative models have demonstrated great\npromise for accelerating scientific discovery, particularly in drug design.\nHowever, these models often struggle to generate high-quality molecules,\nespecially in conditional scenarios where specific molecular properties must be\nsatisfied. In this work, we introduce GeoRCG, a general framework to improve\nmolecular generative models by integrating geometric representation conditions\nwith provable theoretical guarantees. We decompose the generation process into\ntwo stages: first, generating an informative geometric representation; second,\ngenerating a molecule conditioned on the representation. Compared with\nsingle-stage generation, the easy-to-generate representation in the first stage\nguides the second stage generation toward a high-quality molecule in a\ngoal-oriented way. Leveraging EDM and SemlaFlow as base generators, we observe\nsignificant quality improvements in unconditional molecule generation on the\nwidely used QM9 and GEOM-DRUG datasets. More notably, in the challenging\nconditional molecular generation task, our framework achieves an average 50\\%\nperformance improvement over state-of-the-art approaches, highlighting the\nsuperiority of conditioning on semantically rich geometric representations.\nFurthermore, with such representation guidance, the number of diffusion steps\ncan be reduced to as small as 100 while largely preserving the generation\nquality achieved with 1,000 steps, thereby significantly reducing the\ngeneration iterations needed.", "journal": ""}
{"doi": "10.48550/arXiv.2412.18337", "date": "2024-12-24", "title": "The Value of AI-Generated Metadata for UGC Platforms: Evidence from a Large-scale Field Experiment", "authors": "Xinyi Zhang, Chenshuo Sun, Renyu Zhang, Khim-Yong Goh", "abstract": "AI-generated content (AIGC), such as advertisement copy, product\ndescriptions, and social media posts, is becoming ubiquitous in business\npractices. However, the value of AI-generated metadata, such as titles, remains\nunclear on user-generated content (UGC) platforms. To address this gap, we\nconducted a large-scale field experiment on a leading short-video platform in\nAsia to provide about 1 million users access to AI-generated titles for their\nuploaded videos. Our findings show that the provision of AI-generated titles\nsignificantly boosted content consumption, increasing valid watches by 1.6% and\nwatch duration by 0.9%. When producers adopted these titles, these increases\njumped to 7.1% and 4.1%, respectively. This viewership-boost effect was largely\nattributed to the use of this generative AI (GAI) tool increasing the\nlikelihood of videos having a title by 41.4%. The effect was more pronounced\nfor groups more affected by metadata sparsity. Mechanism analysis revealed that\nAI-generated metadata improved user-video matching accuracy in the platform's\nrecommender system. Interestingly, for a video for which the producer would\nhave posted a title anyway, adopting the AI-generated title decreased its\nviewership on average, implying that AI-generated titles may be of lower\nquality than human-generated ones. However, when producers chose to co-create\nwith GAI and significantly revised the AI-generated titles, the videos\noutperformed their counterparts with either fully AI-generated or\nhuman-generated titles, showcasing the benefits of human-AI co-creation. This\nstudy highlights the value of AI-generated metadata and human-AI metadata\nco-creation in enhancing user-content matching and content consumption for UGC\nplatforms.", "journal": ""}
{"doi": "10.48550/arXiv.2412.18530", "date": "2024-12-24", "title": "Characterizations of Language Generation With Breadth", "authors": "Alkis Kalavasis, Anay Mehrotra, Grigoris Velegkas", "abstract": "We study language generation in the limit, introduced by Kleinberg and\nMullainathan [KM24], building on classical works of Gold [Gol67] and Angluin\n[Ang79]. [KM24] proposed an algorithm that generates strings from any countable\nlanguage collection in the limit. While their algorithm eventually outputs\nstrings from the target language $K$, it sacrifices breadth, i.e., the ability\nto generate all strings in $K$. A key open question in [KM24] is whether this\ntrade-off between consistency and breadth is inherrent.\n  Recent works proposed different notions of consistent generation with\nbreadth. Kalavasis, Mehrotra, and Velegkas [KVM24] introduced three\ndefinitions: generation with exact breadth, approximate breadth, and\nunambiguous generation. Concurrently and independently, Charikar and Pabbaraju\n[CP24a] proposed exhaustive generation. Both works examined when generation\nwith these notions of breadth is possible.\n  Building on [CP24a, KVM24], we fully characterize language generation for\nthese notions and their natural combinations. For exact breadth, we provide an\nunconditional lower bound, removing a technical condition from [KVM24] and\nextending the result of [CP24a] that holds for specific collections of\nlanguages. We show that generation with exact breadth is characterized by\nAngluin's condition for identification. We further introduce a weaker version\nof Angluin's condition that tightly characterizes both approximate breadth and\nexhaustive generation, proving their equivalence. Additionally, we show that\nunambiguous generation is also characterized by Angluin's condition as a\nspecial case of a broader result. Finally, we strengthen [KVM24] by giving\nunconditional lower bounds for stable generators, showing that Angluin's\ncondition characterizes the previous breadth notions for stable generators.\nThis shows a separation between stable and unstable generation with approximate\nbreadth.", "journal": ""}
{"doi": "10.48550/arXiv.2501.11340", "date": "2025-01-20", "title": "GenVidBench: A Challenging Benchmark for Detecting AI-Generated Video", "authors": "Zhenliang Ni, Qiangyu Yan, Mouxiao Huang, Tianning Yuan, Yehui Tang, Hailin Hu, Xinghao Chen, Yunhe Wang", "abstract": "The rapid advancement of video generation models has made it increasingly\nchallenging to distinguish AI-generated videos from real ones. This issue\nunderscores the urgent need for effective AI-generated video detectors to\nprevent the dissemination of false information through such videos. However,\nthe development of high-performance generative video detectors is currently\nimpeded by the lack of large-scale, high-quality datasets specifically designed\nfor generative video detection. To this end, we introduce GenVidBench, a\nchallenging AI-generated video detection dataset with several key advantages:\n1) Cross Source and Cross Generator: The cross-generation source mitigates the\ninterference of video content on the detection. The cross-generator ensures\ndiversity in video attributes between the training and test sets, preventing\nthem from being overly similar. 2) State-of-the-Art Video Generators: The\ndataset includes videos from 8 state-of-the-art AI video generators, ensuring\nthat it covers the latest advancements in the field of video generation. 3)\nRich Semantics: The videos in GenVidBench are analyzed from multiple dimensions\nand classified into various semantic categories based on their content. This\nclassification ensures that the dataset is not only large but also diverse,\naiding in the development of more generalized and effective detection models.\nWe conduct a comprehensive evaluation of different advanced video generators\nand present a challenging setting. Additionally, we present rich experimental\nresults including advanced video classification models as baselines. With the\nGenVidBench, researchers can efficiently develop and evaluate AI-generated\nvideo detection models. Datasets and code are available at\nhttps://genvidbench.github.io.", "journal": ""}
{"doi": "10.48550/arXiv.2501.18410", "date": "2025-01-30", "title": "On the generalized Poisson and transposed Poisson algebras", "authors": "Askar Dzhumadil'daev, Nurlan Ismailov, Farukh Mashurov", "abstract": "We provide the polynomial identities of algebras that are both generalized\nPoisson algebras and transposed Poisson algebras. We establish defining\nidentities via single operation for generalized Poisson algebras and prove that\nIto's theorem holds for generalized Poisson algebras.", "journal": ""}
{"doi": "10.48550/arXiv.2505.14671", "date": "2025-05-20", "title": "UniCTokens: Boosting Personalized Understanding and Generation via Unified Concept Tokens", "authors": "Ruichuan An, Sihan Yang, Renrui Zhang, Zijun Shen, Ming Lu, Gaole Dai, Hao Liang, Ziyu Guo, Shilin Yan, Yulin Luo, Bocheng Zou, Chaoqun Yang, Wentao Zhang", "abstract": "Personalized models have demonstrated remarkable success in understanding and\ngenerating concepts provided by users. However, existing methods use separate\nconcept tokens for understanding and generation, treating these tasks in\nisolation. This may result in limitations for generating images with complex\nprompts. For example, given the concept $\\langle bo\\rangle$, generating\n\"$\\langle bo\\rangle$ wearing its hat\" without additional textual descriptions\nof its hat. We call this kind of generation personalized knowledge-driven\ngeneration. To address the limitation, we present UniCTokens, a novel framework\nthat effectively integrates personalized information into a unified vision\nlanguage model (VLM) for understanding and generation. UniCTokens trains a set\nof unified concept tokens to leverage complementary semantics, boosting two\npersonalized tasks. Moreover, we propose a progressive training strategy with\nthree stages: understanding warm-up, bootstrapping generation from\nunderstanding, and deepening understanding from generation to enhance mutual\nbenefits between both tasks. To quantitatively evaluate the unified VLM\npersonalization, we present UnifyBench, the first benchmark for assessing\nconcept understanding, concept generation, and knowledge-driven generation.\nExperimental results on UnifyBench indicate that UniCTokens shows competitive\nperformance compared to leading methods in concept understanding, concept\ngeneration, and achieving state-of-the-art results in personalized\nknowledge-driven generation. Our research demonstrates that enhanced\nunderstanding improves generation, and the generation process can yield\nvaluable insights into understanding. Our code and dataset will be released at:\n\\href{https://github.com/arctanxarc/UniCTokens}{https://github.com/arctanxarc/UniCTokens}.", "journal": ""}
{"doi": "10.48550/arXiv.2505.18716", "date": "2025-05-24", "title": "Generic singularities of affine distance functions and plane congruences", "authors": "Igor Chagas Santos", "abstract": "In this paper, we classify the generic singularities of 2-parameter plane\ncongruences in $\\mathbb{R^4}$ and the generic singularities of affine normal\nplane congruences. We also study the generic singularities of the family of\naffine distance functions.", "journal": ""}
{"doi": "10.48550/arXiv.9512103", "date": "1995-12-01", "title": "Generalization of Clauses under Implication", "authors": "P. Idestam-Almquist", "abstract": "In the area of inductive learning, generalization is a main operation, and\nthe usual definition of induction is based on logical implication. Recently\nthere has been a rising interest in clausal representation of knowledge in\nmachine learning. Almost all inductive learning systems that perform\ngeneralization of clauses use the relation theta-subsumption instead of\nimplication. The main reason is that there is a well-known and simple technique\nto compute least general generalizations under theta-subsumption, but not under\nimplication. However generalization under theta-subsumption is inappropriate\nfor learning recursive clauses, which is a crucial problem since recursion is\nthe basic program structure of logic programs. We note that implication between\nclauses is undecidable, and we therefore introduce a stronger form of\nimplication, called T-implication, which is decidable between clauses. We show\nthat for every finite set of clauses there exists a least general\ngeneralization under T-implication. We describe a technique to reduce\ngeneralizations under implication of a clause to generalizations under\ntheta-subsumption of what we call an expansion of the original clause. Moreover\nwe show that for every non-tautological clause there exists a T-complete\nexpansion, which means that every generalization under T-implication of the\nclause is reduced to a generalization under theta-subsumption of the expansion.", "journal": "Journal of Artificial Intelligence Research, Vol 3, (1995),\n  467-489"}
{"doi": "10.48550/arXiv.9702013", "date": "1997-02-17", "title": "Differential Geometry of generalized almost quaternionic structures, 1", "authors": "V. F. Kirichenko, O. E Arseneva", "abstract": "The fibre bundles adjoint to generalized almost quaternionic structures are\nstudied. The most important classes of generalized almost quaternionic\nmanifolds are considered.", "journal": ""}
{"doi": "10.48550/arXiv.0407103", "date": "2004-07-27", "title": "Minisuperspace Approach of Generalized Gravitational Models", "authors": "Guido Cognola, Sergio Zerbini", "abstract": "Motivated by the dark energy issue, the minisuperspace approach for general\nrelativistic cosmological theories is outlined.", "journal": ""}
{"doi": "10.48550/arXiv.0611001", "date": "2006-10-31", "title": "On solutions of a Heavenly equations and their generalizations", "authors": "Valerii Dryuma", "abstract": "Some solutions of the Heavenly equations and their generalizations are\nconsidered", "journal": ""}
{"doi": "10.48550/arXiv.0007192", "date": "2000-07-31", "title": "The Hodge Conjecture for general Prym varieties", "authors": "Indranil Biswas, Kapil H. Paranjape", "abstract": "The space of Hodge cycles of the general Prym variety is proved to be\ngenerated by its Neron-Severi group.", "journal": ""}
{"doi": "10.48550/arXiv.0112281", "date": "2001-12-27", "title": "Words restricted by 3-letter generalized multipermutation patterns", "authors": "Alexander Burstein, Toufik Mansour", "abstract": "We find exact formulas and/or generating functions for the number of words\navoiding 3-letter generalized multipermutation patterns and find which of them\nare equally avoided.", "journal": ""}
{"doi": "10.48550/arXiv.0309249", "date": "2003-09-15", "title": "Minimal generating sets for the first syzygies of a monomial ideal", "authors": "John A. Eagon", "abstract": "Two minimal generating sets of the first syzygies of a monomial ideal are\nproduced, given the minimal generating set of the ideal.", "journal": ""}
{"doi": "10.48550/arXiv.0409421", "date": "2004-09-22", "title": "Statistics on Wreath Products", "authors": "Michael Fire", "abstract": "We present methods of calculating statistics generating functions over the\ncolored permutation groups, and generalizing known theorems from the symmetric\ngroups to general colored permutations groups.", "journal": ""}
{"doi": "10.48550/arXiv.0512172", "date": "2005-12-08", "title": "A generalization of an inequality from IMO 2005", "authors": "Nikolai Nikolov", "abstract": "A generalization of an inequality from IMO is proven.", "journal": "Mathematics Plus, Vol. 13 (51), No 3 ( 2005), 62-64 (in Bulgarian)"}
{"doi": "10.48550/arXiv.0606472", "date": "2006-06-19", "title": "Generalized 2-vector spaces and general linear 2-groups", "authors": "Josep Elgueta", "abstract": "In this paper a notion of {\\it generalized 2-vector space} is introduced\nwhich includes Kapranov and Voevodsky 2-vector spaces. Various kinds of\ngeneralized 2-vector spaces are considered and examples are given. The\nexistence of non free generalized 2-vector spaces and of generalized 2-vector\nspaces which are non Karoubian (hence, non abelian) categories is discussed,\nand it is shown how any generalized 2-vector space can be identified with a\nfull subcategory of an (abelian) functor category with values in the category\n${\\bf VECT}_K$ of (possibly infinite dimensional) vector spaces. The\ncorresponding general linear 2-groups $\\mathbb{G}\\mathbb{L}({\\bf\nVect}_K[\\mathcal{C}])$ are considered. Specifically, it is shown that\n$\\mathbb{G}\\mathbb{L}({\\bf Vect}_K[\\mathcal{C}])$ always contains as a (non\nfull) sub-2-group the 2-group ${\\sf Equiv}_{Cat}(\\mathcal{C})$ (hence, for\nfinite categories $\\mathcal{C}$, they contain {\\sl Weyl sub-2-groups} analogous\nto usual Weyl subgroups of the general linear groups), and\n$\\mathbb{G}\\mathbb{L}({\\bf Vect}_K[\\mathcal{C}])$ is explicitly computed (up to\nequivalence) in a special case of generalized 2-vector spaces which include\nthose of Kapranov and Voevodsky. Finally, other important drawbacks of the\nnotion of generalized 2-vector space, besides the fact that it is in general a\nnon Karoubian category, are also mentioned at the end of the paper.", "journal": "Journal of Pure and Applied Algebra 212 (2008) 2069-2091"}
{"doi": "10.48550/arXiv.0608158", "date": "2006-08-07", "title": "Towards a general theory of unprojection", "authors": "Stavros Papadakis", "abstract": "We propose a general definition of unprojection, and prove that it indeed\ngeneralizes previous efforts.", "journal": ""}
{"doi": "10.48550/arXiv.0702794", "date": "2007-02-26", "title": "Real Analytic Generalized Functions", "authors": "S. Pilipovi\u0107, D. Scarpalezos, V. Valmorin", "abstract": "Real analytic generalized functions are investigated as well as the analytic\nsingular support and analytic wave front of a generalized function in\n$\\mathcal{G}(\\Omega)$ are introduced and described.", "journal": ""}
{"doi": "10.48550/arXiv.0011041", "date": "2000-11-17", "title": "The generation of gravitational waves", "authors": "A. Loinger", "abstract": "A proof that the generation of gravitational waves is physically impossible.", "journal": ""}
{"doi": "10.48550/arXiv.0704.1350", "date": "2007-04-11", "title": "Specialized computer algebra system for application in general relativity", "authors": "S. Tertychniy", "abstract": "A brief characteristic of the specialized computer algebra system GRG_EC\nintended for symbolic computations in the field of general relativity is given.", "journal": ""}
{"doi": "10.48550/arXiv.0707.1361", "date": "2007-07-10", "title": "A generalization of the Shestakov-Umirbaev inequality", "authors": "Shigeru Kuroda", "abstract": "We give a generalization of the Shestakov-Umirbaev inequality which plays an\nimportant role in their solution of the tame generators conjecture.", "journal": ""}
{"doi": "10.48550/arXiv.0711.1145", "date": "2007-11-07", "title": "A critique of general relativity", "authors": "Wasley S. Krogdahl", "abstract": "General relativity's successes and limitations are compared to those of\nspecial relativity.", "journal": ""}
{"doi": "10.48550/arXiv.0711.2341", "date": "2007-11-15", "title": "Conservation laws for a general Lorentz connection", "authors": "Nikodem J. Poplawski", "abstract": "We derive conservation laws for energy-momentum (canonical and dynamical) and\nangular momentum for a general Lorentz connection.", "journal": ""}
{"doi": "10.48550/arXiv.0907.4670", "date": "2009-07-27", "title": "Invariant generators for generalized distributions", "authors": "Madeleine Jotz, Tudor S. Ratiu", "abstract": "The existence of invariant generators for distributions satisfying a\ncompatibility condition with the symmetry algebra is proved.", "journal": ""}
{"doi": "10.48550/arXiv.1007.0096", "date": "2010-07-01", "title": "A Group-Pertmutation Algorithm to Solve the Generalized SUDOKU", "authors": "Florentin Smarandache", "abstract": "In this short paper we present an algorithm for finding a solution to a\ngeneralized Sudoku.", "journal": "Recreatii matematice, Ia\\'Ei, Romania, 20-22, Nr.1/2011"}
{"doi": "10.48550/arXiv.1007.3440", "date": "2010-07-13", "title": "A Generalization of the Idea of Disjunction", "authors": "Kerry M. Soileau", "abstract": "We generalize the concept of disjunction.", "journal": ""}
{"doi": "10.48550/arXiv.1011.1044", "date": "2010-11-04", "title": "Generalized Hamming schemes", "authors": "Chris Godsil", "abstract": "We introduce a class of association schemes that generalizes the Hamming\nscheme. We derive generating functions for their eigenvalues, and use these to\nobtain a version of MacWilliams theorem.", "journal": ""}
{"doi": "10.48550/arXiv.1011.2190", "date": "2010-11-09", "title": "Topological properties of regular generalized function algebras", "authors": "Hans Vernaeve", "abstract": "We investigate density of various subalgebras of regular generalized\nfunctions in the special Colombeau algebra of generalized functions.", "journal": "Monatsh. Math. (2014) 173: 433-439"}
{"doi": "10.48550/arXiv.1011.3989", "date": "2010-11-17", "title": "Maximum entropy generation in open systems: the Fourth Law?", "authors": "Umberto Lucia", "abstract": "This paper develops an analytical and rigorous formulation of the maximum\nentropy generation principle. The result is suggested as the Fourth Law of\nThermodynamics.", "journal": ""}
{"doi": "10.48550/arXiv.1104.0524", "date": "2011-04-04", "title": "Hodge theory on generalized normal crossing varieties", "authors": "Yujiro Kawamata", "abstract": "We generalize some results in Hodge theory to generalized normal crossing\nvarieties.", "journal": ""}
{"doi": "10.48550/arXiv.1203.1435", "date": "2012-03-07", "title": "On a (\u03b2,q)-generalized Fisher information and inequalities involving q-Gaussian distributions", "authors": "J. -F. Bercher", "abstract": "In the present paper, we would like to draw attention to a possible\ngeneralized Fisher information that fits well in the formalism of nonextensive\nthermostatistics. This generalized Fisher information is defined for densities\non $\\mathbb{R}^{n}.$ Just as the maximum R\\'enyi or Tsallis entropy subject to\nan elliptic moment constraint is a generalized q-Gaussian, we show that the\nminimization of the generalized Fisher information also leads a generalized\nq-Gaussian. This yields a generalized Cram\\'er-Rao inequality. In addition, we\nshow that the generalized Fisher information naturally pops up in a simple\ninequality that links the generalized entropies, the generalized Fisher\ninformation and an elliptic moment. Finally, we give an extended Stam\ninequality. In this series of results, the extremal functions are the\ngeneralized q-Gaussians. Thus, these results complement the classical\ncharacterization of the generalized q-Gaussian and introduce a generalized\nFisher information as a new information measure in nonextensive\nthermostatistics.", "journal": "J. Math. Phys. 53, 063303 (2012)"}
{"doi": "10.48550/arXiv.1501.02901", "date": "2015-01-13", "title": "Functionally $\u03c3$-discrete mappings and a generalization of Banach's theorem", "authors": "Olena Karlova", "abstract": "We present $\\sigma$-strongly functionally discrete mappings which expand the\nclass of $\\sigma$-discrete mappings and generalize Banach's theorem on\nanalytically representable functions", "journal": ""}
{"doi": "10.48550/arXiv.1502.06466", "date": "2014-03-26", "title": "On vector field generated by the Hopf map $S^3$ on $S^2$", "authors": "Valerii Dryuma", "abstract": "The examples of solutions of the system of differential equations generated\nby the Hopf map $S^3\\rightarrow S^2$ are constructed. Their properties are\ndiscussed.", "journal": ""}
{"doi": "10.48550/arXiv.1508.06883", "date": "2015-08-21", "title": "Global approximation theorems for general gamma type operators", "authors": "Alok Kumar", "abstract": "In this paper, we obtained some global approximation results for general\nGamma type operators.", "journal": ""}
{"doi": "10.48550/arXiv.1602.06017", "date": "2016-02-19", "title": "On a generalization of the Gauss's formula", "authors": "Marius Tarnauceanu", "abstract": "In this paper we study a group theoretical generalization of the well-known\nGauss's formula that uses the generalized Euler's totient function introduced\nin [11].", "journal": ""}
{"doi": "10.48550/arXiv.1611.04940", "date": "2016-11-15", "title": "A generalization of the b-function lemma", "authors": "Sam Raskin", "abstract": "We establish some cohomological bounds in D-module theory that are known in\nthe holonomic case and folklore in general. The method rests on a\ngeneralization of the b-function lemma for non-holonomic D-modules.", "journal": ""}
{"doi": "10.48550/arXiv.1611.06624", "date": "2016-11-21", "title": "Temporal Generative Adversarial Nets with Singular Value Clipping", "authors": "Masaki Saito, Eiichi Matsumoto, Shunta Saito", "abstract": "In this paper, we propose a generative model, Temporal Generative Adversarial\nNets (TGAN), which can learn a semantic representation of unlabeled videos, and\nis capable of generating videos. Unlike existing Generative Adversarial Nets\n(GAN)-based methods that generate videos with a single generator consisting of\n3D deconvolutional layers, our model exploits two different types of\ngenerators: a temporal generator and an image generator. The temporal generator\ntakes a single latent variable as input and outputs a set of latent variables,\neach of which corresponds to an image frame in a video. The image generator\ntransforms a set of such latent variables into a video. To deal with\ninstability in training of GAN with such advanced networks, we adopt a recently\nproposed model, Wasserstein GAN, and propose a novel method to train it stably\nin an end-to-end manner. The experimental results demonstrate the effectiveness\nof our methods.", "journal": ""}
{"doi": "10.48550/arXiv.1706.07068", "date": "2017-06-21", "title": "CAN: Creative Adversarial Networks, Generating \"Art\" by Learning About Styles and Deviating from Style Norms", "authors": "Ahmed Elgammal, Bingchen Liu, Mohamed Elhoseiny, Marian Mazzone", "abstract": "We propose a new system for generating art. The system generates art by\nlooking at art and learning about style; and becomes creative by increasing the\narousal potential of the generated art by deviating from the learned styles. We\nbuild over Generative Adversarial Networks (GAN), which have shown the ability\nto learn to generate novel images simulating a given distribution. We argue\nthat such networks are limited in their ability to generate creative products\nin their original design. We propose modifications to its objective to make it\ncapable of generating creative art by maximizing deviation from established\nstyles and minimizing deviation from art distribution. We conducted experiments\nto compare the response of human subjects to the generated art with their\nresponse to art created by artists. The results show that human subjects could\nnot distinguish art generated by the proposed system from art generated by\ncontemporary artists and shown in top art fairs. Human subjects even rated the\ngenerated images higher on various scales.", "journal": ""}
{"doi": "10.48550/arXiv.1712.00684", "date": "2017-12-03", "title": "GAGAN: Geometry-Aware Generative Adversarial Networks", "authors": "Jean Kossaifi, Linh Tran, Yannis Panagakis, Maja Pantic", "abstract": "Deep generative models learned through adversarial training have become\nincreasingly popular for their ability to generate naturalistic image textures.\nHowever, aside from their texture, the visual appearance of objects is\nsignificantly influenced by their shape geometry; information which is not\ntaken into account by existing generative models. This paper introduces the\nGeometry-Aware Generative Adversarial Networks (GAGAN) for incorporating\ngeometric information into the image generation process. Specifically, in GAGAN\nthe generator samples latent variables from the probability space of a\nstatistical shape model. By mapping the output of the generator to a canonical\ncoordinate frame through a differentiable geometric transformation, we enforce\nthe geometry of the objects and add an implicit connection from the prior to\nthe generated object. Experimental results on face generation indicate that the\nGAGAN can generate realistic images of faces with arbitrary facial attributes\nsuch as facial expression, pose, and morphology, that are of better quality\nthan current GAN-based methods. Our method can be used to augment any existing\nGAN architecture and improve the quality of the images generated.", "journal": ""}
{"doi": "10.48550/arXiv.1802.04880", "date": "2018-02-13", "title": "Generic Existence of Independent Families", "authors": "Michael Perron", "abstract": "We apply the concept of generic existence to p-point, q, and selective\nindependent families that complements and emulates the ultrafilter generic\nexistence results from Canjar and Ketonen.", "journal": ""}
{"doi": "10.48550/arXiv.1905.01977", "date": "2019-05-06", "title": "Generalized connections, spinors, and integrability of generalized structures on Courant algebroids", "authors": "Vicente Cort\u00e9s, Liana David", "abstract": "We present a characterization, in terms of torsion-free generalized\nconnections, for the integrability of various generalized structures\n(generalized almost complex structures, generalized almost hypercomplex\nstructures, generalized almost Hermitian structures and generalized almost\nhyper-Hermitian structures) defined on Courant algebroids. We develop a new,\nself-contained, approach for the theory of Dirac generating operators on\nregular Courant algebroids with scalar product of neutral signature. As an\napplication we provide a criterion for the integrability of generalized almost\nHermitian structures (G, \\mathcal J) and generalized almost hyper-Hermitian\nstructures (G, \\mathcal J_{1}, \\mathcal J_{2}, \\mathcal J_{3}) defined on a\nregular Courant algebroid E with scalar product of neutral signature, in terms\nof canonically defined differential operators on spinor bundles associated to\nE_{\\pm} (the subbundles of E determined by the generalized metric G).", "journal": ""}
{"doi": "10.48550/arXiv.1909.10067", "date": "2019-09-22", "title": "Congruences for Generalized Frobenius Partitions of Nonzero Row Difference", "authors": "Kelsey Scott", "abstract": "We extend George Andrew's general principle for counting generalized\nFrobenius partitions to include arrays with nonzero row difference and\nestablish some congruences for these arrays.", "journal": ""}
{"doi": "10.48550/arXiv.1503.03847", "date": "2015-03-12", "title": "Ideals generated by $2$--minors of Hankel matrices", "authors": "Faryal Chaudhry, Ayesha Asloob Qureshi", "abstract": "We study ideals generated by $2$--minors of generic Hankel matrices.", "journal": ""}
{"doi": "10.48550/arXiv.1801.01775", "date": "2017-12-19", "title": "Mercer's inequality for h-convex functions", "authors": "M. W. Alomari", "abstract": "A generalization of Mercer inequality for h-convex function is presented. As\napplication, a weighted generalization of triangle inequality is given.", "journal": ""}
{"doi": "10.48550/arXiv.1805.02481", "date": "2018-05-07", "title": "MEGAN: Mixture of Experts of Generative Adversarial Networks for Multimodal Image Generation", "authors": "David Keetae Park, Seungjoo Yoo, Hyojin Bahng, Jaegul Choo, Noseong Park", "abstract": "Recently, generative adversarial networks (GANs) have shown promising\nperformance in generating realistic images. However, they often struggle in\nlearning complex underlying modalities in a given dataset, resulting in\npoor-quality generated images. To mitigate this problem, we present a novel\napproach called mixture of experts GAN (MEGAN), an ensemble approach of\nmultiple generator networks. Each generator network in MEGAN specializes in\ngenerating images with a particular subset of modalities, e.g., an image class.\nInstead of incorporating a separate step of handcrafted clustering of multiple\nmodalities, our proposed model is trained through an end-to-end learning of\nmultiple generators via gating networks, which is responsible for choosing the\nappropriate generator network for a given condition. We adopt the categorical\nreparameterization trick for a categorical decision to be made in selecting a\ngenerator while maintaining the flow of the gradients. We demonstrate that\nindividual generators learn different and salient subparts of the data and\nachieve a multiscale structural similarity (MS-SSIM) score of 0.2470 for CelebA\nand a competitive unsupervised inception score of 8.33 in CIFAR-10.", "journal": ""}
{"doi": "10.48550/arXiv.1805.06760", "date": "2018-05-11", "title": "Topology and Higher Concurrencies", "authors": "Nils A. Baas", "abstract": "We formulate a general approach to higher concurrencies in general and neural\ncodes in particular, and suggest how the higher order aspects may be dealt with\nin using topology.", "journal": ""}
{"doi": "10.48550/arXiv.1809.06739", "date": "2018-09-17", "title": "A general explicit form for higher order approximations for fractional derivatives and its consequences", "authors": "W. A. Gunarathna, H. M. Nasir, W. B. Daundasekera", "abstract": "A general explicit form for generating functions for approximating fractional\nderivatives is derived. To achieve this, an equivalent characterisation for\nconsistency and order of approximations established on a general generating\nfunction is used to form a linear system of equations with Vandermonde matrix\nfor the coefficients of the generating function which is in the form of power\nof a polynomial. This linear system is solved for the coefficients of the\npolynomial in the generating function. These generating functions completely\ncharacterise Gr\\\"unwald type approximations with shifts and order of accuracy.\nIncidentally, the constructed generating functions happen to be generalization\nof the previously known Lubich forms of generating functions without shift. As\na consquence, a general explicit form for new finite difference formulas for\ninteger-order derivatives with any order of accuracy are derived.", "journal": "Applied Numerical Mathematics Volume 143, September 2019, Pages\n  51-60"}
{"doi": "10.48550/arXiv.2003.13686", "date": "2020-03-29", "title": "A Brief Survey on Fibrewise General Topology", "authors": "Giorgio Nordo", "abstract": "We present some recent results in Fibrewise General Topology with special\nregard to the theory of Tychonoff compactifications of mappings. Several open\nproblems are also proposed.", "journal": ""}
{"doi": "10.48550/arXiv.1609.09133", "date": "2016-09-28", "title": "Analysis of the p-adic q-Volkenborn Integrals: an approach to Apostol-type special numbers and polynomials", "authors": "Yilmaz Simsek", "abstract": "By applying the p-adic q-Volkenborn Integrals including the bosonic and the\nfermionic p-adic integrals on p-adic integers, we define generating functions,\nattached to the Dirichlet character, for the generalized Apostol-Bernoulli\nnumbers and polynomials, the generalized Apostol-Euler numbers and polynomials,\ngeneralized Apostol-Daehee numbers and polynomials, and also generalized\nApostol-Changhee numbers and polynomials. We investigate some properties of\nthese numbers and polynomials with their generating functions. By using these\ngenerating functions and their functional equation, we give some identities and\nrelations including the generalized Apostol-Daehee and Apostol-Changhee numbers\nand polynomials, the Stirling numbers, the Bernoulli numbers of the second\nkind, Frobenious-Euler polynomials, the generalized Bernoulli numbers and the\ngeneralized Euler numbers and the Frobenious-Euler polynomials. By using the\nbosonic and the fermionic p-adic integrals, we derive integral represantations\nfor the generalized Apostol-type Daehee numbers and the generalized\nApostol-type Changhee numbers.", "journal": "Cogent Mathematics, 3: 1269393 (2016)"}
{"doi": "10.48550/arXiv.1906.09324", "date": "2019-06-15", "title": "Automatic Conditional Generation of Personalized Social Media Short Texts", "authors": "Ziwen Wang, Jie Wang, Haiqian Gu, Fei Su, Bojin Zhuang", "abstract": "Automatic text generation has received much attention owing to rapid\ndevelopment of deep neural networks. In general, text generation systems based\non statistical language model will not consider anthropomorphic\ncharacteristics, which results in machine-like generated texts. To fill the\ngap, we propose a conditional language generation model with Big Five\nPersonality (BFP) feature vectors as input context, which writes human-like\nshort texts. The short text generator consists of a layer of long short memory\nnetwork (LSTM), where a BFP feature vector is concatenated as one part of input\nfor each cell. To enable supervised training generation model, a text\nclassification model based convolution neural network (CNN) has been used to\nprepare BFP-tagged Chinese micro-blog corpora. Validated by a BFP linguistic\ncomputational model, our generated Chinese short texts exhibit discriminative\npersonality styles, which are also syntactically correct and semantically\nsmooth with appropriate emoticons. With combination of natural language\ngeneration with psychological linguistics, our proposed BFP-dependent text\ngeneration model can be widely used for individualization in machine\ntranslation, image caption, dialogue generation and so on.", "journal": "In: Geng X., Kang BH. (eds) PRICAI 2018: Trends in Artificial\n  Intelligence"}
{"doi": "10.48550/arXiv.1911.12140", "date": "2019-11-26", "title": "Generalized shift operator of certain encodings of real numbers", "authors": "Symon Serbenyuk", "abstract": "The present article is devoted to the investigation of some properties of the\ngeneralized shift operator of numbers represented in terms of numeral systems\nwith a variable alphabet.", "journal": ""}
{"doi": "10.48550/arXiv.2002.03082", "date": "2020-02-08", "title": "RL-Duet: Online Music Accompaniment Generation Using Deep Reinforcement Learning", "authors": "Nan Jiang, Sheng Jin, Zhiyao Duan, Changshui Zhang", "abstract": "This paper presents a deep reinforcement learning algorithm for online\naccompaniment generation, with potential for real-time interactive\nhuman-machine duet improvisation. Different from offline music generation and\nharmonization, online music accompaniment requires the algorithm to respond to\nhuman input and generate the machine counterpart in a sequential order. We cast\nthis as a reinforcement learning problem, where the generation agent learns a\npolicy to generate a musical note (action) based on previously generated\ncontext (state). The key of this algorithm is the well-functioning reward\nmodel. Instead of defining it using music composition rules, we learn this\nmodel from monophonic and polyphonic training data. This model considers the\ncompatibility of the machine-generated note with both the machine-generated\ncontext and the human-generated context. Experiments show that this algorithm\nis able to respond to the human part and generate a melodic, harmonic and\ndiverse machine part. Subjective evaluations on preferences show that the\nproposed algorithm generates music pieces of higher quality than the baseline\nmethod.", "journal": ""}
{"doi": "10.48550/arXiv.2005.08526", "date": "2020-05-18", "title": "Unconditional Audio Generation with Generative Adversarial Networks and Cycle Regularization", "authors": "Jen-Yu Liu, Yu-Hua Chen, Yin-Cheng Yeh, Yi-Hsuan Yang", "abstract": "In a recent paper, we have presented a generative adversarial network\n(GAN)-based model for unconditional generation of the mel-spectrograms of\nsinging voices. As the generator of the model is designed to take a\nvariable-length sequence of noise vectors as input, it can generate\nmel-spectrograms of variable length. However, our previous listening test shows\nthat the quality of the generated audio leaves room for improvement. The\npresent paper extends and expands that previous work in the following aspects.\nFirst, we employ a hierarchical architecture in the generator to induce some\nstructure in the temporal dimension. Second, we introduce a cycle\nregularization mechanism to the generator to avoid mode collapse. Third, we\nevaluate the performance of the new model not only for generating singing\nvoices, but also for generating speech voices. Evaluation result shows that new\nmodel outperforms the prior one both objectively and subjectively. We also\nemploy the model to unconditionally generate sequences of piano and violin\nmusic and find the result promising. Audio examples, as well as the code for\nimplementing our model, will be publicly available online upon paper\npublication.", "journal": ""}
{"doi": "10.48550/arXiv.2008.05856", "date": "2020-08-13", "title": "Recurrent Deconvolutional Generative Adversarial Networks with Application to Text Guided Video Generation", "authors": "Hongyuan Yu, Yan Huang, Lihong Pi, Liang Wang", "abstract": "This paper proposes a novel model for video generation and especially makes\nthe attempt to deal with the problem of video generation from text\ndescriptions, i.e., synthesizing realistic videos conditioned on given texts.\nExisting video generation methods cannot be easily adapted to handle this task\nwell, due to the frame discontinuity issue and their text-free generation\nschemes. To address these problems, we propose a recurrent deconvolutional\ngenerative adversarial network (RD-GAN), which includes a recurrent\ndeconvolutional network (RDN) as the generator and a 3D convolutional neural\nnetwork (3D-CNN) as the discriminator. The RDN is a deconvolutional version of\nconventional recurrent neural network, which can well model the long-range\ntemporal dependency of generated video frames and make good use of conditional\ninformation. The proposed model can be jointly trained by pushing the RDN to\ngenerate realistic videos so that the 3D-CNN cannot distinguish them from real\nones. We apply the proposed RD-GAN to a series of tasks including conventional\nvideo generation, conditional video generation, video prediction and video\nclassification, and demonstrate its effectiveness by achieving well\nperformance.", "journal": ""}
{"doi": "10.48550/arXiv.2009.09735", "date": "2020-09-21", "title": "About isolators of finitely generated subgroups of free groups", "authors": "David Moldavanskii", "abstract": "It is known that in any free group the isolator of finitely generated\nsubgroup is finitely generated subgroup. A very simple proof of this statement\nis proposed.", "journal": ""}
{"doi": "10.48550/arXiv.2012.03449", "date": "2020-12-07", "title": "Efficient Heuristic Generation for Robot Path Planning with Recurrent Generative Model", "authors": "Zhaoting Li, Jiankun Wang, Max Q. -H. Meng", "abstract": "Robot path planning is difficult to solve due to the contradiction between\noptimality of results and complexity of algorithms, even in 2D environments. To\nfind an optimal path, the algorithm needs to search all the state space, which\ncosts a lot of computation resource. To address this issue, we present a novel\nrecurrent generative model (RGM) which generates efficient heuristic to reduce\nthe search efforts of path planning algorithm. This RGM model adopts the\nframework of general generative adversarial networks (GAN), which consists of a\nnovel generator that can generate heuristic by refining the outputs recurrently\nand two discriminators that check the connectivity and safety properties of\nheuristic. We test the proposed RGM module in various 2D environments to\ndemonstrate its effectiveness and efficiency. The results show that the RGM\nsuccessfully generates appropriate heuristic in both seen and new unseen maps\nwith a high accuracy, demonstrating the good generalization ability of this\nmodel. We also compare the rapidly-exploring random tree star (RRT*) with\ngenerated heuristic and the conventional RRT* in four different maps, showing\nthat the generated heuristic can guide the algorithm to find both initial and\noptimal solution in a faster and more efficient way.", "journal": ""}
{"doi": "10.48550/arXiv.2103.16299", "date": "2021-03-30", "title": "Generalized $b$-symbol weights of Linear Codes and $b$-symbol MDS Codes", "authors": "Hongwei Liu, Xu Pan", "abstract": "Generalized pair weights of linear codes are generalizations of minimum\nsymbol-pair weights, which were introduced by Liu and Pan \\cite{LP} recently.\nGeneralized pair weights can be used to characterize the ability of protecting\ninformation in the symbol-pair read wire-tap channels of type II. In this\npaper, we introduce the notion of generalized $b$-symbol weights of linear\ncodes over finite fields, which is a generalization of generalized Hamming\nweights and generalized pair weights. We obtain some basic properties and\nbounds of generalized $b$-symbol weights which are called Singleton-like bounds\nfor generalized $b$-symbol weights. As examples, we calculate generalized\nweight matrices for simplex codes and Hamming codes. We provide a necessary and\nsufficient condition for a linear code to be a $b$-symbol MDS code by using the\ngenerator matrix and the parity check matrix of this linear code. Finally, a\nnecessary and sufficient condition of a linear isomorphism preserving\n$b$-symbol weights between two linear codes is obtained. As a corollary, we get\nthe classical MacWilliams extension theorem when $b=1$.", "journal": ""}
{"doi": "10.48550/arXiv.2104.06106", "date": "2021-04-13", "title": "Level Generation for Angry Birds with Sequential VAE and Latent Variable Evolution", "authors": "Takumi Tanabe, Kazuto Fukuchi, Jun Sakuma, Youhei Akimoto", "abstract": "Video game level generation based on machine learning (ML), in particular,\ndeep generative models, has attracted attention as a technique to automate\nlevel generation. However, applications of existing ML-based level generations\nare mostly limited to tile-based level representation. When ML techniques are\napplied to game domains with non-tile-based level representation, such as Angry\nBirds, where objects in a level are specified by real-valued parameters, ML\noften fails to generate playable levels. In this study, we develop a\ndeep-generative-model-based level generation for the game domain of Angry\nBirds. To overcome these drawbacks, we propose a sequential encoding of a level\nand process it as text data, whereas existing approaches employ a tile-based\nencoding and process it as an image. Experiments show that the proposed level\ngenerator drastically improves the stability and diversity of generated levels\ncompared with existing approaches. We apply latent variable evolution with the\nproposed generator to control the feature of a generated level computed through\nan AI agent's play, while keeping the level stable and natural.", "journal": ""}
{"doi": "10.48550/arXiv.2106.04367", "date": "2021-06-07", "title": "New discovery of a conversion of generalized singular values", "authors": "Weiwei Xu, Yingzhou Lee", "abstract": "In this paper, we give a new discovery of conversion of generalized singular\nvalues. New formulation is proposed.", "journal": ""}
{"doi": "10.48550/arXiv.2106.15587", "date": "2021-06-29", "title": "Generalization of Reinforcement Learning with Policy-Aware Adversarial Data Augmentation", "authors": "Hanping Zhang, Yuhong Guo", "abstract": "The generalization gap in reinforcement learning (RL) has been a significant\nobstacle that prevents the RL agent from learning general skills and adapting\nto varying environments. Increasing the generalization capacity of the RL\nsystems can significantly improve their performance on real-world working\nenvironments. In this work, we propose a novel policy-aware adversarial data\naugmentation method to augment the standard policy learning method with\nautomatically generated trajectory data. Different from the commonly used\nobservation transformation based data augmentations, our proposed method\nadversarially generates new trajectory data based on the policy gradient\nobjective and aims to more effectively increase the RL agent's generalization\nability with the policy-aware data augmentation. Moreover, we further deploy a\nmixup step to integrate the original and generated data to enhance the\ngeneralization capacity while mitigating the over-deviation of the adversarial\ndata. We conduct experiments on a number of RL tasks to investigate the\ngeneralization performance of the proposed method by comparing it with the\nstandard baselines and the state-of-the-art mixreg approach. The results show\nour method can generalize well with limited training diversity, and achieve the\nstate-of-the-art generalization test performance.", "journal": ""}
{"doi": "10.48550/arXiv.2107.07738", "date": "2021-07-16", "title": "Privacy-preserving Spatiotemporal Scenario Generation of Renewable Energies: A Federated Deep Generative Learning Approach", "authors": "Yang Li, Jiazheng Li, Yi Wang", "abstract": "Scenario generation is a fundamental and crucial tool for decision-making in\npower systems with high-penetration renewables. Based on big historical data, a\nnovel federated deep generative learning framework, called Fed-LSGAN, is\nproposed by integrating federated learning and least square generative\nadversarial networks (LSGANs) for renewable scenario generation. Specifically,\nfederated learning learns a shared global model in a central server from\nrenewable sites at network edges, which enables the Fed-LSGAN to generate\nscenarios in a privacy-preserving manner without sacrificing the generation\nquality by transferring model parameters, rather than all data. Meanwhile, the\nLSGANs-based deep generative model generates scenarios that conform to the\ndistribution of historical data through fully capturing the spatial-temporal\ncharacteristics of renewable powers, which leverages the least squares loss\nfunction to improve the training stability and generation quality. The\nsimulation results demonstrate that the proposal manages to generate\nhigh-quality renewable scenarios and outperforms the state-of-the-art\ncentralized methods. Besides, an experiment with different federated learning\nsettings is designed and conducted to verify the robustness of our method.", "journal": "IEEE Transactions on Industrial Informatics 18 (2022) 2310-2320"}
{"doi": "10.48550/arXiv.2108.01285", "date": "2021-08-03", "title": "Toward Spatially Unbiased Generative Models", "authors": "Jooyoung Choi, Jungbeom Lee, Yonghyun Jeong, Sungroh Yoon", "abstract": "Recent image generation models show remarkable generation performance.\nHowever, they mirror strong location preference in datasets, which we call\nspatial bias. Therefore, generators render poor samples at unseen locations and\nscales. We argue that the generators rely on their implicit positional encoding\nto render spatial content. From our observations, the generator's implicit\npositional encoding is translation-variant, making the generator spatially\nbiased. To address this issue, we propose injecting explicit positional\nencoding at each scale of the generator. By learning the spatially unbiased\ngenerator, we facilitate the robust use of generators in multiple tasks, such\nas GAN inversion, multi-scale generation, generation of arbitrary sizes and\naspect ratios. Furthermore, we show that our method can also be applied to\ndenoising diffusion probabilistic models.", "journal": ""}
{"doi": "10.48550/arXiv.2206.00162", "date": "2022-06-01", "title": "PAGER: Progressive Attribute-Guided Extendable Robust Image Generation", "authors": "Zohreh Azizi, C. -C. Jay Kuo", "abstract": "This work presents a generative modeling approach based on successive\nsubspace learning (SSL). Unlike most generative models in the literature, our\nmethod does not utilize neural networks to analyze the underlying source\ndistribution and synthesize images. The resulting method, called the\nprogressive attribute-guided extendable robust image generative (PAGER) model,\nhas advantages in mathematical transparency, progressive content generation,\nlower training time, robust performance with fewer training samples, and\nextendibility to conditional image generation. PAGER consists of three modules:\ncore generator, resolution enhancer, and quality booster. The core generator\nlearns the distribution of low-resolution images and performs unconditional\nimage generation. The resolution enhancer increases image resolution via\nconditional generation. Finally, the quality booster adds finer details to\ngenerated images. Extensive experiments on MNIST, Fashion-MNIST, and CelebA\ndatasets are conducted to demonstrate generative performance of PAGER.", "journal": ""}
{"doi": "10.48550/arXiv.2209.02588", "date": "2022-08-04", "title": "A generalization of Chu-Vandermonde's Identity", "authors": "Seyed Saeed Naghibi, Mohsen Hooshmand", "abstract": "We present and prove a general form of Vandermonde's identity and use it as\nan alternative solution to a classic probability problem.", "journal": ""}
{"doi": "10.48550/arXiv.2210.03611", "date": "2022-10-07", "title": "Irreducible generating tuples of Fuchsian groups", "authors": "Ederson Dutra, Richard Weidmann", "abstract": "L. Louder showed that any generating tuple of a surface group is Nielsen\nequivalent to a stabilized standard generating tuple i.e. $(a_1,\\ldots\n,a_k,1\\ldots, 1)$ where $(a_1,\\ldots ,a_k)$ is the standard generating tuple.\nThis implies in particular that irreducible generating tuples, i.e. tuples that\nare not Nielsen equivalent to a tuple of the form $(g_1,\\ldots ,g_k,1)$, are\nminimal. In a previous work the first author generalized Louder's ideas and\nshowed that all irreducible and non-standard generating tuples of sufficiently\nlarge Fuchsian groups can be represented by so-called almost orbifold covers\nendowed with a rigid generating tuple.\n  In the present paper a variation of the ideas from \\cite{W2} is used to show\nthat this almost orbifold cover with a rigid generating tuple is unique up to\nthe appropriate equivalence. It is moreover shown that any such generating\ntuple is irreducible. This provides a way to exhibit many Nielsen classes of\nnon-minimal irreducible generating tuples for Fuchsian groups.\n  As an application we show that generating tuples of fundamental groups of\nHaken Seifert manifolds corresponding to irreducible horizontal Heegaard\nsplittings are irreducible.", "journal": ""}
{"doi": "10.48550/arXiv.2211.10800", "date": "2022-11-19", "title": "Contraction theorem for generalized pairs", "authors": "Lingyao Xie", "abstract": "We use Koll\\'ar's gluing theory to prove the contraction theorem for\ngeneralized pairs. In particular, we show that we can run the MMP for any\ngeneralized log canonical pairs.", "journal": ""}
{"doi": "10.48550/arXiv.2304.04103", "date": "2023-04-08", "title": "TC-VAE: Uncovering Out-of-Distribution Data Generative Factors", "authors": "Cristian Meo, Anirudh Goyal, Justin Dauwels", "abstract": "Uncovering data generative factors is the ultimate goal of disentanglement\nlearning. Although many works proposed disentangling generative models able to\nuncover the underlying generative factors of a dataset, so far no one was able\nto uncover OOD generative factors (i.e., factors of variations that are not\nexplicitly shown on the dataset). Moreover, the datasets used to validate these\nmodels are synthetically generated using a balanced mixture of some predefined\ngenerative factors, implicitly assuming that generative factors are uniformly\ndistributed across the datasets. However, real datasets do not present this\nproperty. In this work we analyse the effect of using datasets with unbalanced\ngenerative factors, providing qualitative and quantitative results for widely\nused generative models. Moreover, we propose TC-VAE, a generative model\noptimized using a lower bound of the joint total correlation between the\nlearned latent representations and the input data. We show that the proposed\nmodel is able to uncover OOD generative factors on different datasets and\noutperforms on average the related baselines in terms of downstream\ndisentanglement metrics.", "journal": ""}
{"doi": "10.48550/arXiv.2305.07508", "date": "2023-05-11", "title": "MolDiff: Addressing the Atom-Bond Inconsistency Problem in 3D Molecule Diffusion Generation", "authors": "Xingang Peng, Jiaqi Guan, Qiang Liu, Jianzhu Ma", "abstract": "Deep generative models have recently achieved superior performance in 3D\nmolecule generation. Most of them first generate atoms and then add chemical\nbonds based on the generated atoms in a post-processing manner. However, there\nmight be no corresponding bond solution for the temporally generated atoms as\ntheir locations are generated without considering potential bonds. We define\nthis problem as the atom-bond inconsistency problem and claim it is the main\nreason for current approaches to generating unrealistic 3D molecules. To\novercome this problem, we propose a new diffusion model called MolDiff which\ncan generate atoms and bonds simultaneously while still maintaining their\nconsistency by explicitly modeling the dependence between their relationships.\nWe evaluated the generation ability of our proposed model and the quality of\nthe generated molecules using criteria related to both geometry and chemical\nproperties. The empirical studies showed that our model outperforms previous\napproaches, achieving a three-fold improvement in success rate and generating\nmolecules with significantly better quality.", "journal": ""}
{"doi": "10.48550/arXiv.2305.16310", "date": "2023-05-25", "title": "Securing Deep Generative Models with Universal Adversarial Signature", "authors": "Yu Zeng, Mo Zhou, Yuan Xue, Vishal M. Patel", "abstract": "Recent advances in deep generative models have led to the development of\nmethods capable of synthesizing high-quality, realistic images. These models\npose threats to society due to their potential misuse. Prior research attempted\nto mitigate these threats by detecting generated images, but the varying traces\nleft by different generative models make it challenging to create a universal\ndetector capable of generalizing to new, unseen generative models. In this\npaper, we propose to inject a universal adversarial signature into an arbitrary\npre-trained generative model, in order to make its generated contents more\ndetectable and traceable. First, the imperceptible optimal signature for each\nimage can be found by a signature injector through adversarial training.\nSubsequently, the signature can be incorporated into an arbitrary generator by\nfine-tuning it with the images processed by the signature injector. In this\nway, the detector corresponding to the signature can be reused for any\nfine-tuned generator for tracking the generator identity. The proposed method\nis validated on the FFHQ and ImageNet datasets with various state-of-the-art\ngenerative models, consistently showing a promising detection rate. Code will\nbe made publicly available at \\url{https://github.com/zengxianyu/genwm}.", "journal": ""}
{"doi": "10.48550/arXiv.2307.00760", "date": "2023-07-03", "title": "A generalization of the Gronwall-Bellman lemma", "authors": "G. A. Grigorian", "abstract": "The Riccati equation method is used to obtain a generalization of the\nGronvall-Bellman lemma the obtained result is used to generalize a result of\nLyapunov.", "journal": ""}
{"doi": "10.48550/arXiv.2307.02839", "date": "2023-07-06", "title": "Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation", "authors": "Le Xiao, Xiaolin Chen", "abstract": "News summary generation is an important task in the field of intelligence\nanalysis, which can provide accurate and comprehensive information to help\npeople better understand and respond to complex real-world events. However,\ntraditional news summary generation methods face some challenges, which are\nlimited by the model itself and the amount of training data, as well as the\ninfluence of text noise, making it difficult to generate reliable information\naccurately. In this paper, we propose a new paradigm for news summary\ngeneration using LLM with powerful natural language understanding and\ngenerative capabilities. We use LLM to extract multiple structured event\npatterns from the events contained in news paragraphs, evolve the event pattern\npopulation with genetic algorithm, and select the most adaptive event pattern\nto input into the LLM to generate news summaries. A News Summary Generator\n(NSG) is designed to select and evolve the event pattern populations and\ngenerate news summaries. The experimental results show that the news summary\ngenerator is able to generate accurate and reliable news summaries with some\ngeneralization ability.", "journal": ""}
{"doi": "10.48550/arXiv.2307.14712", "date": "2023-07-27", "title": "Evaluating Generative Models for Graph-to-Text Generation", "authors": "Shuzhou Yuan, Michael F\u00e4rber", "abstract": "Large language models (LLMs) have been widely employed for graph-to-text\ngeneration tasks. However, the process of finetuning LLMs requires significant\ntraining resources and annotation work. In this paper, we explore the\ncapability of generative models to generate descriptive text from graph data in\na zero-shot setting. Specifically, we evaluate GPT-3 and ChatGPT on two\ngraph-to-text datasets and compare their performance with that of finetuned LLM\nmodels such as T5 and BART. Our results demonstrate that generative models are\ncapable of generating fluent and coherent text, achieving BLEU scores of 10.57\nand 11.08 for the AGENDA and WebNLG datasets, respectively. However, our error\nanalysis reveals that generative models still struggle with understanding the\nsemantic relations between entities, and they also tend to generate text with\nhallucinations or irrelevant information. As a part of error analysis, we\nutilize BERT to detect machine-generated text and achieve high macro-F1 scores.\nWe have made the text generated by generative models publicly available.", "journal": ""}
{"doi": "10.48550/arXiv.2309.04612", "date": "2023-09-08", "title": "Self-optimizing Feature Generation via Categorical Hashing Representation and Hierarchical Reinforcement Crossing", "authors": "Wangyang Ying, Dongjie Wang, Kunpeng Liu, Leilei Sun, Yanjie Fu", "abstract": "Feature generation aims to generate new and meaningful features to create a\ndiscriminative representation space.A generated feature is meaningful when the\ngenerated feature is from a feature pair with inherent feature interaction. In\nthe real world, experienced data scientists can identify potentially useful\nfeature-feature interactions, and generate meaningful dimensions from an\nexponentially large search space, in an optimal crossing form over an optimal\ngeneration path. But, machines have limited human-like abilities.We generalize\nsuch learning tasks as self-optimizing feature generation. Self-optimizing\nfeature generation imposes several under-addressed challenges on existing\nsystems: meaningful, robust, and efficient generation. To tackle these\nchallenges, we propose a principled and generic representation-crossing\nframework to solve self-optimizing feature generation.To achieve hashing\nrepresentation, we propose a three-step approach: feature discretization,\nfeature hashing, and descriptive summarization. To achieve reinforcement\ncrossing, we develop a hierarchical reinforcement feature crossing approach.We\npresent extensive experimental results to demonstrate the effectiveness and\nefficiency of the proposed method. The code is available at\nhttps://github.com/yingwangyang/HRC_feature_cross.git.", "journal": ""}
{"doi": "10.48550/arXiv.2310.02442", "date": "2023-10-03", "title": "GenCO: Generating Diverse Designs with Combinatorial Constraints", "authors": "Aaron Ferber, Arman Zharmagambetov, Taoan Huang, Bistra Dilkina, Yuandong Tian", "abstract": "Deep generative models like GAN and VAE have shown impressive results in\ngenerating unconstrained objects like images. However, many design settings\narising in industrial design, material science, computer graphics and more\nrequire that the generated objects satisfy hard combinatorial constraints or\nmeet objectives in addition to modeling a data distribution. To address this,\nwe propose GenCO, a generative framework that guarantees constraint\nsatisfaction throughout training by leveraging differentiable combinatorial\nsolvers to enforce feasibility. GenCO imposes the generative loss on provably\nfeasible solutions rather than intermediate soft solutions, meaning that the\ndeep generative network can focus on ensuring the generated objects match the\ndata distribution without having to also capture feasibility. This shift\nenables practitioners to enforce hard constraints on the generated outputs\nduring end-to-end training, enabling assessments of their feasibility and\nintroducing additional combinatorial loss components to deep generative\ntraining. We demonstrate the effectiveness of our approach on a variety of\ngenerative combinatorial tasks, including game level generation, map creation\nfor path planning, and photonic device design, consistently demonstrating its\ncapability to yield diverse, high-quality solutions that verifiably adhere to\nuser-specified combinatorial properties.", "journal": ""}
{"doi": "10.48550/arXiv.2310.05165", "date": "2023-10-08", "title": "On the Zero-Shot Generalization of Machine-Generated Text Detectors", "authors": "Xiao Pu, Jingyu Zhang, Xiaochuang Han, Yulia Tsvetkov, Tianxing He", "abstract": "The rampant proliferation of large language models, fluent enough to generate\ntext indistinguishable from human-written language, gives unprecedented\nimportance to the detection of machine-generated text. This work is motivated\nby an important research question: How will the detectors of machine-generated\ntext perform on outputs of a new generator, that the detectors were not trained\non? We begin by collecting generation data from a wide range of LLMs, and train\nneural detectors on data from each generator and test its performance on\nheld-out generators. While none of the detectors can generalize to all\ngenerators, we observe a consistent and interesting pattern that the detectors\ntrained on data from a medium-size LLM can zero-shot generalize to the larger\nversion. As a concrete application, we demonstrate that robust detectors can be\nbuilt on an ensemble of training data from medium-sized models.", "journal": ""}
{"doi": "10.48550/arXiv.2310.07683", "date": "2023-10-11", "title": "Controllable Data Generation Via Iterative Data-Property Mutual Mappings", "authors": "Bo Pan, Muran Qin, Shiyu Wang, Yifei Zhang, Liang Zhao", "abstract": "Deep generative models have been widely used for their ability to generate\nrealistic data samples in various areas, such as images, molecules, text, and\nspeech. One major goal of data generation is controllability, namely to\ngenerate new data with desired properties. Despite growing interest in the area\nof controllable generation, significant challenges still remain, including 1)\ndisentangling desired properties with unrelated latent variables, 2)\nout-of-distribution property control, and 3) objective optimization for\nout-of-distribution property control. To address these challenges, in this\npaper, we propose a general framework to enhance VAE-based data generators with\nproperty controllability and ensure disentanglement. Our proposed objective can\nbe optimized on both data seen and unseen in the training set. We propose a\ntraining procedure to train the objective in a semi-supervised manner by\niteratively conducting mutual mappings between the data and properties. The\nproposed framework is implemented on four VAE-based controllable generators to\nevaluate its performance on property error, disentanglement, generation\nquality, and training time. The results indicate that our proposed framework\nenables more precise control over the properties of generated samples in a\nshort training time, ensuring the disentanglement and keeping the validity of\nthe generated samples.", "journal": ""}
{"doi": "10.48550/arXiv.2310.16338", "date": "2023-10-25", "title": "Generative Pre-training for Speech with Flow Matching", "authors": "Alexander H. Liu, Matt Le, Apoorv Vyas, Bowen Shi, Andros Tjandra, Wei-Ning Hsu", "abstract": "Generative models have gained more and more attention in recent years for\ntheir remarkable success in tasks that required estimating and sampling data\ndistribution to generate high-fidelity synthetic data. In speech,\ntext-to-speech synthesis and neural vocoder are good examples where generative\nmodels have shined. While generative models have been applied to different\napplications in speech, there exists no general-purpose generative model that\nmodels speech directly. In this work, we take a step toward this direction by\nshowing a single pre-trained generative model can be adapted to different\ndownstream tasks with strong performance. Specifically, we pre-trained a\ngenerative model, named SpeechFlow, on 60k hours of untranscribed speech with\nFlow Matching and masked conditions. Experiment results show the pre-trained\ngenerative model can be fine-tuned with task-specific data to match or surpass\nexisting expert models on speech enhancement, separation, and synthesis. Our\nwork suggested a foundational model for generation tasks in speech can be built\nwith generative pre-training.", "journal": ""}
{"doi": "10.48550/arXiv.2311.12534", "date": "2023-11-21", "title": "Evaluation Metrics of Language Generation Models for Synthetic Traffic Generation Tasks", "authors": "Simone Filice, Jason Ingyu Choi, Giuseppe Castellucci, Eugene Agichtein, Oleg Rokhlenko", "abstract": "Many Natural Language Generation (NLG) tasks aim to generate a single output\ntext given an input prompt. Other settings require the generation of multiple\ntexts, e.g., for Synthetic Traffic Generation (STG). This generation task is\ncrucial for training and evaluating QA systems as well as conversational\nagents, where the goal is to generate multiple questions or utterances\nresembling the linguistic variability of real users. In this paper, we show\nthat common NLG metrics, like BLEU, are not suitable for evaluating STG. We\npropose and evaluate several metrics designed to compare the generated traffic\nto the distribution of real user texts. We validate our metrics with an\nautomatic procedure to verify whether they capture different types of quality\nissues of generated data; we also run human annotations to verify the\ncorrelation with human judgements. Experiments on three tasks, i.e., Shopping\nUtterance Generation, Product Question Generation and Query Auto Completion,\ndemonstrate that our metrics are effective for evaluating STG tasks, and\nimprove the agreement with human judgement up to 20% with respect to common NLG\nmetrics. We believe these findings can pave the way towards better solutions\nfor estimating the representativeness of synthetic text data.", "journal": ""}
{"doi": "10.48550/arXiv.2402.04504", "date": "2024-02-07", "title": "Text2Street: Controllable Text-to-image Generation for Street Views", "authors": "Jinming Su, Songen Gu, Yiting Duan, Xingyue Chen, Junfeng Luo", "abstract": "Text-to-image generation has made remarkable progress with the emergence of\ndiffusion models. However, it is still a difficult task to generate images for\nstreet views based on text, mainly because the road topology of street scenes\nis complex, the traffic status is diverse and the weather condition is various,\nwhich makes conventional text-to-image models difficult to deal with. To\naddress these challenges, we propose a novel controllable text-to-image\nframework, named \\textbf{Text2Street}. In the framework, we first introduce the\nlane-aware road topology generator, which achieves text-to-map generation with\nthe accurate road structure and lane lines armed with the counting adapter,\nrealizing the controllable road topology generation. Then, the position-based\nobject layout generator is proposed to obtain text-to-layout generation through\nan object-level bounding box diffusion strategy, realizing the controllable\ntraffic object layout generation. Finally, the multiple control image generator\nis designed to integrate the road topology, object layout and weather\ndescription to realize controllable street-view image generation. Extensive\nexperiments show that the proposed approach achieves controllable street-view\ntext-to-image generation and validates the effectiveness of the Text2Street\nframework for street views.", "journal": ""}
{"doi": "10.48550/arXiv.2402.17063", "date": "2024-02-26", "title": "An Identity for Generalized Euler Polynomials", "authors": "Chellal Redha", "abstract": "In this paper, we introduce a novel identity for generalized Euler\npolynomials, leading to further generalizations for several relations involving\nclassical Euler numbers, Euler polynomials, Genocchi polynomials, and Genocchi\nnumbers.", "journal": ""}
{"doi": "10.48550/arXiv.2403.17104", "date": "2024-03-25", "title": "Attribute First, then Generate: Locally-attributable Grounded Text Generation", "authors": "Aviv Slobodkin, Eran Hirsch, Arie Cattan, Tal Schuster, Ido Dagan", "abstract": "Recent efforts to address hallucinations in Large Language Models (LLMs) have\nfocused on attributed text generation, which supplements generated texts with\ncitations of supporting sources for post-generation fact-checking and\ncorrections. Yet, these citations often point to entire documents or\nparagraphs, burdening users with extensive verification work. In this paper, we\nintroduce a locally-attributable text generation approach, prioritizing concise\nattributions. Our method, named \"Attribute First, then Generate\", breaks down\nthe conventional end-to-end generation process into three intuitive steps:\ncontent selection, sentence planning, and sequential sentence generation. By\ninitially identifying relevant source segments (\"select first\") and then\nconditioning the generation process on them (\"then generate\"), we ensure these\nsegments also act as the output's fine-grained attributions (\"select\" becomes\n\"attribute\"). Tested on Multi-document Summarization and Long-form\nQuestion-answering, our method not only yields more concise citations than the\nbaselines but also maintains - and in some cases enhances - both generation\nquality and attribution accuracy. Furthermore, it significantly reduces the\ntime required for fact verification by human assessors.", "journal": ""}
{"doi": "10.48550/arXiv.2405.08331", "date": "2024-05-14", "title": "Are Generics and Negativity about Social Groups Common on Social Media? A Comparative Analysis of Twitter (X) Data", "authors": "Uwe Peters, Ignacio Ojea Quintana", "abstract": "Generics (unquantified generalizations) are thought to be pervasive in\ncommunication and when they are about social groups, this may offend and\npolarize people because generics gloss over variations between individuals.\nGenerics about social groups might be particularly common on Twitter (X). This\nremains unexplored, however. Using machine learning (ML) techniques, we\ntherefore developed an automatic classifier for social generics, applied it to\nmore than a million tweets about people, and analyzed the tweets. We found that\nmost tweets (78%) about people contained no generics. However, tweets with\nsocial generics received more 'likes' and retweets. Furthermore, while recent\npsychological research may lead to the prediction that tweets with generics\nabout political groups are more common than tweets with generics about ethnic\ngroups, we found the opposite. However, consistent with recent claims that\npolitical animosity is less constrained by social norms than animosity against\ngender and ethnic groups, negative tweets with generics about political groups\nwere significantly more prevalent and retweeted than negative tweets about\nethnic groups. Our study provides the first ML-based insights into the use and\nimpact of social generics on Twitter.", "journal": ""}
{"doi": "10.48550/arXiv.2405.11591", "date": "2024-05-19", "title": "Generative Students: Using LLM-Simulated Student Profiles to Support Question Item Evaluation", "authors": "Xinyi Lu, Xu Wang", "abstract": "Evaluating the quality of automatically generated question items has been a\nlong standing challenge. In this paper, we leverage LLMs to simulate student\nprofiles and generate responses to multiple-choice questions (MCQs). The\ngenerative students' responses to MCQs can further support question item\nevaluation. We propose Generative Students, a prompt architecture designed\nbased on the KLI framework. A generative student profile is a function of the\nlist of knowledge components the student has mastered, has confusion about or\nhas no evidence of knowledge of. We instantiate the Generative Students concept\non the subject domain of heuristic evaluation. We created 45 generative\nstudents using GPT-4 and had them respond to 20 MCQs. We found that the\ngenerative students produced logical and believable responses that were aligned\nwith their profiles. We then compared the generative students' responses to\nreal students' responses on the same set of MCQs and found a high correlation.\nMoreover, there was considerable overlap in the difficult questions identified\nby generative students and real students. A subsequent case study demonstrated\nthat an instructor could improve question quality based on the signals provided\nby Generative Students.", "journal": ""}
{"doi": "10.48550/arXiv.2405.13184", "date": "2024-05-21", "title": "Generalized Tribonacci Hyperbolic Spinors", "authors": "Zehra \u0130\u015fbilir, Bahar Do\u011fan Yaz\u0131c\u0131, Murat Tosun", "abstract": "In this study, we introduce the generalized Tribonacci hyperbolic spinors and\nproperties of this new special numbers system by the generalized Tribonacci\nnumbers, which are one of the most general form of the third-order recurrence\nsequences, generalized Tribonacci quaternions, and hyperbolic spinors, which\nhave quite an importance and framework from mathematics to physics. This study\nespecially improves the relations between the hyperbolic spinors and\ngeneralized Tribonacci numbers with the help of the generalized Tribonacci\nsplit quaternions. Furthermore, we examine some special cases of them and\nconstruct both new equalities and fundamental properties such as recurrence\nrelation, Binet formula, generating function, exponential generating function,\nPoisson generating function, summation formulas, special determinant\nproperties, matrix formula, and special determinant equations. Also, we give\nsome numerical algorithms with respect to the obtained materials. In addition\nto these, we give a brief introduction for further research: generalized\nTribonacci polynomial hyperbolic spinor sequence.", "journal": ""}
{"doi": "10.48550/arXiv.2405.15572", "date": "2024-05-24", "title": "Toward a generalization of Lehmer's problem to adelic curves", "authors": "Mounir Hajli", "abstract": "In this short note, we investigate the generalization of Lehmer's problem to\nfinitely generated fields over $\\mathbb{Q}$.", "journal": ""}
{"doi": "10.48550/arXiv.2407.01417", "date": "2024-07-01", "title": "Generalized Motives through Witt Vectors", "authors": "Xin Tong", "abstract": "We generalize condensed motives, through Witt vectors and the associated\nmoduli stacks of generalized line bundles.", "journal": ""}
{"doi": "10.48550/arXiv.2408.06145", "date": "2024-08-12", "title": "Efficient and Scalable Point Cloud Generation with Sparse Point-Voxel Diffusion Models", "authors": "Ioannis Romanelis, Vlassios Fotis, Athanasios Kalogeras, Christos Alexakos, Konstantinos Moustakas, Adrian Munteanu", "abstract": "We propose a novel point cloud U-Net diffusion architecture for 3D generative\nmodeling capable of generating high-quality and diverse 3D shapes while\nmaintaining fast generation times. Our network employs a dual-branch\narchitecture, combining the high-resolution representations of points with the\ncomputational efficiency of sparse voxels. Our fastest variant outperforms all\nnon-diffusion generative approaches on unconditional shape generation, the most\npopular benchmark for evaluating point cloud generative models, while our\nlargest model achieves state-of-the-art results among diffusion methods, with a\nruntime approximately 70% of the previously state-of-the-art PVD. Beyond\nunconditional generation, we perform extensive evaluations, including\nconditional generation on all categories of ShapeNet, demonstrating the\nscalability of our model to larger datasets, and implicit generation which\nallows our network to produce high quality point clouds on fewer timesteps,\nfurther decreasing the generation time. Finally, we evaluate the architecture's\nperformance in point cloud completion and super-resolution. Our model excels in\nall tasks, establishing it as a state-of-the-art diffusion U-Net for point\ncloud generative modeling. The code is publicly available at\nhttps://github.com/JohnRomanelis/SPVD.git.", "journal": ""}
{"doi": "10.48550/arXiv.2408.17095", "date": "2024-08-30", "title": "RISSOLE: Parameter-efficient Diffusion Models via Block-wise Generation and Retrieval-Guidance", "authors": "Avideep Mukherjee, Soumya Banerjee, Piyush Rai, Vinay P. Namboodiri", "abstract": "Diffusion-based models demonstrate impressive generation capabilities.\nHowever, they also have a massive number of parameters, resulting in enormous\nmodel sizes, thus making them unsuitable for deployment on resource-constraint\ndevices. Block-wise generation can be a promising alternative for designing\ncompact-sized (parameter-efficient) deep generative models since the model can\ngenerate one block at a time instead of generating the whole image at once.\nHowever, block-wise generation is also considerably challenging because\nensuring coherence across generated blocks can be non-trivial. To this end, we\ndesign a retrieval-augmented generation (RAG) approach and leverage the\ncorresponding blocks of the images retrieved by the RAG module to condition the\ntraining and generation stages of a block-wise denoising diffusion model. Our\nconditioning schemes ensure coherence across the different blocks during\ntraining and, consequently, during generation. While we showcase our approach\nusing the latent diffusion model (LDM) as the base model, it can be used with\nother variants of denoising diffusion models. We validate the solution of the\ncoherence problem through the proposed approach by reporting substantive\nexperiments to demonstrate our approach's effectiveness in compact model size\nand excellent generation quality.", "journal": ""}
{"doi": "10.48550/arXiv.2412.01407", "date": "2024-12-02", "title": "HoloDrive: Holistic 2D-3D Multi-Modal Street Scene Generation for Autonomous Driving", "authors": "Zehuan Wu, Jingcheng Ni, Xiaodong Wang, Yuxin Guo, Rui Chen, Lewei Lu, Jifeng Dai, Yuwen Xiong", "abstract": "Generative models have significantly improved the generation and prediction\nquality on either camera images or LiDAR point clouds for autonomous driving.\nHowever, a real-world autonomous driving system uses multiple kinds of input\nmodality, usually cameras and LiDARs, where they contain complementary\ninformation for generation, while existing generation methods ignore this\ncrucial feature, resulting in the generated results only covering separate 2D\nor 3D information. In order to fill the gap in 2D-3D multi-modal joint\ngeneration for autonomous driving, in this paper, we propose our framework,\n\\emph{HoloDrive}, to jointly generate the camera images and LiDAR point clouds.\nWe employ BEV-to-Camera and Camera-to-BEV transform modules between\nheterogeneous generative models, and introduce a depth prediction branch in the\n2D generative model to disambiguate the un-projecting from image space to BEV\nspace, then extend the method to predict the future by adding temporal\nstructure and carefully designed progressive training. Further, we conduct\nexperiments on single frame generation and world model benchmarks, and\ndemonstrate our method leads to significant performance gains over SOTA methods\nin terms of generation metrics.", "journal": ""}
{"doi": "10.48550/arXiv.2502.07616", "date": "2025-02-11", "title": "Tractable Transformers for Flexible Conditional Generation", "authors": "Anji Liu, Xuejie Liu, Dayuan Zhao, Mathias Niepert, Yitao Liang, Guy Van den Broeck", "abstract": "Non-autoregressive (NAR) generative models are valuable because they can\nhandle diverse conditional generation tasks in a more principled way than their\nautoregressive (AR) counterparts, which are constrained by sequential\ndependency requirements. Recent advancements in NAR models, such as diffusion\nlanguage models, have demonstrated superior performance in unconditional\ngeneration compared to AR models (e.g., GPTs) of similar sizes. However, such\nimprovements do not always lead to improved conditional generation performance.\nWe show that a key reason for this gap is the difficulty in generalizing to\nconditional probability queries unseen during training. As a result, strong\nunconditional generation performance does not guarantee high-quality\nconditional generation. This paper proposes Tractable Transformers\n(Tracformer), a Transformer-based generative model that is more robust to\ndifferent conditional generation tasks. Unlike existing models that rely solely\non global contextual features derived from full inputs, Tracformers incorporate\na sparse Transformer encoder to capture both local and global contextual\ninformation. This information is routed through a decoder for conditional\ngeneration. Empirical results demonstrate that Tracformers achieve\nstate-of-the-art conditional generation performance on text modeling compared\nto recent diffusion and AR model baselines.", "journal": ""}
{"doi": "10.48550/arXiv.2503.14076", "date": "2025-03-18", "title": "Theoretical Foundation of Flow-Based Time Series Generation: Provable Approximation, Generalization, and Efficiency", "authors": "Jiangxuan Long, Zhao Song, Chiwun Yang", "abstract": "Recent studies suggest utilizing generative models instead of traditional\nauto-regressive algorithms for time series forecasting (TSF) tasks. These\nnon-auto-regressive approaches involving different generative methods,\nincluding GAN, Diffusion, and Flow Matching for time series, have empirically\ndemonstrated high-quality generation capability and accuracy. However, we still\nlack an appropriate understanding of how it processes approximation and\ngeneralization. This paper presents the first theoretical framework from the\nperspective of flow-based generative models to relieve the knowledge of\nlimitations. In particular, we provide our insights with strict guarantees from\nthree perspectives: $\\textbf{Approximation}$, $\\textbf{Generalization}$ and\n$\\textbf{Efficiency}$. In detail, our analysis achieves the contributions as\nfollows:\n  $\\bullet$ By assuming a general data model, the fitting of the flow-based\ngenerative models is confirmed to converge to arbitrary error under the\nuniversal approximation of Diffusion Transformer (DiT).\n  $\\bullet$ Introducing a polynomial-based regularization for flow matching,\nthe generalization error thus be bounded since the generalization of polynomial\napproximation.\n  $\\bullet$ The sampling for generation is considered as an optimization\nprocess, we demonstrate its fast convergence with updating standard first-order\ngradient descent of some objective.", "journal": ""}
{"doi": "10.48550/arXiv.2504.02361", "date": "2025-04-03", "title": "MG-Gen: Single Image to Motion Graphics Generation with Layer Decomposition", "authors": "Takahiro Shirakawa, Tomoyuki Suzuki, Daichi Haraguchi", "abstract": "General image-to-video generation methods often produce suboptimal animations\nthat do not meet the requirements of animated graphics, as they lack active\ntext motion and exhibit object distortion. Also, code-based animation\ngeneration methods typically require layer-structured vector data which are\noften not readily available for motion graphic generation. To address these\nchallenges, we propose a novel framework named MG-Gen that reconstructs data in\nvector format from a single raster image to extend the capabilities of\ncode-based methods to enable motion graphics generation from a raster image in\nthe framework of general image-to-video generation. MG-Gen first decomposes the\ninput image into layer-wise elements, reconstructs them as HTML format data and\nthen generates executable JavaScript code for the reconstructed HTML data. We\nexperimentally confirm that MG-Gen generates motion graphics while preserving\ntext readability and input consistency. These successful results indicate that\ncombining layer decomposition and animation code generation is an effective\nstrategy for motion graphics generation.", "journal": ""}
{"doi": "10.48550/arXiv.2504.07382", "date": "2025-04-10", "title": "Model Discrepancy Learning: Synthetic Faces Detection Based on Multi-Reconstruction", "authors": "Qingchao Jiang, Zhishuo Xu, Zhiying Zhu, Ning Chen, Haoyue Wang, Zhongjie Ba", "abstract": "Advances in image generation enable hyper-realistic synthetic faces but also\npose risks, thus making synthetic face detection crucial. Previous research\nfocuses on the general differences between generated images and real images,\noften overlooking the discrepancies among various generative techniques. In\nthis paper, we explore the intrinsic relationship between synthetic images and\ntheir corresponding generation technologies. We find that specific images\nexhibit significant reconstruction discrepancies across different generative\nmethods and that matching generation techniques provide more accurate\nreconstructions. Based on this insight, we propose a Multi-Reconstruction-based\ndetector. By reversing and reconstructing images using multiple generative\nmodels, we analyze the reconstruction differences among real, GAN-generated,\nand DM-generated images to facilitate effective differentiation. Additionally,\nwe introduce the Asian Synthetic Face Dataset (ASFD), containing synthetic\nAsian faces generated with various GANs and DMs. This dataset complements\nexisting synthetic face datasets. Experimental results demonstrate that our\ndetector achieves exceptional performance, with strong generalization and\nrobustness.", "journal": ""}
{"doi": "10.48550/arXiv.2504.10507", "date": "2025-04-09", "title": "PinRec: Outcome-Conditioned, Multi-Token Generative Retrieval for Industry-Scale Recommendation Systems", "authors": "Anirudhan Badrinath, Prabhat Agarwal, Laksh Bhasin, Jaewon Yang, Jiajing Xu, Charles Rosenberg", "abstract": "Generative retrieval methods utilize generative sequential modeling\ntechniques, such as transformers, to generate candidate items for recommender\nsystems. These methods have demonstrated promising results in academic\nbenchmarks, surpassing traditional retrieval models like two-tower\narchitectures. However, current generative retrieval methods lack the\nscalability required for industrial recommender systems, and they are\ninsufficiently flexible to satisfy the multiple metric requirements of modern\nsystems. This paper introduces PinRec, a novel generative retrieval model\ndeveloped for applications at Pinterest. PinRec utilizes outcome-conditioned\ngeneration, enabling modelers to specify how to balance various outcome\nmetrics, such as the number of saves and clicks, to effectively align with\nbusiness goals and user exploration. Additionally, PinRec incorporates\nmulti-token generation to enhance output diversity while optimizing generation.\nOur experiments demonstrate that PinRec can successfully balance performance,\ndiversity, and efficiency, delivering a significant positive impact to users\nusing generative models. This paper marks a significant milestone in generative\nretrieval, as it presents, to our knowledge, the first rigorous study on\nimplementing generative retrieval at the scale of Pinterest.", "journal": ""}
{"doi": "10.48550/arXiv.2504.18283", "date": "2025-04-25", "title": "Seeing Soundscapes: Audio-Visual Generation and Separation from Soundscapes Using Audio-Visual Separator", "authors": "Minjae Kang, Martim Brand\u00e3o", "abstract": "Recent audio-visual generative models have made substantial progress in\ngenerating images from audio. However, existing approaches focus on generating\nimages from single-class audio and fail to generate images from mixed audio. To\naddress this, we propose an Audio-Visual Generation and Separation model\n(AV-GAS) for generating images from soundscapes (mixed audio containing\nmultiple classes). Our contribution is threefold: First, we propose a new\nchallenge in the audio-visual generation task, which is to generate an image\ngiven a multi-class audio input, and we propose a method that solves this task\nusing an audio-visual separator. Second, we introduce a new audio-visual\nseparation task, which involves generating separate images for each class\npresent in a mixed audio input. Lastly, we propose new evaluation metrics for\nthe audio-visual generation task: Class Representation Score (CRS) and a\nmodified R@K. Our model is trained and evaluated on the VGGSound dataset. We\nshow that our method outperforms the state-of-the-art, achieving 7% higher CRS\nand 4% higher R@2* in generating plausible images with mixed audio.", "journal": ""}
{"doi": "10.48550/arXiv.2505.04342", "date": "2025-05-07", "title": "Extending Generalized Splines Over The Integers", "authors": "G\u00f6k\u00e7en Dilaver, Selma Alt\u0131nok", "abstract": "Let $R$ be a commutative ring with identity and $G$ a graph. \\emph{An\nextending generalized spline} on $G$ is a vertex labeling $f \\in \\prod_{v} M_v$\nsuch that at each edge $e=uv$ there is an $R$-module $M_{uv}$ together with\nhomomorphisms $ \\varphi_u : M_u \\to M_{uv}$ and $ \\varphi_v : M_v \\to M_{uv}$\nfor each vertex $u, v$ incident to the edge $e$ so that\n$\\varphi_u(f_u)=\\varphi_v(f_v).$ Extending generalized splines are further\ngeneralizations for generalized splines. They can also be considered as\ngeneralized splines over modules.\n  The main goal of this paper is to study the $R$-module structure of extending\ngeneralized splines. We concentrate on two following questions: which of the\nresults for general splines extend to generalized splines over modules and if\nthere is an algorithm or an explicit formula for special basis classes, called\na flow up basis, for generalized splines over modules. We show that certain\nresults concerning generalized splines can be extended to a setting where each\nvertex $v$ is assigned a module $M_v=m_v\\mathbb Z$. We provide an algorithm to\nconstruct a special basis for generalized splines over these modules on paths.\nAdditionally, we introduce a new technique to construct a flow-up basis on\narbitrary graphs using the idea of an algorithm on paths.", "journal": ""}
{"doi": "10.48550/arXiv.2505.10993", "date": "2025-05-16", "title": "Generative Models in Computational Pathology: A Comprehensive Survey on Methods, Applications, and Challenges", "authors": "Yuan Zhang, Xinfeng Zhang, Xiaoming Qi, Xinyu Wu, Feng Chen, Guanyu Yang, Huazhu Fu", "abstract": "Generative modeling has emerged as a promising direction in computational\npathology, offering capabilities such as data-efficient learning, synthetic\ndata augmentation, and multimodal representation across diverse diagnostic\ntasks. This review provides a comprehensive synthesis of recent progress in the\nfield, organized into four key domains: image generation, text generation,\nmultimodal image-text generation, and other generative applications, including\nspatial simulation and molecular inference. By analyzing over 150\nrepresentative studies, we trace the evolution of generative architectures from\nearly generative adversarial networks to recent advances in diffusion models\nand foundation models with generative capabilities. We further examine the\ndatasets and evaluation protocols commonly used in this domain and highlight\nongoing limitations, including challenges in generating high-fidelity whole\nslide images, clinical interpretability, and concerns related to the ethical\nand legal implications of synthetic data. The review concludes with a\ndiscussion of open challenges and prospective research directions, with an\nemphasis on developing unified, multimodal, and clinically deployable\ngenerative systems. This work aims to provide a foundational reference for\nresearchers and practitioners developing and applying generative models in\ncomputational pathology.", "journal": ""}
{"doi": "10.48550/arXiv.2505.23043", "date": "2025-05-29", "title": "Are Unified Vision-Language Models Necessary: Generalization Across Understanding and Generation", "authors": "Jihai Zhang, Tianle Li, Linjie Li, Zhengyuan Yang, Yu Cheng", "abstract": "Recent advancements in unified vision-language models (VLMs), which integrate\nboth visual understanding and generation capabilities, have attracted\nsignificant attention. The underlying hypothesis is that a unified architecture\nwith mixed training on both understanding and generation tasks can enable\nmutual enhancement between understanding and generation. However, this\nhypothesis remains underexplored in prior works on unified VLMs. To address\nthis gap, this paper systematically investigates the generalization across\nunderstanding and generation tasks in unified VLMs. Specifically, we design a\ndataset closely aligned with real-world scenarios to facilitate extensive\nexperiments and quantitative evaluations. We evaluate multiple unified VLM\narchitectures to validate our findings. Our key findings are as follows. First,\nunified VLMs trained with mixed data exhibit mutual benefits in understanding\nand generation tasks across various architectures, and this mutual benefits can\nscale up with increased data. Second, better alignment between multimodal input\nand output spaces will lead to better generalization. Third, the knowledge\nacquired during generation tasks can transfer to understanding tasks, and this\ncross-task generalization occurs within the base language model, beyond\nmodality adapters. Our findings underscore the critical necessity of unifying\nunderstanding and generation in VLMs, offering valuable insights for the design\nand optimization of unified VLMs.", "journal": ""}
{"doi": "10.48550/arXiv.2506.00741", "date": "2025-05-31", "title": "Data Swarms: Optimizable Generation of Synthetic Evaluation Data", "authors": "Shangbin Feng, Yike Wang, Weijia Shi, Yulia Tsvetkov", "abstract": "We propose Data Swarms, an algorithm to optimize the generation of synthetic\nevaluation data and advance quantitative desiderata of LLM evaluation. We first\ntrain a swarm of initial data generators using existing data, and define\nvarious evaluation objectives to reflect the desired properties of evaluation\n(e.g., generate more difficult problems for the evaluated models) and\nquantitatively evaluate data generators. We then employ particle swarm\noptimization to optimize the swarm of data generators, where they\ncollaboratively search through the model parameter space to find new generators\nthat advance these objectives. We further extend it to Adversarial Swarms,\nwhere the data generator swarm generates harder data while the test taker model\nswarm learns from such data, co-evolving dynamically for better data and models\nsimultaneously. Extensive experiments demonstrate that Data Swarms outperforms\neight data generation baselines across five evaluation objectives, while\nAdversarial Swarms produce more robust learning of synthetic data and stronger\ngeneralization. Further analysis reveals that Data Swarms successfully\noptimizes compositions of multiple evaluation objectives and generalizes to new\noff-the-shelf LLMs, unseen at optimization time.", "journal": ""}
{"doi": "10.48550/arXiv.2211.01678", "date": "2022-11-03", "title": "Revisiting Language Support for Generic Programming: When Genericity Is a Core Design Goal", "authors": "Benjamin Chetioui, Jaakko J\u00e4rvi, Magne Haveraaen", "abstract": "Context: Generic programming, as defined by Stepanov, is a methodology for\nwriting efficient and reusable algorithms by considering only the required\nproperties of their underlying data types and operations. Generic programming\nhas proven to be an effective means of constructing libraries of reusable\nsoftware components in languages that support it. Generics-related language\ndesign choices play a major role in how conducive generic programming is in\npractice.\n  Inquiry: Several mainstream programming languages (e.g. Java and C++) were\nfirst created without generics; features to support generic programming were\nadded later, gradually. Much of the existing literature on supporting generic\nprogramming focuses thus on retrofitting generic programming into existing\nlanguages and identifying related implementation challenges. Is the programming\nexperience significantly better, or different when programming with a language\ndesigned for generic programming without limitations from prior language design\nchoices?\n  Approach: We examine Magnolia, a language designed to embody generic\nprogramming. Magnolia is representative of an approach to language design\nrooted in algebraic specifications. We repeat a well-known experiment, where we\nput Magnolia's generic programming facilities under scrutiny by implementing a\nsubset of the Boost Graph Library, and reflect on our development experience.\n  Knowledge: We discover that the idioms identified as key features for\nsupporting Stepanov-style generic programming in the previous studies and work\non the topic do not tell a full story. We clarify which of them are more of a\nmeans to an end, rather than fundamental features for supporting generic\nprogramming. Based on the development experience with Magnolia, we identify\nvariadics as an additional key feature for generic programming and point out\nlimitations and challenges of genericity by property.\n  Grounding: Our work uses a well-known framework for evaluating the generic\nprogramming facilities of a language from the literature to evaluate the\nalgebraic approach through Magnolia, and we draw comparisons with well-known\nprogramming languages.\n  Importance: This work gives a fresh perspective on generic programming, and\nclarifies what are fundamental language properties and their trade-offs when\nconsidering supporting Stepanov-style generic programming. The understanding of\nhow to set the ground for generic programming will inform future language\ndesign.", "journal": "The Art, Science, and Engineering of Programming, 2023, Vol. 7,\n  Issue 2, Article 4"}
{"doi": "10.48550/arXiv.9312006", "date": "1993-12-03", "title": "Landau Level Ground--State Degeneracy, and Its Relevance for a General Quantization Procedure", "authors": "Robert Alicki, John R. Klauder, Jerzy Lewandowski", "abstract": "The quantum dynamics of a two-dimensional charged spin $1/2$ particle is\nstudied for general, symmetry--free curved surfaces and general, nonuniform\nmagnetic fields that are, when different from zero, orthogonal to the defining\ntwo surface. Although higher Landau levels generally lose their degeneracy\nunder such general conditions, the lowest Landau level, the ground state,\nremains degenerate. Previous discussions of this problem have had less\ngenerality and/or used supersymmetry, or else have appealed to very general\nmathematical theorems from differential geometry. In contrast our discussion\nrelies on simple and standard quantum mechanical concepts.\n  The mathematical similarity of the physical problem at hand and that of a\nphase-space path integral quantization scheme of a general classical system is\nemphasized. Adopting this analogy in the general case leads to a general\nquantization procedure that is invariant under general coordinate\ntransformations-- completely unlike any of the conventional quantization\nprescriptions -- and therefore generalizes the concept of quantization to new\nand hitherto inaccesible situations.\n  In a complementary fashion , the so-obtained picture of general quantization\nhelps to derive useful semiclassical formulas for the Hall current in the case\nof a filling factor equal to one for a general surface and magnetic field.", "journal": "Phys.Rev. A48 (1993) 2538-2548"}
{"doi": "10.48550/arXiv.1806.10840", "date": "2018-06-28", "title": "Training Discriminative Models to Evaluate Generative Ones", "authors": "Timoth\u00e9e Lesort, Andrei Stoain, Jean-Fran\u00e7ois Goudou, David Filliat", "abstract": "Generative models are known to be difficult to assess. Recent works,\nespecially on generative adversarial networks (GANs), produce good visual\nsamples of varied categories of images. However, the validation of their\nquality is still difficult to define and there is no existing agreement on the\nbest evaluation process. This paper aims at making a step toward an objective\nevaluation process for generative models. It presents a new method to assess a\ntrained generative model by evaluating the test accuracy of a classifier\ntrained with generated data. The test set is composed of real images.\nTherefore, The classifier accuracy is used as a proxy to evaluate if the\ngenerative model fit the true data distribution. By comparing results with\ndifferent generated datasets we are able to classify and compare generative\nmodels. The motivation of this approach is also to evaluate if generative\nmodels can help discriminative neural networks to learn, i.e., measure if\ntraining on generated data is able to make a model successful at testing on\nreal settings. Our experiments compare different generators from the\nVariational Auto-Encoders (VAE) and Generative Adversarial Network (GAN)\nframeworks on MNIST and fashion MNIST datasets. Our results show that none of\nthe generative models is able to replace completely true data to train a\ndiscriminative model. But they also show that the initial GAN and WGAN are the\nbest choices to generate on MNIST database (Modified National Institute of\nStandards and Technology database) and fashion MNIST database.", "journal": ""}
{"doi": "10.48550/arXiv.1810.04310", "date": "2018-10-10", "title": "Trapezoidal Generalization over Linear Constraints", "authors": "David Greve, Andrew Gacek", "abstract": "We are developing a model-based fuzzing framework that employs mathematical\nmodels of system behavior to guide the fuzzing process. Whereas traditional\nfuzzing frameworks generate tests randomly, a model-based framework can deduce\ntests from a behavioral model using a constraint solver. Because the state\nspace being explored by the fuzzer is often large, the rapid generation of test\nvectors is crucial. The need to generate tests quickly, however, is\nantithetical to the use of a constraint solver. Our solution to this problem is\nto use the constraint solver to generate an initial solution, to generalize\nthat solution relative to the system model, and then to perform rapid,\nrepeated, randomized sampling of the generalized solution space to generate\nfuzzing tests. Crucial to the success of this endeavor is a generalization\nprocedure with reasonable size and performance costs that produces generalized\nsolution spaces that can be sampled efficiently. This paper describes a\ngeneralization technique for logical formulae expressed in terms of Boolean\ncombinations of linear constraints that meets the unique performance\nrequirements of model-based fuzzing. The technique represents generalizations\nusing trapezoidal solution sets consisting of ordered, hierarchical\nconjunctions of linear constraints that are more expressive than simple\nintervals but are more efficient to manipulate and sample than generic\npolytopes. Supporting materials contain an ACL2 proof that verifies the\ncorrectness of a low-level implementation of the generalization algorithm\nagainst a specification of generalization correctness. Finally a\npost-processing procedure is described that results in a restricted trapezoidal\nsolution that can be sampled (solved) rapidly and efficiently without\nbacktracking, even for integer domains. While informal correctness arguments\nare provided, a formal proof of the correctness of the restriction algorithm\nremains as future work.", "journal": "EPTCS 280, 2018, pp. 30-46"}
{"doi": "10.48550/arXiv.1805.08704", "date": "2018-05-14", "title": "Replicating Active Appearance Model by Generator Network", "authors": "Tian Han, Jiawen Wu, Ying Nian Wu", "abstract": "A recent Cell paper [Chang and Tsao, 2017] reports an interesting discovery.\nFor the face stimuli generated by a pre-trained active appearance model (AAM),\nthe responses of neurons in the areas of the primate brain that are responsible\nfor face recognition exhibit strong linear relationship with the shape\nvariables and appearance variables of the AAM that generates the face stimuli.\nIn this paper, we show that this behavior can be replicated by a deep\ngenerative model called the generator network, which assumes that the observed\nsignals are generated by latent random variables via a top-down convolutional\nneural network. Specifically, we learn the generator network from the face\nimages generated by a pre-trained AAM model using variational auto-encoder, and\nwe show that the inferred latent variables of the learned generator network\nhave strong linear relationship with the shape and appearance variables of the\nAAM model that generates the face images. Unlike the AAM model that has an\nexplicit shape model where the shape variables generate the control points or\nlandmarks, the generator network has no such shape model and shape variables.\nYet the generator network can learn the shape knowledge in the sense that some\nof the latent variables of the learned generator network capture the shape\nvariations in the face images generated by AAM.", "journal": ""}
{"doi": "10.48550/arXiv.1912.12215", "date": "2019-12-27", "title": "Local Class-Specific and Global Image-Level Generative Adversarial Networks for Semantic-Guided Scene Generation", "authors": "Hao Tang, Dan Xu, Yan Yan, Philip H. S. Torr, Nicu Sebe", "abstract": "In this paper, we address the task of semantic-guided scene generation. One\nopen challenge in scene generation is the difficulty of the generation of small\nobjects and detailed local texture, which has been widely observed in global\nimage-level generation methods. To tackle this issue, in this work we consider\nlearning the scene generation in a local context, and correspondingly design a\nlocal class-specific generative network with semantic maps as a guidance, which\nseparately constructs and learns sub-generators concentrating on the generation\nof different classes, and is able to provide more scene details. To learn more\ndiscriminative class-specific feature representations for the local generation,\na novel classification module is also proposed. To combine the advantage of\nboth the global image-level and the local class-specific generation, a joint\ngeneration network is designed with an attention fusion module and a\ndual-discriminator structure embedded. Extensive experiments on two scene image\ngeneration tasks show superior generation performance of the proposed model.\nThe state-of-the-art results are established by large margins on both tasks and\non challenging public benchmarks. The source code and trained models are\navailable at https://github.com/Ha0Tang/LGGAN.", "journal": ""}
{"doi": "10.48550/arXiv.2002.00748", "date": "2020-01-27", "title": "Asking Questions the Human Way: Scalable Question-Answer Generation from Text Corpus", "authors": "Bang Liu, Haojie Wei, Di Niu, Haolan Chen, Yancheng He", "abstract": "The ability to ask questions is important in both human and machine\nintelligence. Learning to ask questions helps knowledge acquisition, improves\nquestion-answering and machine reading comprehension tasks, and helps a chatbot\nto keep the conversation flowing with a human. Existing question generation\nmodels are ineffective at generating a large amount of high-quality\nquestion-answer pairs from unstructured text, since given an answer and an\ninput passage, question generation is inherently a one-to-many mapping. In this\npaper, we propose Answer-Clue-Style-aware Question Generation (ACS-QG), which\naims at automatically generating high-quality and diverse question-answer pairs\nfrom unlabeled text corpus at scale by imitating the way a human asks\nquestions. Our system consists of: i) an information extractor, which samples\nfrom the text multiple types of assistive information to guide question\ngeneration; ii) neural question generators, which generate diverse and\ncontrollable questions, leveraging the extracted assistive information; and\niii) a neural quality controller, which removes low-quality generated data\nbased on text entailment. We compare our question generation models with\nexisting approaches and resort to voluntary human evaluation to assess the\nquality of the generated question-answer pairs. The evaluation results suggest\nthat our system dramatically outperforms state-of-the-art neural question\ngeneration models in terms of the generation quality, while being scalable in\nthe meantime. With models trained on a relatively smaller amount of data, we\ncan generate 2.8 million quality-assured question-answer pairs from a million\nsentences found in Wikipedia.", "journal": ""}
{"doi": "10.48550/arXiv.2002.11304", "date": "2020-02-26", "title": "PaDGAN: A Generative Adversarial Network for Performance Augmented Diverse Designs", "authors": "Wei Chen, Faez Ahmed", "abstract": "Deep generative models are proven to be a useful tool for automatic design\nsynthesis and design space exploration. When applied in engineering design,\nexisting generative models face three challenges: 1) generated designs lack\ndiversity and do not cover all areas of the design space, 2) it is difficult to\nexplicitly improve the overall performance or quality of generated designs, and\n3) existing models generally do not generate novel designs, outside the domain\nof the training data. In this paper, we simultaneously address these challenges\nby proposing a new Determinantal Point Processes based loss function for\nprobabilistic modeling of diversity and quality. With this new loss function,\nwe develop a variant of the Generative Adversarial Network, named \"Performance\nAugmented Diverse Generative Adversarial Network\" or PaDGAN, which can generate\nnovel high-quality designs with good coverage of the design space. Using three\nsynthetic examples and one real-world airfoil design example, we demonstrate\nthat PaDGAN can generate diverse and high-quality designs. In comparison to a\nvanilla Generative Adversarial Network, on average, it generates samples with a\n28% higher mean quality score with larger diversity and without the mode\ncollapse issue. Unlike typical generative models that usually generate new\ndesigns by interpolating within the boundary of training data, we show that\nPaDGAN expands the design space boundary outside the training data towards\nhigh-quality regions. The proposed method is broadly applicable to many tasks\nincluding design space exploration, design optimization, and creative solution\nrecommendation.", "journal": ""}
{"doi": "10.48550/arXiv.2007.04481", "date": "2020-07-09", "title": "Multi-dimensional backward stochastic differential equations of diagonally quadratic generators: the general result", "authors": "Shengjun Fan, Ying Hu, Shanjian Tang", "abstract": "This paper is devoted to a general solvability of a multi-dimensional\nbackward stochastic differential equation (BSDE) of a diagonally quadratic\ngenerator $g(t,y,z)$, by relaxing the assumptions of \\citet{HuTang2016SPA} on\nthe generator and terminal value. More precisely, the generator $g(t,y,z)$ can\nhave more general growth and continuity in $y$ in the local solution; while in\nthe global solution, the generator $g(t,y,z)$ can have a skew sub-quadratic but\nin addition \"strictly and diagonally\" quadratic growth in the second unknown\nvariable $z$, or the terminal value can be unbounded but the generator\n$g(t,y,z)$ is \"diagonally dependent\" on the second unknown variable $z$ (i.e.,\nthe $i$-th component $g^i$ of the generator $g$ only depends on the $i$-th row\n$z^i$ of the variable $z$ for each $i=1,\\cdots,n$ ). Three new results are\nestablished on the local and global solutions when the terminal value is\nbounded and the generator $g$ is subject to some general assumptions. When the\nterminal value is unbounded but is of exponential moments of arbitrary order,\nan existence and uniqueness result is given under the assumptions that the\ngenerator $g(t,y,z)$ is Lipschitz continuous in the first unknown variable $y$,\nand varies with the second unknown variable $z$ in a \"diagonal\" ,\n\"component-wisely convex or concave\", and \"quadratically growing\" way, which\nseems to be the first general solvability of systems of quadratic BSDEs with\nunbounded terminal values. This generalizes and strengthens some existing\nresults via some new ideas.", "journal": ""}
{"doi": "10.48550/arXiv.2007.06686", "date": "2020-07-13", "title": "A Systematic Survey on Deep Generative Models for Graph Generation", "authors": "Xiaojie Guo, Liang Zhao", "abstract": "Graphs are important data representations for describing objects and their\nrelationships, which appear in a wide diversity of real-world scenarios. As one\nof a critical problem in this area, graph generation considers learning the\ndistributions of given graphs and generating more novel graphs. Owing to their\nwide range of applications, generative models for graphs, which have a rich\nhistory, however, are traditionally hand-crafted and only capable of modeling a\nfew statistical properties of graphs. Recent advances in deep generative models\nfor graph generation is an important step towards improving the fidelity of\ngenerated graphs and paves the way for new kinds of applications. This article\nprovides an extensive overview of the literature in the field of deep\ngenerative models for graph generation. Firstly, the formal definition of deep\ngenerative models for the graph generation and the preliminary knowledge are\nprovided. Secondly, taxonomies of deep generative models for both unconditional\nand conditional graph generation are proposed respectively; the existing works\nof each are compared and analyzed. After that, an overview of the evaluation\nmetrics in this specific domain is provided. Finally, the applications that\ndeep graph generation enables are summarized and five promising future research\ndirections are highlighted.", "journal": ""}
{"doi": "10.48550/arXiv.2106.10876", "date": "2021-06-21", "title": "Total Generate: Cycle in Cycle Generative Adversarial Networks for Generating Human Faces, Hands, Bodies, and Natural Scenes", "authors": "Hao Tang, Nicu Sebe", "abstract": "We propose a novel and unified Cycle in Cycle Generative Adversarial Network\n(C2GAN) for generating human faces, hands, bodies, and natural scenes. Our\nproposed C2GAN is a cross-modal model exploring the joint exploitation of the\ninput image data and guidance data in an interactive manner. C2GAN contains two\ndifferent generators, i.e., an image-generation generator and a\nguidance-generation generator. Both generators are mutually connected and\ntrained in an end-to-end fashion and explicitly form three cycled subnets,\ni.e., one image generation cycle and two guidance generation cycles. Each cycle\naims at reconstructing the input domain and simultaneously produces a useful\noutput involved in the generation of another cycle. In this way, the cycles\nconstrain each other implicitly providing complementary information from both\nimage and guidance modalities and bringing an extra supervision gradient across\nthe cycles, facilitating a more robust optimization of the whole model.\nExtensive results on four guided image-to-image translation subtasks\ndemonstrate that the proposed C2GAN is effective in generating more realistic\nimages compared with state-of-the-art models. The code is available at\nhttps://github.com/Ha0Tang/C2GAN.", "journal": ""}
{"doi": "10.48550/arXiv.2106.10947", "date": "2021-06-21", "title": "Leveraging Conditional Generative Models in a General Explanation Framework of Classifier Decisions", "authors": "Martin Charachon, Paul-Henry Courn\u00e8de, C\u00e9line Hudelot, Roberto Ardon", "abstract": "Providing a human-understandable explanation of classifiers' decisions has\nbecome imperative to generate trust in their use for day-to-day tasks. Although\nmany works have addressed this problem by generating visual explanation maps,\nthey often provide noisy and inaccurate results forcing the use of heuristic\nregularization unrelated to the classifier in question. In this paper, we\npropose a new general perspective of the visual explanation problem overcoming\nthese limitations. We show that visual explanation can be produced as the\ndifference between two generated images obtained via two specific conditional\ngenerative models. Both generative models are trained using the classifier to\nexplain and a database to enforce the following properties: (i) All images\ngenerated by the first generator are classified similarly to the input image,\nwhereas the second generator's outputs are classified oppositely. (ii)\nGenerated images belong to the distribution of real images. (iii) The distances\nbetween the input image and the corresponding generated images are minimal so\nthat the difference between the generated elements only reveals relevant\ninformation for the studied classifier. Using symmetrical and cyclic\nconstraints, we present two different approximations and implementations of the\ngeneral formulation. Experimentally, we demonstrate significant improvements\nw.r.t the state-of-the-art on three different public data sets. In particular,\nthe localization of regions influencing the classifier is consistent with human\nannotations.", "journal": ""}
{"doi": "10.48550/arXiv.2112.15283", "date": "2021-12-31", "title": "ERNIE-ViLG: Unified Generative Pre-training for Bidirectional Vision-Language Generation", "authors": "Han Zhang, Weichong Yin, Yewei Fang, Lanxin Li, Boqiang Duan, Zhihua Wu, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang", "abstract": "Conventional methods for the image-text generation tasks mainly tackle the\nnaturally bidirectional generation tasks separately, focusing on designing\ntask-specific frameworks to improve the quality and fidelity of the generated\nsamples. Recently, Vision-Language Pre-training models have greatly improved\nthe performance of the image-to-text generation tasks, but large-scale\npre-training models for text-to-image synthesis task are still under-developed.\nIn this paper, we propose ERNIE-ViLG, a unified generative pre-training\nframework for bidirectional image-text generation with transformer model. Based\non the image quantization models, we formulate both image generation and text\ngeneration as autoregressive generative tasks conditioned on the text/image\ninput. The bidirectional image-text generative modeling eases the semantic\nalignments across vision and language. For the text-to-image generation\nprocess, we further propose an end-to-end training method to jointly learn the\nvisual sequence generator and the image reconstructor. To explore the landscape\nof large-scale pre-training for bidirectional text-image generation, we train a\n10-billion parameter ERNIE-ViLG model on a large-scale dataset of 145 million\n(Chinese) image-text pairs which achieves state-of-the-art performance for both\ntext-to-image and image-to-text tasks, obtaining an FID of 7.9 on MS-COCO for\ntext-to-image synthesis and best results on COCO-CN and AIC-ICC for image\ncaptioning.", "journal": ""}
{"doi": "10.48550/arXiv.2209.06427", "date": "2022-09-14", "title": "Efficient low-thrust trajectory data generation based on generative adversarial network", "authors": "Ruida Xie, Andrew G. Dempster", "abstract": "Deep learning-based techniques have been introduced into the field of\ntrajectory optimization in recent years. Deep Neural Networks (DNNs) are\ntrained and used as the surrogates of conventional optimization process. They\ncan provide low thrust (LT) transfer cost estimation and enable more complex\npreliminary mission designs. However, it is a challenge to efficiently obtain\nthe required amount of trajectory data for training. A Generative Adversarial\nNetwork (GAN) is adapted to generate the feasible LT trajectory data\nefficiently. The GAN consists of a generator and a discriminator, both of which\nare deep networks. The generator generates fake LT transfer features using\nrandom noise as input, while the discriminator distinguishes the generator's\nfake LT transfer features from real LT transfer features. The GAN is trained\nuntil the generator generates fake LT transfers that the discriminator cannot\nidentify. This indicates the generator generates low thrust transfer features\nthat have the same distribution as the real transfer features. The generated\nlow thrust transfer data have a high convergence rate, and they can be used to\nefficiently produce training data for deep learning models. The proposed\napproach is validated by generating feasible LT transfers in a Near-Earth\nAsteroid (NEA) mission scenario. The convergence rate of GAN-generated samples\nis 84.3%.", "journal": ""}
{"doi": "10.48550/arXiv.2303.09295", "date": "2023-03-16", "title": "DIRE for Diffusion-Generated Image Detection", "authors": "Zhendong Wang, Jianmin Bao, Wengang Zhou, Weilun Wang, Hezhen Hu, Hong Chen, Houqiang Li", "abstract": "Diffusion models have shown remarkable success in visual synthesis, but have\nalso raised concerns about potential abuse for malicious purposes. In this\npaper, we seek to build a detector for telling apart real images from\ndiffusion-generated images. We find that existing detectors struggle to detect\nimages generated by diffusion models, even if we include generated images from\na specific diffusion model in their training data. To address this issue, we\npropose a novel image representation called DIffusion Reconstruction Error\n(DIRE), which measures the error between an input image and its reconstruction\ncounterpart by a pre-trained diffusion model. We observe that\ndiffusion-generated images can be approximately reconstructed by a diffusion\nmodel while real images cannot. It provides a hint that DIRE can serve as a\nbridge to distinguish generated and real images. DIRE provides an effective way\nto detect images generated by most diffusion models, and it is general for\ndetecting generated images from unseen diffusion models and robust to various\nperturbations. Furthermore, we establish a comprehensive diffusion-generated\nbenchmark including images generated by eight diffusion models to evaluate the\nperformance of diffusion-generated image detectors. Extensive experiments on\nour collected benchmark demonstrate that DIRE exhibits superiority over\nprevious generated-image detectors. The code and dataset are available at\nhttps://github.com/ZhendongWang6/DIRE.", "journal": ""}
{"doi": "10.48550/arXiv.2308.01861", "date": "2023-08-03", "title": "ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation", "authors": "Xueying Du, Mingwei Liu, Kaixin Wang, Hanlin Wang, Junwei Liu, Yixuan Chen, Jiayi Feng, Chaofeng Sha, Xin Peng, Yiling Lou", "abstract": "In this work, we make the first attempt to evaluate LLMs in a more\nchallenging code generation scenario, i.e. class-level code generation. We\nfirst manually construct the first class-level code generation benchmark\nClassEval of 100 class-level Python code generation tasks with approximately\n500 person-hours. Based on it, we then perform the first study of 11\nstate-of-the-art LLMs on class-level code generation. Based on our results, we\nhave the following main findings. First, we find that all existing LLMs show\nmuch worse performance on class-level code generation compared to on standalone\nmethod-level code generation benchmarks like HumanEval; and the method-level\ncoding ability cannot equivalently reflect the class-level coding ability among\nLLMs. Second, we find that GPT-4 and GPT-3.5 still exhibit dominate superior\nthan other LLMs on class-level code generation, and the second-tier models\nincludes Instruct-Starcoder, Instruct-Codegen, and Wizardcoder with very\nsimilar performance. Third, we find that generating the entire class all at\nonce (i.e. holistic generation strategy) is the best generation strategy only\nfor GPT-4 and GPT-3.5, while method-by-method generation (i.e. incremental and\ncompositional) is better strategies for the other models with limited ability\nof understanding long instructions and utilizing the middle information.\nLastly, we find the limited model ability of generating method-dependent code\nand discuss the frequent error types in generated classes. Our benchmark is\navailable at https://github.com/FudanSELab/ClassEval.", "journal": ""}
{"doi": "10.48550/arXiv.2310.19410", "date": "2023-10-30", "title": "Generated Distributions Are All You Need for Membership Inference Attacks Against Generative Models", "authors": "Minxing Zhang, Ning Yu, Rui Wen, Michael Backes, Yang Zhang", "abstract": "Generative models have demonstrated revolutionary success in various visual\ncreation tasks, but in the meantime, they have been exposed to the threat of\nleaking private information of their training data. Several membership\ninference attacks (MIAs) have been proposed to exhibit the privacy\nvulnerability of generative models by classifying a query image as a training\ndataset member or nonmember. However, these attacks suffer from major\nlimitations, such as requiring shadow models and white-box access, and either\nignoring or only focusing on the unique property of diffusion models, which\nblock their generalization to multiple generative models. In contrast, we\npropose the first generalized membership inference attack against a variety of\ngenerative models such as generative adversarial networks, [variational]\nautoencoders, implicit functions, and the emerging diffusion models. We\nleverage only generated distributions from target generators and auxiliary\nnon-member datasets, therefore regarding target generators as black boxes and\nagnostic to their architectures or application scenarios. Experiments validate\nthat all the generative models are vulnerable to our attack. For instance, our\nwork achieves attack AUC $>0.99$ against DDPM, DDIM, and FastDPM trained on\nCIFAR-10 and CelebA. And the attack against VQGAN, LDM (for the\ntext-conditional generation), and LIIF achieves AUC $>0.90.$ As a result, we\nappeal to our community to be aware of such privacy leakage risks when\ndesigning and publishing generative models.", "journal": ""}
{"doi": "10.48550/arXiv.2401.03968", "date": "2024-01-08", "title": "scDiffusion: conditional generation of high-quality single-cell data using diffusion model", "authors": "Erpai Luo, Minsheng Hao, Lei Wei, Xuegong Zhang", "abstract": "Single-cell RNA sequencing (scRNA-seq) data are important for studying the\nlaws of life at single-cell level. However, it is still challenging to obtain\nenough high-quality scRNA-seq data. To mitigate the limited availability of\ndata, generative models have been proposed to computationally generate\nsynthetic scRNA-seq data. Nevertheless, the data generated with current models\nare not very realistic yet, especially when we need to generate data with\ncontrolled conditions. In the meantime, the Diffusion models have shown their\npower in generating data at high fidelity, providing a new opportunity for\nscRNA-seq generation.\n  In this study, we developed scDiffusion, a generative model combining\ndiffusion model and foundation model to generate high-quality scRNA-seq data\nwith controlled conditions. We designed multiple classifiers to guide the\ndiffusion process simultaneously, enabling scDiffusion to generate data under\nmultiple condition combinations. We also proposed a new control strategy called\nGradient Interpolation. This strategy allows the model to generate continuous\ntrajectories of cell development from a given cell state.\n  Experiments showed that scDiffusion can generate single-cell gene expression\ndata closely resembling real scRNA-seq data. Also, scDiffusion can\nconditionally produce data on specific cell types including rare cell types.\nFurthermore, we could use the multiple-condition generation of scDiffusion to\ngenerate cell type that was out of the training data. Leveraging the Gradient\nInterpolation strategy, we generated a continuous developmental trajectory of\nmouse embryonic cells. These experiments demonstrate that scDiffusion is a\npowerful tool for augmenting the real scRNA-seq data and can provide insights\ninto cell fate research.", "journal": ""}
{"doi": "10.48550/arXiv.2401.04418", "date": "2024-01-09", "title": "Some Generalized Information and Divergence Generating Functions: Properties, Estimation, Validation and Applications", "authors": "Shital Saha, Suchandan Kayal, N. Balakrishnan", "abstract": "We propose R\\'enyi information generating function and discuss its\nproperties. A connection between the R\\'enyi information generating function\nand the diversity index is proposed for discrete type random variables. The\nrelation between the R\\'enyi information generating function and Shannon\nentropy of order $q>0$ is established and several bounds are obtained. The\nR\\'enyi information generating function of escort distribution is derived.\nFurthermore, we introduce R\\'enyi divergence information generating function\nand discuss its effect under monotone transformations. We present\nnon-parametric and parametric estimators of the R\\'enyi information generating\nfunction. A simulation study is carried out and a real data relating to the\nfailure times of electronic components is analyzed. A comparison study between\nthe non-parametric and parametric estimators is made in terms of the standard\ndeviation, absolute bias, and mean square error. We have observed superior\nperformance for the newly proposed estimators. Some applications of the\nproposed R\\'enyi information generating function and R\\'enyi divergence\ninformation generating function are provided. For three coherent systems, we\ncalculate the values of the R\\'enyi information generating function and other\nwell-established uncertainty measures and similar behaviour of the R\\'enyi\ninformation generating function is observed. Further, a study regarding the\nusefulness of the R\\'enyi divergence information generating function and\nR\\'enyi information generating function as model selection criteria is\nconducted. Finally, three chaotic maps are considered and then used to\nestablish a validation of the proposed information generating function.", "journal": ""}
{"doi": "10.48550/arXiv.2403.08294", "date": "2024-03-13", "title": "Attack Deterministic Conditional Image Generative Models for Diverse and Controllable Generation", "authors": "Tianyi Chu, Wei Xing, Jiafu Chen, Zhizhong Wang, Jiakai Sun, Lei Zhao, Haibo Chen, Huaizhong Lin", "abstract": "Existing generative adversarial network (GAN) based conditional image\ngenerative models typically produce fixed output for the same conditional\ninput, which is unreasonable for highly subjective tasks, such as large-mask\nimage inpainting or style transfer. On the other hand, GAN-based diverse image\ngenerative methods require retraining/fine-tuning the network or designing\ncomplex noise injection functions, which is computationally expensive,\ntask-specific, or struggle to generate high-quality results. Given that many\ndeterministic conditional image generative models have been able to produce\nhigh-quality yet fixed results, we raise an intriguing question: is it possible\nfor pre-trained deterministic conditional image generative models to generate\ndiverse results without changing network structures or parameters? To answer\nthis question, we re-examine the conditional image generation tasks from the\nperspective of adversarial attack and propose a simple and efficient plug-in\nprojected gradient descent (PGD) like method for diverse and controllable image\ngeneration. The key idea is attacking the pre-trained deterministic generative\nmodels by adding a micro perturbation to the input condition. In this way,\ndiverse results can be generated without any adjustment of network structures\nor fine-tuning of the pre-trained models. In addition, we can also control the\ndiverse results to be generated by specifying the attack direction according to\na reference text or image. Our work opens the door to applying adversarial\nattack to low-level vision tasks, and experiments on various conditional image\ngeneration tasks demonstrate the effectiveness and superiority of the proposed\nmethod.", "journal": ""}
{"doi": "10.48550/arXiv.2405.05435", "date": "2024-05-08", "title": "Analysis and prevention of AI-based phishing email attacks", "authors": "Chibuike Samuel Eze, Lior Shamir", "abstract": "Phishing email attacks are among the most common and most harmful\ncybersecurity attacks. With the emergence of generative AI, phishing attacks\ncan be based on emails generated automatically, making it more difficult to\ndetect them. That is, instead of a single email format sent to a large number\nof recipients, generative AI can be used to send each potential victim a\ndifferent email, making it more difficult for cybersecurity systems to identify\nthe scam email before it reaches the recipient. Here we describe a corpus of\nAI-generated phishing emails. We also use different machine learning tools to\ntest the ability of automatic text analysis to identify AI-generated phishing\nemails. The results are encouraging, and show that machine learning tools can\nidentify an AI-generated phishing email with high accuracy compared to regular\nemails or human-generated scam email. By applying descriptive analytic, the\nspecific differences between AI-generated emails and manually crafted scam\nemails are profiled, and show that AI-generated emails are different in their\nstyle from human-generated phishing email scams. Therefore, automatic\nidentification tools can be used as a warning for the user. The paper also\ndescribes the corpus of AI-generated phishing emails that is made open to the\npublic, and can be used for consequent studies. While the ability of machine\nlearning to detect AI-generated phishing email is encouraging, AI-generated\nphishing emails are different from regular phishing emails, and therefore it is\nimportant to train machine learning systems also with AI-generated emails in\norder to repel future phishing attacks that are powered by generative AI.", "journal": ""}
{"doi": "10.48550/arXiv.2405.14598", "date": "2024-05-23", "title": "Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation", "authors": "Shiqi Yang, Zhi Zhong, Mengjie Zhao, Shusuke Takahashi, Masato Ishii, Takashi Shibuya, Yuki Mitsufuji", "abstract": "In recent years, with the realistic generation results and a wide range of\npersonalized applications, diffusion-based generative models gain huge\nattention in both visual and audio generation areas. Compared to the\nconsiderable advancements of text2image or text2audio generation, research in\naudio2visual or visual2audio generation has been relatively slow. The recent\naudio-visual generation methods usually resort to huge large language model or\ncomposable diffusion models. Instead of designing another giant model for\naudio-visual generation, in this paper we take a step back showing a simple and\nlightweight generative transformer, which is not fully investigated in\nmulti-modal generation, can achieve excellent results on image2audio\ngeneration. The transformer operates in the discrete audio and visual\nVector-Quantized GAN space, and is trained in the mask denoising manner. After\ntraining, the classifier-free guidance could be deployed off-the-shelf\nachieving better performance, without any extra training or modification. Since\nthe transformer model is modality symmetrical, it could also be directly\ndeployed for audio2image generation and co-generation. In the experiments, we\nshow that our simple method surpasses recent image2audio generation methods.\nGenerated audio samples can be found at\nhttps://docs.google.com/presentation/d/1ZtC0SeblKkut4XJcRaDsSTuCRIXB3ypxmSi7HTY3IyQ/", "journal": ""}
{"doi": "10.48550/arXiv.2410.08898", "date": "2024-10-11", "title": "Low-Dimension-to-High-Dimension Generalization And Its Implications for Length Generalization", "authors": "Yang Chen, Long Yang, Yitao Liang, Zhouchen Lin", "abstract": "Low-Dimension-to-High-Dimension (LDHD) generalization is a special case of\nOut-of-Distribution (OOD) generalization, where the training data are\nrestricted to a low-dimensional subspace of the high-dimensional testing space.\nAssuming that each instance is generated from a latent variable and the\ndimension of the latent variable reflects the problem scale, the inherent\nscaling challenge in length generalization can be captured by the LDHD\ngeneralization in the latent space. We theoretically demonstrate that LDHD\ngeneralization is generally unattainable without exploiting prior knowledge to\nprovide appropriate inductive bias. Specifically, we explore LDHD\ngeneralization in Boolean functions. We verify that different architectures\ntrained with (S)GD converge to \\emph{min-degree interpolators w.r.t. different\nindependent sets}. LDHD generalization is achievable if and only if the target\nfunction coincides with this inductive bias. Applying the insights from LDHD\ngeneralization to length generalization, we explain the effectiveness of CoT as\nchanging the structure latent space to enable better LDHD generalization. We\nalso propose a principle for position embedding design to handle both the\ninherent LDHD generalization and the nuisances such as the data format.\nFollowing the principle, we propose a novel position embedding called\nRPE-Square that remedies the RPE for dealing with the data format nuisance.", "journal": ""}
{"doi": "10.48550/arXiv.2410.14223", "date": "2024-10-18", "title": "G-NeuroDAVIS: A Neural Network model for generalized embedding, data visualization and sample generation", "authors": "Chayan Maitra, Rajat K. De", "abstract": "Visualizing high-dimensional datasets through a generalized embedding has\nbeen a challenge for a long time. Several methods have shown up for the same,\nbut still, they have not been able to generate a generalized embedding, which\nnot only can reveal the hidden patterns present in the data but also generate\nrealistic high-dimensional samples from it. Motivated by this aspect, in this\nstudy, a novel generative model, called G-NeuroDAVIS, has been developed, which\nis capable of visualizing high-dimensional data through a generalized\nembedding, and thereby generating new samples. The model leverages advanced\ngenerative techniques to produce high-quality embedding that captures the\nunderlying structure of the data more effectively than existing methods.\nG-NeuroDAVIS can be trained in both supervised and unsupervised settings. We\nrigorously evaluated our model through a series of experiments, demonstrating\nsuperior performance in classification tasks, which highlights the robustness\nof the learned representations. Furthermore, the conditional sample generation\ncapability of the model has been described through qualitative assessments,\nrevealing a marked improvement in generating realistic and diverse samples.\nG-NeuroDAVIS has outperformed the Variational Autoencoder (VAE) significantly\nin multiple key aspects, including embedding quality, classification\nperformance, and sample generation capability. These results underscore the\npotential of our generative model to serve as a powerful tool in various\napplications requiring high-quality data generation and representation\nlearning.", "journal": ""}
{"doi": "10.48550/arXiv.2502.06097", "date": "2025-02-10", "title": "NLGR: Utilizing Neighbor Lists for Generative Rerank in Personalized Recommendation Systems", "authors": "Shuli Wang, Xue Wei, Senjie Kou, Chi Wang, Wenshuai Chen, Qi Tang, Yinhua Zhu, Xiong Xiao, Xingxing Wang", "abstract": "Reranking plays a crucial role in modern multi-stage recommender systems by\nrearranging the initial ranking list. Due to the inherent challenges of\ncombinatorial search spaces, some current research adopts an\nevaluator-generator paradigm, with a generator generating feasible sequences\nand an evaluator selecting the best sequence based on the estimated list\nutility. However, these methods still face two issues. Firstly, due to the goal\ninconsistency problem between the evaluator and generator, the generator tends\nto fit the local optimal solution of exposure distribution rather than\ncombinatorial space optimization. Secondly, the strategy of generating target\nitems one by one is difficult to achieve optimality because it ignores the\ninformation of subsequent items.\n  To address these issues, we propose a utilizing Neighbor Lists model for\nGenerative Reranking (NLGR), which aims to improve the performance of the\ngenerator in the combinatorial space. NLGR follows the evaluator-generator\nparadigm and improves the generator's training and generating methods.\nSpecifically, we use neighbor lists in combination space to enhance the\ntraining process, making the generator perceive the relative scores and find\nthe optimization direction. Furthermore, we propose a novel sampling-based\nnon-autoregressive generation method, which allows the generator to jump\nflexibly from the current list to any neighbor list. Extensive experiments on\npublic and industrial datasets validate NLGR's effectiveness and we have\nsuccessfully deployed NLGR on the Meituan food delivery platform.", "journal": ""}
{"doi": "10.48550/arXiv.2504.16485", "date": "2025-04-23", "title": "On Developers' Self-Declaration of AI-Generated Code: An Analysis of Practices", "authors": "Syed Mohammad Kashif, Peng Liang, Amjed Tahir", "abstract": "AI code generation tools have gained significant popularity among developers,\nwho use them to assist in software development due to their capability to\ngenerate code. Existing studies mainly explored the quality, e.g., correctness\nand security, of AI-generated code, while in real-world software development,\nthe prerequisite is to distinguish AI-generated code from human-written code,\nwhich emphasizes the need to explicitly declare AI-generated code by\ndevelopers. To this end, this study intends to understand the ways developers\nuse to self-declare AI-generated code and explore the reasons why developers\nchoose to self-declare or not. We conducted a mixed-methods study consisting of\ntwo phases. In the first phase, we mined GitHub repositories and collected 613\ninstances of AI-generated code snippets. In the second phase, we conducted a\nfollow-up industrial survey, which received 111 valid responses. Our research\nrevealed the practices followed by developers to self-declare AI-generated\ncode. Most practitioners (76.6%) always or sometimes self-declare AI-generated\ncode. In contrast, other practitioners (23.4%) noted that they never\nself-declare AI-generated code. The reasons for self-declaring AI-generated\ncode include the need to track and monitor the code for future review and\ndebugging, and ethical considerations. The reasons for not self-declaring\nAI-generated code include extensive modifications to AI-generated code and the\ndevelopers' perception that self-declaration is an unnecessary activity. We\nfinally provided guidelines for practitioners to self-declare AI-generated\ncode, addressing ethical and code quality concerns.", "journal": ""}
{"doi": "10.48550/arXiv.2505.05474", "date": "2025-05-08", "title": "3D Scene Generation: A Survey", "authors": "Beichen Wen, Haozhe Xie, Zhaoxi Chen, Fangzhou Hong, Ziwei Liu", "abstract": "3D scene generation seeks to synthesize spatially structured, semantically\nmeaningful, and photorealistic environments for applications such as immersive\nmedia, robotics, autonomous driving, and embodied AI. Early methods based on\nprocedural rules offered scalability but limited diversity. Recent advances in\ndeep generative models (e.g., GANs, diffusion models) and 3D representations\n(e.g., NeRF, 3D Gaussians) have enabled the learning of real-world scene\ndistributions, improving fidelity, diversity, and view consistency. Recent\nadvances like diffusion models bridge 3D scene synthesis and photorealism by\nreframing generation as image or video synthesis problems. This survey provides\na systematic overview of state-of-the-art approaches, organizing them into four\nparadigms: procedural generation, neural 3D-based generation, image-based\ngeneration, and video-based generation. We analyze their technical foundations,\ntrade-offs, and representative results, and review commonly used datasets,\nevaluation protocols, and downstream applications. We conclude by discussing\nkey challenges in generation capacity, 3D representation, data and annotations,\nand evaluation, and outline promising directions including higher fidelity,\nphysics-aware and interactive generation, and unified perception-generation\nmodels. This review organizes recent advances in 3D scene generation and\nhighlights promising directions at the intersection of generative AI, 3D\nvision, and embodied intelligence. To track ongoing developments, we maintain\nan up-to-date project page:\nhttps://github.com/hzxie/Awesome-3D-Scene-Generation.", "journal": ""}
{"doi": "10.48550/arXiv.9611203", "date": "1996-11-26", "title": "Generalized Distribution Functions and an Alternative Approach to Generalized Planck Radiation Law", "authors": "Ugur Tirnakli, Fevzi Buyukkilic, Dogan Demirhan", "abstract": "In this study, recently introduced generalized distribution functions are\nsummarized and by using one of these distribution functions, namely generalized\nPlanck distribution, an alternative approach to the generalized Planck law for\nthe blackbody radiation has been tackled.", "journal": "Physica A 240 (1997) 657"}
{"doi": "10.48550/arXiv.0005198", "date": "2000-05-11", "title": "Generalized Entropy approach to far-from-equilibrium statistical mechanics", "authors": "Alexei V. Tkachenko", "abstract": "We present a new approach to far-from-equilibrium statistical mechanics,\nbased on the concept of generalized entropy, which is a microscopically-defined\ngeneralization of Onsager-Machlup functional. In the case when a set of slow\n(adiabatic) variables can be chosen, our formalism yields a general form of the\nmacroscopic evolution law (Generalized Langevin Equation) and extends\nFluctuation Dissipative Theorem. It also provides for a simple understanding of\nrecently-discovered Fluctuation Theorem", "journal": ""}
{"doi": "10.48550/arXiv.0603694", "date": "2006-03-26", "title": "Replica symmetry breaking related to a general ultrametric space III: the case of general measure", "authors": "A. Yu. Khrennikov, S. V. Kozyrev", "abstract": "Family of replica matrices, related to general ultrametric spaces with\ngeneral measures, is introduced. These matrices generalize the known Parisi\nmatrices. Some functionals of replica approach are computed. Replica symmetry\nbreaking solution is found.", "journal": "Physica A: Statistical Mechanics and its Applications. 2007.\n  V.378. N.2. P.283-298"}
{"doi": "10.48550/arXiv.9712070", "date": "1997-12-16", "title": "Perturbative dynamics of quantum general relativity", "authors": "John F. Donoghue", "abstract": "The quantum theory of General Relativity at low energy exists and is of the\nform called \"effective field theory\". In this talk I describe the ideas of\neffective field theory and its application to General Relativity.", "journal": ""}
{"doi": "10.48550/arXiv.9910096", "date": "1999-10-26", "title": "Generating rotating fields in general relativity", "authors": "Gerard Clement", "abstract": "I present a new method to generate rotating solutions of the Einstein-Maxwell\nequations from static solutions, give several examples of its application, and\ndiscuss its general properties.", "journal": "Grav.Cosmol. 5 (1999) 281-284"}
{"doi": "10.48550/arXiv.0703014", "date": "2007-03-02", "title": "A New Formulation of General Relativity - Part II: Pre-Radar Charts and Generating Functions in Arbitrary Space-Times", "authors": "Joachim Schr\u00f6ter", "abstract": "In this paper (Part II), the so-called inverse problem is treated. This means\nthe question whether it is possible to define pre-radar charts, i.e. generating\nfunctions in arbitrary space-times. This problem is subtle. A local general\nconstructive solution of it is presented. Sufficient conditions for the\nexistence of global solutions are given.", "journal": ""}
{"doi": "10.48550/arXiv.0407192", "date": "2004-07-16", "title": "Possible Chandra-Mechanism for Generation Bound", "authors": "K. Koike", "abstract": "In the generation structure, the quark mass increases extremely rapidly with\nthe increase of generation index, and there is the bound for generation number.\nThe ground for this bound is investigated on the basis of a certain kind of\ncomposite model of leptons and quarks, in which they are supposed to be\ncomposed of sub-constituents with fermi statistics. Possible Chandrasekhar-like\nmechanism for generation bound is proposed.", "journal": ""}
{"doi": "10.48550/arXiv.9201294", "date": "1991-10-11", "title": "On the quasisymmetrical classification of infinitely renormalizable maps: I. Maps with Feigenbaum's topology.", "authors": "Yunping Jiang", "abstract": "A semigroup (dynamical system) generated by $C^{1+\\alpha}$-contracting\nmappings is considered. We call a such semigroup regular if the maximum $K$ of\nthe conformal dilatations of generators, the maximum $l$ of the norms of the\nderivatives of generators and the smoothness $\\alpha$ of the generators satisfy\na compatibility condition $K< 1/l^{\\alpha}$. We prove the {\\em geometric\ndistortion lemma} for a regular semigroup generated by\n$C^{1+\\alpha}$-contracting mappings.", "journal": ""}
{"doi": "10.48550/arXiv.0006025", "date": "2000-06-05", "title": "A note on polarizations of finitely generated fields", "authors": "Atsushi Moriwaki", "abstract": "In our previous paper, we established Northcott's theorem for height\nfunctions over finitely generated fields. Unfortunately, Northcott's theorem on\nfinitely generated fields does not hold in general. Actually, it depends on the\nchoice of a polarization. In this short note, we will propose a weaker\ncondition of the polarization to guarantee Northcott's theorem. We will also\nshow the generalization of conjectures of Bogomolov and Lang in under the\nweaker condition.", "journal": ""}
{"doi": "10.48550/arXiv.0212244", "date": "2002-12-18", "title": "Spherical simplices generating discrete reflection groups", "authors": "A. Felikson", "abstract": "Let $P$ be a simplex in $S^n$ and $G_P$ be a group generated by the\nreflections with respect to the facets of $P$. We are interested in the case\nwhen the group $G_P$ is discrete. In this case we say that $G$ generates the\ndiscrete reflection group $G_P$. We develop the criteria for a simplex\ngenerating a discrete reflection group. We also describe all indecomposable\nspherical simplices generating discrete reflection groups.", "journal": ""}
{"doi": "10.48550/arXiv.0304034", "date": "2003-04-03", "title": "Some representations of nongraded Lie algebras of generalized Witt type", "authors": "Yucai Su, Jianhua Zhou", "abstract": "In a paper by Xu, some simple Lie algebras of generalized Cartan type were\nconstructed, using the mixtures of grading operators and down-grading\noperators. Among them, are the simple Lie algebras of generalized Witt type,\nwhich are in general nongraded and have no torus. In this paper, some\nrepresentations of these simple Lie algebras of generalized Witt type are\npresented.", "journal": "J .Alg., 246 (2001), 721-738"}
{"doi": "10.48550/arXiv.0504061", "date": "2005-04-04", "title": "Generalized Group Actions in a Global Setting", "authors": "Sanja Konjik, Michael Kunzinger", "abstract": "We study generalized group actions on differentiable manifolds in the\nColombeau framework, extending previous work on flows of generalized vector\nfields and symmetry group analysis of generalized solutions. As an application,\nwe analyze group invariant generalized functions in this setting.", "journal": "J. Math. Anal. Appl., 322, 420-436, 2006"}
{"doi": "10.48550/arXiv.0505126", "date": "2005-05-09", "title": "Generalized Integral Operators and Applications", "authors": "S\u00e9verine Bernard, Jean-Fran\u00e7ois Colombeau, Antoine Delcroix", "abstract": "We extend the theory of distributional kernel operators to a framework of\ngeneralized functions, in which they are replaced by integral kernel operators.\nMoreover, in contrast to the distributional case, we show that these\ngeneralized integral operators can be composed unrestrictedly. This leads to\nthe definition of the exponential, and more generally entire functions, of a\nsubclass of such operators.", "journal": ""}
{"doi": "10.48550/arXiv.0511484", "date": "2005-11-19", "title": "On a q-analogue of the p-adic generalized twisted L-functions and p-adic q-integrals", "authors": "Lee-Chae Jang", "abstract": "The purpose of this paper is to define generalized twisted q-Bernoulli\nnumbers by using p-adic q-integrals. Furthermore, we construct a q-analogue of\nthe p-adic generalized twisted L-functions which interpolate generalized\ntwisted q-Bernoulli numbers. This is the generalization of Kim's h-extension of\np-adic q-L-function which was constructed in [5] and is a partial answer for\nthe open question which was remained in [3]", "journal": ""}
{"doi": "10.48550/arXiv.0603596", "date": "2006-03-25", "title": "Formality in generalized Kahler geometry", "authors": "Gil R. Cavalcanti", "abstract": "We prove that no nilpotent Lie algebra admits an invariant generalized\nKaehler structure. This is done by showing that a certain differential graded\nalgebra associated to a generalized complex manifold is formal in the\ngeneralized Kaehler case, while it is never formal for a generalized complex\nstructure on a nilpotent Lie algebra.", "journal": "Topology Appl., 154, 1119--1125, 2007"}
{"doi": "10.48550/arXiv.0604495", "date": "2006-04-23", "title": "Spherical completeness of the non-archimedean ring of Colombeau generalized numbers", "authors": "Eberhard Mayerhofer", "abstract": "We show spherical completeness of the ring of Colombeau generalized real (or\ncomplex) numbers endowed with the sharp norm. As an application, we establish a\nHahn Banach extension theorem for ultra pseudo normed modules (over the ring of\ngeneralized numbers) of generalized functions in the sense of Colombeau.", "journal": "Bulletin Inst. Math. Academia Sinica (New Series) Vol.2, No. 3,\n  pp. 769-783 (2007)"}
{"doi": "10.48550/arXiv.0610448", "date": "2006-10-14", "title": "Generalized Kac-Moody Lie Algebras And Product Quivers", "authors": "Yiqiang Li, Zongzhu Lin", "abstract": "We construct the entire generalized Kac-Moody Lie algebra as a quotient of\nthe positive part of another generalized Kac-Moody Lie algebra. The positive\npart of a generalized Kac-Moody Lie algebra can be constructed from\nrepresentations of quivers using Ringel's Hall algebra construction. Thus we\ngive a direct realization of the entire generalized Kac-Moody Lie algebra.", "journal": ""}
{"doi": "10.48550/arXiv.0607045", "date": "2006-07-20", "title": "Generalized q-deformed oscillators, q-Hermite polynomials, generalized coherent states", "authors": "I. M. Burban", "abstract": "The aim of this paper is to study generalized q-analogs of the well-known\nq-deformed harmonic oscillators and to connect them with q-Hermite polynomials.\nWe give a construction of the appropriate oscillator-like algebras and show\nthat corresponding Hermite polynomials are generalization of the discrete\nq-Hermite I and the discrete q-Hermite II polynomials. We also construct\ngeneralized coherent states of Barut-Girardello type for oscillator-like\nsystems connected with these polynomials.", "journal": ""}
{"doi": "10.48550/arXiv.0305041", "date": "2003-05-22", "title": "The Generalized Harry Dym Equation", "authors": "Ziemowit Popowicz", "abstract": "The Harry Dym equation is generalized to the system of equations in the\nmanner as the Korteweg - de Vries equation is generalized to the Hirota -\nSatsuma equation . The Lax and Hamiltonian formulation for this generalization\nis given.This generalized Lax operator gives the hierarchy of equations also.", "journal": "Phys. Lett. A317 260-264 (2003)"}
{"doi": "10.48550/arXiv.9911011", "date": "1999-11-10", "title": "On Gravitational Shielding in Electromagnetic Fields", "authors": "M. Agop, C. Gh. Buzea, B. Ciobanu", "abstract": "We show the presence of an electromagnetic field can cause a gravitational\nMeissner effect and, as a result, a gravitational shielding. With this aim in\nview we must first unveil the following problems : generalized Maxwell\nequations, generalized London equations, generalized Meissner effect,\ngeneralized shielding, etc.", "journal": ""}
{"doi": "10.48550/arXiv.0302067", "date": "2003-02-20", "title": "Superconducting Power Generation", "authors": "Mario Rabinowitz", "abstract": "The superconducting ac generator has the greatest potential for large-scale\ncommercial application of superconductivity that can benefit the public.\nElectric power is a vital ingredient of modern society, and generation may be\nconsidered to be the vital ingredient of a power system. This articles gives\nbackground, and an insight into the physics and engineering of superconducting\npower generation.", "journal": "IEEE Power Engineering Review 20 No.5 (2000) pp.8 - 11"}
{"doi": "10.48550/arXiv.0510269", "date": "2005-10-31", "title": "Realistic Cosmological Constant", "authors": "Gordon Chalmers", "abstract": "Scenarios of supersymmetry breaking at various scales from TeV to GUT to the\nstring are generated. A previous analysis generated the value of the\nexperimentally measured cosmological constant from supersymmetry breaking at\nthe TeV scale. Via a reorganization of the perturbative series, values of the\ncosmological constant are generically reconcilable with supersymmetry breaking\nscenarios having scales from the TeV on up to the string. The scenario with\nonly a single supersymmetry breaking scale occurs at the GUT scale,\ngenerically.", "journal": ""}
{"doi": "10.48550/arXiv.0610237", "date": "2006-10-26", "title": "On the rational relationship between Heisenberg principle and general relativity", "authors": "Jianhua Xiao", "abstract": "The research shows that the Heisenberg principle is the logic results of\ngeneral relativity principle. If inertia coordinator system is used, the\ngeneral relativity will logically be derived from the Heisenberg principle. The\nintrinsic relation between the quantum mechanics and general relativity is\nbroken by introducing pure-imaginary time to explain the Lorentz\ntransformation. Therefore, this research shows a way to establish an unified\nfield theory of physics", "journal": ""}
{"doi": "10.48550/arXiv.0603127", "date": "2006-03-15", "title": "General pure multipartite entangled states and the Segre variety", "authors": "Hoshang Heydari", "abstract": "In this paper, we construct a measure of entanglement by generalizing the\nquadric polynomial of the Segre variety for general multipartite states. We\ngive explicit expressions for general pure three-partite and four-partite\nstates. Moreover, we will discuss and compare this measure of entanglement with\nthe generalized concurrence.", "journal": "J. Phys. A: Math. Gen. 39 (2006) 9839-9844"}
{"doi": "10.48550/arXiv.9706001", "date": "1997-05-30", "title": "R-Matrices and Generalized Inverses", "authors": "H. W. Braden", "abstract": "Four results are given that address the existence, ambiguities and\nconstruction of a classical R-matrix given a Lax pair. They enable the uniform\nconstruction of R-matrices in terms of any generalized inverse of $ad L$. For\ngeneric $L$ a generalized inverse (and indeed the Moore-Penrose inverse) is\nexplicitly constructed. The R-matrices are in general momentum dependent and\ndynamical. The construction applies equally to Lax matrices with spectral\nparameter.", "journal": ""}
{"doi": "10.48550/arXiv.0710.0628", "date": "2007-10-02", "title": "New explicit spike solution -- non-local component of the generalized Mixmaster attractor", "authors": "Woei Chet Lim", "abstract": "By applying a standard solution-generating transformation to an arbitrary\nvacuum Bianchi type II solution, one generates a new solution with spikes\ncommonly observed in numerical simulations. It is conjectured that the spike\nsolution is part of the generalized Mixmaster attractor.", "journal": "Class.Quant.Grav.25:045014,2008"}
{"doi": "10.48550/arXiv.0801.3755", "date": "2008-01-24", "title": "Generalized iteration, catastrophes and generalized Sharkovsky's ordering", "authors": "Andrei Vieru", "abstract": "We define iteration of functions that map n-dimensional vector spaces into\nm-dimensional vector spaces (m at most equal to n). It happens that usual\niteration and Fibonacci iterative methods become special cases of this\ngeneralized iteration. Mathematical objects such as orbits, bifurcations,\nchaos, Feigenbaum constant, (generalized) Sharkovsky ordering, (generalized)\nJulia and Mandelbrot sets and a new kind of catastrophe can be found and\nstudied in this enlarged context.", "journal": ""}
{"doi": "10.48550/arXiv.0803.4350", "date": "2008-03-30", "title": "Generating Forms for Exact Volume-Preserving Maps", "authors": "H. E. Lomel\u00ed, J. D. Meiss", "abstract": "We study the group of volume-preserving diffeomorphisms on a manifold. We\ndevelop a general theory of implicit generating forms. Our results generalize\nthe classical formulas for generating functions of symplectic twist maps.", "journal": "Disc. Cont. Dyn. Sys. Series S 2(2): 361-377 (2009)"}
{"doi": "10.48550/arXiv.0805.1280", "date": "2008-05-09", "title": "Pattern Avoidance in Generalized Non-crossing Trees", "authors": "Yidong Sun, Zhiping Wang", "abstract": "In this paper, the problem of pattern avoidance in generalized non-crossing\ntrees is studied. The generating functions for generalized non-crossing trees\navoiding patterns of length one and two are obtained. Lagrange inversion\nformula is used to obtain the explicit formulas for some special cases.\nBijection is also established between generalized non-crossing trees with\nspecial pattern avoidance and the little Schr\\\"{o}der paths.", "journal": ""}
{"doi": "10.48550/arXiv.0805.3880", "date": "2008-05-26", "title": "The Formation of Black Holes in General Relativity", "authors": "Demetrios Christodoulou", "abstract": "The subject of this work is the formation of black holes in pure general\nrelativity, by the focusing of incoming gravitational waves. The theorems\nestablished in this monograph constitute the first foray into the long time\ndynamics of general relativity in the large, that is, when the initial data are\nno longer confined to a suitably small neighborhood of Minkowskian data. The\ntheorems are general, no symmetry conditions on the initial data being imposed.", "journal": ""}
{"doi": "10.48550/arXiv.0807.1436", "date": "2008-07-09", "title": "Two Generalizations of Tensor Products, Beyond Vector Spaces", "authors": "Elemer E Rosinger", "abstract": "Two successive generalizations of the usual tensor products are given. One\ncan be constructed for arbitrary binary operations, and not only for\nsemigroups, groups or vector spaces. The second one, still more general, is\nconstructed for arbitrary generators on sets.", "journal": ""}
{"doi": "10.48550/arXiv.0810.3266", "date": "2008-10-17", "title": "Generating varieties for affine Grassmannians", "authors": "Peter J. Littig, Stephen A. Mitchell", "abstract": "We study the topological group structure (coming from loop multiplication) on\nan affine Grassmannian. In particular, we study finite-dimensional subvarieties\nthat generate the homology ring. We show that there is a canonical family of\ngenerating Schubert varieties, namely those defined by the negative of the\ncoroot associated to the highest root. These not only generate the homology,\nbut generate the affine Grassmannian itself in a precise sense.", "journal": ""}
{"doi": "10.48550/arXiv.0903.4652", "date": "2009-03-26", "title": "Maximal Graded Orders over Crystalline Graded Rings", "authors": "Tim Neijens, Fred Van Oystaeyen", "abstract": "Crystalline graded rings are generalizations of certain classes of rings like\ngeneralized twisted group rings, generalized Weyl algebras, and generalized\nskew crossed products. When the base ring is a commutative Dedekind domain, two\nconstructions are given for producing maximal graded orders. On the way, a new\nconcept appears, so-called, spectrally twisted group. Some general properties\nof it are studied. At the end of the paper several examples are considered.", "journal": ""}
{"doi": "10.48550/arXiv.0904.4614", "date": "2009-04-29", "title": "Compact generation for Lie groupoids", "authors": "Nicolas Raimbaud", "abstract": "Thirty years after the birth of foliations in the 1950's, Andr\\'e Haefliger\nhas introduced a special property satisfied by holonomy pseudogroups of\nfoliations on compact manifolds, called compact generation. Up to now, this is\nthe only general property known about holonomy on compact manifolds. In this\narticle, we give a Morita-invariant generalization of Haefliger's compact\ngeneration, from pseudogroups to object-separated Lie groupoids.", "journal": ""}
{"doi": "10.48550/arXiv.0906.2740", "date": "2009-06-15", "title": "The Equivariant Generating Hypothesis", "authors": "Anna Marie Bohmann", "abstract": "We state the generating hypothesis in the homotopy category of G-spectra for\na compact Lie group G, and prove that if G is finite, then the generating\nhypothesis implies the strong generating hypothesis, just as in the\nnon-equivariant case. We also give an explicit counterexample to the generating\nhypothesis in the category of rational S^1-equivariant spectra.", "journal": "Algebr. Geom. Topol. 10 (2010) 1003-1016"}
{"doi": "10.48550/arXiv.0908.4178", "date": "2009-08-28", "title": "Geometrical Properties and Propagation for the Proca Field Theory", "authors": "Luca Fabbri", "abstract": "We consider the Proca field with dynamical term given by the exterior\nderivative with respect to the most general connection; the most general Proca\nfield equations are given, and a discussion about the propagation and the\ngeometrical properties are presented: it is shown that this generalization is\ninconsistent. So the standard theory is already the most general Proca Theory\npossible.", "journal": "Annales Fond.Broglie 36:19-28,2011"}
{"doi": "10.48550/arXiv.0911.0030", "date": "2009-10-30", "title": "Finitely generated maximal partial clones and their intersections", "authors": "Miguel Couceiro, Lucien Haddad", "abstract": "Let A be a finite non-singleton set. For |A|=2 we show that the partial clone\nconsisting of all selfdual monotone partial functions on A is not finitely\ngenerated, while it is the intersection of two finitely generated maximal\npartial clones on A. Moreover for |A| >= 3 we show that there are pairs of\nfinitely generated maximal partial clones whose intersection is a non-finitely\ngenerated partial clone on A.", "journal": ""}
{"doi": "10.48550/arXiv.1003.0714", "date": "2010-03-03", "title": "Generalized Luzin sets", "authors": "Robert Ralowski, Szymon Zeberski", "abstract": "In this paper we invastigate the notion of generalized (I,J) - Luzin set.\nThis notion generalize the standard notion of Luzin set and Sierpinski set. We\nfind set theoretical conditions which imply the existence of generalized (I,J)\n- Luzin set. We show how to construct large family of pairwise non-equivalent\n(I,J) - Luzin sets. We find a class of forcings which preserves the property of\nbeing (I,J) - Luzin set.", "journal": ""}
{"doi": "10.48550/arXiv.1004.2672", "date": "2010-04-15", "title": "Coherent mixing in three and four quark generations", "authors": "Yu. A. Simonov", "abstract": "New dynamical mechanism of quark mass generations and mixing is demonstrated\nin the examples of three and four generations. In the framework of the new\nmixing pattern, called the coherent mixing, the CKM elements are predicted\ncompatible with experimental data for three generations, and are strongly\nconstrained for four generations.", "journal": "Phys.Atom.Nucl.74:643-649,2011"}
{"doi": "10.48550/arXiv.1009.3566", "date": "2010-09-18", "title": "Finding generically stable measures", "authors": "Pierre Simon", "abstract": "We discuss two constructions for obtaining generically stable Keisler\nmeasures in an NIP theory. First, we show how to symmetrize an arbitrary\ninvariant measure to obtain a generically stable one from it. Next, we show\nthat suitable sigma-additive probability measures give rise to generically\nstable measures. Also included is a proof that generically stable measures over\no-minimal theories and the p-adics are smooth.", "journal": "J. Symbolic Logic, Volume 77, Issue 1 (2012), 263 -- 278"}
{"doi": "10.48550/arXiv.1012.0632", "date": "2010-12-03", "title": "Generalizations of Quantum Discord", "authors": "Jianwei Xu", "abstract": "The original definition of quantum discord of bipartite states was defined\nover projective measurements, in this paper we discuss some generalizations of\nit. These generalizations are defined over general measurements, rank-one\ngeneral measurements or Neumark extension measurements. We investigate the\nnonnegativity, zero-discord sets of all these quantum discords and some\nproperties about them.", "journal": ""}
{"doi": "10.48550/arXiv.1102.2122", "date": "2011-02-10", "title": "On the covering radius of first order generalized Reed-Muller codes", "authors": "Elodie Leducq", "abstract": "We generalize to any q a theorem about covering radius of linear codes proved\nby Helleseth, Klove and Mykkelvit. Then we determine the covering radius of\nfirst order generalized Reed-Muller codes in second order generalized\nReed-Muller codes. Using these results, we are able to give bounds for the\ncovering radius of first order generalized Reed-Muller codes. Finaly, using\nMagma, we get some improvements for q=3.", "journal": ""}
{"doi": "10.48550/arXiv.1103.1408", "date": "2011-02-28", "title": "The Exact General Solution of Painlev\u00e9's Sixth Equation (PVI) and The Exact General Solution of the Navier Stokes Equations with Applications to Boundary Layer Problems", "authors": "Lance Arthur Roman-Miller", "abstract": "This paper provides the first known exact general solutions of Painlev\\'e's\nsixth equation (PVI) and the exact general solutions of the Navier Stokes\nequations and Prandtl's boundary layer equations.", "journal": ""}
{"doi": "10.48550/arXiv.1103.4743", "date": "2011-03-24", "title": "FRW Universe Models in Conformally Flat Spacetime Coordinates. I: General Formalism", "authors": "Oyvind Gron, Steinar Johannesen", "abstract": "The 3-space of a universe model is defined at a certain simultaneity. Hence\nspace depends on which time is used. We find a general formula generating all\nknown and also some new transformations to conformally flat spacetime\ncoordinates. A general formula for the recession velocity is deduced.", "journal": "Eur.Phys.J.Plus.126:28,2011"}
{"doi": "10.48550/arXiv.1104.0904", "date": "2011-04-05", "title": "A presentation of the trace algebra of three 3x3 matrices", "authors": "Torsten Hoge", "abstract": "The trace algebra C_{nd} is generated by all traces of products of d generic\nn x n matrices. Minimal generating sets of C_{nd} and their defining relations\nare known for n < 3 and n = 3, d=2. This paper states a minimal generating set\nand their defining relations for n=d=3. Furthermore the computations yield a\ndescription of C_{33} as a free module over the ring generated by a homogeneous\nsystem of parameters.", "journal": ""}
{"doi": "10.48550/arXiv.1105.4833", "date": "2011-05-24", "title": "On the generalized Feng-Rao numbers of numerical semigroups generated by intervals", "authors": "M. Delgado, J. I. Farr\u00e1n, P. A. Garc\u00eda-S\u00e1nchez, D. Llena", "abstract": "We give some general results concerning the computation of the generalized\nFeng-Rao numbers of numerical semigroups. In the case of a numerical semigroup\ngenerated by an interval, a formula for the $r^{th}$ Feng-Rao number is\nobtained.", "journal": "Mathematics of Computation, 82 (2013) 1813-1836"}
{"doi": "10.48550/arXiv.1112.0946", "date": "2011-12-05", "title": "On a property of superposition of the generating functions ln(1/(1-F(x)))", "authors": "Dmitry Kruchinin", "abstract": "Obtained a new property of superposition of the generating functions\nln(1/(1-F(x))), where F(x) - generating function with integer coefficients,\nwhich allows the construction a primality tests. The theorem which is based on\ncompositions of positive numbers and its corollary are proved. Examples are\ngiven. Key words: Generating functions, superposition of generating functions,\ncomposition of a natural number.", "journal": ""}
{"doi": "10.48550/arXiv.1112.1048", "date": "2011-12-05", "title": "Using Quasigroups for Generating Pseudorandom Numbers", "authors": "Vinod Kumar Godavarty", "abstract": "This paper presents an algorithm for generating pseudorandom numbers using\nquasigroups. Random numbers have several applications in the area of secure\ncommunication. The proposed algorithm uses a matrix of size n x n which is\npre-generated and stored. The quality of random numbers generated is compared\nwith other pseudorandom number generator using Marsaglia's Diehard battery of\ntests.", "journal": ""}
{"doi": "10.48550/arXiv.1112.3603", "date": "2011-12-15", "title": "A general method for building reflections", "authors": "Olivia Caramello", "abstract": "We establish a general method for generating reflections between categories.\nWe then apply our technique to generate adjunctions starting from geometric\nmorphisms between Grothendieck toposes; as particular cases, we recover various\nwell-known Stone-type adjunctions and establish several new ones.", "journal": ""}
{"doi": "10.48550/arXiv.1201.1831", "date": "2012-01-09", "title": "On Brylawski's generalized duality", "authors": "Gary Gordon", "abstract": "We introduce a notion of duality (due to Brylawski) that generalizes matroid\nduality to arbitrary rank functions. This generalized duality allows for\ngeneralized operations (deletion and contraction) and a generalized polynomial\nbased on the matroid Tutte polynomial. This polynomial satisfies a\ndeletion-contraction recursion. We explore this notion of duality for\ngreedoids, antimatroids and demi-matroids, proving that matroids correspond\nprecisely to objects that are simultaneously greedoids and \"dual\" greedoids.", "journal": ""}
{"doi": "10.48550/arXiv.1202.6125", "date": "2012-02-28", "title": "Rule-based Test Generation with Mind Maps", "authors": "Dimitry Polivaev", "abstract": "This paper introduces basic concepts of rule based test generation with mind\nmaps, and reports experiences learned from industrial application of this\ntechnique in the domain of smart card testing by Giesecke & Devrient GmbH over\nthe last years. It describes the formalization of test selection criteria used\nby our test generator, our test generation architecture and test generation\nframework.", "journal": "EPTCS 80, 2012, pp. 103-114"}
{"doi": "10.48550/arXiv.1203.2778", "date": "2012-03-13", "title": "Seven Means, Generalized Triangular Discrimination, and Generating Divergence Measures", "authors": "Inder Jeet Tameja", "abstract": "From geometrical point of view, Eve (2003) studied seven means. These means\nare Harmonic, Geometric, Arithmetic, Heronian, Contra-harmonic, Root-mean\nsquare and Centroidal mean. We have considered for the first time a new measure\ncalling generalized triangular discrimination. Inequalities among non-negative\ndifferences arising due to seven means and particular cases of generalized\ntriangular discrimination are considered. Some new generating measures and\ntheir exponential representations are also presented.", "journal": ""}
{"doi": "10.48550/arXiv.1211.3244", "date": "2012-11-14", "title": "The method for obtaining expressions for coefficients of reverse generating functions", "authors": "Vladimir Kruchinin", "abstract": "The powers of generating functions and its properties are analyzed. A new\nclass of functions is introduced, based on the application of compositions of\nan integer $n$, called composita. The methods for obtaining reciprocal and\nreverse generating functions, and solutions of the functional equations\n$F(A(x))=G(x)$, where $A(x)$ is an unknown generating function, are proposed.\n  Key words: generating functions, reverse, reciprocal, composita, method.", "journal": ""}
{"doi": "10.48550/arXiv.1302.6674", "date": "2013-02-27", "title": "Generic regular universes in higher order gravity theories", "authors": "Spiros Cotsakis, Dimitrios Trachilis, Antonios Tsokaros", "abstract": "We review recent results on the Cauchy-Kowalevsky structure of theories with\nhigher derivatives in vacuum. We prove genericity of regularity of solutions\nunder the assumption of analyticity. Our approach is framed in the general\ncontext of formal series expansions of the metric around a regular point.", "journal": ""}
{"doi": "10.48550/arXiv.1303.5574", "date": "2013-03-22", "title": "Higher order generalized Euler characteristics and generating series", "authors": "S. M. Gusein-Zade, I. Luengo, A. Melle-Hern\u00e1ndez", "abstract": "For a complex quasi-projective manifold with a finite group action, we define\nhigher order generalized Euler characteristics with values in the Grothendieck\nring of complex quasi-projective varieties extended by the rational powers of\nthe class of the affine line. We compute the generating series of generalized\nEuler characteristics of a fixed order of the Cartesian products of the\nmanifold with the wreath product actions on them.", "journal": ""}
{"doi": "10.48550/arXiv.1305.1074", "date": "2013-05-06", "title": "Maass relations for generalized Cohen-Eisenstein series of degree two and of degree three", "authors": "Shuichi Hayashida", "abstract": "The aim of this paper is to generalize the Maass relation for generalized\nCohen-Eisenstein series of degree two and of degree three. Here the generalized\nCohen-Eisenstein series are certain Siegel modular forms of half-integral\nweight, and generalized Maass relations are certain relations among\nFourier-Jacobi coefficients of them.", "journal": ""}
{"doi": "10.48550/arXiv.1306.6678", "date": "2013-06-27", "title": "Invertible extensions of symmetric operators and the corresponding generalized resolvents", "authors": "Sergey M. Zagorodnyuk", "abstract": "In this paper we study invertible extensions of a symmetric operator in a\nHilbert space $H$. All such extensions are characterized by a parameter in the\ngeneralized Neumann's formulas. Generalized resolvents, which are generated by\nthe invertible extensions, are extracted by a boundary condition among all\ngeneralized resolvents in the Shtraus formula.", "journal": ""}
{"doi": "10.48550/arXiv.1308.0783", "date": "2013-08-04", "title": "Generic A-family of exponential sums", "authors": "Hui June Zhu", "abstract": "In this paper we construct a generating polynomial over the rationals for the\ngeneric Newton polygon for the L function of exponential sums of the family of\nf = x^d+ a x^s parameterized by a, and prove some of its key properties. The\ngenerating polynomial encodes information of and determines the generic Newton\npolygon at each prime p when p is large enough, and vice versa.", "journal": "J. Number Theory 143 (2014), 82--101"}
{"doi": "10.48550/arXiv.1309.5589", "date": "2013-09-22", "title": "A generalization of \u0106iri\u0107 fixed point theorem", "authors": "Nguyen Van Dung, Poom Kumam, Kanokwan Sitthithakerngkiet", "abstract": "In this paper, we state and prove a generalization of \\'Ciri\\'c fixed point\ntheorems in metric space by using a new generalized quasi-contractive map.\nThese theorems extend other well known fundamental metrical fixed point\ntheorems in the literature. Moreover, a multi-valued version for generalized\nquasi-contraction is also established.", "journal": ""}
{"doi": "10.48550/arXiv.1309.7092", "date": "2013-09-27", "title": "Generating Anisotropic Collapse and Expansion Solutions of Einstein's Equations", "authors": "E. N. Glass", "abstract": "Analytic gravitational collapse and expansion solutions with anisotropic\npressure are generated. Metric functions are found by requiring zero heat flow\nscalar. It emerges that a single function generates the anisotropic solutions.\nEach generating function contains an arbitrary function of time which can be\nchosen to fit various astrophysical time profiles. Two examples are provided: a\nbounded collapse metric and an expanding cosmological solution", "journal": ""}
{"doi": "10.48550/arXiv.1310.6612", "date": "2013-10-24", "title": "Aitken delta-squared generalized Juncgk-type iterative procedure", "authors": "M. De la sen", "abstract": "This paper discusses a general Aitken delta-squared generalized\nJungck-modified iterative scheme. The study applies generalized versions of\nAitken delta squared procedure and Venter theorem to discuss positivity and\nglobal stability of the generalized Jungck iterative scheme which is of\ninterest in numerical methods and its acceleration of convergence.", "journal": ""}
{"doi": "10.48550/arXiv.1310.7085", "date": "2013-10-26", "title": "Generalized wreath products of graphs and groups", "authors": "Alfredo Donno", "abstract": "Inspired by the definition of generalized wreath product of permutation\ngroups, we define the generalized wreath product of graphs, containing the\nclassical Cartesian and wreath product of graphs as particular cases. We prove\nthat the generalized wreath product of Cayley graphs of finite groups is the\nCayley graph of the generalized wreath product of the corresponding groups.", "journal": "Graphs Combin. 31 (2015) no. 4, 915-926"}
{"doi": "10.48550/arXiv.1401.5234", "date": "2014-01-21", "title": "On the third weight of generalized Reed-Muller codes", "authors": "Elodie Leducq", "abstract": "In this paper, we study the third weight of generalized Reed-Muller codes. We\nprove under some restrictive condition that the third weight of generalized\nReed-Muller codes depends on the third weight of generalized Reed-Muller codes\nof small order with two variables. In some cases, we are able to determine the\nthird weight and the third weight codewords of generalized Reed-Muller codes.", "journal": ""}
{"doi": "10.48550/arXiv.1403.3513", "date": "2014-03-14", "title": "Generalized mixed product ideals", "authors": "J\u00fcrgen Herzog, Roya Moghimipor, Siamak Yassemi", "abstract": "We consider classes of ideals which generalize the mixed product ideals\nintroduced by Restuccia and Villarreal, and also generalize the expansion\nconstruction by Bayati and the first author \\cite{BH}. We compute the minimal\ngraded free resolution of generalized mixed product ideals and show that the\nregularity of a generalized mixed product ideal coincides with regularity of\nthe monomial ideal by which it is induced.", "journal": ""}
{"doi": "10.48550/arXiv.1404.3417", "date": "2014-04-13", "title": "Skeletally generated spaces and absolutes", "authors": "V. Valov", "abstract": "Some properties of skelatally generated spaces are established. In\nparticular, it is shown that any compactum co-absolute to a $\\kappa$-metrizable\ncompactum is skeletally generated. We also prove that a compactum $X$ is\nskeletally generated if and only if its superextension $\\lambda X$ is\nskeletally Dugundji and raise some natural questions.", "journal": ""}
{"doi": "10.48550/arXiv.1404.3964", "date": "2014-04-15", "title": "Generalized Convex Functions and Some Inequalities on Fractal Sets", "authors": "Huixia Mo, Xin Sui, Dongyan Yu", "abstract": "In the paper, we introduce the generalized convex function on fractal sets of\nreal line numbers and study the properties of the generalized convex function.\nBased on these properties, we establish the generalized Jensen inequality and\ngeneralized Hermite-Hadamard inequality. Furthermore,some applications are\ngiven.", "journal": ""}
{"doi": "10.48550/arXiv.1407.3925", "date": "2014-07-15", "title": "On the properties of circulant matrices involving Generalized Tribonacci and Generalized Tribonacci-Lucas numbers", "authors": "Nazmiye Yilmaz, Yasin Yazlik, Necati Taskara", "abstract": "In this paper, firstly, we define the Generalized Tribonacci-Lucas numbers.\nIn addition, by also defining circulant matrices C_{n}(G) and C_{n}(S) whose\nentries are Generalized Tribonacci and Generalized Tribonacci-Lucas numbers, we\ncompute spectral norms and determinants of these matrices.", "journal": ""}
{"doi": "10.48550/arXiv.1502.04741", "date": "2015-02-16", "title": "Left Adjoints for Generalized Multicategories", "authors": "A. D. Elmendorf", "abstract": "We construct generalized multicategories associated to an arbitrary operad in\nCat that is $\\Sigma$-free. The construction generalizes the passage to\nsymmetric multicategories from permutative categories, which is the case when\nthe operad is the categorical version of the Barratt-Eccles operad. The main\ntheorem is that there is an adjoint pair relating algebras over the operad to\nthis sort of generalized multicategory. The construction is flexible enough to\nallow for equivariant generalizations.", "journal": ""}
{"doi": "10.48550/arXiv.1505.03218", "date": "2015-05-13", "title": "Musings on generic-case complexity", "authors": "Ilya Kapovich", "abstract": "We propose a more general definition of generic-case complexity, based on\nusing a random process for generating inputs of an algorithm and using the time\nneeded to generate an input as a way of measuring the size of that input.", "journal": ""}
{"doi": "10.48550/arXiv.1506.04297", "date": "2015-06-13", "title": "Algebraic cycles on a generalized Kummer variety", "authors": "Ze Xu", "abstract": "We compute explicitly the Chow motive of any generalized Kummer variety\nassociated to any abelian surface. In fact, it lies in the rigid tensor\nsubcategory of the category of Chow motives generated by the Chow motive of the\nunderlying abelian surface. One application of this calculation is to show that\nthe Hodge conjecture holds for arbitrary products of generalized Kummer\nvarieties. As another application, all numerically trivial 1-cycles on\narbitrary products of generalized Kummer varieties are smash-nipotent.", "journal": ""}
{"doi": "10.48550/arXiv.1506.09090", "date": "2015-06-30", "title": "Generalized Chern-Simons action principles for gravity", "authors": "D. C. Robinson", "abstract": "Generalized differential forms are employed to construct generalized\nconnections. Lorentzian four-metrics determined by certain of these connections\nsatisfy Einstein's vacuum field equations when the connections are flat.\nGeneralized Chern-Simons action principles with Einstein's equations as\nEuler-Lagrange equations are constructed by using these connections.", "journal": ""}
{"doi": "10.48550/arXiv.1507.04455", "date": "2015-07-16", "title": "New Lie tori from Naoi tori", "authors": "Yoji Yoshii", "abstract": "We define general Lie tori which generalize original Lie tori. We show that a\nNaoi torus is a general Lie torus. We give examples and prove several\nproperties of general Lie tori. We also review isotopies of Lie tori, and prove\nthat a general Lie torus is, in fact, isotopic to an original Lie torus.\nFinally, we suggest a very simple way of defining a Lie torus corresponding to\na locally extended affine root system R, which we call a Lie R-torus.", "journal": ""}
{"doi": "10.48550/arXiv.1511.07588", "date": "2015-11-24", "title": "Some new identities of generalized Fibonacci and generalized Pell numbers via a new type of numbers", "authors": "W. M. Abd-Elhameed, N. A. Zeyada", "abstract": "This paper is concerned with developing some new identities of generalized\nFibonacci numbers and generalized Pell numbers. A new class of generalized\nnumbers is introduced for this purpose. The two well-known identities of Sury\nand Marques which are recently developed are deduced as special cases.\nMoreover, some other interesting identities involving the celebrated Fibonacci,\nLucas, Pell and Pell-Lucas numbers are also deduced", "journal": ""}
{"doi": "10.48550/arXiv.1511.07859", "date": "2015-11-24", "title": "Hilbert polynomials and module generating degrees", "authors": "Roger Dellaca", "abstract": "We establish a form of the Gotzmann representation of the Hilbert polynomial\nbased on rank and generating degrees of a module, which allow for a\ngeneralization of Gotzmann's Regularity Theorem. Under an additional assumption\non the generating degrees, the Gotzmann regularity bound becomes sharp. An\nanaloguous modification of the Macaulay representation is used along the way,\nwhich generalizes the theorems of Macaulay and Green, and Gotzmann's\nPersistence Theorem.", "journal": ""}
{"doi": "10.48550/arXiv.1606.05298", "date": "2016-05-31", "title": "Fractals of generalized F- Hutchinson operator in b-metric spaces", "authors": "Talat Nazir, Sergei Silvestrov, Xiaomin Qi", "abstract": "The aim of this paper is to construct a fractal with the help of a finite\nfamily of generalized F-contraction mappings, a class of mappings more general\nthan contraction mappings, defined in the setup of b-metric space.\nConsequently, we obtain a variety of results for iterated function system\nsatisfying a different set of contractive conditions. Our results unify,\ngeneralize and extend various results in the existing literature.", "journal": ""}
{"doi": "10.48550/arXiv.1607.02756", "date": "2016-07-10", "title": "Marichev-Saigo-Maeda fractional operator representations of generalized Struve function", "authors": "K. S. Nisar", "abstract": "The aim of this paper is to apply generalized operators of fractional\nintegration and differentiation involving Appells function due to\nMarichev-Saigo-Maeda, to the generalized Struve function. The results are\nexpressed in terms of generalized Wright function. The results obtained here\nare general in nature and can easily obtain various known results.", "journal": ""}
{"doi": "10.48550/arXiv.1612.04879", "date": "2016-12-14", "title": "Generalized Bump-Hoffstein conjecture for coverings of the general linear groups", "authors": "Fan Gao", "abstract": "In this paper, we investigate the extent to which the Bump-Hoffstein\nconjecture could be generalized for central coverings of general linear groups.\nWe provide evidence for such generalized Bump-Hoffstein conjecture by proving\nsome special cases.", "journal": ""}
{"doi": "10.48550/arXiv.1702.01960", "date": "2017-02-07", "title": "Certain new unified integrals associated with the product of generalized Struve function", "authors": "Kottakkaran Sooppy Nisar", "abstract": "We aim to present two new generalized integral formulae involving product of\ngeneralized Struve function $\\mathcal{W}_{p,b,c}\\left( z\\right)$, which are\nexpressed in terms of the generalized Lauricella functions. The main results\npresented here, being the very general character, reduce to yield known and new\nintegral formulae. Some special cases of our main results are also considered.", "journal": ""}
{"doi": "10.48550/arXiv.1706.04164", "date": "2017-06-13", "title": "Chip-firing on trees of loops", "authors": "Sameer Kailasa, Vivian Kuperberg, Nicholas Wawrykow", "abstract": "Cools, Draisma, Payne, and Robeva proved that generic metric graphs that are\n\"paths of loops\" are Brill-Noether general. We show that Brill-Noether\ngenerality does not hold for \"trees of loops\": the only trees of loops that are\nBrill-Noether general are paths of loops. We study various notions of\ngenerality and examine which of these graphs satisfy them.", "journal": ""}
{"doi": "10.48550/arXiv.1709.03740", "date": "2017-09-12", "title": "An algebra involving braids and ties", "authors": "Francesca Aicardi, Jesus Juyumaya", "abstract": "In this note we study a family of algebras with one parameter defined by\ngenerators and relations. The set of generators contains the generators of the\nusual braids algebra, and another set of generators which is interpreted as\nties between consecutive strings. We also study the representations theory of\nthe algebra when the parameter is specialized to 1.", "journal": ""}
{"doi": "10.48550/arXiv.1712.02397", "date": "2017-12-06", "title": "Turbulence Generation from a stochastic wavelet model", "authors": "Yifan Du, Guang Lin", "abstract": "This research presents a new turbulence generation method based on stochastic\nwavelets and tests its various properties in both homogeneous and inhomogeneous\nturbulence. Turbulence field can be generated with less basis compared to\nprevious synthetic Fourier methods. Adaptive generation of inhomogeneous\nturbulence is achieved by scale reduction algorithm and lead to smaller\ncomputation cost. The generated turbulence shows good agreement with input data\nand theoretical results.", "journal": ""}
{"doi": "10.48550/arXiv.1802.05897", "date": "2018-02-16", "title": "The generalized bi-periodic Fibonacci quaternions and octonions", "authors": "Elif Tan, Murat \u015eahin, Semih Y\u0131lmaz", "abstract": "In this paper, we present a further generalization of the bi- periodic\nFibonacci quaternions and octonions. We give the generating function, the Binet\nformula, and some basic properties of these quaternions and octonions. The\nresults of this paper not only give a generalization of the bi-periodic\nFibonacci quaternions and octonions, but also include new results such as the\nmatrix representation and the norm value of the generalized bi-periodic\nFibonacci quaternions.", "journal": ""}
{"doi": "10.48550/arXiv.1802.07096", "date": "2018-02-20", "title": "Generating functions associated to Frobenius algebras", "authors": "Josep \u00c0lvarez Montaner", "abstract": "We introduce a generating function associated to the homogeneous generators\nof a graded algebra that measures how far is this algebra from being finitely\ngenerated. For the case of some algebras of Frobenius endomorphisms we describe\nthis generating function explicitly as a rational function.", "journal": ""}
{"doi": "10.48550/arXiv.1812.02955", "date": "2018-12-07", "title": "Mixed restricted Stirling numbers", "authors": "Somaya Barati, Be\u00e1ta B\u00e9nyi, Abbas Jafarzadeh, Daniel Yaqubi", "abstract": "In this note we investigate mixed partitions with extra condition on the\nsizes of the blocks. We give a general formula and the generating function. We\nconsider in more details a special case, determining the generating functions,\nsome recurrences and a connection to r-Stirling numbers. To obtain our results,\nwe use pure combinatorial arguments, classical manipulations of generating\nfunctions and to derive the generating functions we apply the symbolic method.", "journal": ""}
{"doi": "10.48550/arXiv.1812.11115", "date": "2018-12-28", "title": "Estimating Some General Molecular Descriptors of Saturated Hydrocarbons", "authors": "Akbar Ali, Zhibin Du, Kiran Shehzadi", "abstract": "Three general molecular descriptors, namely the general sum-connectivity\nindex, general Platt index and ordinary generalized geometric-arithmetic index,\nare studied here. Best possible bounds for the aforementioned descriptors of\narbitrary saturated hydrocarbons are derived. These bounds are expressed in\nterms of number of carbon atoms and number of carbon-carbon bonds of the\nconsidered hydrocarbons.", "journal": "Molecular Informatics 38 (2019) Art# 1900007"}
{"doi": "10.48550/arXiv.1908.07504", "date": "2019-08-20", "title": "Quasi-local conserved charges in General Relativity", "authors": "Henk Bart", "abstract": "A general prescription for constructing quasi-local conserved quantities in\nGeneral Relativity is proposed. The construction is applied to BMS symmetry\ngenerators in Newman-Unti gauge, so as to define quasi-local BMS charges. It is\nargued that the zero mode of this BMS charge is a promising definition of\nquasi-local energy.", "journal": ""}
{"doi": "10.48550/arXiv.1909.06138", "date": "2019-09-13", "title": "Relative Generalized Hamming weights of affine Cartesian codes", "authors": "Mrinmoy Datta", "abstract": "We explicitly determine all the relative generalized Hamming weights of\naffine Cartesian codes using the notion of footprints and results from extremal\ncombinatorics. This generalizes the previous works on the determination of\nrelative generalized Hamming weights of Reed-Muller codes by Geil and Martin,\nas well as the determination of all the generalized Hamming weights of the\naffine Cartesian codes by Beelen and Datta.", "journal": ""}
{"doi": "10.48550/arXiv.2006.05322", "date": "2020-06-06", "title": "Generalized Drazin-Meromorphic Invertible Operators and Browder's Type Theorems", "authors": "Anuradha Gupta, Ankit Kumar", "abstract": "In this paper we give necessary and sufficient conditions for a bounded\nlinear operator $T$ to be generalized Drazin-Riesz invertible or generalized\nDrazin-meromorphic invertible. Also, we study generalized Browder's theorem and\ngeneralized a-Browder's theorem by means of set of interior points of various\nparts of spectrum of $T$.", "journal": ""}
{"doi": "10.48550/arXiv.2006.05523", "date": "2020-06-09", "title": "Invariable generation does not pass to finite index subgroups", "authors": "Gil Goffer, Nir Lazarovich", "abstract": "Using small cancellation methods, we show that the property invariable\ngeneration does not pass to finite index subgroups, answering questions of\nWiegold and Kantor-Lubotzky-Shalev. We further show that a finitely generated\ngroup that is invariably generated is not necessarily finitely invariably\ngenerated, answering a question of Cox. The same results were also obtained\nindependently by Minasyan.", "journal": ""}
{"doi": "10.48550/arXiv.2006.09789", "date": "2020-06-17", "title": "Abstract Cauchy problems for the generalized fractional calculus", "authors": "Giacomo Ascione", "abstract": "We focus on eventually non-linear abstract Cauchy problems with a generalized\nfractional derivative in time. First we prove a local existence and uniqueness\nresult, then we focus on a generalized Gr\\\"onwall inequality. Before addressing\nthe inequality, we study some properties of eigenvalues and eigenfunctions of\nthe generalized fractional derivatives. Finally, we prove some consequences of\nthe generalized Gr\\\"onwall inequality.", "journal": ""}
{"doi": "10.48550/arXiv.2111.08849", "date": "2021-11-17", "title": "Smooth distributions on subcartesian spaces are globally finitely generated", "authors": "Qianqian Xia", "abstract": "We prove that a connected subcartesian space admits embedding in a Euclidean\nspace. The Whitney Embedding Theorem is then stated as a corollary of our\nresult. Based on the above result together with the theory of distribution on\nsmooth manifolds, we show that smooth generalized distributions on connected\nsubcartesian spaces are globally finitely generated. We also show that smooth\ngeneralized subbundles of vector bundles on connected subcartesian spaces are\nglobally finitely generated.", "journal": ""}
{"doi": "10.48550/arXiv.2111.13973", "date": "2021-11-27", "title": "General Fully Coupled Forward Backward Stochastic Differential Equations with delayed generator", "authors": "Auguste Aman, Harouna Coulibaly, Jasmina Djordjevic", "abstract": "This paper is devoted to study different type of BSDE with delayed generator.\nWe first establish an existence and uniqueness result under delayed Lipschitz\ncondition for non homogenous backward stochastic differential equation with\ndelayed generator. Next, existence and uniqueness result for general fully\ncoupled forward backward stochastic differential equation with delayed\ncoefficients has been derived.", "journal": ""}
{"doi": "10.48550/arXiv.1311.0102", "date": "2013-11-01", "title": "Lie bialgebras of generalized loop Virasoro algebras", "authors": "Henan Wu, Song Wang, Xiaoqing Yue", "abstract": "The first cohomology group of a generalized loop Virasoro algebra with\ncoefficients in the tensor product of its adjoint module is shown to be\ntrivial. The result is applied to prove that Lie bialgebra structures on\ngeneralized loop Virasoro algebras are coboundary triangular. We then\ngeneralize the results to generalized map Virasoro algebras.", "journal": ""}
{"doi": "10.48550/arXiv.1801.01329", "date": "2018-01-04", "title": "Bounded normal generation is not equivalent to topological bounded normal generation", "authors": "Philip A. Dowerk, Fran\u00e7ois Le Ma\u00eetre", "abstract": "We show that some derived $\\mathrm{L}^1$ full groups provide examples of non\nsimple Polish groups with the topological bounded normal generation property.\nIn particular, it follows that there are Polish groups with the topological\nbounded normal generation property but not the bounded normal generation\nproperty.", "journal": ""}
{"doi": "10.48550/arXiv.1801.01579", "date": "2018-01-04", "title": "Hygienic Source-Code Generation Using Functors", "authors": "Karl Crary", "abstract": "Existing source-code-generating tools such as Lex and Yacc suffer from\npractical inconveniences because they use disembodied code to implement\nactions. To prevent this problem, such tools could generate closed functors\nthat are then instantiated by the programmer with appropriate action code. This\nresults in all code being type checked in its appropriate context, and it\nassists the type checker in localizing errors correctly. We have implemented a\nlexer generator and parser generator based on this technique for Standard ML,\nOCaml, and Haskell.", "journal": ""}
{"doi": "10.48550/arXiv.1801.04111", "date": "2018-01-12", "title": "On the goodness-of-fit of generalized linear geostatistical models", "authors": "Emanuele Giorgi", "abstract": "We propose a generalization of Zhang's coefficient of determination to\ngeneralized linear geostatistical models and illustrate its application to\nriver-blindness mapping. The generalized coefficient of determination has a\nmore intuitive interpretation than other measures of predictive performance and\nallows to assess the individual contribution of each explanatory variable and\nthe random effects to spatial prediction. The developed methodology is also\nmore widely applicable to any generalized linear mixed model.", "journal": ""}
{"doi": "10.48550/arXiv.1805.06762", "date": "2018-05-11", "title": "On certain new means generated by generalized trigonometric functions", "authors": "J\u00f3zsef S\u00e1ndor, Barkat Ali Bhayo", "abstract": "In this paper, authors generalize logarithmic mean $L$, Neuman-S\\'andor $M$,\ntwo Seiffert means $P$ and $T$ as an application of generalized trigonometric\nand hyperbolic functions. Moreover, several two-sided inequalities involving\nthese generalized means are established.", "journal": ""}
{"doi": "10.48550/arXiv.1805.07664", "date": "2018-05-19", "title": "Generating adjoint groups", "authors": "Be'eri Greenfeld", "abstract": "We prove two approximations of the open problem of whether the adjoint group\nof a non-nilpotent nil ring can be finitely generated: We show that the adjoint\ngroup of a non-nilpotent Jacobson radical cannot be boundedly generated, and on\nthe other hand construct a finitely generated, infinite dimensional nil algebra\nwhose adjoint group is generated by elements of bounded torsion.", "journal": ""}
{"doi": "10.48550/arXiv.1809.01369", "date": "2018-09-05", "title": "Towards quantitative methods to assess network generative models", "authors": "Vahid Mostofi, Sadegh Aliakbary", "abstract": "Assessing generative models is not an easy task. Generative models should\nsynthesize graphs which are not replicates of real networks but show\ntopological features similar to real graphs. We introduce an approach for\nassessing graph generative models using graph classifiers. The inability of an\nestablished graph classifier for distinguishing real and synthesized graphs\ncould be considered as a performance measurement for graph generators.", "journal": ""}
{"doi": "10.48550/arXiv.1405.4570", "date": "2014-05-19", "title": "On prime-generating linear polynomials and x^2+1", "authors": "Hil\u00e1rio Fernandes", "abstract": "In this paper we use Dirichlet's theorem in order to elementally prove two\ntheorems. The first says that since a polynomial ax+b generates one prime, it\nalso generates infinites. The second theorem (which is proved in a very\nsimillar way to the first) says that x^2+1 generates infinitely many primes.", "journal": ""}
{"doi": "10.48550/arXiv.1410.1062", "date": "2014-10-04", "title": "Generalized Hermite-Hadamard Type Inequalities Involving Local Fractional Integrals", "authors": "Huixia Mo", "abstract": "In the paper, two new identities involving the local fractional integrals\nhave been established. Using these two identities, we obtain some generalized\nHermite-Hadamard type integral inequalities for the local differentiable\ngeneralized convex functions.", "journal": ""}
{"doi": "10.48550/arXiv.1811.01300", "date": "2018-11-03", "title": "A simple method to generate exact physically acceptable anisotropic solutions in general relativity", "authors": "J Ovalle, A Sotomayor", "abstract": "By using the gravitational decoupling through the minimal geometric\ndeformation approach (MGD-decoupling), we show a simple and powerful method to\ngenerate physically acceptable exact analytical solutions for anisotropic\nstellar distributions in general relativity. We find that some perfect fluid\nconfigurations could be incompatible with anisotropic effects produced by\nscalar fields.", "journal": "Eur. Phys. J. Plus (2018) 133: 428"}
{"doi": "10.48550/arXiv.1902.00695", "date": "2019-02-02", "title": "The generalized Weyl Poisson algebras and their Poisson simplicity criterion", "authors": "V. V. Bavula", "abstract": "A new class of Poisson algebras, the class of {\\em generalized Weyl Poisson\nalgebras}, is introduced. It can be seen as Poisson algebra analogue of\ngeneralized Weyl algebras or as giving a Poisson structure to (certain)\ngeneralized Weyl algebras. A Poisson simplicity criterion is given for\ngeneralized Weyl Poisson algebras and explicit descriptions of the Poisson\ncentre and the absolute Poisson centre are obtained. Many examples are\nconsidered.", "journal": ""}
{"doi": "10.48550/arXiv.1906.03491", "date": "2019-06-08", "title": "Finding a Generator Matrix of a Multidimensional Cyclic Code", "authors": "R. Andriamifidisoa, R. M. Lalasoa, T. J. Rabeherimanana", "abstract": "We generalize Sepasdar's method for finding a generator matrix of\ntwo-dimensional cyclic codes to find an independent subset of a general\nmulticyclic code, which may form a basis of the code as a vector subspace. A\ngenerator matrix can be then constructed from this basis.", "journal": ""}
