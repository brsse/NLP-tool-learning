{"doi": "10.48550/arXiv.1909.03550", "date": "2019-09-08", "title": "Lecture Notes: Optimization for Machine Learning", "authors": "Elad Hazan", "abstract": "Lecture notes on optimization for machine learning, derived from a course at\nPrinceton University and tutorials given in MLSS, Buenos Aires, as well as\nSimons Foundation, Berkeley.", "journal": ""}
{"doi": "10.48550/arXiv.1811.04422", "date": "2018-11-11", "title": "An Optimal Control View of Adversarial Machine Learning", "authors": "Xiaojin Zhu", "abstract": "I describe an optimal control view of adversarial machine learning, where the\ndynamical system is the machine learner, the input are adversarial actions, and\nthe control costs are defined by the adversary's goals to do harm and be hard\nto detect. This view encompasses many types of adversarial machine learning,\nincluding test-item attacks, training-data poisoning, and adversarial reward\nshaping. The view encourages adversarial machine learning researcher to utilize\nadvances in control theory and reinforcement learning.", "journal": ""}
{"doi": "10.48550/arXiv.1707.04849", "date": "2017-07-16", "title": "Minimax deviation strategies for machine learning and recognition with short learning samples", "authors": "Michail Schlesinger, Evgeniy Vodolazskiy", "abstract": "The article is devoted to the problem of small learning samples in machine\nlearning. The flaws of maximum likelihood learning and minimax learning are\nlooked into and the concept of minimax deviation learning is introduced that is\nfree of those flaws.", "journal": ""}
{"doi": "10.48550/arXiv.1909.09246", "date": "2019-09-19", "title": "Machine Learning for Clinical Predictive Analytics", "authors": "Wei-Hung Weng", "abstract": "In this chapter, we provide a brief overview of applying machine learning\ntechniques for clinical prediction tasks. We begin with a quick introduction to\nthe concepts of machine learning and outline some of the most common machine\nlearning algorithms. Next, we demonstrate how to apply the algorithms with\nappropriate toolkits to conduct machine learning experiments for clinical\nprediction tasks. The objectives of this chapter are to (1) understand the\nbasics of machine learning techniques and the reasons behind why they are\nuseful for solving clinical prediction problems, (2) understand the intuition\nbehind some machine learning models, including regression, decision trees, and\nsupport vector machines, and (3) understand how to apply these models to\nclinical prediction problems using publicly available datasets via case\nstudies.", "journal": ""}
{"doi": "10.48550/arXiv.2301.09753", "date": "2023-01-23", "title": "Towards Modular Machine Learning Solution Development: Benefits and Trade-offs", "authors": "Samiyuru Menik, Lakshmish Ramaswamy", "abstract": "Machine learning technologies have demonstrated immense capabilities in\nvarious domains. They play a key role in the success of modern businesses.\nHowever, adoption of machine learning technologies has a lot of untouched\npotential. Cost of developing custom machine learning solutions that solve\nunique business problems is a major inhibitor to far-reaching adoption of\nmachine learning technologies. We recognize that the monolithic nature\nprevalent in today's machine learning applications stands in the way of\nefficient and cost effective customized machine learning solution development.\nIn this work we explore the benefits of modular machine learning solutions and\ndiscuss how modular machine learning solutions can overcome some of the major\nsolution engineering limitations of monolithic machine learning solutions. We\nanalyze the trade-offs between modular and monolithic machine learning\nsolutions through three deep learning problems; one text based and the two\nimage based. Our experimental results show that modular machine learning\nsolutions have a promising potential to reap the solution engineering\nadvantages of modularity while gaining performance and data advantages in a way\nthe monolithic machine learning solutions do not permit.", "journal": ""}
{"doi": "10.48550/arXiv.0904.3664", "date": "2009-04-23", "title": "Introduction to Machine Learning: Class Notes 67577", "authors": "Amnon Shashua", "abstract": "Introduction to Machine learning covering Statistical Inference (Bayes, EM,\nML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),\nand PAC learning (the Formal model, VC dimension, Double Sampling theorem).", "journal": ""}
{"doi": "10.48550/arXiv.2012.04105", "date": "2020-12-07", "title": "The Tribes of Machine Learning and the Realm of Computer Architecture", "authors": "Ayaz Akram, Jason Lowe-Power", "abstract": "Machine learning techniques have influenced the field of computer\narchitecture like many other fields. This paper studies how the fundamental\nmachine learning techniques can be applied towards computer architecture\nproblems. We also provide a detailed survey of computer architecture research\nthat employs different machine learning methods. Finally, we present some\nfuture opportunities and the outstanding challenges that need to be overcome to\nexploit full potential of machine learning for computer architecture.", "journal": ""}
{"doi": "10.48550/arXiv.2204.07492", "date": "2022-04-15", "title": "A Machine Learning Tutorial for Operational Meteorology, Part I: Traditional Machine Learning", "authors": "Randy J. Chase, David R. Harrison, Amanda Burke, Gary M. Lackmann, Amy McGovern", "abstract": "Recently, the use of machine learning in meteorology has increased greatly.\nWhile many machine learning methods are not new, university classes on machine\nlearning are largely unavailable to meteorology students and are not required\nto become a meteorologist. The lack of formal instruction has contributed to\nperception that machine learning methods are 'black boxes' and thus end-users\nare hesitant to apply the machine learning methods in their every day workflow.\nTo reduce the opaqueness of machine learning methods and lower hesitancy\ntowards machine learning in meteorology, this paper provides a survey of some\nof the most common machine learning methods. A familiar meteorological example\nis used to contextualize the machine learning methods while also discussing\nmachine learning topics using plain language. The following machine learning\nmethods are demonstrated: linear regression; logistic regression; decision\ntrees; random forest; gradient boosted decision trees; naive Bayes; and support\nvector machines. Beyond discussing the different methods, the paper also\ncontains discussions on the general machine learning process as well as best\npractices to enable readers to apply machine learning to their own datasets.\nFurthermore, all code (in the form of Jupyter notebooks and Google Colaboratory\nnotebooks) used to make the examples in the paper is provided in an effort to\ncatalyse the use of machine learning in meteorology.", "journal": "Weather and Forecasting 37 (2022) 1509-1529"}
{"doi": "10.48550/arXiv.1911.06612", "date": "2019-11-12", "title": "Position Paper: Towards Transparent Machine Learning", "authors": "Dustin Juliano", "abstract": "Transparent machine learning is introduced as an alternative form of machine\nlearning, where both the model and the learning system are represented in\nsource code form. The goal of this project is to enable direct human\nunderstanding of machine learning models, giving us the ability to learn,\nverify, and refine them as programs. If solved, this technology could represent\na best-case scenario for the safety and security of AI systems going forward.", "journal": ""}
{"doi": "10.48550/arXiv.1909.01866", "date": "2019-09-02", "title": "Understanding Bias in Machine Learning", "authors": "Jindong Gu, Daniela Oelke", "abstract": "Bias is known to be an impediment to fair decisions in many domains such as\nhuman resources, the public sector, health care etc. Recently, hope has been\nexpressed that the use of machine learning methods for taking such decisions\nwould diminish or even resolve the problem. At the same time, machine learning\nexperts warn that machine learning models can be biased as well. In this\narticle, our goal is to explain the issue of bias in machine learning from a\ntechnical perspective and to illustrate the impact that biased data can have on\na machine learning model. To reach such a goal, we develop interactive plots to\nvisualizing the bias learned from synthetic data.", "journal": "1st Workshop on Visualization for AI Explainability in 2018 IEEE\n  Vis"}
{"doi": "10.48550/arXiv.1903.08801", "date": "2019-03-21", "title": "A Unified Analytical Framework for Trustable Machine Learning and Automation Running with Blockchain", "authors": "Tao Wang", "abstract": "Traditional machine learning algorithms use data from databases that are\nmutable, and therefore the data cannot be fully trusted. Also, the machine\nlearning process is difficult to automate. This paper proposes building a\ntrustable machine learning system by using blockchain technology, which can\nstore data in a permanent and immutable way. In addition, smart contracts are\nused to automate the machine learning process. This paper makes three\ncontributions. First, it establishes a link between machine learning technology\nand blockchain technology. Previously, machine learning and blockchain have\nbeen considered two independent technologies without an obvious link. Second,\nit proposes a unified analytical framework for trustable machine learning by\nusing blockchain technology. This unified framework solves both the\ntrustability and automation issues in machine learning. Third, it enables a\ncomputer to translate core machine learning implementation from a single thread\non a single machine to multiple threads on multiple machines running with\nblockchain by using a unified approach. The paper uses association rule mining\nas an example to demonstrate how trustable machine learning can be implemented\nwith blockchain, and it shows how this approach can be used to analyze opioid\nprescriptions to help combat the opioid crisis.", "journal": ""}
{"doi": "10.48550/arXiv.1707.09562", "date": "2017-07-29", "title": "MLBench: How Good Are Machine Learning Clouds for Binary Classification Tasks on Structured Data?", "authors": "Yu Liu, Hantian Zhang, Luyuan Zeng, Wentao Wu, Ce Zhang", "abstract": "We conduct an empirical study of machine learning functionalities provided by\nmajor cloud service providers, which we call machine learning clouds. Machine\nlearning clouds hold the promise of hiding all the sophistication of running\nlarge-scale machine learning: Instead of specifying how to run a machine\nlearning task, users only specify what machine learning task to run and the\ncloud figures out the rest. Raising the level of abstraction, however, rarely\ncomes free - a performance penalty is possible. How good, then, are current\nmachine learning clouds on real-world machine learning workloads?\n  We study this question with a focus on binary classication problems. We\npresent mlbench, a novel benchmark constructed by harvesting datasets from\nKaggle competitions. We then compare the performance of the top winning code\navailable from Kaggle with that of running machine learning clouds from both\nAzure and Amazon on mlbench. Our comparative study reveals the strength and\nweakness of existing machine learning clouds and points out potential future\ndirections for improvement.", "journal": ""}
{"doi": "10.48550/arXiv.2108.07915", "date": "2021-08-18", "title": "Data Pricing in Machine Learning Pipelines", "authors": "Zicun Cong, Xuan Luo, Pei Jian, Feida Zhu, Yong Zhang", "abstract": "Machine learning is disruptive. At the same time, machine learning can only\nsucceed by collaboration among many parties in multiple steps naturally as\npipelines in an eco-system, such as collecting data for possible machine\nlearning applications, collaboratively training models by multiple parties and\ndelivering machine learning services to end users. Data is critical and\npenetrating in the whole machine learning pipelines. As machine learning\npipelines involve many parties and, in order to be successful, have to form a\nconstructive and dynamic eco-system, marketplaces and data pricing are\nfundamental in connecting and facilitating those many parties. In this article,\nwe survey the principles and the latest research development of data pricing in\nmachine learning pipelines. We start with a brief review of data marketplaces\nand pricing desiderata. Then, we focus on pricing in three important steps in\nmachine learning pipelines. To understand pricing in the step of training data\ncollection, we review pricing raw data sets and data labels. We also\ninvestigate pricing in the step of collaborative training of machine learning\nmodels, and overview pricing machine learning models for end users in the step\nof machine learning deployment. We also discuss a series of possible future\ndirections.", "journal": ""}
{"doi": "10.48550/arXiv.1907.08908", "date": "2019-07-21", "title": "Techniques for Automated Machine Learning", "authors": "Yi-Wei Chen, Qingquan Song, Xia Hu", "abstract": "Automated machine learning (AutoML) aims to find optimal machine learning\nsolutions automatically given a machine learning problem. It could release the\nburden of data scientists from the multifarious manual tuning process and\nenable the access of domain experts to the off-the-shelf machine learning\nsolutions without extensive experience. In this paper, we review the current\ndevelopments of AutoML in terms of three categories, automated feature\nengineering (AutoFE), automated model and hyperparameter learning (AutoMHL),\nand automated deep learning (AutoDL). State-of-the-art techniques adopted in\nthe three categories are presented, including Bayesian optimization,\nreinforcement learning, evolutionary algorithm, and gradient-based approaches.\nWe summarize popular AutoML frameworks and conclude with current open\nchallenges of AutoML.", "journal": ""}
{"doi": "10.48550/arXiv.2312.03120", "date": "2023-12-05", "title": "The Landscape of Modern Machine Learning: A Review of Machine, Distributed and Federated Learning", "authors": "Omer Subasi, Oceane Bel, Joseph Manzano, Kevin Barker", "abstract": "With the advance of the powerful heterogeneous, parallel and distributed\ncomputing systems and ever increasing immense amount of data, machine learning\nhas become an indispensable part of cutting-edge technology, scientific\nresearch and consumer products. In this study, we present a review of modern\nmachine and deep learning. We provide a high-level overview for the latest\nadvanced machine learning algorithms, applications, and frameworks. Our\ndiscussion encompasses parallel distributed learning, deep learning as well as\nfederated learning. As a result, our work serves as an introductory text to the\nvast field of modern machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.2206.07090", "date": "2022-05-08", "title": "Parallelization of Machine Learning Algorithms Respectively on Single Machine and Spark", "authors": "Jiajun Shen", "abstract": "With the rapid development of big data technologies, how to dig out useful\ninformation from massive data becomes an essential problem. However, using\nmachine learning algorithms to analyze large data may be time-consuming and\ninefficient on the traditional single machine. To solve these problems, this\npaper has made some research on the parallelization of several classic machine\nlearning algorithms respectively on the single machine and the big data\nplatform Spark. We compare the runtime and efficiency of traditional machine\nlearning algorithms with parallelized machine learning algorithms respectively\non the single machine and Spark platform. The research results have shown\nsignificant improvement in runtime and efficiency of parallelized machine\nlearning algorithms.", "journal": ""}
{"doi": "10.48550/arXiv.1507.02188", "date": "2015-07-08", "title": "AutoCompete: A Framework for Machine Learning Competition", "authors": "Abhishek Thakur, Artus Krohn-Grimberghe", "abstract": "In this paper, we propose AutoCompete, a highly automated machine learning\nframework for tackling machine learning competitions. This framework has been\nlearned by us, validated and improved over a period of more than two years by\nparticipating in online machine learning competitions. It aims at minimizing\nhuman interference required to build a first useful predictive model and to\nassess the practical difficulty of a given machine learning challenge. The\nproposed system helps in identifying data types, choosing a machine learn- ing\nmodel, tuning hyper-parameters, avoiding over-fitting and optimization for a\nprovided evaluation metric. We also observe that the proposed system produces\nbetter (or comparable) results with less runtime as compared to other\napproaches.", "journal": ""}
{"doi": "10.48550/arXiv.1212.2686", "date": "2012-12-12", "title": "Joint Training of Deep Boltzmann Machines", "authors": "Ian Goodfellow, Aaron Courville, Yoshua Bengio", "abstract": "We introduce a new method for training deep Boltzmann machines jointly. Prior\nmethods require an initial learning pass that trains the deep Boltzmann machine\ngreedily, one layer at a time, or do not perform well on classifi- cation\ntasks.", "journal": ""}
{"doi": "10.48550/arXiv.1607.02450", "date": "2016-07-08", "title": "Proceedings of the 2016 ICML Workshop on #Data4Good: Machine Learning in Social Good Applications", "authors": "Kush R. Varshney", "abstract": "This is the Proceedings of the ICML Workshop on #Data4Good: Machine Learning\nin Social Good Applications, which was held on June 24, 2016 in New York.", "journal": ""}
{"doi": "10.48550/arXiv.2007.01503", "date": "2020-07-03", "title": "Mathematical Perspective of Machine Learning", "authors": "Yarema Boryshchak", "abstract": "We take a closer look at some theoretical challenges of Machine Learning as a\nfunction approximation, gradient descent as the default optimization algorithm,\nlimitations of fixed length and width networks and a different approach to RNNs\nfrom a mathematical perspective.", "journal": ""}
{"doi": "10.48550/arXiv.2001.04942", "date": "2020-01-14", "title": "Private Machine Learning via Randomised Response", "authors": "David Barber", "abstract": "We introduce a general learning framework for private machine learning based\non randomised response. Our assumption is that all actors are potentially\nadversarial and as such we trust only to release a single noisy version of an\nindividual's datapoint. We discuss a general approach that forms a consistent\nway to estimate the true underlying machine learning model and demonstrate this\nin the case of logistic regression.", "journal": ""}
{"doi": "10.48550/arXiv.1906.06821", "date": "2019-06-17", "title": "A Survey of Optimization Methods from a Machine Learning Perspective", "authors": "Shiliang Sun, Zehui Cao, Han Zhu, Jing Zhao", "abstract": "Machine learning develops rapidly, which has made many theoretical\nbreakthroughs and is widely applied in various fields. Optimization, as an\nimportant part of machine learning, has attracted much attention of\nresearchers. With the exponential growth of data amount and the increase of\nmodel complexity, optimization methods in machine learning face more and more\nchallenges. A lot of work on solving optimization problems or improving\noptimization methods in machine learning has been proposed successively. The\nsystematic retrospect and summary of the optimization methods from the\nperspective of machine learning are of great significance, which can offer\nguidance for both developments of optimization and machine learning research.\nIn this paper, we first describe the optimization problems in machine learning.\nThen, we introduce the principles and progresses of commonly used optimization\nmethods. Next, we summarize the applications and developments of optimization\nmethods in some popular machine learning fields. Finally, we explore and give\nsome challenges and open problems for the optimization in machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.1911.00776", "date": "2019-11-02", "title": "Ten-year Survival Prediction for Breast Cancer Patients", "authors": "Changmao Li, Han He, Yunze Hao, Caleb Ziems", "abstract": "This report assesses different machine learning approaches to 10-year\nsurvival prediction of breast cancer patients.", "journal": ""}
{"doi": "10.48550/arXiv.2505.13457", "date": "2025-04-30", "title": "Tuning Learning Rates with the Cumulative-Learning Constant", "authors": "Nathan Faraj", "abstract": "This paper introduces a novel method for optimizing learning rates in machine\nlearning. A previously unrecognized proportionality between learning rates and\ndataset sizes is discovered, providing valuable insights into how dataset scale\ninfluences training dynamics. Additionally, a cumulative learning constant is\nidentified, offering a framework for designing and optimizing advanced learning\nrate schedules. These findings have the potential to enhance training\nefficiency and performance across a wide range of machine learning\napplications.", "journal": ""}
{"doi": "10.48550/arXiv.2011.11819", "date": "2020-11-24", "title": "When Machine Learning Meets Privacy: A Survey and Outlook", "authors": "Bo Liu, Ming Ding, Sina Shaham, Wenny Rahayu, Farhad Farokhi, Zihuai Lin", "abstract": "The newly emerged machine learning (e.g. deep learning) methods have become a\nstrong driving force to revolutionize a wide range of industries, such as smart\nhealthcare, financial technology, and surveillance systems. Meanwhile, privacy\nhas emerged as a big concern in this machine learning-based artificial\nintelligence era. It is important to note that the problem of privacy\npreservation in the context of machine learning is quite different from that in\ntraditional data privacy protection, as machine learning can act as both friend\nand foe. Currently, the work on the preservation of privacy and machine\nlearning (ML) is still in an infancy stage, as most existing solutions only\nfocus on privacy problems during the machine learning process. Therefore, a\ncomprehensive study on the privacy preservation problems and machine learning\nis required. This paper surveys the state of the art in privacy issues and\nsolutions for machine learning. The survey covers three categories of\ninteractions between privacy and machine learning: (i) private machine\nlearning, (ii) machine learning aided privacy protection, and (iii) machine\nlearning-based privacy attack and corresponding protection schemes. The current\nresearch progress in each category is reviewed and the key challenges are\nidentified. Finally, based on our in-depth analysis of the area of privacy and\nmachine learning, we point out future research directions in this field.", "journal": ""}
{"doi": "10.48550/arXiv.2004.00993", "date": "2020-03-31", "title": "Augmented Q Imitation Learning (AQIL)", "authors": "Xiao Lei Zhang, Anish Agarwal", "abstract": "The study of unsupervised learning can be generally divided into two\ncategories: imitation learning and reinforcement learning. In imitation\nlearning the machine learns by mimicking the behavior of an expert system\nwhereas in reinforcement learning the machine learns via direct environment\nfeedback. Traditional deep reinforcement learning takes a significant time\nbefore the machine starts to converge to an optimal policy. This paper proposes\nAugmented Q-Imitation-Learning, a method by which deep reinforcement learning\nconvergence can be accelerated by applying Q-imitation-learning as the initial\ntraining process in traditional Deep Q-learning.", "journal": ""}
{"doi": "10.48550/arXiv.2009.11087", "date": "2020-09-23", "title": "Probabilistic Machine Learning for Healthcare", "authors": "Irene Y. Chen, Shalmali Joshi, Marzyeh Ghassemi, Rajesh Ranganath", "abstract": "Machine learning can be used to make sense of healthcare data. Probabilistic\nmachine learning models help provide a complete picture of observed data in\nhealthcare. In this review, we examine how probabilistic machine learning can\nadvance healthcare. We consider challenges in the predictive model building\npipeline where probabilistic models can be beneficial including calibration and\nmissing data. Beyond predictive models, we also investigate the utility of\nprobabilistic machine learning models in phenotyping, in generative models for\nclinical use cases, and in reinforcement learning.", "journal": ""}
{"doi": "10.48550/arXiv.2303.18087", "date": "2023-03-31", "title": "Evaluation Challenges for Geospatial ML", "authors": "Esther Rolf", "abstract": "As geospatial machine learning models and maps derived from their predictions\nare increasingly used for downstream analyses in science and policy, it is\nimperative to evaluate their accuracy and applicability. Geospatial machine\nlearning has key distinctions from other learning paradigms, and as such, the\ncorrect way to measure performance of spatial machine learning outputs has been\na topic of debate. In this paper, I delineate unique challenges of model\nevaluation for geospatial machine learning with global or remotely sensed\ndatasets, culminating in concrete takeaways to improve evaluations of\ngeospatial model performance.", "journal": ""}
{"doi": "10.48550/arXiv.2401.11351", "date": "2024-01-21", "title": "A comprehensive review of Quantum Machine Learning: from NISQ to Fault Tolerance", "authors": "Yunfei Wang, Junyu Liu", "abstract": "Quantum machine learning, which involves running machine learning algorithms\non quantum devices, has garnered significant attention in both academic and\nbusiness circles. In this paper, we offer a comprehensive and unbiased review\nof the various concepts that have emerged in the field of quantum machine\nlearning. This includes techniques used in Noisy Intermediate-Scale Quantum\n(NISQ) technologies and approaches for algorithms compatible with\nfault-tolerant quantum computing hardware. Our review covers fundamental\nconcepts, algorithms, and the statistical learning theory pertinent to quantum\nmachine learning.", "journal": "Rep. Prog. Phys. 87 116402, 2024"}
{"doi": "10.48550/arXiv.2003.05155", "date": "2020-03-11", "title": "Towards CRISP-ML(Q): A Machine Learning Process Model with Quality Assurance Methodology", "authors": "Stefan Studer, Thanh Binh Bui, Christian Drescher, Alexander Hanuschkin, Ludwig Winkler, Steven Peters, Klaus-Robert Mueller", "abstract": "Machine learning is an established and frequently used technique in industry\nand academia but a standard process model to improve success and efficiency of\nmachine learning applications is still missing. Project organizations and\nmachine learning practitioners have a need for guidance throughout the life\ncycle of a machine learning application to meet business expectations. We\ntherefore propose a process model for the development of machine learning\napplications, that covers six phases from defining the scope to maintaining the\ndeployed machine learning application. The first phase combines business and\ndata understanding as data availability oftentimes affects the feasibility of\nthe project. The sixth phase covers state-of-the-art approaches for monitoring\nand maintenance of a machine learning applications, as the risk of model\ndegradation in a changing environment is eminent. With each task of the\nprocess, we propose quality assurance methodology that is suitable to adress\nchallenges in machine learning development that we identify in form of risks.\nThe methodology is drawn from practical experience and scientific literature\nand has proven to be general and stable. The process model expands on CRISP-DM,\na data mining process model that enjoys strong industry support but lacks to\naddress machine learning specific tasks. Our work proposes an industry and\napplication neutral process model tailored for machine learning applications\nwith focus on technical tasks for quality assurance.", "journal": ""}
{"doi": "10.48550/arXiv.1706.08001", "date": "2017-06-24", "title": "Temporal-related Convolutional-Restricted-Boltzmann-Machine capable of learning relational order via reinforcement learning procedure?", "authors": "Zizhuang Wang", "abstract": "In this article, we extend the conventional framework of\nconvolutional-Restricted-Boltzmann-Machine to learn highly abstract features\namong abitrary number of time related input maps by constructing a layer of\nmultiplicative units, which capture the relations among inputs. In many cases,\nmore than two maps are strongly related, so it is wise to make multiplicative\nunit learn relations among more input maps, in other words, to find the optimal\nrelational-order of each unit. In order to enable our machine to learn\nrelational order, we developed a reinforcement-learning method whose optimality\nis proven to train the network.", "journal": ""}
{"doi": "10.48550/arXiv.2405.03720", "date": "2024-05-05", "title": "Spatial Transfer Learning with Simple MLP", "authors": "Hongjian Yang", "abstract": "First step to investigate the potential of transfer learning applied to the\nfield of spatial statistics", "journal": ""}
{"doi": "10.48550/arXiv.1207.4676", "date": "2012-07-19", "title": "Proceedings of the 29th International Conference on Machine Learning (ICML-12)", "authors": "John Langford, Joelle Pineau", "abstract": "This is an index to the papers that appear in the Proceedings of the 29th\nInternational Conference on Machine Learning (ICML-12). The conference was held\nin Edinburgh, Scotland, June 27th - July 3rd, 2012.", "journal": ""}
{"doi": "10.48550/arXiv.1603.02185", "date": "2016-03-07", "title": "Distributed Multi-Task Learning with Shared Representation", "authors": "Jialei Wang, Mladen Kolar, Nathan Srebro", "abstract": "We study the problem of distributed multi-task learning with shared\nrepresentation, where each machine aims to learn a separate, but related, task\nin an unknown shared low-dimensional subspaces, i.e. when the predictor matrix\nhas low rank. We consider a setting where each task is handled by a different\nmachine, with samples for the task available locally on the machine, and study\ncommunication-efficient methods for exploiting the shared structure.", "journal": ""}
{"doi": "10.48550/arXiv.1910.12387", "date": "2019-10-25", "title": "Components of Machine Learning: Binding Bits and FLOPS", "authors": "Alexander Jung", "abstract": "Many machine learning problems and methods are combinations of three\ncomponents: data, hypothesis space and loss function. Different machine\nlearning methods are obtained as combinations of different choices for the\nrepresentation of data, hypothesis space and loss function. After reviewing the\nmathematical structure of these three components, we discuss intrinsic\ntrade-offs between statistical and computational properties of machine learning\nmethods.", "journal": ""}
{"doi": "10.48550/arXiv.2007.05479", "date": "2020-07-10", "title": "Impact of Legal Requirements on Explainability in Machine Learning", "authors": "Adrien Bibal, Michael Lognoul, Alexandre de Streel, Beno\u00eet Fr\u00e9nay", "abstract": "The requirements on explainability imposed by European laws and their\nimplications for machine learning (ML) models are not always clear. In that\nperspective, our research analyzes explanation obligations imposed for private\nand public decision-making, and how they can be implemented by machine learning\ntechniques.", "journal": ""}
{"doi": "10.48550/arXiv.2007.14206", "date": "2020-07-27", "title": "Machine Learning Potential Repository", "authors": "Atsuto Seko", "abstract": "This paper introduces a machine learning potential repository that includes\nPareto optimal machine learning potentials. It also shows the systematic\ndevelopment of accurate and fast machine learning potentials for a wide range\nof elemental systems. As a result, many Pareto optimal machine learning\npotentials are available in the repository from a website. Therefore, the\nrepository will help many scientists to perform accurate and fast atomistic\nsimulations.", "journal": ""}
{"doi": "10.48550/arXiv.2412.18979", "date": "2024-12-25", "title": "Quantum memristors for neuromorphic quantum machine learning", "authors": "Lucas Lamata", "abstract": "Quantum machine learning may permit to realize more efficient machine\nlearning calculations with near-term quantum devices. Among the diverse quantum\nmachine learning paradigms which are currently being considered, quantum\nmemristors are promising as a way of combining, in the same quantum hardware, a\nunitary evolution with the nonlinearity provided by the measurement and\nfeedforward. Thus, an efficient way of deploying neuromorphic quantum computing\nfor quantum machine learning may be enabled.", "journal": ""}
{"doi": "10.48550/arXiv.1908.04710", "date": "2019-08-13", "title": "metric-learn: Metric Learning Algorithms in Python", "authors": "William de Vazelhes, CJ Carey, Yuan Tang, Nathalie Vauquier, Aur\u00e9lien Bellet", "abstract": "metric-learn is an open source Python package implementing supervised and\nweakly-supervised distance metric learning algorithms. As part of\nscikit-learn-contrib, it provides a unified interface compatible with\nscikit-learn which allows to easily perform cross-validation, model selection,\nand pipelining with other machine learning estimators. metric-learn is\nthoroughly tested and available on PyPi under the MIT licence.", "journal": "Journal of Machine Learning Research (JMLR), 21(138):1-6, 2020"}
{"doi": "10.48550/arXiv.2002.12364", "date": "2020-02-27", "title": "Theoretical Models of Learning to Learn", "authors": "Jonathan Baxter", "abstract": "A Machine can only learn if it is biased in some way. Typically the bias is\nsupplied by hand, for example through the choice of an appropriate set of\nfeatures. However, if the learning machine is embedded within an {\\em\nenvironment} of related tasks, then it can {\\em learn} its own bias by learning\nsufficiently many tasks from the environment. In this paper two models of bias\nlearning (or equivalently, learning to learn) are introduced and the main\ntheoretical results presented. The first model is a PAC-type model based on\nempirical process theory, while the second is a hierarchical Bayes model.", "journal": "in Learning to Learn (edited by Sebastian Thrun and Lorien Pratt),\n  159-179 (1998)"}
{"doi": "10.48550/arXiv.1509.00913", "date": "2015-09-03", "title": "On-the-Fly Learning in a Perpetual Learning Machine", "authors": "Andrew J. R. Simpson", "abstract": "Despite the promise of brain-inspired machine learning, deep neural networks\n(DNN) have frustratingly failed to bridge the deceptively large gap between\nlearning and memory. Here, we introduce a Perpetual Learning Machine; a new\ntype of DNN that is capable of brain-like dynamic 'on the fly' learning because\nit exists in a self-supervised state of Perpetual Stochastic Gradient Descent.\nThus, we provide the means to unify learning and memory within a machine\nlearning framework. We also explore the elegant duality of abstraction and\nsynthesis: the Yin and Yang of deep learning.", "journal": ""}
{"doi": "10.48550/arXiv.1607.01400", "date": "2016-07-05", "title": "An Aggregate and Iterative Disaggregate Algorithm with Proven Optimality in Machine Learning", "authors": "Young Woong Park, Diego Klabjan", "abstract": "We propose a clustering-based iterative algorithm to solve certain\noptimization problems in machine learning, where we start the algorithm by\naggregating the original data, solving the problem on aggregated data, and then\nin subsequent steps gradually disaggregate the aggregated data. We apply the\nalgorithm to common machine learning problems such as the least absolute\ndeviation regression problem, support vector machines, and semi-supervised\nsupport vector machines. We derive model-specific data aggregation and\ndisaggregation procedures. We also show optimality, convergence, and the\noptimality gap of the approximated solution in each iteration. A computational\nstudy is provided.", "journal": "Machine Learning 105 (2016) 199 - 232"}
{"doi": "10.48550/arXiv.2202.10564", "date": "2022-02-21", "title": "Human-in-the-loop Machine Learning: A Macro-Micro Perspective", "authors": "Jiangtao Wang, Bin Guo, Liming Chen", "abstract": "Though technical advance of artificial intelligence and machine learning has\nenabled many promising intelligent systems, many computing tasks are still not\nable to be fully accomplished by machine intelligence. Motivated by the\ncomplementary nature of human and machine intelligence, an emerging trend is to\ninvolve humans in the loop of machine learning and decision-making. In this\npaper, we provide a macro-micro review of human-in-the-loop machine learning.\nWe first describe major machine learning challenges which can be addressed by\nhuman intervention in the loop. Then we examine closely the latest research and\nfindings of introducing humans into each step of the lifecycle of machine\nlearning. Finally, we analyze current research gaps and point out future\nresearch directions.", "journal": ""}
{"doi": "10.48550/arXiv.2407.05526", "date": "2024-07-08", "title": "Can Machines Learn the True Probabilities?", "authors": "Jinsook Kim", "abstract": "When there exists uncertainty, AI machines are designed to make decisions so\nas to reach the best expected outcomes. Expectations are based on true facts\nabout the objective environment the machines interact with, and those facts can\nbe encoded into AI models in the form of true objective probability functions.\nAccordingly, AI models involve probabilistic machine learning in which the\nprobabilities should be objectively interpreted. We prove under some basic\nassumptions when machines can learn the true objective probabilities, if any,\nand when machines cannot learn them.", "journal": ""}
{"doi": "10.48550/arXiv.2110.12773", "date": "2021-10-25", "title": "Scientific Machine Learning Benchmarks", "authors": "Jeyan Thiyagalingam, Mallikarjun Shankar, Geoffrey Fox, Tony Hey", "abstract": "The breakthrough in Deep Learning neural networks has transformed the use of\nAI and machine learning technologies for the analysis of very large\nexperimental datasets. These datasets are typically generated by large-scale\nexperimental facilities at national laboratories. In the context of science,\nscientific machine learning focuses on training machines to identify patterns,\ntrends, and anomalies to extract meaningful scientific insights from such\ndatasets. With a new generation of experimental facilities, the rate of data\ngeneration and the scale of data volumes will increasingly require the use of\nmore automated data analysis. At present, identifying the most appropriate\nmachine learning algorithm for the analysis of any given scientific dataset is\nstill a challenge for scientists. This is due to many different machine\nlearning frameworks, computer architectures, and machine learning models.\nHistorically, for modelling and simulation on HPC systems such problems have\nbeen addressed through benchmarking computer applications, algorithms, and\narchitectures. Extending such a benchmarking approach and identifying metrics\nfor the application of machine learning methods to scientific datasets is a new\nchallenge for both scientists and computer scientists. In this paper, we\ndescribe our approach to the development of scientific machine learning\nbenchmarks and review other approaches to benchmarking scientific machine\nlearning.", "journal": ""}
{"doi": "10.48550/arXiv.2001.09608", "date": "2020-01-27", "title": "Some Insights into Lifelong Reinforcement Learning Systems", "authors": "Changjian Li", "abstract": "A lifelong reinforcement learning system is a learning system that has the\nability to learn through trail-and-error interaction with the environment over\nits lifetime. In this paper, I give some arguments to show that the traditional\nreinforcement learning paradigm fails to model this type of learning system.\nSome insights into lifelong reinforcement learning are provided, along with a\nsimplistic prototype lifelong reinforcement learning system.", "journal": ""}
{"doi": "10.48550/arXiv.1612.04858", "date": "2016-12-14", "title": "Bayesian Optimization for Machine Learning : A Practical Guidebook", "authors": "Ian Dewancker, Michael McCourt, Scott Clark", "abstract": "The engineering of machine learning systems is still a nascent field; relying\non a seemingly daunting collection of quickly evolving tools and best\npractices. It is our hope that this guidebook will serve as a useful resource\nfor machine learning practitioners looking to take advantage of Bayesian\noptimization techniques. We outline four example machine learning problems that\ncan be solved using open source machine learning libraries, and highlight the\nbenefits of using Bayesian optimization in the context of these common machine\nlearning applications.", "journal": ""}
{"doi": "10.48550/arXiv.1702.08608", "date": "2017-02-28", "title": "Towards A Rigorous Science of Interpretable Machine Learning", "authors": "Finale Doshi-Velez, Been Kim", "abstract": "As machine learning systems become ubiquitous, there has been a surge of\ninterest in interpretable machine learning: systems that provide explanation\nfor their outputs. These explanations are often used to qualitatively assess\nother criteria such as safety or non-discrimination. However, despite the\ninterest in interpretability, there is very little consensus on what\ninterpretable machine learning is and how it should be measured. In this\nposition paper, we first define interpretability and describe when\ninterpretability is needed (and when it is not). Next, we suggest a taxonomy\nfor rigorous evaluation and expose open questions towards a more rigorous\nscience of interpretable machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.1705.07538", "date": "2017-05-22", "title": "Infrastructure for Usable Machine Learning: The Stanford DAWN Project", "authors": "Peter Bailis, Kunle Olukotun, Christopher Re, Matei Zaharia", "abstract": "Despite incredible recent advances in machine learning, building machine\nlearning applications remains prohibitively time-consuming and expensive for\nall but the best-trained, best-funded engineering organizations. This expense\ncomes not from a need for new and improved statistical models but instead from\na lack of systems and tools for supporting end-to-end machine learning\napplication development, from data preparation and labeling to\nproductionization and monitoring. In this document, we outline opportunities\nfor infrastructure supporting usable, end-to-end machine learning applications\nin the context of the nascent DAWN (Data Analytics for What's Next) project at\nStanford.", "journal": ""}
{"doi": "10.48550/arXiv.1808.00033", "date": "2018-07-31", "title": "Techniques for Interpretable Machine Learning", "authors": "Mengnan Du, Ninghao Liu, Xia Hu", "abstract": "Interpretable machine learning tackles the important problem that humans\ncannot understand the behaviors of complex machine learning models and how\nthese models arrive at a particular decision. Although many approaches have\nbeen proposed, a comprehensive understanding of the achievements and challenges\nis still lacking. We provide a survey covering existing techniques to increase\nthe interpretability of machine learning models. We also discuss crucial issues\nthat the community should consider in future work such as designing\nuser-friendly explanations and developing comprehensive evaluation metrics to\nfurther push forward the area of interpretable machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.1911.08587", "date": "2019-11-17", "title": "Solving machine learning optimization problems using quantum computers", "authors": "Venkat R. Dasari, Mee Seong Im, Lubjana Beshaj", "abstract": "Classical optimization algorithms in machine learning often take a long time\nto compute when applied to a multi-dimensional problem and require a huge\namount of CPU and GPU resource. Quantum parallelism has a potential to speed up\nmachine learning algorithms. We describe a generic mathematical model to\nleverage quantum parallelism to speed-up machine learning algorithms. We also\napply quantum machine learning and quantum parallelism applied to a\n$3$-dimensional image that vary with time.", "journal": ""}
{"doi": "10.48550/arXiv.2007.01977", "date": "2020-07-04", "title": "Lale: Consistent Automated Machine Learning", "authors": "Guillaume Baudart, Martin Hirzel, Kiran Kate, Parikshit Ram, Avraham Shinnar", "abstract": "Automated machine learning makes it easier for data scientists to develop\npipelines by searching over possible choices for hyperparameters, algorithms,\nand even pipeline topologies. Unfortunately, the syntax for automated machine\nlearning tools is inconsistent with manual machine learning, with each other,\nand with error checks. Furthermore, few tools support advanced features such as\ntopology search or higher-order operators. This paper introduces Lale, a\nlibrary of high-level Python interfaces that simplifies and unifies automated\nmachine learning in a consistent way.", "journal": ""}
{"doi": "10.48550/arXiv.2007.07981", "date": "2020-07-15", "title": "Differential Replication in Machine Learning", "authors": "Irene Unceta, Jordi Nin, Oriol Pujol", "abstract": "When deployed in the wild, machine learning models are usually confronted\nwith data and requirements that constantly vary, either because of changes in\nthe generating distribution or because external constraints change the\nenvironment where the model operates. To survive in such an ecosystem, machine\nlearning models need to adapt to new conditions by evolving over time. The idea\nof model adaptability has been studied from different perspectives. In this\npaper, we propose a solution based on reusing the knowledge acquired by the\nalready deployed machine learning models and leveraging it to train future\ngenerations. This is the idea behind differential replication of machine\nlearning models.", "journal": ""}
{"doi": "10.48550/arXiv.2008.08080", "date": "2020-08-18", "title": "mlr3proba: An R Package for Machine Learning in Survival Analysis", "authors": "Raphael Sonabend, Franz J. Kir\u00e1ly, Andreas Bender, Bernd Bischl, Michel Lang", "abstract": "As machine learning has become increasingly popular over the last few\ndecades, so too has the number of machine learning interfaces for implementing\nthese models. Whilst many R libraries exist for machine learning, very few\noffer extended support for survival analysis. This is problematic considering\nits importance in fields like medicine, bioinformatics, economics, engineering,\nand more. mlr3proba provides a comprehensive machine learning interface for\nsurvival analysis and connects with mlr3's general model tuning and\nbenchmarking facilities to provide a systematic infrastructure for survival\nmodeling and evaluation.", "journal": ""}
{"doi": "10.48550/arXiv.2108.08712", "date": "2021-08-19", "title": "Teaching Uncertainty Quantification in Machine Learning through Use Cases", "authors": "Matias Valdenegro-Toro", "abstract": "Uncertainty in machine learning is not generally taught as general knowledge\nin Machine Learning course curricula. In this paper we propose a short\ncurriculum for a course about uncertainty in machine learning, and complement\nthe course with a selection of use cases, aimed to trigger discussion and let\nstudents play with the concepts of uncertainty in a programming setting. Our\nuse cases cover the concept of output uncertainty, Bayesian neural networks and\nweight distributions, sources of uncertainty, and out of distribution\ndetection. We expect that this curriculum and set of use cases motivates the\ncommunity to adopt these important concepts into courses for safety in AI.", "journal": ""}
{"doi": "10.48550/arXiv.2212.12303", "date": "2022-12-23", "title": "Introduction to Machine Learning for Physicians: A Survival Guide for Data Deluge", "authors": "Ri\u010dards Marcinkevi\u010ds, Ece Ozkan, Julia E. Vogt", "abstract": "Many modern research fields increasingly rely on collecting and analysing\nmassive, often unstructured, and unwieldy datasets. Consequently, there is\ngrowing interest in machine learning and artificial intelligence applications\nthat can harness this `data deluge'. This broad nontechnical overview provides\na gentle introduction to machine learning with a specific focus on medical and\nbiological applications. We explain the common types of machine learning\nalgorithms and typical tasks that can be solved, illustrating the basics with\nconcrete examples from healthcare. Lastly, we provide an outlook on open\nchallenges, limitations, and potential impacts of machine-learning-powered\nmedicine.", "journal": ""}
{"doi": "10.48550/arXiv.2305.15410", "date": "2023-04-28", "title": "Machine learning-assisted close-set X-ray diffraction phase identification of transition metals", "authors": "Maksim Zhdanov, Andrey Zhdanov", "abstract": "Machine learning has been applied to the problem of X-ray diffraction phase\nprediction with promising results. In this paper, we describe a method for\nusing machine learning to predict crystal structure phases from X-ray\ndiffraction data of transition metals and their oxides. We evaluate the\nperformance of our method and compare the variety of its settings. Our results\ndemonstrate that the proposed machine learning framework achieves competitive\nperformance. This demonstrates the potential for machine learning to\nsignificantly impact the field of X-ray diffraction and crystal structure\ndetermination. Open-source implementation:\nhttps://github.com/maxnygma/NeuralXRD.", "journal": ""}
{"doi": "10.48550/arXiv.2306.14624", "date": "2023-06-26", "title": "Insights From Insurance for Fair Machine Learning", "authors": "Christian Fr\u00f6hlich, Robert C. Williamson", "abstract": "We argue that insurance can act as an analogon for the social situatedness of\nmachine learning systems, hence allowing machine learning scholars to take\ninsights from the rich and interdisciplinary insurance literature. Tracing the\ninteraction of uncertainty, fairness and responsibility in insurance provides a\nfresh perspective on fairness in machine learning. We link insurance fairness\nconceptions to their machine learning relatives, and use this bridge to\nproblematize fairness as calibration. In this process, we bring to the\nforefront two themes that have been largely overlooked in the machine learning\nliterature: responsibility and aggregate-individual tensions.", "journal": ""}
{"doi": "10.48550/arXiv.2407.19890", "date": "2024-07-07", "title": "Quantum Dynamics of Machine Learning", "authors": "Peng Wang, Maimaitiniyazi Maimaitiabudula", "abstract": "The quantum dynamic equation (QDE) of machine learning is obtained based on\nSchr\\\"odinger equation and potential energy equivalence relationship. Through\nWick rotation, the relationship between quantum dynamics and thermodynamics is\nalso established in this paper. This equation reformulates the iterative\nprocess of machine learning into a time-dependent partial differential equation\nwith a clear mathematical structure, offering a theoretical framework for\ninvestigating machine learning iterations through quantum and mathematical\ntheories. Within this framework, the fundamental iterative process, the\ndiffusion model, and the Softmax and Sigmoid functions are examined, validating\nthe proposed quantum dynamics equations. This approach not only presents a\nrigorous theoretical foundation for machine learning but also holds promise for\nsupporting the implementation of machine learning algorithms on quantum\ncomputers.", "journal": ""}
{"doi": "10.48550/arXiv.2412.00464", "date": "2024-11-30", "title": "On the Conditions for Domain Stability for Machine Learning: a Mathematical Approach", "authors": "Gabriel Pedroza", "abstract": "This work proposes a mathematical approach that (re)defines a property of\nMachine Learning models named stability and determines sufficient conditions to\nvalidate it. Machine Learning models are represented as functions, and the\ncharacteristics in scope depend upon the domain of the function, what allows us\nto adopt topological and metric spaces theory as a basis. Finally, this work\nprovides some equivalences useful to prove and test stability in Machine\nLearning models. The results suggest that whenever stability is aligned with\nthe notion of function smoothness, then the stability of Machine Learning\nmodels primarily depends upon certain topological, measurable properties of the\nclassification sets within the ML model domain.", "journal": ""}
{"doi": "10.48550/arXiv.1510.00633", "date": "2015-10-02", "title": "Distributed Multitask Learning", "authors": "Jialei Wang, Mladen Kolar, Nathan Srebro", "abstract": "We consider the problem of distributed multi-task learning, where each\nmachine learns a separate, but related, task. Specifically, each machine learns\na linear predictor in high-dimensional space,where all tasks share the same\nsmall support. We present a communication-efficient estimator based on the\ndebiased lasso and show that it is comparable with the optimal centralized\nmethod.", "journal": ""}
{"doi": "10.48550/arXiv.1802.03830", "date": "2018-02-11", "title": "Distributed Stochastic Multi-Task Learning with Graph Regularization", "authors": "Weiran Wang, Jialei Wang, Mladen Kolar, Nathan Srebro", "abstract": "We propose methods for distributed graph-based multi-task learning that are\nbased on weighted averaging of messages from other machines. Uniform averaging\nor diminishing stepsize in these methods would yield consensus (single task)\nlearning. We show how simply skewing the averaging weights or controlling the\nstepsize allows learning different, but related, tasks on the different\nmachines.", "journal": ""}
{"doi": "10.48550/arXiv.2106.07032", "date": "2021-06-13", "title": "Category Theory in Machine Learning", "authors": "Dan Shiebler, Bruno Gavranovi\u0107, Paul Wilson", "abstract": "Over the past two decades machine learning has permeated almost every realm\nof technology. At the same time, many researchers have begun using category\ntheory as a unifying language, facilitating communication between different\nscientific disciplines. It is therefore unsurprising that there is a burgeoning\ninterest in applying category theory to machine learning. We aim to document\nthe motivations, goals and common themes across these applications. We touch on\ngradient-based learning, probability, and equivariant learning.", "journal": ""}
{"doi": "10.48550/arXiv.2102.05639", "date": "2021-02-10", "title": "Energy-Harvesting Distributed Machine Learning", "authors": "Basak Guler, Aylin Yener", "abstract": "This paper provides a first study of utilizing energy harvesting for\nsustainable machine learning in distributed networks. We consider a distributed\nlearning setup in which a machine learning model is trained over a large number\nof devices that can harvest energy from the ambient environment, and develop a\npractical learning framework with theoretical convergence guarantees. We\ndemonstrate through numerical experiments that the proposed framework can\nsignificantly outperform energy-agnostic benchmarks. Our framework is scalable,\nrequires only local estimation of the energy statistics, and can be applied to\na wide range of distributed training settings, including machine learning in\nwireless networks, edge computing, and mobile internet of things.", "journal": ""}
{"doi": "10.48550/arXiv.1909.09248", "date": "2019-09-19", "title": "Representation Learning for Electronic Health Records", "authors": "Wei-Hung Weng, Peter Szolovits", "abstract": "Information in electronic health records (EHR), such as clinical narratives,\nexamination reports, lab measurements, demographics, and other patient\nencounter entries, can be transformed into appropriate data representations\nthat can be used for downstream clinical machine learning tasks using\nrepresentation learning. Learning better representations is critical to improve\nthe performance of downstream tasks. Due to the advances in machine learning,\nwe now can learn better and meaningful representations from EHR through\ndisentangling the underlying factors inside data and distilling large amounts\nof information and knowledge from heterogeneous EHR sources. In this chapter,\nwe first introduce the background of learning representations and reasons why\nwe need good EHR representations in machine learning for medicine and\nhealthcare in Section 1. Next, we explain the commonly-used machine learning\nand evaluation methods for representation learning using a deep learning\napproach in Section 2. Following that, we review recent related studies of\nlearning patient state representation from EHR for clinical machine learning\ntasks in Section 3. Finally, in Section 4 we discuss more techniques, studies,\nand challenges for learning natural language representations when free texts,\nsuch as clinical notes, examination reports, or biomedical literature are used.\nWe also discuss challenges and opportunities in these rapidly growing research\nfields.", "journal": ""}
{"doi": "10.48550/arXiv.1810.03548", "date": "2018-10-08", "title": "Meta-Learning: A Survey", "authors": "Joaquin Vanschoren", "abstract": "Meta-learning, or learning to learn, is the science of systematically\nobserving how different machine learning approaches perform on a wide range of\nlearning tasks, and then learning from this experience, or meta-data, to learn\nnew tasks much faster than otherwise possible. Not only does this dramatically\nspeed up and improve the design of machine learning pipelines or neural\narchitectures, it also allows us to replace hand-engineered algorithms with\nnovel approaches learned in a data-driven way. In this chapter, we provide an\noverview of the state of the art in this fascinating and continuously evolving\nfield.", "journal": ""}
{"doi": "10.48550/arXiv.1711.06552", "date": "2017-11-15", "title": "Introduction to intelligent computing unit 1", "authors": "Isa Inuwa-Dutse", "abstract": "This brief note highlights some basic concepts required toward understanding\nthe evolution of machine learning and deep learning models. The note starts\nwith an overview of artificial intelligence and its relationship to biological\nneuron that ultimately led to the evolution of todays intelligent models.", "journal": ""}
{"doi": "10.48550/arXiv.2004.05366", "date": "2020-04-11", "title": "In-Machine-Learning Database: Reimagining Deep Learning with Old-School SQL", "authors": "Len Du", "abstract": "In-database machine learning has been very popular, almost being a cliche.\nHowever, can we do it the other way around? In this work, we say \"yes\" by\napplying plain old SQL to deep learning, in a sense implementing deep learning\nalgorithms with SQL. Most deep learning frameworks, as well as generic machine\nlearning ones, share a de facto standard of multidimensional array operations,\nunderneath fancier infrastructure such as automatic differentiation. As SQL\ntables can be regarded as generalisations of (multi-dimensional) arrays, we\nhave found a way to express common deep learning operations in SQL, encouraging\na different way of thinking and thus potentially novel models. In particular,\none of the latest trend in deep learning was the introduction of sparsity in\nthe name of graph convolutional networks, whereas we take sparsity almost for\ngranted in the database world. As both databases and machine learning involve\ntransformation of datasets, we hope this work can inspire further works\nutilizing the large body of existing wisdom, algorithms and technologies in the\ndatabase field to advance the state of the art in machine learning, rather than\nmerely integerating machine learning into databases.", "journal": ""}
{"doi": "10.48550/arXiv.1807.06722", "date": "2018-07-18", "title": "Machine Learning Interpretability: A Science rather than a tool", "authors": "Abdul Karim, Avinash Mishra, MA Hakim Newton, Abdul Sattar", "abstract": "The term \"interpretability\" is oftenly used by machine learning researchers\neach with their own intuitive understanding of it. There is no universal well\nagreed upon definition of interpretability in machine learning. As any type of\nscience discipline is mainly driven by the set of formulated questions rather\nthan by different tools in that discipline, e.g. astrophysics is the discipline\nthat learns the composition of stars, not as the discipline that use the\nspectroscopes. Similarly, we propose that machine learning interpretability\nshould be a discipline that answers specific questions related to\ninterpretability. These questions can be of statistical, causal and\ncounterfactual nature. Therefore, there is a need to look into the\ninterpretability problem of machine learning in the context of questions that\nneed to be addressed rather than different tools. We discuss about a\nhypothetical interpretability framework driven by a question based scientific\napproach rather than some specific machine learning model. Using a question\nbased notion of interpretability, we can step towards understanding the science\nof machine learning rather than its engineering. This notion will also help us\nunderstanding any specific problem more in depth rather than relying solely on\nmachine learning methods.", "journal": ""}
{"doi": "10.48550/arXiv.2201.06921", "date": "2021-12-13", "title": "Can Machine Learning be Moral?", "authors": "Miguel Sicart, Irina Shklovski, Mirabelle Jones", "abstract": "The ethics of Machine Learning has become an unavoidable topic in the AI\nCommunity. The deployment of machine learning systems in multiple social\ncontexts has resulted in a closer ethical scrutiny of the design, development,\nand application of these systems. The AI/ML community has come to terms with\nthe imperative to think about the ethical implications of machine learning, not\nonly as a product but also as a practice (Birhane, 2021; Shen et al. 2021). The\ncritical question that is troubling many debates is what can constitute an\nethically accountable machine learning system. In this paper we explore\npossibilities for ethical evaluation of machine learning methodologies. We\nscrutinize techniques, methods and technical practices in machine learning from\na relational ethics perspective, taking into consideration how machine learning\nsystems are part of the world and how they relate to different forms of agency.\nTaking a page from Phil Agre (1997) we use the notion of a critical technical\npractice as a means of analysis of machine learning approaches. Our radical\nproposal is that supervised learning appears to be the only machine learning\nmethod that is ethically defensible.", "journal": ""}
{"doi": "10.48550/arXiv.2103.00742", "date": "2021-03-01", "title": "Automated Machine Learning on Graphs: A Survey", "authors": "Ziwei Zhang, Xin Wang, Wenwu Zhu", "abstract": "Machine learning on graphs has been extensively studied in both academic and\nindustry. However, as the literature on graph learning booms with a vast number\nof emerging methods and techniques, it becomes increasingly difficult to\nmanually design the optimal machine learning algorithm for different\ngraph-related tasks. To solve this critical challenge, automated machine\nlearning (AutoML) on graphs which combines the strength of graph machine\nlearning and AutoML together, is gaining attention from the research community.\nTherefore, we comprehensively survey AutoML on graphs in this paper, primarily\nfocusing on hyper-parameter optimization (HPO) and neural architecture search\n(NAS) for graph machine learning. We further overview libraries related to\nautomated graph machine learning and in-depth discuss AutoGL, the first\ndedicated open-source library for AutoML on graphs. In the end, we share our\ninsights on future research directions for automated graph machine learning.\nThis paper is the first systematic and comprehensive review of automated\nmachine learning on graphs to the best of our knowledge.", "journal": ""}
{"doi": "10.48550/arXiv.1812.01410", "date": "2018-12-04", "title": "Compressive Classification (Machine Learning without learning)", "authors": "Vincent Schellekens, Laurent Jacques", "abstract": "Compressive learning is a framework where (so far unsupervised) learning\ntasks use not the entire dataset but a compressed summary (sketch) of it. We\npropose a compressive learning classification method, and a novel sketch\nfunction for images.", "journal": ""}
{"doi": "10.48550/arXiv.1707.03184", "date": "2017-07-11", "title": "A Survey on Resilient Machine Learning", "authors": "Atul Kumar, Sameep Mehta", "abstract": "Machine learning based system are increasingly being used for sensitive tasks\nsuch as security surveillance, guiding autonomous vehicle, taking investment\ndecisions, detecting and blocking network intrusion and malware etc. However,\nrecent research has shown that machine learning models are venerable to attacks\nby adversaries at all phases of machine learning (eg, training data collection,\ntraining, operation). All model classes of machine learning systems can be\nmisled by providing carefully crafted inputs making them wrongly classify\ninputs. Maliciously created input samples can affect the learning process of a\nML system by either slowing down the learning process, or affecting the\nperformance of the learned mode, or causing the system make error(s) only in\nattacker's planned scenario. Because of these developments, understanding\nsecurity of machine learning algorithms and systems is emerging as an important\nresearch area among computer security and machine learning researchers and\npractitioners. We present a survey of this emerging area in machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.1611.03969", "date": "2016-11-12", "title": "An Introduction to MM Algorithms for Machine Learning and Statistical", "authors": "Hien D. Nguyen", "abstract": "MM (majorization--minimization) algorithms are an increasingly popular tool\nfor solving optimization problems in machine learning and statistical\nestimation. This article introduces the MM algorithm framework in general and\nvia three popular example applications: Gaussian mixture regressions,\nmultinomial logistic regressions, and support vector machines. Specific\nalgorithms for the three examples are derived and numerical demonstrations are\npresented. Theoretical and practical aspects of MM algorithm design are\ndiscussed.", "journal": ""}
{"doi": "10.48550/arXiv.1810.11383", "date": "2018-10-25", "title": "Some Requests for Machine Learning Research from the East African Tech Scene", "authors": "Milan Cvitkovic", "abstract": "Based on 46 in-depth interviews with scientists, engineers, and CEOs, this\ndocument presents a list of concrete machine research problems, progress on\nwhich would directly benefit tech ventures in East Africa.", "journal": ""}
{"doi": "10.48550/arXiv.2104.05314", "date": "2021-04-12", "title": "Machine learning and deep learning", "authors": "Christian Janiesch, Patrick Zschech, Kai Heinrich", "abstract": "Today, intelligent systems that offer artificial intelligence capabilities\noften rely on machine learning. Machine learning describes the capacity of\nsystems to learn from problem-specific training data to automate the process of\nanalytical model building and solve associated tasks. Deep learning is a\nmachine learning concept based on artificial neural networks. For many\napplications, deep learning models outperform shallow machine learning models\nand traditional data analysis approaches. In this article, we summarize the\nfundamentals of machine learning and deep learning to generate a broader\nunderstanding of the methodical underpinning of current intelligent systems. In\nparticular, we provide a conceptual distinction between relevant terms and\nconcepts, explain the process of automated analytical model building through\nmachine learning and deep learning, and discuss the challenges that arise when\nimplementing such intelligent systems in the field of electronic markets and\nnetworked business. These naturally go beyond technological aspects and\nhighlight issues in human-machine interaction and artificial intelligence\nservitization.", "journal": ""}
{"doi": "10.48550/arXiv.1612.04251", "date": "2016-12-13", "title": "TF.Learn: TensorFlow's High-level Module for Distributed Machine Learning", "authors": "Yuan Tang", "abstract": "TF.Learn is a high-level Python module for distributed machine learning\ninside TensorFlow. It provides an easy-to-use Scikit-learn style interface to\nsimplify the process of creating, configuring, training, evaluating, and\nexperimenting a machine learning model. TF.Learn integrates a wide range of\nstate-of-art machine learning algorithms built on top of TensorFlow's low level\nAPIs for small to large-scale supervised and unsupervised problems. This module\nfocuses on bringing machine learning to non-specialists using a general-purpose\nhigh-level language as well as researchers who want to implement, benchmark,\nand compare their new methods in a structured environment. Emphasis is put on\nease of use, performance, documentation, and API consistency.", "journal": ""}
{"doi": "10.48550/arXiv.1908.00868", "date": "2019-08-02", "title": "Machine Learning as Ecology", "authors": "Owen Howell, Cui Wenping, Robert Marsland III, Pankaj Mehta", "abstract": "Machine learning methods have had spectacular success on numerous problems.\nHere we show that a prominent class of learning algorithms - including Support\nVector Machines (SVMs) -- have a natural interpretation in terms of ecological\ndynamics. We use these ideas to design new online SVM algorithms that exploit\necological invasions, and benchmark performance using the MNIST dataset. Our\nwork provides a new ecological lens through which we can view statistical\nlearning and opens the possibility of designing ecosystems for machine\nlearning.\n  Supplemental code is found at https://github.com/owenhowell20/EcoSVM.", "journal": ""}
{"doi": "10.48550/arXiv.1910.02544", "date": "2019-10-06", "title": "Using Deep Learning and Machine Learning to Detect Epileptic Seizure with Electroencephalography (EEG) Data", "authors": "Haotian Liu, Lin Xi, Ying Zhao, Zhixiang Li", "abstract": "The prediction of epileptic seizure has always been extremely challenging in\nmedical domain. However, as the development of computer technology, the\napplication of machine learning introduced new ideas for seizure forecasting.\nApplying machine learning model onto the predication of epileptic seizure could\nhelp us obtain a better result and there have been plenty of scientists who\nhave been doing such works so that there are sufficient medical data provided\nfor researchers to do training of machine learning models.", "journal": ""}
{"doi": "10.48550/arXiv.1405.1304", "date": "2014-05-03", "title": "Application of Machine Learning Techniques in Aquaculture", "authors": "Akhlaqur Rahman, Sumaira Tasnim", "abstract": "In this paper we present applications of different machine learning\nalgorithms in aquaculture. Machine learning algorithms learn models from\nhistorical data. In aquaculture historical data are obtained from farm\npractices, yields, and environmental data sources. Associations between these\ndifferent variables can be obtained by applying machine learning algorithms to\nhistorical data. In this paper we present applications of different machine\nlearning algorithms in aquaculture applications.", "journal": "International Journal of Computer Trends and Technology (IJCTT)\n  V10(3):214-215 Apr 2014. ISSN:2231-2803"}
{"doi": "10.48550/arXiv.2001.11489", "date": "2019-11-18", "title": "Machine Learning in Network Security Using KNIME Analytics", "authors": "Munther Abualkibash", "abstract": "Machine learning has more and more effect on our every day's life. This field\nkeeps growing and expanding into new areas. Machine learning is based on the\nimplementation of artificial intelligence that gives systems the capability to\nautomatically learn and enhance from experiments without being explicitly\nprogrammed. Machine Learning algorithms apply mathematical equations to analyze\ndatasets and predict values based on the dataset. In the field of\ncybersecurity, machine learning algorithms can be utilized to train and analyze\nthe Intrusion Detection Systems (IDSs) on security-related datasets. In this\npaper, we tested different machine learning algorithms to analyze NSL-KDD\ndataset using KNIME analytics.", "journal": ""}
{"doi": "10.48550/arXiv.2103.11249", "date": "2021-03-20", "title": "SELM: Software Engineering of Machine Learning Models", "authors": "Nafiseh Jafari, Mohammad Reza Besharati, Mohammad Izadi, Maryam Hourali", "abstract": "One of the pillars of any machine learning model is its concepts. Using\nsoftware engineering, we can engineer these concepts and then develop and\nexpand them. In this article, we present a SELM framework for Software\nEngineering of machine Learning Models. We then evaluate this framework through\na case study. Using the SELM framework, we can improve a machine learning\nprocess efficiency and provide more accuracy in learning with less processing\nhardware resources and a smaller training dataset. This issue highlights the\nimportance of an interdisciplinary approach to machine learning. Therefore, in\nthis article, we have provided interdisciplinary teams' proposals for machine\nlearning.", "journal": ""}
{"doi": "10.48550/arXiv.2303.09491", "date": "2023-03-16", "title": "Challenges and Opportunities in Quantum Machine Learning", "authors": "M. Cerezo, Guillaume Verdon, Hsin-Yuan Huang, Lukasz Cincio, Patrick J. Coles", "abstract": "At the intersection of machine learning and quantum computing, Quantum\nMachine Learning (QML) has the potential of accelerating data analysis,\nespecially for quantum data, with applications for quantum materials,\nbiochemistry, and high-energy physics. Nevertheless, challenges remain\nregarding the trainability of QML models. Here we review current methods and\napplications for QML. We highlight differences between quantum and classical\nmachine learning, with a focus on quantum neural networks and quantum deep\nlearning. Finally, we discuss opportunities for quantum advantage with QML.", "journal": "Nature Computational Science 2, 567-576 (2022)"}
{"doi": "10.48550/arXiv.2407.05520", "date": "2024-07-07", "title": "A Theory of Machine Learning", "authors": "Jinsook Kim, Jinho Kang", "abstract": "We critically review three major theories of machine learning and provide a\nnew theory according to which machines learn a function when the machines\nsuccessfully compute it. We show that this theory challenges common assumptions\nin the statistical and the computational learning theories, for it implies that\nlearning true probabilities is equivalent neither to obtaining a correct\ncalculation of the true probabilities nor to obtaining an almost-sure\nconvergence to them. We also briefly discuss some case studies from natural\nlanguage processing and macroeconomics from the perspective of the new theory.", "journal": ""}
{"doi": "10.48550/arXiv.1605.07805", "date": "2016-05-25", "title": "Learning Moore Machines from Input-Output Traces", "authors": "Georgios Giantamidis, Stavros Tripakis", "abstract": "The problem of learning automata from example traces (but no equivalence or\nmembership queries) is fundamental in automata learning theory and practice. In\nthis paper we study this problem for finite state machines with inputs and\noutputs, and in particular for Moore machines. We develop three algorithms for\nsolving this problem: (1) the PTAP algorithm, which transforms a set of\ninput-output traces into an incomplete Moore machine and then completes the\nmachine with self-loops; (2) the PRPNI algorithm, which uses the well-known\nRPNI algorithm for automata learning to learn a product of automata encoding a\nMoore machine; and (3) the MooreMI algorithm, which directly learns a Moore\nmachine using PTAP extended with state merging. We prove that MooreMI has the\nfundamental identification in the limit property. We also compare the\nalgorithms experimentally in terms of the size of the learned machine and\nseveral notions of accuracy, introduced in this paper. Finally, we compare with\nOSTIA, an algorithm that learns a more general class of transducers, and find\nthat OSTIA generally does not learn a Moore machine, even when fed with a\ncharacteristic sample.", "journal": ""}
{"doi": "10.48550/arXiv.2006.15680", "date": "2020-06-28", "title": "Modeling Generalization in Machine Learning: A Methodological and Computational Study", "authors": "Pietro Barbiero, Giovanni Squillero, Alberto Tonda", "abstract": "As machine learning becomes more and more available to the general public,\ntheoretical questions are turning into pressing practical issues. Possibly, one\nof the most relevant concerns is the assessment of our confidence in trusting\nmachine learning predictions. In many real-world cases, it is of utmost\nimportance to estimate the capabilities of a machine learning algorithm to\ngeneralize, i.e., to provide accurate predictions on unseen data, depending on\nthe characteristics of the target problem. In this work, we perform a\nmeta-analysis of 109 publicly-available classification data sets, modeling\nmachine learning generalization as a function of a variety of data set\ncharacteristics, ranging from number of samples to intrinsic dimensionality,\nfrom class-wise feature skewness to $F1$ evaluated on test samples falling\noutside the convex hull of the training set. Experimental results demonstrate\nthe relevance of using the concept of the convex hull of the training data in\nassessing machine learning generalization, by emphasizing the difference\nbetween interpolated and extrapolated predictions. Besides several predictable\ncorrelations, we observe unexpectedly weak associations between the\ngeneralization ability of machine learning models and all metrics related to\ndimensionality, thus challenging the common assumption that the \\textit{curse\nof dimensionality} might impair generalization in machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.2003.10146", "date": "2020-03-23", "title": "Julia Language in Machine Learning: Algorithms, Applications, and Open Issues", "authors": "Kaifeng Gao, Gang Mei, Francesco Piccialli, Salvatore Cuomo, Jingzhi Tu, Zenan Huo", "abstract": "Machine learning is driving development across many fields in science and\nengineering. A simple and efficient programming language could accelerate\napplications of machine learning in various fields. Currently, the programming\nlanguages most commonly used to develop machine learning algorithms include\nPython, MATLAB, and C/C ++. However, none of these languages well balance both\nefficiency and simplicity. The Julia language is a fast, easy-to-use, and\nopen-source programming language that was originally designed for\nhigh-performance computing, which can well balance the efficiency and\nsimplicity. This paper summarizes the related research work and developments in\nthe application of the Julia language in machine learning. It first surveys the\npopular machine learning algorithms that are developed in the Julia language.\nThen, it investigates applications of the machine learning algorithms\nimplemented with the Julia language. Finally, it discusses the open issues and\nthe potential future directions that arise in the use of the Julia language in\nmachine learning.", "journal": "Computer Science Review, Volume 37, 2020, 100254"}
{"doi": "10.48550/arXiv.2105.03726", "date": "2021-05-08", "title": "Mental Models of Adversarial Machine Learning", "authors": "Lukas Bieringer, Kathrin Grosse, Michael Backes, Battista Biggio, Katharina Krombholz", "abstract": "Although machine learning is widely used in practice, little is known about\npractitioners' understanding of potential security challenges. In this work, we\nclose this substantial gap and contribute a qualitative study focusing on\ndevelopers' mental models of the machine learning pipeline and potentially\nvulnerable components. Similar studies have helped in other security fields to\ndiscover root causes or improve risk communication. Our study reveals two\n\\facets of practitioners' mental models of machine learning security. Firstly,\npractitioners often confuse machine learning security with threats and defences\nthat are not directly related to machine learning. Secondly, in contrast to\nmost academic research, our participants perceive security of machine learning\nas not solely related to individual models, but rather in the context of entire\nworkflows that consist of multiple components. Jointly with our additional\nfindings, these two facets provide a foundation to substantiate mental models\nfor machine learning security and have implications for the integration of\nadversarial machine learning into corporate workflows, \\new{decreasing\npractitioners' reported uncertainty}, and appropriate regulatory frameworks for\nmachine learning security.", "journal": ""}
{"doi": "10.48550/arXiv.1803.10311", "date": "2018-03-27", "title": "How Developers Iterate on Machine Learning Workflows -- A Survey of the Applied Machine Learning Literature", "authors": "Doris Xin, Litian Ma, Shuchen Song, Aditya Parameswaran", "abstract": "Machine learning workflow development is anecdotally regarded to be an\niterative process of trial-and-error with humans-in-the-loop. However, we are\nnot aware of quantitative evidence corroborating this popular belief. A\nquantitative characterization of iteration can serve as a benchmark for machine\nlearning workflow development in practice, and can aid the development of\nhuman-in-the-loop machine learning systems. To this end, we conduct a\nsmall-scale survey of the applied machine learning literature from five\ndistinct application domains. We collect and distill statistics on the role of\niteration within machine learning workflow development, and report preliminary\ntrends and insights from our investigation, as a starting point towards this\nbenchmark. Based on our findings, we finally describe desiderata for effective\nand versatile human-in-the-loop machine learning systems that can cater to\nusers in diverse domains.", "journal": ""}
{"doi": "10.48550/arXiv.1912.09630", "date": "2019-12-20", "title": "Practical Solutions for Machine Learning Safety in Autonomous Vehicles", "authors": "Sina Mohseni, Mandar Pitale, Vasu Singh, Zhangyang Wang", "abstract": "Autonomous vehicles rely on machine learning to solve challenging tasks in\nperception and motion planning. However, automotive software safety standards\nhave not fully evolved to address the challenges of machine learning safety\nsuch as interpretability, verification, and performance limitations. In this\npaper, we review and organize practical machine learning safety techniques that\ncan complement engineering safety for machine learning based software in\nautonomous vehicles. Our organization maps safety strategies to\nstate-of-the-art machine learning techniques in order to enhance dependability\nand safety of machine learning algorithms. We also discuss security limitations\nand user experience aspects of machine learning components in autonomous\nvehicles.", "journal": ""}
{"doi": "10.48550/arXiv.2209.02057", "date": "2022-09-05", "title": "Applying Machine Learning to Life Insurance: some knowledge sharing to master it", "authors": "Antoine Chancel, Laura Bradier, Antoine Ly, Razvan Ionescu, Laurene Martin, Marguerite Sauce", "abstract": "Machine Learning permeates many industries, which brings new source of\nbenefits for companies. However within the life insurance industry, Machine\nLearning is not widely used in practice as over the past years statistical\nmodels have shown their efficiency for risk assessment. Thus insurers may face\ndifficulties to assess the value of the artificial intelligence. Focusing on\nthe modification of the life insurance industry over time highlights the stake\nof using Machine Learning for insurers and benefits that it can bring by\nunleashing data value. This paper reviews traditional actuarial methodologies\nfor survival modeling and extends them with Machine Learning techniques. It\npoints out differences with regular machine learning models and emphasizes\nimportance of specific implementations to face censored data with machine\nlearning models family. In complement to this article, a Python library has\nbeen developed. Different open-source Machine Learning algorithms have been\nadjusted to adapt the specificities of life insurance data, namely censoring\nand truncation. Such models can be easily applied from this SCOR library to\naccurately model life insurance risks.", "journal": ""}
{"doi": "10.48550/arXiv.2312.14050", "date": "2023-12-21", "title": "Machine learning and domain decomposition methods -- a survey", "authors": "Axel Klawonn, Martin Lanser, Janine Weber", "abstract": "Hybrid algorithms, which combine black-box machine learning methods with\nexperience from traditional numerical methods and domain expertise from diverse\napplication areas, are progressively gaining importance in scientific machine\nlearning and various industrial domains, especially in computational science\nand engineering. In the present survey, several promising avenues of research\nwill be examined which focus on the combination of machine learning (ML) and\ndomain decomposition methods (DDMs). The aim of this survey is to provide an\noverview of existing work within this field and to structure it into domain\ndecomposition for machine learning and machine learning-enhanced domain\ndecomposition, including: domain decomposition for classical machine learning,\ndomain decomposition to accelerate the training of physics-aware neural\nnetworks, machine learning to enhance the convergence properties or\ncomputational efficiency of DDMs, and machine learning as a discretization\nmethod in a DDM for the solution of PDEs. In each of these fields, we summarize\nexisting work and key advances within a common framework and, finally, disuss\nongoing challenges and opportunities for future research.", "journal": ""}
{"doi": "10.48550/arXiv.2409.03632", "date": "2024-09-05", "title": "Beyond Model Interpretability: Socio-Structural Explanations in Machine Learning", "authors": "Andrew Smart, Atoosa Kasirzadeh", "abstract": "What is it to interpret the outputs of an opaque machine learning model. One\napproach is to develop interpretable machine learning techniques. These\ntechniques aim to show how machine learning models function by providing either\nmodel centric local or global explanations, which can be based on mechanistic\ninterpretations revealing the inner working mechanisms of models or\nnonmechanistic approximations showing input feature output data relationships.\nIn this paper, we draw on social philosophy to argue that interpreting machine\nlearning outputs in certain normatively salient domains could require appealing\nto a third type of explanation that we call sociostructural explanation. The\nrelevance of this explanation type is motivated by the fact that machine\nlearning models are not isolated entities but are embedded within and shaped by\nsocial structures. Sociostructural explanations aim to illustrate how social\nstructures contribute to and partially explain the outputs of machine learning\nmodels. We demonstrate the importance of sociostructural explanations by\nexamining a racially biased healthcare allocation algorithm. Our proposal\nhighlights the need for transparency beyond model interpretability,\nunderstanding the outputs of machine learning systems could require a broader\nanalysis that extends beyond the understanding of the machine learning model\nitself.", "journal": "AI & Soc (2024)."}
{"doi": "10.48550/arXiv.2502.01708", "date": "2025-02-03", "title": "Aspects of Artificial Intelligence: Transforming Machine Learning Systems Naturally", "authors": "Xiuzhan Guo", "abstract": "In this paper, we study the machine learning elements which we are interested\nin together as a machine learning system, consisting of a collection of machine\nlearning elements and a collection of relations between the elements. The\nrelations we concern are algebraic operations, binary relations, and binary\nrelations with composition that can be reasoned categorically. A machine\nlearning system transformation between two systems is a map between the\nsystems, which preserves the relations we concern. The system transformations\ngiven by quotient or clustering, representable functor, and Yoneda embedding\nare highlighted and discussed by machine learning examples. An adjunction\nbetween machine learning systems, a special machine learning system\ntransformation loop, provides the optimal way of solving problems. Machine\nlearning system transformations are linked and compared by their maps at\n2-cell, natural transformations. New insights and structures can be obtained\nfrom universal properties and algebraic structures given by monads, which are\ngenerated from adjunctions.", "journal": ""}
{"doi": "10.48550/arXiv.1902.04622", "date": "2019-02-12", "title": "Learning Theory and Support Vector Machines - a primer", "authors": "Michael Banf", "abstract": "The main goal of statistical learning theory is to provide a fundamental\nframework for the problem of decision making and model construction based on\nsets of data. Here, we present a brief introduction to the fundamentals of\nstatistical learning theory, in particular the difference between empirical and\nstructural risk minimization, including one of its most prominent\nimplementations, i.e. the Support Vector Machine.", "journal": ""}
{"doi": "10.48550/arXiv.1907.03010", "date": "2019-07-03", "title": "Financial Time Series Data Processing for Machine Learning", "authors": "Fabrice Daniel", "abstract": "This article studies the financial time series data processing for machine\nlearning. It introduces the most frequent scaling methods, then compares the\nresulting stationarity and preservation of useful information for trend\nforecasting. It proposes an empirical test based on the capability to learn\nsimple data relationship with simple models. It also speaks about the data\nsplit method specific to time series, avoiding unwanted overfitting and\nproposes various labelling for classification and regression.", "journal": ""}
{"doi": "10.48550/arXiv.2103.03122", "date": "2021-03-03", "title": "Machine Learning using Stata/Python", "authors": "Giovanni Cerulli", "abstract": "We present two related Stata modules, r_ml_stata and c_ml_stata, for fitting\npopular Machine Learning (ML) methods both in regression and classification\nsettings. Using the recent Stata/Python integration platform (sfi) of Stata 16,\nthese commands provide hyper-parameters' optimal tuning via K-fold\ncross-validation using greed search. More specifically, they make use of the\nPython Scikit-learn API to carry out both cross-validation and outcome/label\nprediction.", "journal": ""}
{"doi": "10.48550/arXiv.2206.13446", "date": "2022-06-27", "title": "Pen and Paper Exercises in Machine Learning", "authors": "Michael U. Gutmann", "abstract": "This is a collection of (mostly) pen-and-paper exercises in machine learning.\nThe exercises are on the following topics: linear algebra, optimisation,\ndirected graphical models, undirected graphical models, expressive power of\ngraphical models, factor graphs and message passing, inference for hidden\nMarkov models, model-based learning (including ICA and unnormalised models),\nsampling and Monte-Carlo integration, and variational inference.", "journal": ""}
{"doi": "10.48550/arXiv.2310.11470", "date": "2023-05-24", "title": "Classic machine learning methods", "authors": "Johann Faouzi, Olivier Colliot", "abstract": "In this chapter, we present the main classic machine learning methods. A\nlarge part of the chapter is devoted to supervised learning techniques for\nclassification and regression, including nearest-neighbor methods, linear and\nlogistic regressions, support vector machines and tree-based algorithms. We\nalso describe the problem of overfitting as well as strategies to overcome it.\nWe finally provide a brief overview of unsupervised learning methods, namely\nfor clustering and dimensionality reduction.", "journal": ""}
{"doi": "10.48550/arXiv.1501.04309", "date": "2015-01-18", "title": "Information Theory and its Relation to Machine Learning", "authors": "Bao-Gang Hu", "abstract": "In this position paper, I first describe a new perspective on machine\nlearning (ML) by four basic problems (or levels), namely, \"What to learn?\",\n\"How to learn?\", \"What to evaluate?\", and \"What to adjust?\". The paper stresses\nmore on the first level of \"What to learn?\", or \"Learning Target Selection\".\nTowards this primary problem within the four levels, I briefly review the\nexisting studies about the connection between information theoretical learning\n(ITL [1]) and machine learning. A theorem is given on the relation between the\nempirically-defined similarity measure and information measures. Finally, a\nconjecture is proposed for pursuing a unified mathematical interpretation to\nlearning target selection.", "journal": ""}
{"doi": "10.48550/arXiv.1602.00198", "date": "2016-01-31", "title": "Discussion on Mechanical Learning and Learning Machine", "authors": "Chuyu Xiong", "abstract": "Mechanical learning is a computing system that is based on a set of simple\nand fixed rules, and can learn from incoming data. A learning machine is a\nsystem that realizes mechanical learning. Importantly, we emphasis that it is\nbased on a set of simple and fixed rules, contrasting to often called machine\nlearning that is sophisticated software based on very complicated mathematical\ntheory, and often needs human intervene for software fine tune and manual\nadjustments. Here, we discuss some basic facts and principles of such system,\nand try to lay down a framework for further study. We propose 2 directions to\napproach mechanical learning, just like Church-Turing pair: one is trying to\nrealize a learning machine, another is trying to well describe the mechanical\nlearning.", "journal": ""}
{"doi": "10.48550/arXiv.1908.01262", "date": "2019-08-04", "title": "A systematic review of fuzzing based on machine learning techniques", "authors": "Yan Wang, Peng Jia, Luping Liu, Jiayong Liu", "abstract": "Security vulnerabilities play a vital role in network security system.\nFuzzing technology is widely used as a vulnerability discovery technology to\nreduce damage in advance. However, traditional fuzzing techniques have many\nchallenges, such as how to mutate input seed files, how to increase code\ncoverage, and how to effectively bypass verification. Machine learning\ntechnology has been introduced as a new method into fuzzing test to alleviate\nthese challenges. This paper reviews the research progress of using machine\nlearning technology for fuzzing test in recent years, analyzes how machine\nlearning improve the fuzz process and results, and sheds light on future work\nin fuzzing. Firstly, this paper discusses the reasons why machine learning\ntechniques can be used for fuzzing scenarios and identifies six different\nstages in which machine learning have been used. Then this paper systematically\nstudy the machine learning based fuzzing models from selection of machine\nlearning algorithm, pre-processing methods, datasets, evaluation metrics, and\nhyperparameters setting. Next, this paper assesses the performance of the\nmachine learning models based on the frequently used evaluation metrics. The\nresults of the evaluation prove that machine learning technology has an\nacceptable capability of categorize predictive for fuzzing. Finally, the\ncomparison on capability of discovering vulnerabilities between traditional\nfuzzing tools and machine learning based fuzzing tools is analyzed. The results\ndepict that the introduction of machine learning technology can improve the\nperformance of fuzzing. However, there are still some limitations, such as\nunbalanced training samples and difficult to extract the characteristics\nrelated to vulnerabilities.", "journal": ""}
{"doi": "10.48550/arXiv.2011.03733", "date": "2020-11-07", "title": "Human-Like Active Learning: Machines Simulating the Human Learning Process", "authors": "Jaeseo Lim, Hwiyeol Jo, Byoung-Tak Zhang, Jooyong Park", "abstract": "Although the use of active learning to increase learners' engagement has\nrecently been introduced in a variety of methods, empirical experiments are\nlacking. In this study, we attempted to align two experiments in order to (1)\nmake a hypothesis for machine and (2) empirically confirm the effect of active\nlearning on learning. In Experiment 1, we compared the effect of a passive form\nof learning to active form of learning. The results showed that active learning\nhad a greater learning outcomes than passive learning. In the machine\nexperiment based on the human result, we imitated the human active learning as\na form of knowledge distillation. The active learning framework performed\nbetter than the passive learning framework. In the end, we showed not only that\nwe can make build better machine training framework through the human\nexperiment result, but also empirically confirm the result of human experiment\nthrough imitated machine experiments; human-like active learning have crucial\neffect on learning performance.", "journal": ""}
{"doi": "10.48550/arXiv.2304.01316", "date": "2023-04-03", "title": "Matched Machine Learning: A Generalized Framework for Treatment Effect Inference With Learned Metrics", "authors": "Marco Morucci, Cynthia Rudin, Alexander Volfovsky", "abstract": "We introduce Matched Machine Learning, a framework that combines the\nflexibility of machine learning black boxes with the interpretability of\nmatching, a longstanding tool in observational causal inference.\nInterpretability is paramount in many high-stakes application of causal\ninference. Current tools for nonparametric estimation of both average and\nindividualized treatment effects are black-boxes that do not allow for human\nauditing of estimates. Our framework uses machine learning to learn an optimal\nmetric for matching units and estimating outcomes, thus achieving the\nperformance of machine learning black-boxes, while being interpretable. Our\ngeneral framework encompasses several published works as special cases. We\nprovide asymptotic inference theory for our proposed framework, enabling users\nto construct approximate confidence intervals around estimates of both\nindividualized and average treatment effects. We show empirically that\ninstances of Matched Machine Learning perform on par with black-box machine\nlearning methods and better than existing matching methods for similar\nproblems. Finally, in our application we show how Matched Machine Learning can\nbe used to perform causal inference even when covariate data are highly\ncomplex: we study an image dataset, and produce high quality matches and\nestimates of treatment effects.", "journal": ""}
{"doi": "10.48550/arXiv.1610.08251", "date": "2016-10-26", "title": "Quantum-enhanced machine learning", "authors": "Vedran Dunjko, Jacob M. Taylor, Hans J. Briegel", "abstract": "The emerging field of quantum machine learning has the potential to\nsubstantially aid in the problems and scope of artificial intelligence. This is\nonly enhanced by recent successes in the field of classical machine learning.\nIn this work we propose an approach for the systematic treatment of machine\nlearning, from the perspective of quantum information. Our approach is general\nand covers all three main branches of machine learning: supervised,\nunsupervised and reinforcement learning. While quantum improvements in\nsupervised and unsupervised learning have been reported, reinforcement learning\nhas received much less attention. Within our approach, we tackle the problem of\nquantum enhancements in reinforcement learning as well, and propose a\nsystematic scheme for providing improvements. As an example, we show that\nquadratic improvements in learning efficiency, and exponential improvements in\nperformance over limited time periods, can be obtained for a broad class of\nlearning problems.", "journal": "Phys. Rev. Lett. 117, 130501 (2016)"}
{"doi": "10.48550/arXiv.1302.0406", "date": "2013-02-02", "title": "Generalization Guarantees for a Binary Classification Framework for Two-Stage Multiple Kernel Learning", "authors": "Purushottam Kar", "abstract": "We present generalization bounds for the TS-MKL framework for two stage\nmultiple kernel learning. We also present bounds for sparse kernel learning\nformulations within the TS-MKL framework.", "journal": ""}
{"doi": "10.48550/arXiv.2009.06410", "date": "2020-09-09", "title": "Beneficial and Harmful Explanatory Machine Learning", "authors": "Lun Ai, Stephen H. Muggleton, C\u00e9line Hocquette, Mark Gromowski, Ute Schmid", "abstract": "Given the recent successes of Deep Learning in AI there has been increased\ninterest in the role and need for explanations in machine learned theories. A\ndistinct notion in this context is that of Michie's definition of Ultra-Strong\nMachine Learning (USML). USML is demonstrated by a measurable increase in human\nperformance of a task following provision to the human of a symbolic machine\nlearned theory for task performance. A recent paper demonstrates the beneficial\neffect of a machine learned logic theory for a classification task, yet no\nexisting work to our knowledge has examined the potential harmfulness of\nmachine's involvement for human comprehension during learning. This paper\ninvestigates the explanatory effects of a machine learned theory in the context\nof simple two person games and proposes a framework for identifying the\nharmfulness of machine explanations based on the Cognitive Science literature.\nThe approach involves a cognitive window consisting of two quantifiable bounds\nand it is supported by empirical evidence collected from human trials. Our\nquantitative and qualitative results indicate that human learning aided by a\nsymbolic machine learned theory which satisfies a cognitive window has achieved\nsignificantly higher performance than human self learning. Results also\ndemonstrate that human learning aided by a symbolic machine learned theory that\nfails to satisfy this window leads to significantly worse performance than\nunaided human learning.", "journal": ""}
{"doi": "10.48550/arXiv.1708.07826", "date": "2017-08-24", "title": "Logistic Regression as Soft Perceptron Learning", "authors": "Raul Rojas", "abstract": "We comment on the fact that gradient ascent for logistic regression has a\nconnection with the perceptron learning algorithm. Logistic learning is the\n\"soft\" variant of perceptron learning.", "journal": ""}
{"doi": "10.48550/arXiv.2106.03015", "date": "2021-06-06", "title": "Learning proofs for the classification of nilpotent semigroups", "authors": "Carlos Simpson", "abstract": "Machine learning is applied to find proofs, with smaller or smallest numbers\nof nodes, for the classification of 4-nilpotent semigroups.", "journal": ""}
{"doi": "10.48550/arXiv.2106.09756", "date": "2021-06-17", "title": "PyKale: Knowledge-Aware Machine Learning from Multiple Sources in Python", "authors": "Haiping Lu, Xianyuan Liu, Robert Turner, Peizhen Bai, Raivo E Koot, Shuo Zhou, Mustafa Chasmai, Lawrence Schobs", "abstract": "Machine learning is a general-purpose technology holding promises for many\ninterdisciplinary research problems. However, significant barriers exist in\ncrossing disciplinary boundaries when most machine learning tools are developed\nin different areas separately. We present Pykale - a Python library for\nknowledge-aware machine learning on graphs, images, texts, and videos to enable\nand accelerate interdisciplinary research. We formulate new green machine\nlearning guidelines based on standard software engineering practices and\npropose a novel pipeline-based application programming interface (API). PyKale\nfocuses on leveraging knowledge from multiple sources for accurate and\ninterpretable prediction, thus supporting multimodal learning and transfer\nlearning (particularly domain adaptation) with latest deep learning and\ndimensionality reduction models. We build PyKale on PyTorch and leverage the\nrich PyTorch ecosystem. Our pipeline-based API design enforces standardization\nand minimalism, embracing green machine learning concepts via reducing\nrepetitions and redundancy, reusing existing resources, and recycling learning\nmodels across areas. We demonstrate its interdisciplinary nature via examples\nin bioinformatics, knowledge graph, image/video recognition, and medical\nimaging.", "journal": ""}
{"doi": "10.48550/arXiv.1904.03259", "date": "2019-04-05", "title": "Is 'Unsupervised Learning' a Misconceived Term?", "authors": "Stephen G. Odaibo", "abstract": "Is all of machine learning supervised to some degree? The field of machine\nlearning has traditionally been categorized pedagogically into\n$supervised~vs~unsupervised~learning$; where supervised learning has typically\nreferred to learning from labeled data, while unsupervised learning has\ntypically referred to learning from unlabeled data. In this paper, we assert\nthat all machine learning is in fact supervised to some degree, and that the\nscope of supervision is necessarily commensurate to the scope of learning\npotential. In particular, we argue that clustering algorithms such as k-means,\nand dimensionality reduction algorithms such as principal component analysis,\nvariational autoencoders, and deep belief networks are each internally\nsupervised by the data itself to learn their respective representations of its\nfeatures. Furthermore, these algorithms are not capable of external inference\nuntil their respective outputs (clusters, principal components, or\nrepresentation codes) have been identified and externally labeled in effect. As\nsuch, they do not suffice as examples of unsupervised learning. We propose that\nthe categorization `supervised vs unsupervised learning' be dispensed with, and\ninstead, learning algorithms be categorized as either\n$internally~or~externally~supervised$ (or both). We believe this change in\nperspective will yield new fundamental insights into the structure and\ncharacter of data and of learning algorithms.", "journal": ""}
{"doi": "10.48550/arXiv.1612.07640", "date": "2016-12-16", "title": "Deep Learning and Its Applications to Machine Health Monitoring: A Survey", "authors": "Rui Zhao, Ruqiang Yan, Zhenghua Chen, Kezhi Mao, Peng Wang, Robert X. Gao", "abstract": "Since 2006, deep learning (DL) has become a rapidly growing research\ndirection, redefining state-of-the-art performances in a wide range of areas\nsuch as object recognition, image segmentation, speech recognition and machine\ntranslation. In modern manufacturing systems, data-driven machine health\nmonitoring is gaining in popularity due to the widespread deployment of\nlow-cost sensors and their connection to the Internet. Meanwhile, deep learning\nprovides useful tools for processing and analyzing these big machinery data.\nThe main purpose of this paper is to review and summarize the emerging research\nwork of deep learning on machine health monitoring. After the brief\nintroduction of deep learning techniques, the applications of deep learning in\nmachine health monitoring systems are reviewed mainly from the following\naspects: Auto-encoder (AE) and its variants, Restricted Boltzmann Machines and\nits variants including Deep Belief Network (DBN) and Deep Boltzmann Machines\n(DBM), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN).\nFinally, some new trends of DL-based machine health monitoring methods are\ndiscussed.", "journal": ""}
{"doi": "10.48550/arXiv.1807.01477", "date": "2018-07-04", "title": "Diversity in Machine Learning", "authors": "Zhiqiang Gong, Ping Zhong, Weidong Hu", "abstract": "Machine learning methods have achieved good performance and been widely\napplied in various real-world applications. They can learn the model adaptively\nand be better fit for special requirements of different tasks. Generally, a\ngood machine learning system is composed of plentiful training data, a good\nmodel training process, and an accurate inference. Many factors can affect the\nperformance of the machine learning process, among which the diversity of the\nmachine learning process is an important one. The diversity can help each\nprocedure to guarantee a total good machine learning: diversity of the training\ndata ensures that the training data can provide more discriminative information\nfor the model, diversity of the learned model (diversity in parameters of each\nmodel or diversity among different base models) makes each parameter/model\ncapture unique or complement information and the diversity in inference can\nprovide multiple choices each of which corresponds to a specific plausible\nlocal optimal result. Even though the diversity plays an important role in\nmachine learning process, there is no systematical analysis of the\ndiversification in machine learning system. In this paper, we systematically\nsummarize the methods to make data diversification, model diversification, and\ninference diversification in the machine learning process, respectively. In\naddition, the typical applications where the diversity technology improved the\nmachine learning performance have been surveyed, including the remote sensing\nimaging tasks, machine translation, camera relocalization, image segmentation,\nobject detection, topic modeling, and others. Finally, we discuss some\nchallenges of the diversity technology in machine learning and point out some\ndirections in future work.", "journal": "IEEE Access,2019"}
{"doi": "10.48550/arXiv.1904.00001", "date": "2019-04-01", "title": "Engineering problems in machine learning systems", "authors": "Hiroshi Kuwajima, Hirotoshi Yasuoka, Toshihiro Nakae", "abstract": "Fatal accidents are a major issue hindering the wide acceptance of\nsafety-critical systems that employ machine learning and deep learning models,\nsuch as automated driving vehicles. In order to use machine learning in a\nsafety-critical system, it is necessary to demonstrate the safety and security\nof the system through engineering processes. However, thus far, no such widely\naccepted engineering concepts or frameworks have been established for these\nsystems. The key to using a machine learning model in a deductively engineered\nsystem is decomposing the data-driven training of machine learning models into\nrequirement, design, and verification, particularly for machine learning models\nused in safety-critical systems. Simultaneously, open problems and relevant\ntechnical fields are not organized in a manner that enables researchers to\nselect a theme and work on it. In this study, we identify, classify, and\nexplore the open problems in engineering (safety-critical) machine learning\nsystems --- that is, in terms of requirement, design, and verification of\nmachine learning models and systems --- as well as discuss related works and\nresearch directions, using automated driving vehicles as an example. Our\nresults show that machine learning models are characterized by a lack of\nrequirements specification, lack of design specification, lack of\ninterpretability, and lack of robustness. We also perform a gap analysis on a\nconventional system quality standard SQuARE with the characteristics of machine\nlearning models to study quality models for machine learning systems. We find\nthat a lack of requirements specification and lack of robustness have the\ngreatest impact on conventional quality models.", "journal": ""}
{"doi": "10.48550/arXiv.2201.01288", "date": "2022-01-04", "title": "Automated Graph Machine Learning: Approaches, Libraries, Benchmarks and Directions", "authors": "Xin Wang, Ziwei Zhang, Haoyang Li, Wenwu Zhu", "abstract": "Graph machine learning has been extensively studied in both academic and\nindustry. However, as the literature on graph learning booms with a vast number\nof emerging methods and techniques, it becomes increasingly difficult to\nmanually design the optimal machine learning algorithm for different\ngraph-related tasks. To tackle the challenge, automated graph machine learning,\nwhich aims at discovering the best hyper-parameter and neural architecture\nconfiguration for different graph tasks/data without manual design, is gaining\nan increasing number of attentions from the research community. In this paper,\nwe extensively discuss automated graph machine learning approaches, covering\nhyper-parameter optimization (HPO) and neural architecture search (NAS) for\ngraph machine learning. We briefly overview existing libraries designed for\neither graph machine learning or automated machine learning respectively, and\nfurther in depth introduce AutoGL, our dedicated and the world's first\nopen-source library for automated graph machine learning. Also, we describe a\ntailored benchmark that supports unified, reproducible, and efficient\nevaluations. Last but not least, we share our insights on future research\ndirections for automated graph machine learning. This paper is the first\nsystematic and comprehensive discussion of approaches, libraries as well as\ndirections for automated graph machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.2403.02432", "date": "2024-03-04", "title": "On the impact of measure pre-conditionings on general parametric ML models and transfer learning via domain adaptation", "authors": "Joaqu\u00edn S\u00e1nchez Garc\u00eda", "abstract": "We study a new technique for understanding convergence of learning agents\nunder small modifications of data. We show that such convergence can be\nunderstood via an analogue of Fatou's lemma which yields gamma-convergence. We\nshow it's relevance and applications in general machine learning tasks and\ndomain adaptation transfer learning.", "journal": ""}
{"doi": "10.48550/arXiv.2202.13608", "date": "2022-02-28", "title": "Semi-supervised Learning on Large Graphs: is Poisson Learning a Game-Changer?", "authors": "Canh Hao Nguyen", "abstract": "We explain Poisson learning on graph-based semi-supervised learning to see if\nit could avoid the problem of global information loss problem as Laplace-based\nlearning methods on large graphs. From our analysis, Poisson learning is simply\nLaplace regularization with thresholding, cannot overcome the problem.", "journal": ""}
{"doi": "10.48550/arXiv.1711.01431", "date": "2017-11-04", "title": "The Case for Meta-Cognitive Machine Learning: On Model Entropy and Concept Formation in Deep Learning", "authors": "Johan Loeckx", "abstract": "Machine learning is usually defined in behaviourist terms, where external\nvalidation is the primary mechanism of learning. In this paper, I argue for a\nmore holistic interpretation in which finding more probable, efficient and\nabstract representations is as central to learning as performance. In other\nwords, machine learning should be extended with strategies to reason over its\nown learning process, leading to so-called meta-cognitive machine learning. As\nsuch, the de facto definition of machine learning should be reformulated in\nthese intrinsically multi-objective terms, taking into account not only the\ntask performance but also internal learning objectives. To this end, we suggest\na \"model entropy function\" to be defined that quantifies the efficiency of the\ninternal learning processes. It is conjured that the minimization of this model\nentropy leads to concept formation. Besides philosophical aspects, some initial\nillustrations are included to support the claims.", "journal": ""}
{"doi": "10.48550/arXiv.1907.07543", "date": "2019-07-17", "title": "Low-Shot Classification: A Comparison of Classical and Deep Transfer Machine Learning Approaches", "authors": "Peter Usherwood, Steven Smit", "abstract": "Despite the recent success of deep transfer learning approaches in NLP, there\nis a lack of quantitative studies demonstrating the gains these models offer in\nlow-shot text classification tasks over existing paradigms. Deep transfer\nlearning approaches such as BERT and ULMFiT demonstrate that they can beat\nstate-of-the-art results on larger datasets, however when one has only 100-1000\nlabelled examples per class, the choice of approach is less clear, with\nclassical machine learning and deep transfer learning representing valid\noptions. This paper compares the current best transfer learning approach with\ntop classical machine learning approaches on a trinary sentiment classification\ntask to assess the best paradigm. We find that BERT, representing the best of\ndeep transfer learning, is the best performing approach, outperforming top\nclassical machine learning algorithms by 9.7% on average when trained with 100\nexamples per class, narrowing to 1.8% at 1000 labels per class. We also show\nthe robustness of deep transfer learning in moving across domains, where the\nmaximum loss in accuracy is only 0.7% in similar domain tasks and 3.2% cross\ndomain, compared to classical machine learning which loses up to 20.6%.", "journal": ""}
{"doi": "10.48550/arXiv.2107.11277", "date": "2021-07-23", "title": "Machine Learning with a Reject Option: A survey", "authors": "Kilian Hendrickx, Lorenzo Perini, Dries Van der Plas, Wannes Meert, Jesse Davis", "abstract": "Machine learning models always make a prediction, even when it is likely to\nbe inaccurate. This behavior should be avoided in many decision support\napplications, where mistakes can have severe consequences. Albeit already\nstudied in 1970, machine learning with rejection recently gained interest. This\nmachine learning subfield enables machine learning models to abstain from\nmaking a prediction when likely to make a mistake.\n  This survey aims to provide an overview on machine learning with rejection.\nWe introduce the conditions leading to two types of rejection, ambiguity and\nnovelty rejection, which we carefully formalize. Moreover, we review and\ncategorize strategies to evaluate a model's predictive and rejective quality.\nAdditionally, we define the existing architectures for models with rejection\nand describe the standard techniques for learning such models. Finally, we\nprovide examples of relevant application domains and show how machine learning\nwith rejection relates to other machine learning research areas.", "journal": ""}
{"doi": "10.48550/arXiv.2205.14136", "date": "2022-05-27", "title": "PSL is Dead. Long Live PSL", "authors": "Kevin Smith, Hai Lin, Praveen Tiwari, Marjorie Sayer, Claudionor Coelho", "abstract": "Property Specification Language (PSL) is a form of temporal logic that has\nbeen mainly used in discrete domains (e.g. formal hardware verification). In\nthis paper, we show that by merging machine learning techniques with PSL\nmonitors, we can extend PSL to work on continuous domains. We apply this\ntechnique in machine learning-based anomaly detection to analyze scenarios of\nreal-time streaming events from continuous variables in order to detect\nabnormal behaviors of a system. By using machine learning with formal models,\nwe leverage the strengths of both machine learning methods and formal semantics\nof time. On one hand, machine learning techniques can produce distributions on\ncontinuous variables, where abnormalities can be captured as deviations from\nthe distributions. On the other hand, formal methods can characterize discrete\ntemporal behaviors and relations that cannot be easily learned by machine\nlearning techniques. Interestingly, the anomalies detected by machine learning\nand the underlying time representation used are discrete events. We implemented\na temporal monitoring package (TEF) that operates in conjunction with normal\ndata science packages for anomaly detection machine learning systems, and we\nshow that TEF can be used to perform accurate interpretation of temporal\ncorrelation between events.", "journal": ""}
{"doi": "10.48550/arXiv.2405.16159", "date": "2024-05-25", "title": "A Declarative Query Language for Scientific Machine Learning", "authors": "Hasan M Jamil", "abstract": "The popularity of data science as a discipline and its importance in the\nemerging economy and industrial progress dictate that machine learning be\ndemocratized for the masses. This also means that the current practice of\nworkforce training using machine learning tools, which requires low-level\nstatistical and algorithmic details, is a barrier that needs to be addressed.\nSimilar to data management languages such as SQL, machine learning needs to be\npracticed at a conceptual level to help make it a staple tool for general\nusers. In particular, the technical sophistication demanded by existing machine\nlearning frameworks is prohibitive for many scientists who are not\ncomputationally savvy or well versed in machine learning techniques. The\nlearning curve to use the needed machine learning tools is also too high for\nthem to take advantage of these powerful platforms to rapidly advance science.\nIn this paper, we introduce a new declarative machine learning query language,\ncalled {\\em MQL}, for naive users. We discuss its merit and possible ways of\nimplementing it over a traditional relational database system. We discuss two\nmaterials science experiments implemented using MQL on a materials science\nworkflow system called MatFlow.", "journal": ""}
{"doi": "10.48550/arXiv.1303.2104", "date": "2013-03-08", "title": "Transfer Learning for Voice Activity Detection: A Denoising Deep Neural Network Perspective", "authors": "Xiao-Lei Zhang, Ji Wu", "abstract": "Mismatching problem between the source and target noisy corpora severely\nhinder the practical use of the machine-learning-based voice activity detection\n(VAD). In this paper, we try to address this problem in the transfer learning\nprospective. Transfer learning tries to find a common learning machine or a\ncommon feature subspace that is shared by both the source corpus and the target\ncorpus. The denoising deep neural network is used as the learning machine.\nThree transfer techniques, which aim to learn common feature representations,\nare used for analysis. Experimental results demonstrate the effectiveness of\nthe transfer learning schemes on the mismatch problem.", "journal": ""}
{"doi": "10.48550/arXiv.1807.10681", "date": "2018-07-27", "title": "Learnable: Theory vs Applications", "authors": "Marina Sapir", "abstract": "Two different views on machine learning problem: Applied learning (machine\nlearning with business applications) and Agnostic PAC learning are formalized\nand compared here. I show that, under some conditions, the theory of PAC\nLearnable provides a way to solve the Applied learning problem. However, the\ntheory requires to have the training sets so large, that it would make the\nlearning practically useless. I suggest shedding some theoretical\nmisconceptions about learning to make the theory more aligned with the needs\nand experience of practitioners.", "journal": ""}
{"doi": "10.48550/arXiv.1905.07822", "date": "2019-05-19", "title": "Minimal Achievable Sufficient Statistic Learning", "authors": "Milan Cvitkovic, G\u00fcnther Koliander", "abstract": "We introduce Minimal Achievable Sufficient Statistic (MASS) Learning, a\ntraining method for machine learning models that attempts to produce minimal\nsufficient statistics with respect to a class of functions (e.g. deep networks)\nbeing optimized over. In deriving MASS Learning, we also introduce Conserved\nDifferential Information (CDI), an information-theoretic quantity that - unlike\nstandard mutual information - can be usefully applied to\ndeterministically-dependent continuous random variables like the input and\noutput of a deep network. In a series of experiments, we show that deep\nnetworks trained with MASS Learning achieve competitive performance on\nsupervised learning and uncertainty quantification benchmarks.", "journal": ""}
{"doi": "10.48550/arXiv.2102.11274", "date": "2021-02-22", "title": "Sustainable Federated Learning", "authors": "Basak Guler, Aylin Yener", "abstract": "Potential environmental impact of machine learning by large-scale wireless\nnetworks is a major challenge for the sustainability of future smart\necosystems. In this paper, we introduce sustainable machine learning in\nfederated learning settings, using rechargeable devices that can collect energy\nfrom the ambient environment. We propose a practical federated learning\nframework that leverages intermittent energy arrivals for training, with\nprovable convergence guarantees. Our framework can be applied to a wide range\nof machine learning settings in networked environments, including distributed\nand federated learning in wireless and edge networks. Our experiments\ndemonstrate that the proposed framework can provide significant performance\nimprovement over the benchmark energy-agnostic federated learning settings.", "journal": ""}
{"doi": "10.48550/arXiv.2305.00520", "date": "2023-04-30", "title": "The ART of Transfer Learning: An Adaptive and Robust Pipeline", "authors": "Boxiang Wang, Yunan Wu, Chenglong Ye", "abstract": "Transfer learning is an essential tool for improving the performance of\nprimary tasks by leveraging information from auxiliary data resources. In this\nwork, we propose Adaptive Robust Transfer Learning (ART), a flexible pipeline\nof performing transfer learning with generic machine learning algorithms. We\nestablish the non-asymptotic learning theory of ART, providing a provable\ntheoretical guarantee for achieving adaptive transfer while preventing negative\ntransfer. Additionally, we introduce an ART-integrated-aggregating machine that\nproduces a single final model when multiple candidate algorithms are\nconsidered. We demonstrate the promising performance of ART through extensive\nempirical studies on regression, classification, and sparse learning. We\nfurther present a real-data analysis for a mortality study.", "journal": ""}
{"doi": "10.48550/arXiv.1404.6674", "date": "2014-04-26", "title": "A Comparison of First-order Algorithms for Machine Learning", "authors": "Yu Wei, Pock Thomas", "abstract": "Using an optimization algorithm to solve a machine learning problem is one of\nmainstreams in the field of science. In this work, we demonstrate a\ncomprehensive comparison of some state-of-the-art first-order optimization\nalgorithms for convex optimization problems in machine learning. We concentrate\non several smooth and non-smooth machine learning problems with a loss function\nplus a regularizer. The overall experimental results show the superiority of\nprimal-dual algorithms in solving a machine learning problem from the\nperspectives of the ease to construct, running time and accuracy.", "journal": ""}
{"doi": "10.48550/arXiv.1607.00279", "date": "2016-07-01", "title": "Meaningful Models: Utilizing Conceptual Structure to Improve Machine Learning Interpretability", "authors": "Nick Condry", "abstract": "The last decade has seen huge progress in the development of advanced machine\nlearning models; however, those models are powerless unless human users can\ninterpret them. Here we show how the mind's construction of concepts and\nmeaning can be used to create more interpretable machine learning models. By\nproposing a novel method of classifying concepts, in terms of 'form' and\n'function', we elucidate the nature of meaning and offer proposals to improve\nmodel understandability. As machine learning begins to permeate daily life,\ninterpretable models may serve as a bridge between domain-expert authors and\nnon-expert users.", "journal": ""}
{"doi": "10.48550/arXiv.1812.10422", "date": "2018-12-13", "title": "Machine Learning in Official Statistics", "authors": "Martin Beck, Florian Dumpert, Joerg Feuerhake", "abstract": "In the first half of 2018, the Federal Statistical Office of Germany\n(Destatis) carried out a \"Proof of Concept Machine Learning\" as part of its\nDigital Agenda. A major component of this was surveys on the use of machine\nlearning methods in official statistics, which were conducted at selected\nnational and international statistical institutions and among the divisions of\nDestatis. It was of particular interest to find out in which statistical areas\nand for which tasks machine learning is used and which methods are applied.\nThis paper is intended to make the results of the surveys publicly accessible.", "journal": ""}
{"doi": "10.48550/arXiv.1903.00092", "date": "2019-02-28", "title": "Optimal Algorithms for Ski Rental with Soft Machine-Learned Predictions", "authors": "Rohan Kodialam", "abstract": "We consider a variant of the classic Ski Rental online algorithm with\napplications to machine learning. In our variant, we allow the skier access to\na black-box machine-learning algorithm that provides an estimate of the\nprobability that there will be at most a threshold number of ski-days. We\nderive a class of optimal randomized algorithms to determine the strategy that\nminimizes the worst-case expected competitive ratio for the skier given a\nprediction from the machine learning algorithm,and analyze the performance and\nrobustness of these algorithms.", "journal": ""}
{"doi": "10.48550/arXiv.2006.00700", "date": "2020-06-01", "title": "When Machine Learning Meets Multiscale Modeling in Chemical Reactions", "authors": "Wuyue Yang, Liangrong Peng, Yi Zhu, Liu Hong", "abstract": "Due to the intrinsic complexity and nonlinearity of chemical reactions,\ndirect applications of traditional machine learning algorithms may face with\nmany difficulties. In this study, through two concrete examples with biological\nbackground, we illustrate how the key ideas of multiscale modeling can help to\nreduce the computational cost of machine learning a lot, as well as how machine\nlearning algorithms perform model reduction automatically in a time-scale\nseparated system. Our study highlights the necessity and effectiveness of an\nintegration of machine learning algorithms and multiscale modeling during the\nstudy of chemical reactions.", "journal": ""}
{"doi": "10.48550/arXiv.2111.04439", "date": "2021-10-25", "title": "Addressing Privacy Threats from Machine Learning", "authors": "Mary Anne Smart", "abstract": "Every year at NeurIPS, machine learning researchers gather and discuss\nexciting applications of machine learning in areas such as public health,\ndisaster response, climate change, education, and more. However, many of these\nsame researchers are expressing growing concern about applications of machine\nlearning for surveillance (Nanayakkara et al., 2021). This paper presents a\nbrief overview of strategies for resisting these surveillance technologies and\ncalls for greater collaboration between machine learning and human-computer\ninteraction researchers to address the threats that these technologies pose.", "journal": ""}
{"doi": "10.48550/arXiv.1801.04016", "date": "2018-01-11", "title": "Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution", "authors": "Judea Pearl", "abstract": "Current machine learning systems operate, almost exclusively, in a\nstatistical, or model-free mode, which entails severe theoretical limits on\ntheir power and performance. Such systems cannot reason about interventions and\nretrospection and, therefore, cannot serve as the basis for strong AI. To\nachieve human level intelligence, learning machines need the guidance of a\nmodel of reality, similar to the ones used in causal inference tasks. To\ndemonstrate the essential role of such models, I will present a summary of\nseven tasks which are beyond reach of current machine learning systems and\nwhich have been accomplished using the tools of causal modeling.", "journal": ""}
{"doi": "10.48550/arXiv.1805.07072", "date": "2018-05-18", "title": "Optimizing for Generalization in Machine Learning with Cross-Validation Gradients", "authors": "Shane Barratt, Rishi Sharma", "abstract": "Cross-validation is the workhorse of modern applied statistics and machine\nlearning, as it provides a principled framework for selecting the model that\nmaximizes generalization performance. In this paper, we show that the\ncross-validation risk is differentiable with respect to the hyperparameters and\ntraining data for many common machine learning algorithms, including logistic\nregression, elastic-net regression, and support vector machines. Leveraging\nthis property of differentiability, we propose a cross-validation gradient\nmethod (CVGM) for hyperparameter optimization. Our method enables efficient\noptimization in high-dimensional hyperparameter spaces of the cross-validation\nrisk, the best surrogate of the true generalization ability of our learning\nalgorithm.", "journal": ""}
{"doi": "10.48550/arXiv.1805.11959", "date": "2018-05-26", "title": "Algebraic Expression of Subjective Spatial and Temporal Patterns", "authors": "Chuyu Xiong", "abstract": "Universal learning machine is a theory trying to study machine learning from\nmathematical point of view. The outside world is reflected inside an universal\nlearning machine according to pattern of incoming data. This is subjective\npattern of learning machine. In [2,4], we discussed subjective spatial pattern,\nand established a powerful tool -- X-form, which is an algebraic expression for\nsubjective spatial pattern. However, as the initial stage of study, there we\nonly discussed spatial pattern. Here, we will discuss spatial and temporal\npatterns, and algebraic expression for them.", "journal": ""}
{"doi": "10.48550/arXiv.1902.06789", "date": "2019-02-18", "title": "Seven Myths in Machine Learning Research", "authors": "Oscar Chang, Hod Lipson", "abstract": "We present seven myths commonly believed to be true in machine learning\nresearch, circa Feb 2019. This is an archival copy of the blog post at\nhttps://crazyoscarchang.github.io/2019/02/16/seven-myths-in-machine-learning-research/\n  Myth 1: TensorFlow is a Tensor manipulation library\n  Myth 2: Image datasets are representative of real images found in the wild\n  Myth 3: Machine Learning researchers do not use the test set for validation\n  Myth 4: Every datapoint is used in training a neural network\n  Myth 5: We need (batch) normalization to train very deep residual networks\n  Myth 6: Attention $>$ Convolution\n  Myth 7: Saliency maps are robust ways to interpret neural networks", "journal": ""}
{"doi": "10.48550/arXiv.1911.07679", "date": "2019-11-18", "title": "Towards Quantification of Bias in Machine Learning for Healthcare: A Case Study of Renal Failure Prediction", "authors": "Josie Williams, Narges Razavian", "abstract": "As machine learning (ML) models, trained on real-world datasets, become\ncommon practice, it is critical to measure and quantify their potential biases.\nIn this paper, we focus on renal failure and compare a commonly used\ntraditional risk score, Tangri, with a more powerful machine learning model,\nwhich has access to a larger variable set and trained on 1.6 million patients'\nEHR data. We will compare and discuss the generalization and applicability of\nthese two models, in an attempt to quantify biases of status quo clinical\npractice, compared to ML-driven models.", "journal": ""}
{"doi": "10.48550/arXiv.1911.07749", "date": "2019-11-15", "title": "On the computation of counterfactual explanations -- A survey", "authors": "Andr\u00e9 Artelt, Barbara Hammer", "abstract": "Due to the increasing use of machine learning in practice it becomes more and\nmore important to be able to explain the prediction and behavior of machine\nlearning models. An instance of explanations are counterfactual explanations\nwhich provide an intuitive and useful explanations of machine learning models.\nIn this survey we review model-specific methods for efficiently computing\ncounterfactual explanations of many different machine learning models and\npropose methods for models that have not been considered in literature so far.", "journal": ""}
{"doi": "10.48550/arXiv.1911.12593", "date": "2019-11-28", "title": "Computer Systems Have 99 Problems, Let's Not Make Machine Learning Another One", "authors": "David Mohaisen, Songqing Chen", "abstract": "Machine learning techniques are finding many applications in computer\nsystems, including many tasks that require decision making: network\noptimization, quality of service assurance, and security. We believe machine\nlearning systems are here to stay, and to materialize on their potential we\nadvocate a fresh look at various key issues that need further attention,\nincluding security as a requirement and system complexity, and how machine\nlearning systems affect them. We also discuss reproducibility as a key\nrequirement for sustainable machine learning systems, and leads to pursuing it.", "journal": ""}
{"doi": "10.48550/arXiv.2008.07758", "date": "2020-08-18", "title": "Efficient Private Machine Learning by Differentiable Random Transformations", "authors": "Fei Zheng", "abstract": "With the increasing demands for privacy protection, many privacy-preserving\nmachine learning systems were proposed in recent years. However, most of them\ncannot be put into production due to their slow training and inference speed\ncaused by the heavy cost of homomorphic encryption and secure multiparty\ncomputation(MPC) methods. To circumvent this, I proposed a privacy definition\nwhich is suitable for large amount of data in machine learning tasks. Based on\nthat, I showed that random transformations like linear transformation and\nrandom permutation can well protect privacy. Merging random transformations and\narithmetic sharing together, I designed a framework for private machine\nlearning with high efficiency and low computation cost.", "journal": ""}
{"doi": "10.48550/arXiv.2101.04025", "date": "2021-01-11", "title": "Distributed Double Machine Learning with a Serverless Architecture", "authors": "Malte S. Kurz", "abstract": "This paper explores serverless cloud computing for double machine learning.\nBeing based on repeated cross-fitting, double machine learning is particularly\nwell suited to exploit the high level of parallelism achievable with serverless\ncomputing. It allows to get fast on-demand estimations without additional cloud\nmaintenance effort. We provide a prototype Python implementation\n\\texttt{DoubleML-Serverless} for the estimation of double machine learning\nmodels with the serverless computing platform AWS Lambda and demonstrate its\nutility with a case study analyzing estimation times and costs.", "journal": "In Companion of the ACM/SPEC International Conference on\n  Performance Engineering (ICPE '21), 2021, Association for Computing\n  Machinery, New York, NY, USA, 27-33"}
{"doi": "10.48550/arXiv.2203.06430", "date": "2022-03-12", "title": "Categories of Differentiable Polynomial Circuits for Machine Learning", "authors": "Paul Wilson, Fabio Zanasi", "abstract": "Reverse derivative categories (RDCs) have recently been shown to be a\nsuitable semantic framework for studying machine learning algorithms. Whereas\nemphasis has been put on training methodologies, less attention has been\ndevoted to particular \\emph{model classes}: the concrete categories whose\nmorphisms represent machine learning models. In this paper we study\npresentations by generators and equations of classes of RDCs. In particular, we\npropose \\emph{polynomial circuits} as a suitable machine learning model. We\ngive an axiomatisation for these circuits and prove a functional completeness\nresult. Finally, we discuss the use of polynomial circuits over specific\nsemirings to perform machine learning with discrete values.", "journal": ""}
{"doi": "10.48550/arXiv.2203.16797", "date": "2022-03-31", "title": "When Physics Meets Machine Learning: A Survey of Physics-Informed Machine Learning", "authors": "Chuizheng Meng, Sungyong Seo, Defu Cao, Sam Griesemer, Yan Liu", "abstract": "Physics-informed machine learning (PIML), referring to the combination of\nprior knowledge of physics, which is the high level abstraction of natural\nphenomenons and human behaviours in the long history, with data-driven machine\nlearning models, has emerged as an effective way to mitigate the shortage of\ntraining data, to increase models' generalizability and to ensure the physical\nplausibility of results. In this paper, we survey an abundant number of recent\nworks in PIML and summarize them from three aspects: (1) motivations of PIML,\n(2) physics knowledge in PIML, (3) methods of physics knowledge integration in\nPIML. We also discuss current challenges and corresponding research\nopportunities in PIML.", "journal": ""}
{"doi": "10.48550/arXiv.2208.10896", "date": "2022-08-23", "title": "pystacked: Stacking generalization and machine learning in Stata", "authors": "Achim Ahrens, Christian B. Hansen, Mark E. Schaffer", "abstract": "pystacked implements stacked generalization (Wolpert, 1992) for regression\nand binary classification via Python's scikit-learn. Stacking combines multiple\nsupervised machine learners -- the \"base\" or \"level-0\" learners -- into a\nsingle learner. The currently supported base learners include regularized\nregression, random forest, gradient boosted trees, support vector machines, and\nfeed-forward neural nets (multi-layer perceptron). pystacked can also be used\nwith as a `regular' machine learning program to fit a single base learner and,\nthus, provides an easy-to-use API for scikit-learn's machine learning\nalgorithms.", "journal": ""}
{"doi": "10.48550/arXiv.2305.10472", "date": "2023-05-17", "title": "Nine tips for ecologists using machine learning", "authors": "Marine Desprez, Vincent Miele, Olivier Gimenez", "abstract": "Due to their high predictive performance and flexibility, machine learning\nmodels are an appropriate and efficient tool for ecologists. However,\nimplementing a machine learning model is not yet a trivial task and may seem\nintimidating to ecologists with no previous experience in this area. Here we\nprovide a series of tips to help ecologists in implementing machine learning\nmodels. We focus on classification problems as many ecological studies aim to\nassign data into predefined classes such as ecological states or biological\nentities. Each of the nine tips identifies a common error, trap or challenge in\ndeveloping machine learning models and provides recommendations to facilitate\ntheir use in ecological studies.", "journal": ""}
{"doi": "10.48550/arXiv.2307.02071", "date": "2023-07-05", "title": "A Comparison of Machine Learning Methods for Data with High-Cardinality Categorical Variables", "authors": "Fabio Sigrist", "abstract": "High-cardinality categorical variables are variables for which the number of\ndifferent levels is large relative to the sample size of a data set, or in\nother words, there are few data points per level. Machine learning methods can\nhave difficulties with high-cardinality variables. In this article, we\nempirically compare several versions of two of the most successful machine\nlearning methods, tree-boosting and deep neural networks, and linear mixed\neffects models using multiple tabular data sets with high-cardinality\ncategorical variables. We find that, first, machine learning models with random\neffects have higher prediction accuracy than their classical counterparts\nwithout random effects, and, second, tree-boosting with random effects\noutperforms deep neural networks with random effects.", "journal": ""}
{"doi": "10.48550/arXiv.2311.00196", "date": "2023-11-01", "title": "Machine learning for accuracy in density functional approximations", "authors": "Johannes Voss", "abstract": "Machine learning techniques have found their way into computational chemistry\nas indispensable tools to accelerate atomistic simulations and materials\ndesign. In addition, machine learning approaches hold the potential to boost\nthe predictive power of computationally efficient electronic structure methods,\nsuch as density functional theory, to chemical accuracy and to correct for\nfundamental errors in density functional approaches. Here, recent progress in\napplying machine learning to improve the accuracy of density functional and\nrelated approximations is reviewed. Promises and challenges in devising machine\nlearning models transferable between different chemistries and materials\nclasses are discussed with the help of examples applying promising models to\nsystems far outside their training sets.", "journal": ""}
{"doi": "10.48550/arXiv.2408.12655", "date": "2024-08-22", "title": "Improving Radiography Machine Learning Workflows via Metadata Management for Training Data Selection", "authors": "Mirabel Reid, Christine Sweeney, Oleg Korobkin", "abstract": "Most machine learning models require many iterations of hyper-parameter\ntuning, feature engineering, and debugging to produce effective results. As\nmachine learning models become more complicated, this pipeline becomes more\ndifficult to manage effectively. In the physical sciences, there is an\never-increasing pool of metadata that is generated by the scientific research\ncycle. Tracking this metadata can reduce redundant work, improve\nreproducibility, and aid in the feature and training dataset engineering\nprocess. In this case study, we present a tool for machine learning metadata\nmanagement in dynamic radiography. We evaluate the efficacy of this tool\nagainst the initial research workflow and discuss extensions to general machine\nlearning pipelines in the physical sciences.", "journal": ""}
{"doi": "10.48550/arXiv.2409.03669", "date": "2024-09-05", "title": "A method to benchmark high-dimensional process drift detection", "authors": "Edgar Wolf, Tobias Windisch", "abstract": "Process curves are multivariate finite time series data coming from\nmanufacturing processes. This paper studies machine learning that detect drifts\nin process curve datasets. A theoretic framework to synthetically generate\nprocess curves in a controlled way is introduced in order to benchmark machine\nlearning algorithms for process drift detection. An evaluation score, called\nthe temporal area under the curve, is introduced, which allows to quantify how\nwell machine learning models unveil curves belonging to drift segments.\nFinally, a benchmark study comparing popular machine learning approaches on\nsynthetic data generated with the introduced framework is presented that shows\nthat existing algorithms often struggle with datasets containing multiple drift\nsegments.", "journal": ""}
{"doi": "10.48550/arXiv.2410.10523", "date": "2024-10-14", "title": "Inverse Problems and Data Assimilation: A Machine Learning Approach", "authors": "Eviatar Bach, Ricardo Baptista, Daniel Sanz-Alonso, Andrew Stuart", "abstract": "The aim of these notes is to demonstrate the potential for ideas in machine\nlearning to impact on the fields of inverse problems and data assimilation. The\nperspective is one that is primarily aimed at researchers from inverse problems\nand/or data assimilation who wish to see a mathematical presentation of machine\nlearning as it pertains to their fields. As a by-product, we include a succinct\nmathematical treatment of various topics in machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.1611.09139", "date": "2016-11-28", "title": "Proceedings of NIPS 2016 Workshop on Interpretable Machine Learning for Complex Systems", "authors": "Andrew Gordon Wilson, Been Kim, William Herlands", "abstract": "This is the Proceedings of NIPS 2016 Workshop on Interpretable Machine\nLearning for Complex Systems, held in Barcelona, Spain on December 9, 2016", "journal": ""}
{"doi": "10.48550/arXiv.1711.09522", "date": "2017-11-27", "title": "Proceedings of NIPS 2017 Workshop on Machine Learning for the Developing World", "authors": "Maria De-Arteaga, William Herlands", "abstract": "This is the Proceedings of NIPS 2017 Workshop on Machine Learning for the\nDeveloping World, held in Long Beach, California, USA on December 8, 2017", "journal": ""}
{"doi": "10.48550/arXiv.1802.00382", "date": "2018-02-01", "title": "Classifying medical notes into standard disease codes using Machine Learning", "authors": "Amitabha Karmakar", "abstract": "We investigate the automatic classification of patient discharge notes into\nstandard disease labels. We find that Convolutional Neural Networks with\nAttention outperform previous algorithms used in this task, and suggest further\nareas for improvement.", "journal": ""}
{"doi": "10.48550/arXiv.1703.01977", "date": "2017-02-26", "title": "Linear, Machine Learning and Probabilistic Approaches for Time Series Analysis", "authors": "B. M. Pavlyshenko", "abstract": "In this paper we study different approaches for time series modeling. The\nforecasting approaches using linear models, ARIMA alpgorithm, XGBoost machine\nlearning algorithm are described. Results of different model combinations are\nshown. For probabilistic modeling the approaches using copulas and Bayesian\ninference are considered.", "journal": ""}
{"doi": "10.48550/arXiv.2201.04703", "date": "2022-01-12", "title": "Detection of brain tumors using machine learning algorithms", "authors": "Horacio Corral, Javier Melchor, Balam Sotelo, Jorge Vera", "abstract": "An algorithm capable of processing NMR images was developed for analysis\nusing machine learning techniques to detect the presence of brain tumors.", "journal": ""}
{"doi": "10.48550/arXiv.2001.07278", "date": "2020-01-20", "title": "Mixed integer programming formulation of unsupervised learning", "authors": "Arturo Berrones-Santos", "abstract": "A novel formulation and training procedure for full Boltzmann machines in\nterms of a mixed binary quadratic feasibility problem is given. As a proof of\nconcept, the theory is analytically and numerically tested on XOR patterns.", "journal": ""}
{"doi": "10.48550/arXiv.2211.14401", "date": "2022-11-25", "title": "Elements of effective machine learning datasets in astronomy", "authors": "Bernie Boscoe, Tuan Do, Evan Jones, Yunqi Li, Kevin Alfaro, Christy Ma", "abstract": "In this work, we identify elements of effective machine learning datasets in\nastronomy and present suggestions for their design and creation. Machine\nlearning has become an increasingly important tool for analyzing and\nunderstanding the large-scale flood of data in astronomy. To take advantage of\nthese tools, datasets are required for training and testing. However, building\nmachine learning datasets for astronomy can be challenging. Astronomical data\nis collected from instruments built to explore science questions in a\ntraditional fashion rather than to conduct machine learning. Thus, it is often\nthe case that raw data, or even downstream processed data is not in a form\namenable to machine learning. We explore the construction of machine learning\ndatasets and we ask: what elements define effective machine learning datasets?\nWe define effective machine learning datasets in astronomy to be formed with\nwell-defined data points, structure, and metadata. We discuss why these\nelements are important for astronomical applications and ways to put them in\npractice. We posit that these qualities not only make the data suitable for\nmachine learning, they also help to foster usable, reusable, and replicable\nscience practices.", "journal": ""}
{"doi": "10.48550/arXiv.1807.06689", "date": "2018-07-17", "title": "Efficient Deep Learning on Multi-Source Private Data", "authors": "Nick Hynes, Raymond Cheng, Dawn Song", "abstract": "Machine learning models benefit from large and diverse datasets. Using such\ndatasets, however, often requires trusting a centralized data aggregator. For\nsensitive applications like healthcare and finance this is undesirable as it\ncould compromise patient privacy or divulge trade secrets. Recent advances in\nsecure and privacy-preserving computation, including trusted hardware enclaves\nand differential privacy, offer a way for mutually distrusting parties to\nefficiently train a machine learning model without revealing the training data.\nIn this work, we introduce Myelin, a deep learning framework which combines\nthese privacy-preservation primitives, and use it to establish a baseline level\nof performance for fully private machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.1811.00542", "date": "2018-10-31", "title": "Pymc-learn: Practical Probabilistic Machine Learning in Python", "authors": "Daniel Emaasit", "abstract": "$\\textit{Pymc-learn}$ is a Python package providing a variety of\nstate-of-the-art probabilistic models for supervised and unsupervised machine\nlearning. It is inspired by $\\textit{scikit-learn}$ and focuses on bringing\nprobabilistic machine learning to non-specialists. It uses a general-purpose\nhigh-level language that mimics $\\textit{scikit-learn}$. Emphasis is put on\nease of use, productivity, flexibility, performance, documentation, and an API\nconsistent with $\\textit{scikit-learn}$. It depends on $\\textit{scikit-learn}$\nand $\\textit{pymc3}$ and is distributed under the new BSD-3 license,\nencouraging its use in both academia and industry. Source code, binaries, and\ndocumentation are available on http://github.com/pymc-learn/pymc-learn.", "journal": ""}
{"doi": "10.48550/arXiv.2310.10368", "date": "2023-10-16", "title": "Machine learning in physics: a short guide", "authors": "Francisco A. Rodrigues", "abstract": "Machine learning is a rapidly growing field with the potential to\nrevolutionize many areas of science, including physics. This review provides a\nbrief overview of machine learning in physics, covering the main concepts of\nsupervised, unsupervised, and reinforcement learning, as well as more\nspecialized topics such as causal inference, symbolic regression, and deep\nlearning. We present some of the principal applications of machine learning in\nphysics and discuss the associated challenges and perspectives.", "journal": ""}
{"doi": "10.48550/arXiv.2005.09428", "date": "2020-05-15", "title": "Quantum-Classical Machine learning by Hybrid Tensor Networks", "authors": "Ding Liu, Jiaqi Yao, Zekun Yao, Quan Zhang", "abstract": "Tensor networks (TN) have found a wide use in machine learning, and in\nparticular, TN and deep learning bear striking similarities. In this work, we\npropose the quantum-classical hybrid tensor networks (HTN) which combine tensor\nnetworks with classical neural networks in a uniform deep learning framework to\novercome the limitations of regular tensor networks in machine learning. We\nfirst analyze the limitations of regular tensor networks in the applications of\nmachine learning involving the representation power and architecture\nscalability. We conclude that in fact the regular tensor networks are not\ncompetent to be the basic building blocks of deep learning. Then, we discuss\nthe performance of HTN which overcome all the deficiency of regular tensor\nnetworks for machine learning. In this sense, we are able to train HTN in the\ndeep learning way which is the standard combination of algorithms such as Back\nPropagation and Stochastic Gradient Descent. We finally provide two applicable\ncases to show the potential applications of HTN, including quantum states\nclassification and quantum-classical autoencoder. These cases also demonstrate\nthe great potentiality to design various HTN in deep learning way.", "journal": ""}
{"doi": "10.48550/arXiv.2411.11315", "date": "2024-11-18", "title": "A Review on Machine Unlearning", "authors": "Haibo Zhang, Toru Nakamura, Takamasa Isohara, Kouichi Sakurai", "abstract": "Recently, an increasing number of laws have governed the useability of users'\nprivacy. For example, Article 17 of the General Data Protection Regulation\n(GDPR), the right to be forgotten, requires machine learning applications to\nremove a portion of data from a dataset and retrain it if the user makes such a\nrequest. Furthermore, from the security perspective, training data for machine\nlearning models, i.e., data that may contain user privacy, should be\neffectively protected, including appropriate erasure. Therefore, researchers\npropose various privacy-preserving methods to deal with such issues as machine\nunlearning. This paper provides an in-depth review of the security and privacy\nconcerns in machine learning models. First, we present how machine learning can\nuse users' private data in daily life and the role that the GDPR plays in this\nproblem. Then, we introduce the concept of machine unlearning by describing the\nsecurity threats in machine learning models and how to protect users' privacy\nfrom being violated using machine learning platforms. As the core content of\nthe paper, we introduce and analyze current machine unlearning approaches and\nseveral representative research results and discuss them in the context of the\ndata lineage. Furthermore, we also discuss the future research challenges in\nthis field.", "journal": "SN COMPUT. SCI. 4, 337 (2023)"}
{"doi": "10.48550/arXiv.1706.05749", "date": "2017-06-19", "title": "Dex: Incremental Learning for Complex Environments in Deep Reinforcement Learning", "authors": "Nick Erickson, Qi Zhao", "abstract": "This paper introduces Dex, a reinforcement learning environment toolkit\nspecialized for training and evaluation of continual learning methods as well\nas general reinforcement learning problems. We also present the novel continual\nlearning method of incremental learning, where a challenging environment is\nsolved using optimal weight initialization learned from first solving a similar\neasier environment. We show that incremental learning can produce vastly\nsuperior results than standard methods by providing a strong baseline method\nacross ten Dex environments. We finally develop a saliency method for\nqualitative analysis of reinforcement learning, which shows the impact\nincremental learning has on network attention.", "journal": ""}
{"doi": "10.48550/arXiv.1504.03874", "date": "2015-04-15", "title": "Bridging belief function theory to modern machine learning", "authors": "Thomas Burger", "abstract": "Machine learning is a quickly evolving field which now looks really different\nfrom what it was 15 years ago, when classification and clustering were major\nissues. This document proposes several trends to explore the new questions of\nmodern machine learning, with the strong afterthought that the belief function\nframework has a major role to play.", "journal": ""}
{"doi": "10.48550/arXiv.1505.06614", "date": "2015-05-25", "title": "Electre Tri-Machine Learning Approach to the Record Linkage Problem", "authors": "Renato De Leone, Valentina Minnetti", "abstract": "In this short paper, the Electre Tri-Machine Learning Method, generally used\nto solve ordinal classification problems, is proposed for solving the Record\nLinkage problem. Preliminary experimental results show that, using the Electre\nTri method, high accuracy can be achieved and more than 99% of the matches and\nnonmatches were correctly identified by the procedure.", "journal": ""}
{"doi": "10.48550/arXiv.1606.02767", "date": "2016-06-08", "title": "Theoretical Robopsychology: Samu Has Learned Turing Machines", "authors": "Norbert B\u00e1tfai", "abstract": "From the point of view of a programmer, the robopsychology is a synonym for\nthe activity is done by developers to implement their machine learning\napplications. This robopsychological approach raises some fundamental\ntheoretical questions of machine learning. Our discussion of these questions is\nconstrained to Turing machines. Alan Turing had given an algorithm (aka the\nTuring Machine) to describe algorithms. If it has been applied to describe\nitself then this brings us to Turing's notion of the universal machine. In the\npresent paper, we investigate algorithms to write algorithms. From a pedagogy\npoint of view, this way of writing programs can be considered as a combination\nof learning by listening and learning by doing due to it is based on applying\nagent technology and machine learning. As the main result we introduce the\nproblem of learning and then we show that it cannot easily be handled in\nreality therefore it is reasonable to use machine learning algorithm for\nlearning Turing machines.", "journal": ""}
{"doi": "10.48550/arXiv.1606.05386", "date": "2016-06-16", "title": "Model-Agnostic Interpretability of Machine Learning", "authors": "Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin", "abstract": "Understanding why machine learning models behave the way they do empowers\nboth system designers and end-users in many ways: in model selection, feature\nengineering, in order to trust and act upon the predictions, and in more\nintuitive user interfaces. Thus, interpretability has become a vital concern in\nmachine learning, and work in the area of interpretable models has found\nrenewed interest. In some applications, such models are as accurate as\nnon-interpretable ones, and thus are preferred for their transparency. Even\nwhen they are not accurate, they may still be preferred when interpretability\nis of paramount importance. However, restricting machine learning to\ninterpretable models is often a severe limitation. In this paper we argue for\nexplaining machine learning predictions using model-agnostic approaches. By\ntreating the machine learning models as black-box functions, these approaches\nprovide crucial flexibility in the choice of models, explanations, and\nrepresentations, improving debugging, comparison, and interfaces for a variety\nof users and models. We also outline the main challenges for such methods, and\nreview a recently-introduced model-agnostic explanation approach (LIME) that\naddresses these challenges.", "journal": ""}
{"doi": "10.48550/arXiv.1607.02531", "date": "2016-07-08", "title": "Proceedings of the 2016 ICML Workshop on Human Interpretability in Machine Learning (WHI 2016)", "authors": "Been Kim, Dmitry M. Malioutov, Kush R. Varshney", "abstract": "This is the Proceedings of the 2016 ICML Workshop on Human Interpretability\nin Machine Learning (WHI 2016), which was held in New York, NY, June 23, 2016.\n  Invited speakers were Susan Athey, Rich Caruana, Jacob Feldman, Percy Liang,\nand Hanna Wallach.", "journal": ""}
{"doi": "10.48550/arXiv.1706.08519", "date": "2017-06-26", "title": "On conditional parity as a notion of non-discrimination in machine learning", "authors": "Ya'acov Ritov, Yuekai Sun, Ruofei Zhao", "abstract": "We identify conditional parity as a general notion of non-discrimination in\nmachine learning. In fact, several recently proposed notions of\nnon-discrimination, including a few counterfactual notions, are instances of\nconditional parity. We show that conditional parity is amenable to statistical\nanalysis by studying randomization as a general mechanism for achieving\nconditional parity and a kernel-based test of conditional parity.", "journal": ""}
{"doi": "10.48550/arXiv.1807.01308", "date": "2018-07-03", "title": "Proceedings of the 2018 ICML Workshop on Human Interpretability in Machine Learning (WHI 2018)", "authors": "Been Kim, Kush R. Varshney, Adrian Weller", "abstract": "This is the Proceedings of the 2018 ICML Workshop on Human Interpretability\nin Machine Learning (WHI 2018), which was held in Stockholm, Sweden, July 14,\n2018. Invited speakers were Barbara Engelhardt, Cynthia Rudin, Fernanda\nVi\\'egas, and Martin Wattenberg.", "journal": ""}
{"doi": "10.48550/arXiv.1807.04162", "date": "2018-07-11", "title": "TherML: Thermodynamics of Machine Learning", "authors": "Alexander A. Alemi, Ian Fischer", "abstract": "In this work we offer a framework for reasoning about a wide class of\nexisting objectives in machine learning. We develop a formal correspondence\nbetween this work and thermodynamics and discuss its implications.", "journal": ""}
{"doi": "10.48550/arXiv.1807.05351", "date": "2018-07-14", "title": "ML-Schema: Exposing the Semantics of Machine Learning with Schemas and Ontologies", "authors": "Gustavo Correa Publio, Diego Esteves, Agnieszka \u0141awrynowicz, Pan\u010de Panov, Larisa Soldatova, Tommaso Soru, Joaquin Vanschoren, Hamid Zafar", "abstract": "The ML-Schema, proposed by the W3C Machine Learning Schema Community Group,\nis a top-level ontology that provides a set of classes, properties, and\nrestrictions for representing and interchanging information on machine learning\nalgorithms, datasets, and experiments. It can be easily extended and\nspecialized and it is also mapped to other more domain-specific ontologies\ndeveloped in the area of machine learning and data mining. In this paper we\noverview existing state-of-the-art machine learning interchange formats and\npresent the first release of ML-Schema, a canonical format resulted of more\nthan seven years of experience among different research institutions. We argue\nthat exposing semantics of machine learning algorithms, models, and experiments\nthrough a canonical format may pave the way to better interpretability and to\nrealistically achieve the full interoperability of experiments regardless of\nplatform or adopted workflow solution.", "journal": ""}
{"doi": "10.48550/arXiv.1812.10398", "date": "2018-12-21", "title": "Proceedings of NeurIPS 2018 Workshop on Machine Learning for the Developing World: Achieving Sustainable Impact", "authors": "Maria De-Arteaga, Amanda Coston, William Herlands", "abstract": "This is the Proceedings of NeurIPS 2018 Workshop on Machine Learning for the\nDeveloping World: Achieving Sustainable Impact, held in Montreal, Canada on\nDecember 8, 2018", "journal": ""}
{"doi": "10.48550/arXiv.1903.11726", "date": "2019-03-27", "title": "Radiological images and machine learning: trends, perspectives, and prospects", "authors": "Zhenwei Zhang, Ervin Sejdic", "abstract": "The application of machine learning to radiological images is an increasingly\nactive research area that is expected to grow in the next five to ten years.\nRecent advances in machine learning have the potential to recognize and\nclassify complex patterns from different radiological imaging modalities such\nas x-rays, computed tomography, magnetic resonance imaging and positron\nemission tomography imaging. In many applications, machine learning based\nsystems have shown comparable performance to human decision-making. The\napplications of machine learning are the key ingredients of future clinical\ndecision making and monitoring systems. This review covers the fundamental\nconcepts behind various machine learning techniques and their applications in\nseveral radiological imaging areas, such as medical image segmentation, brain\nfunction studies and neurological disease diagnosis, as well as computer-aided\nsystems, image registration, and content-based image retrieval systems.\nSynchronistically, we will briefly discuss current challenges and future\ndirections regarding the application of machine learning in radiological\nimaging. By giving insight on how take advantage of machine learning powered\napplications, we expect that clinicians can prevent and diagnose diseases more\naccurately and efficiently.", "journal": "Computers in Biology and Medicine (2019)"}
{"doi": "10.48550/arXiv.2006.01387", "date": "2020-06-02", "title": "A combinatorial conjecture from PAC-Bayesian machine learning", "authors": "M. Younsi, A. Lacasse", "abstract": "We present a proof of a combinatorial conjecture from the second author's\nPh.D. thesis. The proof relies on binomial and multinomial sums identities. We\nalso discuss the relevance of the conjecture in the context of PAC-Bayesian\nmachine learning.", "journal": ""}
{"doi": "10.48550/arXiv.2006.02619", "date": "2020-06-04", "title": "Integrating Machine Learning with Physics-Based Modeling", "authors": "Weinan E, Jiequn Han, Linfeng Zhang", "abstract": "Machine learning is poised as a very powerful tool that can drastically\nimprove our ability to carry out scientific research. However, many issues need\nto be addressed before this becomes a reality. This article focuses on one\nparticular issue of broad interest: How can we integrate machine learning with\nphysics-based modeling to develop new interpretable and truly reliable physical\nmodels? After introducing the general guidelines, we discuss the two most\nimportant issues for developing machine learning-based physical models:\nImposing physical constraints and obtaining optimal datasets. We also provide a\nsimple and intuitive explanation for the fundamental reasons behind the success\nof modern machine learning, as well as an introduction to the concurrent\nmachine learning framework needed for integrating machine learning with\nphysics-based modeling. Molecular dynamics and moment closure of kinetic\nequations are used as examples to illustrate the main issues discussed. We end\nwith a general discussion on where this integration will lead us to, and where\nthe new frontier will be after machine learning is successfully integrated into\nscientific modeling.", "journal": ""}
{"doi": "10.48550/arXiv.2006.07237", "date": "2020-06-12", "title": "Power Consumption Variation over Activation Functions", "authors": "Leon Derczynski", "abstract": "The power that machine learning models consume when making predictions can be\naffected by a model's architecture. This paper presents various estimates of\npower consumption for a range of different activation functions, a core factor\nin neural network model architecture design. Substantial differences in\nhardware performance exist between activation functions. This difference\ninforms how power consumption in machine learning models can be reduced.", "journal": ""}
{"doi": "10.48550/arXiv.2006.12270", "date": "2020-06-22", "title": "Classification with Quantum Machine Learning: A Survey", "authors": "Zainab Abohashima, Mohamed Elhosen, Essam H. Houssein, Waleed M. Mohamed", "abstract": "Due to the superiority and noteworthy progress of Quantum Computing (QC) in a\nlot of applications such as cryptography, chemistry, Big data, machine\nlearning, optimization, Internet of Things (IoT), Blockchain, communication,\nand many more. Fully towards to combine classical machine learning (ML) with\nQuantum Information Processing (QIP) to build a new field in the quantum world\nis called Quantum Machine Learning (QML) to solve and improve problems that\ndisplayed in classical machine learning (e.g. time and energy consumption,\nkernel estimation). The aim of this paper presents and summarizes a\ncomprehensive survey of the state-of-the-art advances in Quantum Machine\nLearning (QML). Especially, recent QML classification works. Also, we cover\nabout 30 publications that are published lately in Quantum Machine Learning\n(QML). we propose a classification scheme in the quantum world and discuss\nencoding methods for mapping classical data to quantum data. Then, we provide\nquantum subroutines and some methods of Quantum Computing (QC) in improving\nperformance and speed up of classical Machine Learning (ML). And also some of\nQML applications in various fields, challenges, and future vision will be\npresented.", "journal": ""}
{"doi": "10.48550/arXiv.1703.10121", "date": "2017-03-29", "title": "The Top 10 Topics in Machine Learning Revisited: A Quantitative Meta-Study", "authors": "Patrick Glauner, Manxing Du, Victor Paraschiv, Andrey Boytsov, Isabel Lopez Andrade, Jorge Meira, Petko Valtchev, Radu State", "abstract": "Which topics of machine learning are most commonly addressed in research?\nThis question was initially answered in 2007 by doing a qualitative survey\namong distinguished researchers. In our study, we revisit this question from a\nquantitative perspective. Concretely, we collect 54K abstracts of papers\npublished between 2007 and 2016 in leading machine learning journals and\nconferences. We then use machine learning in order to determine the top 10\ntopics in machine learning. We not only include models, but provide a holistic\nview across optimization, data, features, etc. This quantitative approach\nallows reducing the bias of surveys. It reveals new and up-to-date insights\ninto what the 10 most prolific topics in machine learning research are. This\nallows researchers to identify popular topics as well as new and rising topics\nfor their research.", "journal": "Proceedings of the 25th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN 2017)"}
{"doi": "10.48550/arXiv.1805.04272", "date": "2018-05-11", "title": "An $O(N)$ Sorting Algorithm: Machine Learning Sort", "authors": "Hanqing Zhao, Yuehan Luo", "abstract": "We propose an $O(N\\cdot M)$ sorting algorithm by Machine Learning method,\nwhich shows a huge potential sorting big data. This sorting algorithm can be\napplied to parallel sorting and is suitable for GPU or TPU acceleration.\nFurthermore, we discuss the application of this algorithm to sparse hash table.", "journal": ""}
{"doi": "10.48550/arXiv.1904.01957", "date": "2019-04-02", "title": "A Game of Dice: Machine Learning and the Question Concerning Art", "authors": "Paul Todorov", "abstract": "We review some practical and philosophical questions raised by the use of\nmachine learning in creative practice. Beyond the obvious problems regarding\nplagiarism and authorship, we argue that the novelty in AI Art relies mostly on\na narrow machine learning contribution : manifold approximation. Nevertheless,\nthis contribution creates a radical shift in the way we have to consider this\nmovement. Is this omnipotent tool a blessing or a curse for the artists?", "journal": ""}
{"doi": "10.48550/arXiv.2201.12428", "date": "2022-01-28", "title": "Systematic Training and Testing for Machine Learning Using Combinatorial Interaction Testing", "authors": "Tyler Cody, Erin Lanus, Daniel D. Doyle, Laura Freeman", "abstract": "This paper demonstrates the systematic use of combinatorial coverage for\nselecting and characterizing test and training sets for machine learning\nmodels. The presented work adapts combinatorial interaction testing, which has\nbeen successfully leveraged in identifying faults in software testing, to\ncharacterize data used in machine learning. The MNIST hand-written digits data\nis used to demonstrate that combinatorial coverage can be used to select test\nsets that stress machine learning model performance, to select training sets\nthat lead to robust model performance, and to select data for fine-tuning\nmodels to new domains. Thus, the results posit combinatorial coverage as a\nholistic approach to training and testing for machine learning. In contrast to\nprior work which has focused on the use of coverage in regard to the internal\nof neural networks, this paper considers coverage over simple features derived\nfrom inputs and outputs. Thus, this paper addresses the case where the supplier\nof test and training sets for machine learning models does not have\nintellectual property rights to the models themselves. Finally, the paper\naddresses prior criticism of combinatorial coverage and provides a rebuttal\nwhich advocates the use of coverage metrics in machine learning applications.", "journal": ""}
{"doi": "10.48550/arXiv.1708.02666", "date": "2017-08-08", "title": "Proceedings of the 2017 ICML Workshop on Human Interpretability in Machine Learning (WHI 2017)", "authors": "Been Kim, Dmitry M. Malioutov, Kush R. Varshney, Adrian Weller", "abstract": "This is the Proceedings of the 2017 ICML Workshop on Human Interpretability\nin Machine Learning (WHI 2017), which was held in Sydney, Australia, August 10,\n2017. Invited speakers were Tony Jebara, Pang Wei Koh, and David Sontag.", "journal": ""}
{"doi": "10.48550/arXiv.1804.11238", "date": "2018-03-27", "title": "Privacy Preserving Machine Learning: Threats and Solutions", "authors": "Mohammad Al-Rubaie, J. Morris Chang", "abstract": "For privacy concerns to be addressed adequately in current machine learning\nsystems, the knowledge gap between the machine learning and privacy communities\nmust be bridged. This article aims to provide an introduction to the\nintersection of both fields with special emphasis on the techniques used to\nprotect the data.", "journal": ""}
{"doi": "10.48550/arXiv.1811.04871", "date": "2018-11-12", "title": "Characterizing machine learning process: A maturity framework", "authors": "Rama Akkiraju, Vibha Sinha, Anbang Xu, Jalal Mahmud, Pritam Gundecha, Zhe Liu, Xiaotong Liu, John Schumacher", "abstract": "Academic literature on machine learning modeling fails to address how to make\nmachine learning models work for enterprises. For example, existing machine\nlearning processes cannot address how to define business use cases for an AI\napplication, how to convert business requirements from offering managers into\ndata requirements for data scientists, and how to continuously improve AI\napplications in term of accuracy and fairness, and how to customize general\npurpose machine learning models with industry, domain, and use case specific\ndata to make them more accurate for specific situations etc. Making AI work for\nenterprises requires special considerations, tools, methods and processes. In\nthis paper we present a maturity framework for machine learning model lifecycle\nmanagement for enterprises. Our framework is a re-interpretation of the\nsoftware Capability Maturity Model (CMM) for machine learning model development\nprocess. We present a set of best practices from our personal experience of\nbuilding large scale real-world machine learning models to help organizations\nachieve higher levels of maturity independent of their starting point.", "journal": ""}
{"doi": "10.48550/arXiv.1811.11669", "date": "2018-11-28", "title": "Towards Identifying and Managing Sources of Uncertainty in AI and Machine Learning Models - An Overview", "authors": "Michael Kl\u00e4s", "abstract": "Quantifying and managing uncertainties that occur when data-driven models\nsuch as those provided by AI and machine learning methods are applied is\ncrucial. This whitepaper provides a brief motivation and first overview of the\nstate of the art in identifying and quantifying sources of uncertainty for\ndata-driven components as well as means for analyzing their impact.", "journal": ""}
{"doi": "10.48550/arXiv.1911.09052", "date": "2019-11-08", "title": "Collaborative Machine Learning Markets with Data-Replication-Robust Payments", "authors": "Olga Ohrimenko, Shruti Tople, Sebastian Tschiatschek", "abstract": "We study the problem of collaborative machine learning markets where multiple\nparties can achieve improved performance on their machine learning tasks by\ncombining their training data. We discuss desired properties for these machine\nlearning markets in terms of fair revenue distribution and potential threats,\nincluding data replication. We then instantiate a collaborative market for\ncases where parties share a common machine learning task and where parties'\ntasks are different. Our marketplace incentivizes parties to submit high\nquality training and true validation data. To this end, we introduce a novel\npayment division function that is robust-to-replication and customized output\nmodels that perform well only on requested machine learning tasks. In\nexperiments, we validate the assumptions underlying our theoretical analysis\nand show that these are approximately satisfied for commonly used machine\nlearning models.", "journal": ""}
{"doi": "10.48550/arXiv.1912.07323", "date": "2019-12-16", "title": "Analysis of Software Engineering for Agile Machine Learning Projects", "authors": "Kushal Singla, Joy Bose, Chetan Naik", "abstract": "The number of machine learning, artificial intelligence or data science\nrelated software engineering projects using Agile methodology is increasing.\nHowever, there are very few studies on how such projects work in practice. In\nthis paper, we analyze project issues tracking data taken from Scrum (a popular\ntool for Agile) for several machine learning projects. We compare this data\nwith corresponding data from non-machine learning projects, in an attempt to\nanalyze how machine learning projects are executed differently from normal\nsoftware engineering projects. On analysis, we find that machine learning\nproject issues use different kinds of words to describe issues, have higher\nnumber of exploratory or research oriented tasks as compared to implementation\ntasks, and have a higher number of issues in the product backlog after each\nsprint, denoting that it is more difficult to estimate the duration of machine\nlearning project related tasks in advance. After analyzing this data, we\npropose a few ways in which Agile machine learning projects can be better\nlogged and executed, given their differences with normal software engineering\nprojects.", "journal": ""}
{"doi": "10.48550/arXiv.2005.00478", "date": "2020-05-01", "title": "DriveML: An R Package for Driverless Machine Learning", "authors": "Sayan Putatunda, Dayananda Ubrangala, Kiran Rama, Ravi Kondapalli", "abstract": "In recent years, the concept of automated machine learning has become very\npopular. Automated Machine Learning (AutoML) mainly refers to the automated\nmethods for model selection and hyper-parameter optimization of various\nalgorithms such as random forests, gradient boosting, neural networks, etc. In\nthis paper, we introduce a new package i.e. DriveML for automated machine\nlearning. DriveML helps in implementing some of the pillars of an automated\nmachine learning pipeline such as automated data preparation, feature\nengineering, model building and model explanation by running the function\ninstead of writing lengthy R codes. The DriveML package is available in CRAN.\nWe compare the DriveML package with other relevant packages in CRAN/Github and\nfind that DriveML performs the best across different parameters. We also\nprovide an illustration by applying the DriveML package with default\nconfiguration on a real world dataset. Overall, the main benefits of DriveML\nare in development time savings, reduce developer's errors, optimal tuning of\nmachine learning models and reproducibility.", "journal": ""}
{"doi": "10.48550/arXiv.2009.14596", "date": "2020-09-23", "title": "Machine Learning and Computational Mathematics", "authors": "Weinan E", "abstract": "Neural network-based machine learning is capable of approximating functions\nin very high dimension with unprecedented efficiency and accuracy. This has\nopened up many exciting new possibilities, not just in traditional areas of\nartificial intelligence, but also in scientific computing and computational\nscience. At the same time, machine learning has also acquired the reputation of\nbeing a set of \"black box\" type of tricks, without fundamental principles. This\nhas been a real obstacle for making further progress in machine learning. In\nthis article, we try to address the following two very important questions: (1)\nHow machine learning has already impacted and will further impact computational\nmathematics, scientific computing and computational science? (2) How\ncomputational mathematics, particularly numerical analysis, {can} impact\nmachine learning? We describe some of the most important progress that has been\nmade on these issues. Our hope is to put things into a perspective that will\nhelp to integrate machine learning with computational mathematics.", "journal": ""}
{"doi": "10.48550/arXiv.2011.04328", "date": "2020-11-09", "title": "Risk Assessment for Machine Learning Models", "authors": "Paul Schwerdtner, Florens Gre\u00dfner, Nikhil Kapoor, Felix Assion, Ren\u00e9 Sass, Wiebke G\u00fcnther, Fabian H\u00fcger, Peter Schlicht", "abstract": "In this paper we propose a framework for assessing the risk associated with\ndeploying a machine learning model in a specified environment. For that we\ncarry over the risk definition from decision theory to machine learning. We\ndevelop and implement a method that allows to define deployment scenarios, test\nthe machine learning model under the conditions specified in each scenario, and\nestimate the damage associated with the output of the machine learning model\nunder test. Using the likelihood of each scenario together with the estimated\ndamage we define \\emph{key risk indicators} of a machine learning model.\n  The definition of scenarios and weighting by their likelihood allows for\nstandardized risk assessment in machine learning throughout multiple domains of\napplication. In particular, in our framework, the robustness of a machine\nlearning model to random input corruptions, distributional shifts caused by a\nchanging environment, and adversarial perturbations can be assessed.", "journal": ""}
{"doi": "10.48550/arXiv.2101.12097", "date": "2021-01-28", "title": "Adversarial Machine Learning Attacks on Condition-Based Maintenance Capabilities", "authors": "Hamidreza Habibollahi Najaf Abadi", "abstract": "Condition-based maintenance (CBM) strategies exploit machine learning models\nto assess the health status of systems based on the collected data from the\nphysical environment, while machine learning models are vulnerable to\nadversarial attacks. A malicious adversary can manipulate the collected data to\ndeceive the machine learning model and affect the CBM system's performance.\nAdversarial machine learning techniques introduced in the computer vision\ndomain can be used to make stealthy attacks on CBM systems by adding\nperturbation to data to confuse trained models. The stealthy nature causes\ndifficulty and delay in detection of the attacks. In this paper, adversarial\nmachine learning in the domain of CBM is introduced. A case study shows how\nadversarial machine learning can be used to attack CBM capabilities.\nAdversarial samples are crafted using the Fast Gradient Sign method, and the\nperformance of a CBM system under attack is investigated. The obtained results\nreveal that CBM systems are vulnerable to adversarial machine learning attacks\nand defense strategies need to be considered.", "journal": ""}
{"doi": "10.48550/arXiv.2103.00366", "date": "2021-02-28", "title": "Confronting Machine Learning With Financial Research", "authors": "Kristof Lommers, Ouns El Harzli, Jack Kim", "abstract": "This study aims to examine the challenges and applications of machine\nlearning for financial research. Machine learning algorithms have been\ndeveloped for certain data environments which substantially differ from the one\nwe encounter in finance. Not only do difficulties arise due to some of the\nidiosyncrasies of financial markets, there is a fundamental tension between the\nunderlying paradigm of machine learning and the research philosophy in\nfinancial economics. Given the peculiar features of financial markets and the\nempirical framework within social science, various adjustments have to be made\nto the conventional machine learning methodology. We discuss some of the main\nchallenges of machine learning in finance and examine how these could be\naccounted for. Despite some of the challenges, we argue that machine learning\ncould be unified with financial research to become a robust complement to the\neconometrician's toolbox. Moreover, we discuss the various applications of\nmachine learning in the research process such as estimation, empirical\ndiscovery, testing, causal inference and prediction.", "journal": ""}
{"doi": "10.48550/arXiv.2108.09664", "date": "2021-08-22", "title": "New Trends in Quantum Machine Learning", "authors": "Lorenzo Buffoni, Filippo Caruso", "abstract": "Here we will give a perspective on new possible interplays between Machine\nLearning and Quantum Physics, including also practical cases and applications.\nWe will explore the ways in which machine learning could benefit from new\nquantum technologies and algorithms to find new ways to speed up their\ncomputations by breakthroughs in physical hardware, as well as to improve\nexisting models or devise new learning schemes in the quantum domain. Moreover,\nthere are lots of experiments in quantum physics that do generate incredible\namounts of data and machine learning would be a great tool to analyze those and\nmake predictions, or even control the experiment itself. On top of that, data\nvisualization techniques and other schemes borrowed from machine learning can\nbe of great use to theoreticians to have better intuition on the structure of\ncomplex manifolds or to make predictions on theoretical models. This new\nresearch field, named as Quantum Machine Learning, is very rapidly growing\nsince it is expected to provide huge advantages over its classical counterpart\nand deeper investigations are timely needed since they can be already tested on\nthe already commercially available quantum machines.", "journal": "EPL, 132 (2021) 60004"}
{"doi": "10.48550/arXiv.2205.00210", "date": "2022-04-30", "title": "Software Testing for Machine Learning", "authors": "Dusica Marijan, Arnaud Gotlieb", "abstract": "Machine learning has become prevalent across a wide variety of applications.\nUnfortunately, machine learning has also shown to be susceptible to deception,\nleading to errors, and even fatal failures. This circumstance calls into\nquestion the widespread use of machine learning, especially in safety-critical\napplications, unless we are able to assure its correctness and trustworthiness\nproperties. Software verification and testing are established technique for\nassuring such properties, for example by detecting errors. However, software\ntesting challenges for machine learning are vast and profuse - yet critical to\naddress. This summary talk discusses the current state-of-the-art of software\ntesting for machine learning. More specifically, it discusses six key challenge\nareas for software testing of machine learning systems, examines current\napproaches to these challenges and highlights their limitations. The paper\nprovides a research agenda with elaborated directions for making progress\ntoward advancing the state-of-the-art on testing of machine learning.", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence,\n  34(09), 13576-13582 (2020)"}
{"doi": "10.48550/arXiv.2205.09488", "date": "2022-05-02", "title": "PSI Draft Specification", "authors": "Mark Reid, James Montgomery, Barry Drake, Avraham Ruderman", "abstract": "This document presents the draft specification for delivering machine\nlearning services over HTTP, developed as part of the Protocols and Structures\nfor Inference project, which concluded in 2013. It presents the motivation for\nproviding machine learning as a service, followed by a description of the\nessential and optional components of such a service.", "journal": ""}
{"doi": "10.48550/arXiv.2207.05548", "date": "2022-07-12", "title": "Practical Attacks on Machine Learning: A Case Study on Adversarial Windows Malware", "authors": "Luca Demetrio, Battista Biggio, Fabio Roli", "abstract": "While machine learning is vulnerable to adversarial examples, it still lacks\nsystematic procedures and tools for evaluating its security in different\napplication contexts. In this article, we discuss how to develop automated and\nscalable security evaluations of machine learning using practical attacks,\nreporting a use case on Windows malware detection.", "journal": "IEEE Security & Privacy, 2022"}
{"doi": "10.48550/arXiv.2207.13596", "date": "2022-07-27", "title": "Fairness and Randomness in Machine Learning: Statistical Independence and Relativization", "authors": "Rabanus Derr, Robert C. Williamson", "abstract": "Fair Machine Learning endeavors to prevent unfairness arising in the context\nof machine learning applications embedded in society. Despite the variety of\ndefinitions of fairness and proposed \"fair algorithms\", there remain unresolved\nconceptual problems regarding fairness. In this paper, we dissect the role of\nstatistical independence in fairness and randomness notions regularly used in\nmachine learning. Thereby, we are led to a suprising hypothesis: randomness and\nfairness can be considered equivalent concepts in machine learning.\n  In particular, we obtain a relativized notion of randomness expressed as\nstatistical independence by appealing to Von Mises' century-old foundations for\nprobability. This notion turns out to be \"orthogonal\" in an abstract sense to\nthe commonly used i.i.d.-randomness. Using standard fairness notions in machine\nlearning, which are defined via statistical independence, we then link the ex\nante randomness assumptions about the data to the ex post requirements for fair\npredictions. This connection proves fruitful: we use it to argue that\nrandomness and fairness are essentially relative and that both concepts should\nreflect their nature as modeling assumptions in machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.2208.10463", "date": "2022-08-22", "title": "Survey of Machine Learning Techniques To Predict Heartbeat Arrhythmias", "authors": "Samuel Armstrong", "abstract": "Many works in biomedical computer science research use machine learning\ntechniques to give accurate results. However, these techniques may not be\nfeasible for real-time analysis of data pulled from live hospital feeds. In\nthis project, different machine learning techniques are compared from various\nsources to find one that provides not only high accuracy but also low latency\nand memory overhead to be used in real-world health care systems.", "journal": ""}
{"doi": "10.48550/arXiv.2209.06529", "date": "2022-09-14", "title": "Data Privacy and Trustworthy Machine Learning", "authors": "Martin Strobel, Reza Shokri", "abstract": "The privacy risks of machine learning models is a major concern when training\nthem on sensitive and personal data. We discuss the tradeoffs between data\nprivacy and the remaining goals of trustworthy machine learning (notably,\nfairness, robustness, and explainability).", "journal": "Published in: IEEE Security & Privacy ( Volume: 20, Issue: 5,\n  Sept.-Oct. 2022)"}
{"doi": "10.48550/arXiv.2212.13988", "date": "2022-12-12", "title": "Machine Learning for Detecting Malware in PE Files", "authors": "Collin Connors, Dilip Sarkar", "abstract": "The increasing number of sophisticated malware poses a major cybersecurity\nthreat. Portable executable (PE) files are a common vector for such malware. In\nthis work we review and evaluate machine learning-based PE malware detection\ntechniques. Using a large benchmark dataset, we evaluate features of PE files\nusing the most common machine learning techniques to detect malware.", "journal": ""}
{"doi": "10.48550/arXiv.2303.13735", "date": "2023-03-24", "title": "An investigation of licensing of datasets for machine learning based on the GQM model", "authors": "Junyu Chen, Norihiro Yoshida, Hiroaki Takada", "abstract": "Dataset licensing is currently an issue in the development of machine\nlearning systems. And in the development of machine learning systems, the most\nwidely used are publicly available datasets. However, since the images in the\npublicly available dataset are mainly obtained from the Internet, some images\nare not commercially available. Furthermore, developers of machine learning\nsystems do not often care about the license of the dataset when training\nmachine learning models with it. In summary, the licensing of datasets for\nmachine learning systems is in a state of incompleteness in all aspects at this\nstage.\n  Our investigation of two collection datasets revealed that most of the\ncurrent datasets lacked licenses, and the lack of licenses made it impossible\nto determine the commercial availability of the datasets. Therefore, we decided\nto take a more scientific and systematic approach to investigate the licensing\nof datasets and the licensing of machine learning systems that use the dataset\nto make it easier and more compliant for future developers of machine learning\nsystems.", "journal": ""}
{"doi": "10.48550/arXiv.2403.02467", "date": "2024-03-04", "title": "Applied Causal Inference Powered by ML and AI", "authors": "Victor Chernozhukov, Christian Hansen, Nathan Kallus, Martin Spindler, Vasilis Syrgkanis", "abstract": "An introduction to the emerging fusion of machine learning and causal\ninference. The book presents ideas from classical structural equation models\n(SEMs) and their modern AI equivalent, directed acyclical graphs (DAGs) and\nstructural causal models (SCMs), and covers Double/Debiased Machine Learning\nmethods to do inference in such models using modern predictive tools.", "journal": ""}
{"doi": "10.48550/arXiv.2501.10369", "date": "2024-12-12", "title": "Creative Loss: Ambiguity, Uncertainty and Indeterminacy", "authors": "Tom Holberton", "abstract": "This article evaluates how creative uses of machine learning can address\nthree adjacent terms: ambiguity, uncertainty and indeterminacy. Through the\nprogression of these concepts it reflects on increasing ambitions for machine\nlearning as a creative partner, illustrated with research from Unit 21 at the\nBartlett School of Architecture, UCL. Through indeterminacy are potential\nfuture approaches to machine learning and design.", "journal": ""}
{"doi": "10.48550/arXiv.2502.16931", "date": "2025-02-24", "title": "Machine learning and high dimensional vector search", "authors": "Matthijs Douze", "abstract": "Machine learning and vector search are two research topics that developed in\nparallel in nearby communities. However, unlike many other fields related to\nbig data, machine learning has not significantly impacted vector search. In\nthis opinion paper we attempt to explain this oddity. Along the way, we wander\nover the numerous bridges between the two fields.", "journal": ""}
{"doi": "10.48550/arXiv.2009.08497", "date": "2020-09-17", "title": "The Next Big Thing(s) in Unsupervised Machine Learning: Five Lessons from Infant Learning", "authors": "Lorijn Zaadnoordijk, Tarek R. Besold, Rhodri Cusack", "abstract": "After a surge in popularity of supervised Deep Learning, the desire to reduce\nthe dependence on curated, labelled data sets and to leverage the vast\nquantities of unlabelled data available recently triggered renewed interest in\nunsupervised learning algorithms. Despite a significantly improved performance\ndue to approaches such as the identification of disentangled latent\nrepresentations, contrastive learning, and clustering optimisations, the\nperformance of unsupervised machine learning still falls short of its\nhypothesised potential. Machine learning has previously taken inspiration from\nneuroscience and cognitive science with great success. However, this has mostly\nbeen based on adult learners with access to labels and a vast amount of prior\nknowledge. In order to push unsupervised machine learning forward, we argue\nthat developmental science of infant cognition might hold the key to unlocking\nthe next generation of unsupervised learning approaches. Conceptually, human\ninfant learning is the closest biological parallel to artificial unsupervised\nlearning, as infants too must learn useful representations from unlabelled\ndata. In contrast to machine learning, these new representations are learned\nrapidly and from relatively few examples. Moreover, infants learn robust\nrepresentations that can be used flexibly and efficiently in a number of\ndifferent tasks and contexts. We identify five crucial factors enabling\ninfants' quality and speed of learning, assess the extent to which these have\nalready been exploited in machine learning, and propose how further adoption of\nthese factors can give rise to previously unseen performance levels in\nunsupervised learning.", "journal": ""}
{"doi": "10.48550/arXiv.2004.11149", "date": "2020-04-17", "title": "A Comprehensive Overview and Survey of Recent Advances in Meta-Learning", "authors": "Huimin Peng", "abstract": "This article reviews meta-learning also known as learning-to-learn which\nseeks rapid and accurate model adaptation to unseen tasks with applications in\nhighly automated AI, few-shot learning, natural language processing and\nrobotics. Unlike deep learning, meta-learning can be applied to few-shot\nhigh-dimensional datasets and considers further improving model generalization\nto unseen tasks. Deep learning is focused upon in-sample prediction and\nmeta-learning concerns model adaptation for out-of-sample prediction.\nMeta-learning can continually perform self-improvement to achieve highly\nautonomous AI. Meta-learning may serve as an additional generalization block\ncomplementary for original deep learning model. Meta-learning seeks adaptation\nof machine learning models to unseen tasks which are vastly different from\ntrained tasks. Meta-learning with coevolution between agent and environment\nprovides solutions for complex tasks unsolvable by training from scratch.\nMeta-learning methodology covers a wide range of great minds and thoughts. We\nbriefly introduce meta-learning methodologies in the following categories:\nblack-box meta-learning, metric-based meta-learning, layered meta-learning and\nBayesian meta-learning framework. Recent applications concentrate upon the\nintegration of meta-learning with other machine learning framework to provide\nfeasible integrated problem solutions. We briefly present recent meta-learning\nadvances and discuss potential future research directions.", "journal": ""}
{"doi": "10.48550/arXiv.1705.10201", "date": "2017-05-29", "title": "Machine Learned Learning Machines", "authors": "Leigh Sheneman, Arend Hintze", "abstract": "There are two common approaches for optimizing the performance of a machine:\ngenetic algorithms and machine learning. A genetic algorithm is applied over\nmany generations whereas machine learning works by applying feedback until the\nsystem meets a performance threshold. Though these are methods that typically\noperate separately, we combine evolutionary adaptation and machine learning\ninto one approach. Our focus is on machines that can learn during their\nlifetime, but instead of equipping them with a machine learning algorithm we\naim to let them evolve their ability to learn by themselves. We use evolvable\nnetworks of probabilistic and deterministic logic gates, known as Markov\nBrains, as our computational model organism. The ability of Markov Brains to\nlearn is augmented by a novel adaptive component that can change its\ncomputational behavior based on feedback. We show that Markov Brains can indeed\nevolve to incorporate these feedback gates to improve their adaptability to\nvariable environments. By combining these two methods, we now also implemented\na computational model that can be used to study the evolution of learning.", "journal": ""}
{"doi": "10.48550/arXiv.1912.05796", "date": "2019-12-12", "title": "Automatic Layout Generation with Applications in Machine Learning Engine Evaluation", "authors": "Haoyu Yang, Wen Chen, Piyush Pathak, Frank Gennari, Ya-Chieh Lai, Bei Yu", "abstract": "Machine learning-based lithography hotspot detection has been deeply studied\nrecently, from varies feature extraction techniques to efficient learning\nmodels. It has been observed that such machine learning-based frameworks are\nproviding satisfactory metal layer hotspot prediction results on known public\nmetal layer benchmarks. In this work, we seek to evaluate how these machine\nlearning-based hotspot detectors generalize to complicated patterns. We first\nintroduce a automatic layout generation tool that can synthesize varies layout\npatterns given a set of design rules. The tool currently supports both metal\nlayer and via layer generation. As a case study, we conduct hotspot detection\non the generated via layer layouts with representative machine learning-based\nhotspot detectors, which shows that continuous study on model robustness and\ngenerality is necessary to prototype and integrate the learning engines in DFM\nflows. The source code of the layout generation tool will be available at\nhttps://github. com/phdyang007/layout-generation.", "journal": ""}
{"doi": "10.48550/arXiv.2004.12076", "date": "2020-04-25", "title": "Quantum machine learning and quantum biomimetics: A perspective", "authors": "Lucas Lamata", "abstract": "Quantum machine learning has emerged as an exciting and promising paradigm\ninside quantum technologies. It may permit, on the one hand, to carry out more\nefficient machine learning calculations by means of quantum devices, while, on\nthe other hand, to employ machine learning techniques to better control quantum\nsystems. Inside quantum machine learning, quantum reinforcement learning aims\nat developing \"intelligent\" quantum agents that may interact with the outer\nworld and adapt to it, with the strategy of achieving some final goal. Another\nparadigm inside quantum machine learning is that of quantum autoencoders, which\nmay allow one for employing fewer resources in a quantum device via a training\nprocess. Moreover, the field of quantum biomimetics aims at establishing\nanalogies between biological and quantum systems, to look for previously\ninadvertent connections that may enable useful applications. Two recent\nexamples are the concepts of quantum artificial life, as well as of quantum\nmemristors. In this Perspective, we give an overview of these topics,\ndescribing the related research carried out by the scientific community.", "journal": "Mach. Learn.: Sci. Technol. 1, 033002 (2020)"}
{"doi": "10.48550/arXiv.2306.16156", "date": "2023-06-28", "title": "Recent Advances in Optimal Transport for Machine Learning", "authors": "Eduardo Fernandes Montesuma, Fred Ngol\u00e8 Mboula, Antoine Souloumiac", "abstract": "Recently, Optimal Transport has been proposed as a probabilistic framework in\nMachine Learning for comparing and manipulating probability distributions. This\nis rooted in its rich history and theory, and has offered new solutions to\ndifferent problems in machine learning, such as generative modeling and\ntransfer learning. In this survey we explore contributions of Optimal Transport\nfor Machine Learning over the period 2012 -- 2023, focusing on four sub-fields\nof Machine Learning: supervised, unsupervised, transfer and reinforcement\nlearning. We further highlight the recent development in computational Optimal\nTransport and its extensions, such as partial, unbalanced, Gromov and Neural\nOptimal Transport, and its interplay with Machine Learning practice.", "journal": ""}
{"doi": "10.48550/arXiv.1911.11374", "date": "2019-11-26", "title": "Representation Learning: A Statistical Perspective", "authors": "Jianwen Xie, Ruiqi Gao, Erik Nijkamp, Song-Chun Zhu, Ying Nian Wu", "abstract": "Learning representations of data is an important problem in statistics and\nmachine learning. While the origin of learning representations can be traced\nback to factor analysis and multidimensional scaling in statistics, it has\nbecome a central theme in deep learning with important applications in computer\nvision and computational neuroscience. In this article, we review recent\nadvances in learning representations from a statistical perspective. In\nparticular, we review the following two themes: (a) unsupervised learning of\nvector representations and (b) learning of both vector and matrix\nrepresentations.", "journal": "Annual Review of Statistics and Its Application 2020"}
{"doi": "10.48550/arXiv.2002.03123", "date": "2020-02-08", "title": "Towards a combinatorial characterization of bounded memory learning", "authors": "Alon Gonen, Shachar Lovett, Michal Moshkovitz", "abstract": "Combinatorial dimensions play an important role in the theory of machine\nlearning. For example, VC dimension characterizes PAC learning, SQ dimension\ncharacterizes weak learning with statistical queries, and Littlestone dimension\ncharacterizes online learning.\n  In this paper we aim to develop combinatorial dimensions that characterize\nbounded memory learning. We propose a candidate solution for the case of\nrealizable strong learning under a known distribution, based on the SQ\ndimension of neighboring distributions. We prove both upper and lower bounds\nfor our candidate solution, that match in some regime of parameters. In this\nparameter regime there is an equivalence between bounded memory and SQ\nlearning. We conjecture that our characterization holds in a much wider regime\nof parameters.", "journal": ""}
{"doi": "10.48550/arXiv.1606.08531", "date": "2016-06-28", "title": "A Learning Algorithm for Relational Logistic Regression: Preliminary Results", "authors": "Bahare Fatemi, Seyed Mehran Kazemi, David Poole", "abstract": "Relational logistic regression (RLR) is a representation of conditional\nprobability in terms of weighted formulae for modelling multi-relational data.\nIn this paper, we develop a learning algorithm for RLR models. Learning an RLR\nmodel from data consists of two steps: 1- learning the set of formulae to be\nused in the model (a.k.a. structure learning) and learning the weight of each\nformula (a.k.a. parameter learning). For structure learning, we deploy Schmidt\nand Murphy's hierarchical assumption: first we learn a model with simple\nformulae, then more complex formulae are added iteratively only if all their\nsub-formulae have proven effective in previous learned models. For parameter\nlearning, we convert the problem into a non-relational learning problem and use\nan off-the-shelf logistic regression learning algorithm from Weka, an\nopen-source machine learning tool, to learn the weights. We also indicate how\nhidden features about the individuals can be incorporated into RLR to boost the\nlearning performance. We compare our learning algorithm to other structure and\nparameter learning algorithms in the literature, and compare the performance of\nRLR models to standard logistic regression and RDN-Boost on a modified version\nof the MovieLens data-set.", "journal": ""}
{"doi": "10.48550/arXiv.1908.09788", "date": "2019-08-26", "title": "An Introduction to Advanced Machine Learning : Meta Learning Algorithms, Applications and Promises", "authors": "Farid Ghareh Mohammadi, M. Hadi Amini, Hamid R. Arabnia", "abstract": "In [1, 2], we have explored the theoretical aspects of feature extraction\noptimization processes for solving largescale problems and overcoming machine\nlearning limitations. Majority of optimization algorithms that have been\nintroduced in [1, 2] guarantee the optimal performance of supervised learning,\ngiven offline and discrete data, to deal with curse of dimensionality (CoD)\nproblem. These algorithms, however, are not tailored for solving emerging\nlearning problems. One of the important issues caused by online data is lack of\nsufficient samples per class. Further, traditional machine learning algorithms\ncannot achieve accurate training based on limited distributed data, as data has\nproliferated and dispersed significantly. Machine learning employs a strict\nmodel or embedded engine to train and predict which still fails to learn unseen\nclasses and sufficiently use online data. In this chapter, we introduce these\nchallenges elaborately. We further investigate Meta-Learning (MTL) algorithm,\nand their application and promises to solve the emerging problems by answering\nhow autonomous agents can learn to learn?.", "journal": ""}
{"doi": "10.48550/arXiv.2211.02263", "date": "2022-11-04", "title": "Impact Learning: A Learning Method from Features Impact and Competition", "authors": "Nusrat Jahan Prottasha, Saydul Akbar Murad, Abu Jafar Md Muzahid, Masud Rana, Md Kowsher, Apurba Adhikary, Sujit Biswas, Anupam Kumar Bairagi", "abstract": "Machine learning is the study of computer algorithms that can automatically\nimprove based on data and experience. Machine learning algorithms build a model\nfrom sample data, called training data, to make predictions or judgments\nwithout being explicitly programmed to do so. A variety of wellknown machine\nlearning algorithms have been developed for use in the field of computer\nscience to analyze data. This paper introduced a new machine learning algorithm\ncalled impact learning. Impact learning is a supervised learning algorithm that\ncan be consolidated in both classification and regression problems. It can\nfurthermore manifest its superiority in analyzing competitive data. This\nalgorithm is remarkable for learning from the competitive situation and the\ncompetition comes from the effects of autonomous features. It is prepared by\nthe impacts of the highlights from the intrinsic rate of natural increase\n(RNI). We, moreover, manifest the prevalence of the impact learning over the\nconventional machine learning algorithm.", "journal": ""}
{"doi": "10.48550/arXiv.2104.02466", "date": "2021-04-06", "title": "A Review of Formal Methods applied to Machine Learning", "authors": "Caterina Urban, Antoine Min\u00e9", "abstract": "We review state-of-the-art formal methods applied to the emerging field of\nthe verification of machine learning systems. Formal methods can provide\nrigorous correctness guarantees on hardware and software systems. Thanks to the\navailability of mature tools, their use is well established in the industry,\nand in particular to check safety-critical applications as they undergo a\nstringent certification process. As machine learning is becoming more popular,\nmachine-learned components are now considered for inclusion in critical\nsystems. This raises the question of their safety and their verification. Yet,\nestablished formal methods are limited to classic, i.e. non machine-learned\nsoftware. Applying formal methods to verify systems that include machine\nlearning has only been considered recently and poses novel challenges in\nsoundness, precision, and scalability.\n  We first recall established formal methods and their current use in an\nexemplar safety-critical field, avionic software, with a focus on abstract\ninterpretation based techniques as they provide a high level of scalability.\nThis provides a golden standard and sets high expectations for machine learning\nverification. We then provide a comprehensive and detailed review of the formal\nmethods developed so far for machine learning, highlighting their strengths and\nlimitations. The large majority of them verify trained neural networks and\nemploy either SMT, optimization, or abstract interpretation techniques. We also\ndiscuss methods for support vector machines and decision tree ensembles, as\nwell as methods targeting training and data preparation, which are critical but\noften neglected aspects of machine learning. Finally, we offer perspectives for\nfuture research directions towards the formal verification of machine learning\nsystems.", "journal": ""}
{"doi": "10.48550/arXiv.2205.15104", "date": "2022-05-30", "title": "FLICU: A Federated Learning Workflow for Intensive Care Unit Mortality Prediction", "authors": "Lena Mondrejevski, Ioanna Miliou, Annaclaudia Montanino, David Pitts, Jaakko Hollm\u00e9n, Panagiotis Papapetrou", "abstract": "Although Machine Learning (ML) can be seen as a promising tool to improve\nclinical decision-making for supporting the improvement of medication plans,\nclinical procedures, diagnoses, or medication prescriptions, it remains limited\nby access to healthcare data. Healthcare data is sensitive, requiring strict\nprivacy practices, and typically stored in data silos, making traditional\nmachine learning challenging. Federated learning can counteract those\nlimitations by training machine learning models over data silos while keeping\nthe sensitive data localized. This study proposes a federated learning workflow\nfor ICU mortality prediction. Hereby, the applicability of federated learning\nas an alternative to centralized machine learning and local machine learning is\ninvestigated by introducing federated learning to the binary classification\nproblem of predicting ICU mortality. We extract multivariate time series data\nfrom the MIMIC-III database (lab values and vital signs), and benchmark the\npredictive performance of four deep sequential classifiers (FRNN, LSTM, GRU,\nand 1DCNN) varying the patient history window lengths (8h, 16h, 24h, 48h) and\nthe number of FL clients (2, 4, 8). The experiments demonstrate that both\ncentralized machine learning and federated learning are comparable in terms of\nAUPRC and F1-score. Furthermore, the federated approach shows superior\nperformance over local machine learning. Thus, the federated approach can be\nseen as a valid and privacy-preserving alternative to centralized machine\nlearning for classifying ICU mortality when sharing sensitive patient data\nbetween hospitals is not possible.", "journal": ""}
{"doi": "10.48550/arXiv.1506.01709", "date": "2015-06-04", "title": "The Preference Learning Toolbox", "authors": "Vincent E. Farrugia, H\u00e9ctor P. Mart\u00ednez, Georgios N. Yannakakis", "abstract": "Preference learning (PL) is a core area of machine learning that handles\ndatasets with ordinal relations. As the number of generated data of ordinal\nnature is increasing, the importance and role of the PL field becomes central\nwithin machine learning research and practice. This paper introduces an open\nsource, scalable, efficient and accessible preference learning toolbox that\nsupports the key phases of the data training process incorporating various\npopular data preprocessing, feature selection and preference learning methods.", "journal": ""}
{"doi": "10.48550/arXiv.1703.10444", "date": "2017-03-30", "title": "On Fundamental Limits of Robust Learning", "authors": "Jiashi Feng", "abstract": "We consider the problems of robust PAC learning from distributed and\nstreaming data, which may contain malicious errors and outliers, and analyze\ntheir fundamental complexity questions. In particular, we establish lower\nbounds on the communication complexity for distributed robust learning\nperformed on multiple machines, and on the space complexity for robust learning\nfrom streaming data on a single machine. These results demonstrate that gaining\nrobustness of learning algorithms is usually at the expense of increased\ncomplexities. As far as we know, this work gives the first complexity results\nfor distributed and online robust PAC learning.", "journal": ""}
{"doi": "10.48550/arXiv.1803.08118", "date": "2018-03-21", "title": "Seglearn: A Python Package for Learning Sequences and Time Series", "authors": "David M. Burns, Cari M. Whyne", "abstract": "Seglearn is an open-source python package for machine learning time series or\nsequences using a sliding window segmentation approach. The implementation\nprovides a flexible pipeline for tackling classification, regression, and\nforecasting problems with multivariate sequence and contextual data. This\npackage is compatible with scikit-learn and is listed under scikit-learn\nRelated Projects. The package depends on numpy, scipy, and scikit-learn.\nSeglearn is distributed under the BSD 3-Clause License. Documentation includes\na detailed API description, user guide, and examples. Unit tests provide a high\ndegree of code coverage.", "journal": "Journal of Machine Learning Research 19 (2018) 1-7"}
{"doi": "10.48550/arXiv.2004.13598", "date": "2020-04-28", "title": "Private Dataset Generation Using Privacy Preserving Collaborative Learning", "authors": "Amit Chaulwar", "abstract": "With increasing usage of deep learning algorithms in many application, new\nresearch questions related to privacy and adversarial attacks are emerging.\nHowever, the deep learning algorithm improvement needs more and more data to be\nshared within research community. Methodologies like federated learning,\ndifferential privacy, additive secret sharing provides a way to train machine\nlearning models on edge without moving the data from the edge. However, it is\nvery computationally intensive and prone to adversarial attacks. Therefore,\nthis work introduces a privacy preserving FedCollabNN framework for training\nmachine learning models at edge, which is computationally efficient and robust\nagainst adversarial attacks. The simulation results using MNIST dataset\nindicates the effectiveness of the framework.", "journal": ""}
{"doi": "10.48550/arXiv.2009.12999", "date": "2020-09-28", "title": "Loosely Coupled Federated Learning Over Generative Models", "authors": "Shaoming Song, Yunfeng Shao, Jian Li", "abstract": "Federated learning (FL) was proposed to achieve collaborative machine\nlearning among various clients without uploading private data. However, due to\nmodel aggregation strategies, existing frameworks require strict model\nhomogeneity, limiting the application in more complicated scenarios. Besides,\nthe communication cost of FL's model and gradient transmission is extremely\nhigh. This paper proposes Loosely Coupled Federated Learning (LC-FL), a\nframework using generative models as transmission media to achieve low\ncommunication cost and heterogeneous federated learning. LC-FL can be applied\non scenarios where clients possess different kinds of machine learning models.\nExperiments on real-world datasets covering different multiparty scenarios\ndemonstrate the effectiveness of our proposal.", "journal": ""}
{"doi": "10.48550/arXiv.2012.00152", "date": "2020-11-30", "title": "Every Model Learned by Gradient Descent Is Approximately a Kernel Machine", "authors": "Pedro Domingos", "abstract": "Deep learning's successes are often attributed to its ability to\nautomatically discover new representations of the data, rather than relying on\nhandcrafted features like other learning methods. We show, however, that deep\nnetworks learned by the standard gradient descent algorithm are in fact\nmathematically approximately equivalent to kernel machines, a learning method\nthat simply memorizes the data and uses it directly for prediction via a\nsimilarity function (the kernel). This greatly enhances the interpretability of\ndeep network weights, by elucidating that they are effectively a superposition\nof the training examples. The network architecture incorporates knowledge of\nthe target function into the kernel. This improved understanding should lead to\nbetter learning algorithms.", "journal": ""}
{"doi": "10.48550/arXiv.2012.15505", "date": "2020-12-31", "title": "Flexible model composition in machine learning and its implementation in MLJ", "authors": "Anthony D. Blaom, Sebastian J. Vollmer", "abstract": "A graph-based protocol called `learning networks' which combine assorted\nmachine learning models into meta-models is described. Learning networks are\nshown to overcome several limitations of model composition as implemented in\nthe dominant machine learning platforms. After illustrating the protocol in\nsimple examples, a concise syntax for specifying a learning network,\nimplemented in the MLJ framework, is presented. Using the syntax, it is shown\nthat learning networks are are sufficiently flexible to include Wolpert's model\nstacking, with out-of-sample predictions for the base learners.", "journal": ""}
{"doi": "10.48550/arXiv.2208.04707", "date": "2022-07-17", "title": "Context sequence theory: a common explanation for multiple types of learning", "authors": "Yu Mingcan, Wang Junying", "abstract": "Although principles of neuroscience like reinforcement learning, visual\nperception and attention have been applied in machine learning models, there is\na huge gap between machine learning and mammalian learning. Based on the\nadvances in neuroscience, we propose the context sequence theory to give a\ncommon explanation for multiple types of learning in mammals and hope that can\nprovide a new insight into the construct of machine learning models.", "journal": ""}
{"doi": "10.48550/arXiv.2303.03181", "date": "2023-03-06", "title": "MetaPhysiCa: OOD Robustness in Physics-informed Machine Learning", "authors": "S Chandra Mouli, Muhammad Ashraful Alam, Bruno Ribeiro", "abstract": "A fundamental challenge in physics-informed machine learning (PIML) is the\ndesign of robust PIML methods for out-of-distribution (OOD) forecasting tasks.\nThese OOD tasks require learning-to-learn from observations of the same (ODE)\ndynamical system with different unknown ODE parameters, and demand accurate\nforecasts even under out-of-support initial conditions and out-of-support ODE\nparameters. In this work we propose a solution for such tasks, which we define\nas a meta-learning procedure for causal structure discovery (including\ninvariant risk minimization). Using three different OOD tasks, we empirically\nobserve that the proposed approach significantly outperforms existing\nstate-of-the-art PIML and deep learning methods.", "journal": ""}
{"doi": "10.48550/arXiv.2501.12747", "date": "2025-01-22", "title": "Singular leaning coefficients and efficiency in learning theory", "authors": "Miki Aoyagi", "abstract": "Singular learning models with non-positive Fisher information matrices\ninclude neural networks, reduced-rank regression, Boltzmann machines, normal\nmixture models, and others. These models have been widely used in the\ndevelopment of learning machines. However, theoretical analysis is still in its\nearly stages. In this paper, we examine learning coefficients, which indicate\nthe general learning efficiency of deep linear learning models and three-layer\nneural network models with ReLU units. Finally, we extend the results to\ninclude the case of the Softmax function.", "journal": ""}
{"doi": "10.48550/arXiv.2005.13299", "date": "2020-05-27", "title": "Machine Learning for Software Engineering: A Systematic Mapping", "authors": "Saad Shafiq, Atif Mashkoor, Christoph Mayr-Dorn, Alexander Egyed", "abstract": "Context: The software development industry is rapidly adopting machine\nlearning for transitioning modern day software systems towards highly\nintelligent and self-learning systems. However, the full potential of machine\nlearning for improving the software engineering life cycle itself is yet to be\ndiscovered, i.e., up to what extent machine learning can help reducing the\neffort/complexity of software engineering and improving the quality of\nresulting software systems. To date, no comprehensive study exists that\nexplores the current state-of-the-art on the adoption of machine learning\nacross software engineering life cycle stages. Objective: This article\naddresses the aforementioned problem and aims to present a state-of-the-art on\nthe growing number of uses of machine learning in software engineering. Method:\nWe conduct a systematic mapping study on applications of machine learning to\nsoftware engineering following the standard guidelines and principles of\nempirical software engineering. Results: This study introduces a machine\nlearning for software engineering (MLSE) taxonomy classifying the\nstate-of-the-art machine learning techniques according to their applicability\nto various software engineering life cycle stages. Overall, 227 articles were\nrigorously selected and analyzed as a result of this study. Conclusion: From\nthe selected articles, we explore a variety of aspects that should be helpful\nto academics and practitioners alike in understanding the potential of adopting\nmachine learning techniques during software engineering projects.", "journal": ""}
{"doi": "10.48550/arXiv.2204.13291", "date": "2022-04-28", "title": "Decision Models for Selecting Federated Learning Architecture Patterns", "authors": "Sin Kit Lo, Qinghua Lu, Hye-Young Paik, Liming Zhu", "abstract": "Federated machine learning is growing fast in academia and industries as a\nsolution to solve data hungriness and privacy issues in machine learning. Being\na widely distributed system, federated machine learning requires various system\ndesign thinking. To better design a federated machine learning system,\nresearchers have introduced multiple patterns and tactics that cover various\nsystem design aspects. However, the multitude of patterns leaves the designers\nconfused about when and which pattern to adopt. In this paper, we present a set\nof decision models for the selection of patterns for federated machine learning\narchitecture design based on a systematic literature review on federated\nmachine learning, to assist designers and architects who have limited knowledge\nof federated machine learning. Each decision model maps functional and\nnon-functional requirements of federated machine learning systems to a set of\npatterns. We also clarify the drawbacks of the patterns. We evaluated the\ndecision models by mapping the decision patterns to concrete federated machine\nlearning architectures by big tech firms to assess the models' correctness and\nusefulness. The evaluation results indicate that the proposed decision models\nare able to bring structure to the federated machine learning architecture\ndesign process and help explicitly articulate the design rationale.", "journal": ""}
{"doi": "10.48550/arXiv.1606.01487", "date": "2016-06-05", "title": "Bounds for Vector-Valued Function Estimation", "authors": "Andreas Maurer, Massimiliano Pontil", "abstract": "We present a framework to derive risk bounds for vector-valued learning with\na broad class of feature maps and loss functions. Multi-task learning and\none-vs-all multi-category learning are treated as examples. We discuss in\ndetail vector-valued functions with one hidden layer, and demonstrate that the\nconditions under which shared representations are beneficial for multi- task\nlearning are equally applicable to multi-category learning.", "journal": ""}
{"doi": "10.48550/arXiv.1811.06622", "date": "2018-11-15", "title": "Concept-Oriented Deep Learning: Generative Concept Representations", "authors": "Daniel T. Chang", "abstract": "Generative concept representations have three major advantages over\ndiscriminative ones: they can represent uncertainty, they support integration\nof learning and reasoning, and they are good for unsupervised and\nsemi-supervised learning. We discuss probabilistic and generative deep\nlearning, which generative concept representations are based on, and the use of\nvariational autoencoders and generative adversarial networks for learning\ngenerative concept representations, particularly for concepts whose data are\nsequences, structured data or graphs.", "journal": ""}
{"doi": "10.48550/arXiv.2007.09982", "date": "2020-07-20", "title": "MKLpy: a python-based framework for Multiple Kernel Learning", "authors": "Ivano Lauriola, Fabio Aiolli", "abstract": "Multiple Kernel Learning is a recent and powerful paradigm to learn the\nkernel function from data. In this paper, we introduce MKLpy, a python-based\nframework for Multiple Kernel Learning. The library provides Multiple Kernel\nLearning algorithms for classification tasks, mechanisms to compute kernel\nfunctions for different data types, and evaluation strategies. The library is\nmeant to maximize the usability and to simplify the development of novel\nsolutions.", "journal": ""}
{"doi": "10.48550/arXiv.2010.07744", "date": "2020-10-15", "title": "A Theory of Hyperbolic Prototype Learning", "authors": "Martin Keller-Ressel", "abstract": "We introduce Hyperbolic Prototype Learning, a type of supervised learning,\nwhere class labels are represented by ideal points (points at infinity) in\nhyperbolic space. Learning is achieved by minimizing the 'penalized Busemann\nloss', a new loss function based on the Busemann function of hyperbolic\ngeometry. We discuss several theoretical features of this setup. In particular,\nHyperbolic Prototype Learning becomes equivalent to logistic regression in the\none-dimensional case.", "journal": ""}
{"doi": "10.48550/arXiv.2112.12181", "date": "2021-12-22", "title": "Simple and near-optimal algorithms for hidden stratification and multi-group learning", "authors": "Christopher Tosh, Daniel Hsu", "abstract": "Multi-group agnostic learning is a formal learning criterion that is\nconcerned with the conditional risks of predictors within subgroups of a\npopulation. The criterion addresses recent practical concerns such as subgroup\nfairness and hidden stratification. This paper studies the structure of\nsolutions to the multi-group learning problem, and provides simple and\nnear-optimal algorithms for the learning problem.", "journal": ""}
{"doi": "10.48550/arXiv.1611.00379", "date": "2016-11-01", "title": "The Machine Learning Algorithm as Creative Musical Tool", "authors": "Rebecca Fiebrink, Baptiste Caramiaux", "abstract": "Machine learning is the capacity of a computational system to learn\nstructures from datasets in order to make predictions on newly seen data. Such\nan approach offers a significant advantage in music scenarios in which\nmusicians can teach the system to learn an idiosyncratic style, or can break\nthe rules to explore the system's capacity in unexpected ways. In this chapter\nwe draw on music, machine learning, and human-computer interaction to elucidate\nan understanding of machine learning algorithms as creative tools for music and\nthe sonic arts. We motivate a new understanding of learning algorithms as\nhuman-computer interfaces. We show that, like other interfaces, learning\nalgorithms can be characterised by the ways their affordances intersect with\ngoals of human users. We also argue that the nature of interaction between\nusers and algorithms impacts the usability and usefulness of those algorithms\nin profound ways. This human-centred view of machine learning motivates our\nconcluding discussion of what it means to employ machine learning as a creative\ntool.", "journal": ""}
{"doi": "10.48550/arXiv.2006.05604", "date": "2020-06-10", "title": "Machine Learning and Control Theory", "authors": "Alain Bensoussan, Yiqun Li, Dinh Phan Cao Nguyen, Minh-Binh Tran, Sheung Chi Phillip Yam, Xiang Zhou", "abstract": "We survey in this article the connections between Machine Learning and\nControl Theory. Control Theory provide useful concepts and tools for Machine\nLearning. Conversely Machine Learning can be used to solve large control\nproblems. In the first part of the paper, we develop the connections between\nreinforcement learning and Markov Decision Processes, which are discrete time\ncontrol problems. In the second part, we review the concept of supervised\nlearning and the relation with static optimization. Deep learning which extends\nsupervised learning, can be viewed as a control problem. In the third part, we\npresent the links between stochastic gradient descent and mean-field theory.\nConversely, in the fourth and fifth parts, we review machine learning\napproaches to stochastic control problems, and focus on the deterministic case,\nto explain, more easily, the numerical algorithms.", "journal": ""}
{"doi": "10.48550/arXiv.1901.03678", "date": "2019-01-11", "title": "Machine Learning Automation Toolbox (MLaut)", "authors": "Viktor Kazakov, Franz J. Kir\u00e1ly", "abstract": "In this paper we present MLaut (Machine Learning AUtomation Toolbox) for the\npython data science ecosystem. MLaut automates large-scale evaluation and\nbenchmarking of machine learning algorithms on a large number of datasets.\nMLaut provides a high-level workflow interface to machine algorithm algorithms,\nimplements a local back-end to a database of dataset collections, trained\nalgorithms, and experimental results, and provides easy-to-use interfaces to\nthe scikit-learn and keras modelling libraries. Experiments are easy to set up\nwith default settings in a few lines of code, while remaining fully\ncustomizable to the level of hyper-parameter tuning, pipeline composition, or\ndeep learning architecture.\n  As a principal test case for MLaut, we conducted a large-scale supervised\nclassification study in order to benchmark the performance of a number of\nmachine learning algorithms - to our knowledge also the first larger-scale\nstudy on standard supervised learning data sets to include deep learning\nalgorithms. While corroborating a number of previous findings in literature, we\nfound (within the limitations of our study) that deep neural networks do not\nperform well on basic supervised learning, i.e., outside the more specialized,\nimage-, audio-, or text-based tasks.", "journal": ""}
{"doi": "10.48550/arXiv.2011.08450", "date": "2020-11-17", "title": "A Quantitative Perspective on Values of Domain Knowledge for Machine Learning", "authors": "Jianyi Yang, Shaolei Ren", "abstract": "With the exploding popularity of machine learning, domain knowledge in\nvarious forms has been playing a crucial role in improving the learning\nperformance, especially when training data is limited. Nonetheless, there is\nlittle understanding of to what extent domain knowledge can affect a machine\nlearning task from a quantitative perspective. To increase the transparency and\nrigorously explain the role of domain knowledge in machine learning, we study\nthe problem of quantifying the values of domain knowledge in terms of its\ncontribution to the learning performance in the context of informed machine\nlearning. We propose a quantification method based on Shapley value that fairly\nattributes the overall learning performance improvement to different domain\nknowledge. We also present Monte-Carlo sampling to approximate the fair value\nof domain knowledge with a polynomial time complexity. We run experiments of\ninjecting symbolic domain knowledge into semi-supervised learning tasks on both\nMNIST and CIFAR10 datasets, providing quantitative values of different symbolic\nknowledge and rigorously explaining how it affects the machine learning\nperformance in terms of test accuracy.", "journal": ""}
{"doi": "10.48550/arXiv.1901.05353", "date": "2019-01-16", "title": "A Primer on PAC-Bayesian Learning", "authors": "Benjamin Guedj", "abstract": "Generalised Bayesian learning algorithms are increasingly popular in machine\nlearning, due to their PAC generalisation properties and flexibility. The\npresent paper aims at providing a self-contained survey on the resulting\nPAC-Bayes framework and some of its main theoretical and algorithmic\ndevelopments.", "journal": "Proceedings of the 2nd congress of the Soci\\'et\\'e Math\\'ematique\n  de France, 2019, pp. 391--414"}
{"doi": "10.48550/arXiv.1803.02388", "date": "2018-03-06", "title": "Learning SMaLL Predictors", "authors": "Vikas K. Garg, Ofer Dekel, Lin Xiao", "abstract": "We present a new machine learning technique for training small\nresource-constrained predictors. Our algorithm, the Sparse Multiprototype\nLinear Learner (SMaLL), is inspired by the classic machine learning problem of\nlearning $k$-DNF Boolean formulae. We present a formal derivation of our\nalgorithm and demonstrate the benefits of our approach with a detailed\nempirical study.", "journal": ""}
{"doi": "10.48550/arXiv.2009.06093", "date": "2020-09-13", "title": "Simultaneous Quantum Machine Learning Training and Architecture Discovery", "authors": "Dominic Pasquali", "abstract": "With the onset of gated quantum machine learning, the architecture for such a\nsystem is an open question. Many architectures are created either ad hoc or are\ndirectly analogous from known classical architectures. Presented here is a\nnovel algorithm which learns a gated quantum machine learning architecture\nwhile simultaneously learning its parameters. This proof of concept and some of\nits variations are explored and discussed.", "journal": ""}
{"doi": "10.48550/arXiv.2103.07802", "date": "2021-03-13", "title": "Hybrid computer approach to train a machine learning system", "authors": "Mirko Holzer, Bernd Ulmann", "abstract": "This book chapter describes a novel approach to training machine learning\nsystems by means of a hybrid computer setup i.e. a digital computer tightly\ncoupled with an analog computer. As an example a reinforcement learning system\nis trained to balance an inverted pendulum which is simulated on an analog\ncomputer, thus demonstrating a solution to the major challenge of adequately\nsimulating the environment for reinforcement learning.", "journal": ""}
{"doi": "10.48550/arXiv.2310.03751", "date": "2023-09-22", "title": "A Simple Illustration of Interleaved Learning using Kalman Filter for Linear Least Squares", "authors": "Majnu John, Yihren Wu", "abstract": "Interleaved learning in machine learning algorithms is a biologically\ninspired training method with promising results. In this short note, we\nillustrate the interleaving mechanism via a simple statistical and optimization\nframework based on Kalman Filter for Linear Least Squares.", "journal": "Results in Applied Mathematics. Vol. 20, 2023, 100409; ISSN\n  2590-0374"}
{"doi": "10.48550/arXiv.2410.21339", "date": "2024-10-28", "title": "Machine Learning and Quantum Intelligence for Health Data Scenarios", "authors": "Sanjeev Naguleswaran", "abstract": "The advent of quantum computing has opened new possibilities in data science,\noffering unique capabilities for addressing complex, data-intensive problems.\nTraditional machine learning algorithms often face challenges in\nhigh-dimensional or limited-quality datasets, which are common in healthcare.\nQuantum Machine Learning leverages quantum properties, such as superposition\nand entanglement, to enhance pattern recognition and classification,\npotentially surpassing classical approaches. This paper explores QML's\napplication in healthcare, focusing on quantum kernel methods and hybrid\nquantum-classical networks for heart disease prediction and COVID-19 detection,\nassessing their feasibility and performance.", "journal": ""}
{"doi": "10.48550/arXiv.1805.07938", "date": "2018-05-21", "title": "Transductive Boltzmann Machines", "authors": "Mahito Sugiyama, Koji Tsuda, Hiroyuki Nakahara", "abstract": "We present transductive Boltzmann machines (TBMs), which firstly achieve\ntransductive learning of the Gibbs distribution. While exact learning of the\nGibbs distribution is impossible by the family of existing Boltzmann machines\ndue to combinatorial explosion of the sample space, TBMs overcome the problem\nby adaptively constructing the minimum required sample space from data to avoid\nunnecessary generalization. We theoretically provide bias-variance\ndecomposition of the KL divergence in TBMs to analyze its learnability, and\nempirically demonstrate that TBMs are superior to the fully visible Boltzmann\nmachines and popularly used restricted Boltzmann machines in terms of\nefficiency and effectiveness.", "journal": ""}
{"doi": "10.48550/arXiv.1103.3095", "date": "2011-03-16", "title": "A note on active learning for smooth problems", "authors": "Satyaki Mahalanabis", "abstract": "We show that the disagreement coefficient of certain smooth hypothesis\nclasses is $O(m)$, where $m$ is the dimension of the hypothesis space, thereby\nanswering a question posed in \\cite{friedman09}.", "journal": ""}
{"doi": "10.48550/arXiv.1212.3900", "date": "2012-12-17", "title": "A Tutorial on Probabilistic Latent Semantic Analysis", "authors": "Liangjie Hong", "abstract": "In this tutorial, I will discuss the details about how Probabilistic Latent\nSemantic Analysis (PLSA) is formalized and how different learning algorithms\nare proposed to learn the model.", "journal": ""}
{"doi": "10.48550/arXiv.1408.6618", "date": "2014-08-28", "title": "Falsifiable implies Learnable", "authors": "David Balduzzi", "abstract": "The paper demonstrates that falsifiability is fundamental to learning. We\nprove the following theorem for statistical learning and sequential prediction:\nIf a theory is falsifiable then it is learnable -- i.e. admits a strategy that\npredicts optimally. An analogous result is shown for universal induction.", "journal": ""}
{"doi": "10.48550/arXiv.1502.02704", "date": "2015-02-09", "title": "Learning Reductions that Really Work", "authors": "Alina Beygelzimer, Hal Daum\u00e9 III, John Langford, Paul Mineiro", "abstract": "We provide a summary of the mathematical and computational techniques that\nhave enabled learning reductions to effectively address a wide class of\nproblems, and show that this approach to solving machine learning problems can\nbe broadly useful.", "journal": ""}
{"doi": "10.48550/arXiv.1204.2477", "date": "2012-04-11", "title": "A Simple Explanation of A Spectral Algorithm for Learning Hidden Markov Models", "authors": "Matthew James Johnson", "abstract": "A simple linear algebraic explanation of the algorithm in \"A Spectral\nAlgorithm for Learning Hidden Markov Models\" (COLT 2009). Most of the content\nis in Figure 2; the text just makes everything precise in four nearly-trivial\nclaims.", "journal": ""}
{"doi": "10.48550/arXiv.1809.07904", "date": "2018-09-21", "title": "Automatic Rule Learning for Autonomous Driving Using Semantic Memory", "authors": "Dmitriy Korchev, Aruna Jammalamadaka, Rajan Bhattacharyya", "abstract": "This paper presents a novel approach for automatic rule learning applicable\nto an autonomous driving system using real driving data.", "journal": ""}
{"doi": "10.48550/arXiv.1803.06586", "date": "2018-03-17", "title": "Structural query-by-committee", "authors": "Christopher Tosh, Sanjoy Dasgupta", "abstract": "In this work, we describe a framework that unifies many different interactive\nlearning tasks. We present a generalization of the {\\it query-by-committee}\nactive learning algorithm for this setting, and we study its consistency and\nrate of convergence, both theoretically and empirically, with and without\nnoise.", "journal": ""}
{"doi": "10.48550/arXiv.2012.03130", "date": "2020-12-05", "title": "Rejoinder: New Objectives for Policy Learning", "authors": "Nathan Kallus", "abstract": "I provide a rejoinder for discussion of \"More Efficient Policy Learning via\nOptimal Retargeting\" to appear in the Journal of the American Statistical\nAssociation with discussion by Oliver Dukes and Stijn Vansteelandt; Sijia Li,\nXiudi Li, and Alex Luedtkeand; and Muxuan Liang and Yingqi Zhao.", "journal": ""}
{"doi": "10.48550/arXiv.1610.06072", "date": "2016-10-19", "title": "Learning to Learn Neural Networks", "authors": "Tom Bosc", "abstract": "Meta-learning consists in learning learning algorithms. We use a Long Short\nTerm Memory (LSTM) based network to learn to compute on-line updates of the\nparameters of another neural network. These parameters are stored in the cell\nstate of the LSTM. Our framework allows to compare learned algorithms to\nhand-made algorithms within the traditional train and test methodology. In an\nexperiment, we learn a learning algorithm for a one-hidden layer Multi-Layer\nPerceptron (MLP) on non-linearly separable datasets. The learned algorithm is\nable to update parameters of both layers and generalise well on similar\ndatasets.", "journal": ""}
{"doi": "10.48550/arXiv.2008.01171", "date": "2020-07-31", "title": "Deep Reinforcement Learning using Cyclical Learning Rates", "authors": "Ralf Gulde, Marc Tuscher, Akos Csiszar, Oliver Riedel, Alexander Verl", "abstract": "Deep Reinforcement Learning (DRL) methods often rely on the meticulous tuning\nof hyperparameters to successfully resolve problems. One of the most\ninfluential parameters in optimization procedures based on stochastic gradient\ndescent (SGD) is the learning rate. We investigate cyclical learning and\npropose a method for defining a general cyclical learning rate for various DRL\nproblems. In this paper we present a method for cyclical learning applied to\ncomplex DRL problems. Our experiments show that, utilizing cyclical learning\nachieves similar or even better results than highly tuned fixed learning rates.\nThis paper presents the first application of cyclical learning rates in DRL\nsettings and is a step towards overcoming manual hyperparameter tuning.", "journal": ""}
{"doi": "10.48550/arXiv.2008.07739", "date": "2020-08-18", "title": "Positive semidefinite support vector regression metric learning", "authors": "Lifeng Gu", "abstract": "Most existing metric learning methods focus on learning a similarity or\ndistance measure relying on similar and dissimilar relations between sample\npairs. However, pairs of samples cannot be simply identified as similar or\ndissimilar in many real-world applications, e.g., multi-label learning, label\ndistribution learning. To this end, relation alignment metric learning (RAML)\nframework is proposed to handle the metric learning problem in those scenarios.\nBut RAML framework uses SVR solvers for optimization. It can't learn positive\nsemidefinite distance metric which is necessary in metric learning. In this\npaper, we propose two methds to overcame the weakness. Further, We carry out\nseveral experiments on the single-label classification, multi-label\nclassification, label distribution learning to demonstrate the new methods\nachieves favorable performance against RAML framework.", "journal": ""}
{"doi": "10.48550/arXiv.2503.09833", "date": "2025-03-12", "title": "A Comprehensive Review on Understanding the Decentralized and Collaborative Approach in Machine Learning", "authors": "Sarwar Saif, Md Jahirul Islam, Md. Zihad Bin Jahangir, Parag Biswas, Abdur Rashid, MD Abdullah Al Nasim, Kishor Datta Gupta", "abstract": "The arrival of Machine Learning (ML) completely changed how we can unlock\nvaluable information from data. Traditional methods, where everything was\nstored in one place, had big problems with keeping information private,\nhandling large amounts of data, and avoiding unfair advantages. Machine\nLearning has become a powerful tool that uses Artificial Intelligence (AI) to\novercome these challenges. We started by learning the basics of Machine\nLearning, including the different types like supervised, unsupervised, and\nreinforcement learning. We also explored the important steps involved, such as\npreparing the data, choosing the right model, training it, and then checking\nits performance. Next, we examined some key challenges in Machine Learning,\nsuch as models learning too much from specific examples (overfitting), not\nlearning enough (underfitting), and reflecting biases in the data used. Moving\nbeyond centralized systems, we looked at decentralized Machine Learning and its\nbenefits, like keeping data private, getting answers faster, and using a wider\nvariety of data sources. We then focused on a specific type called federated\nlearning, where models are trained without directly sharing sensitive\ninformation. Real-world examples from healthcare and finance were used to show\nhow collaborative Machine Learning can solve important problems while still\nprotecting information security. Finally, we discussed challenges like\ncommunication efficiency, dealing with different types of data, and security.\nWe also explored using a Zero Trust framework, which provides an extra layer of\nprotection for collaborative Machine Learning systems. This approach is paving\nthe way for a bright future for this groundbreaking technology.", "journal": ""}
{"doi": "10.48550/arXiv.1706.00066", "date": "2017-05-31", "title": "Descriptions of Objectives and Processes of Mechanical Learning", "authors": "Chuyu Xiong", "abstract": "In [1], we introduced mechanical learning and proposed 2 approaches to\nmechanical learning. Here, we follow one such approach to well describe the\nobjects and the processes of learning. We discuss 2 kinds of patterns:\nobjective and subjective pattern. Subjective pattern is crucial for learning\nmachine. We prove that for any objective pattern we can find a proper\nsubjective pattern based upon least base patterns to express the objective\npattern well. X-form is algebraic expression for subjective pattern. Collection\nof X-forms form internal representation space, which is center of learning\nmachine. We discuss learning by teaching and without teaching. We define data\nsufficiency by X-form. We then discussed some learning strategies. We show, in\neach strategy, with sufficient data, and with certain capabilities, learning\nmachine indeed can learn any pattern (universal learning machine). In appendix,\nwith knowledge of learning machine, we try to view deep learning from a\ndifferent angle, i.e. its internal representation space and its learning\ndynamics.", "journal": ""}
{"doi": "10.48550/arXiv.1904.09644", "date": "2019-04-21", "title": "Intermittent Learning: On-Device Machine Learning on Intermittently Powered System", "authors": "Seulki Lee, Bashima Islam, Yubo Luo, Shahriar Nirjon", "abstract": "This paper introduces intermittent learning - the goal of which is to enable\nenergy harvested computing platforms capable of executing certain classes of\nmachine learning tasks effectively and efficiently. We identify unique\nchallenges to intermittent learning relating to the data and application\nsemantics of machine learning tasks, and to address these challenges, we devise\n1) an algorithm that determines a sequence of actions to achieve the desired\nlearning objective under tight energy constraints, and 2) propose three\nheuristics that help an intermittent learner decide whether to learn or discard\ntraining examples at run-time which increases the energy efficiency of the\nsystem. We implement and evaluate three intermittent learning applications that\nlearn the 1) air quality, 2) human presence, and 3) vibration using solar, RF,\nand kinetic energy harvesters, respectively. We demonstrate that the proposed\nframework improves the energy efficiency of a learner by up to 100% and cuts\ndown the number of learning examples by up to 50% when compared to\nstate-of-the-art intermittent computing systems that do not implement the\nproposed intermittent learning framework.", "journal": ""}
{"doi": "10.48550/arXiv.1203.3783", "date": "2012-03-16", "title": "Learning Feature Hierarchies with Centered Deep Boltzmann Machines", "authors": "Gr\u00e9goire Montavon, Klaus-Robert M\u00fcller", "abstract": "Deep Boltzmann machines are in principle powerful models for extracting the\nhierarchical structure of data. Unfortunately, attempts to train layers jointly\n(without greedy layer-wise pretraining) have been largely unsuccessful. We\npropose a modification of the learning algorithm that initially recenters the\noutput of the activation functions to zero. This modification leads to a better\nconditioned Hessian and thus makes learning easier. We test the algorithm on\nreal data and demonstrate that our suggestion, the centered deep Boltzmann\nmachine, learns a hierarchy of increasingly abstract representations and a\nbetter generative model of data.", "journal": ""}
{"doi": "10.48550/arXiv.1502.02127", "date": "2015-02-07", "title": "Hyperparameter Search in Machine Learning", "authors": "Marc Claesen, Bart De Moor", "abstract": "We introduce the hyperparameter search problem in the field of machine\nlearning and discuss its main challenges from an optimization perspective.\nMachine learning methods attempt to build models that capture some element of\ninterest based on given data. Most common learning algorithms feature a set of\nhyperparameters that must be determined before training commences. The choice\nof hyperparameters can significantly affect the resulting model's performance,\nbut determining good values can be complex; hence a disciplined, theoretically\nsound search strategy is essential.", "journal": ""}
{"doi": "10.48550/arXiv.1510.00772", "date": "2015-10-03", "title": "Machine Learning for Machine Data from a CATI Network", "authors": "Sou-Cheng T. Choi", "abstract": "This is a machine learning application paper involving big data. We present\nhigh-accuracy prediction methods of rare events in semi-structured machine log\nfiles, which are produced at high velocity and high volume by NORC's\ncomputer-assisted telephone interviewing (CATI) network for conducting surveys.\nWe judiciously apply natural language processing (NLP) techniques and\ndata-mining strategies to train effective learning and prediction models for\nclassifying uncommon error messages in the log---without access to source code,\nupdated documentation or dictionaries. In particular, our simple but effective\napproach of features preallocation for learning from imbalanced data coupled\nwith naive Bayes classifiers can be conceivably generalized to supervised or\nsemi-supervised learning and prediction methods for other critical events such\nas cyberattack detection.", "journal": ""}
{"doi": "10.48550/arXiv.1511.03198", "date": "2015-11-10", "title": "Sliced Wasserstein Kernels for Probability Distributions", "authors": "Soheil Kolouri, Yang Zou, Gustavo K. Rohde", "abstract": "Optimal transport distances, otherwise known as Wasserstein distances, have\nrecently drawn ample attention in computer vision and machine learning as a\npowerful discrepancy measure for probability distributions. The recent\ndevelopments on alternative formulations of the optimal transport have allowed\nfor faster solutions to the problem and has revamped its practical applications\nin machine learning. In this paper, we exploit the widely used kernel methods\nand provide a family of provably positive definite kernels based on the Sliced\nWasserstein distance and demonstrate the benefits of these kernels in a variety\nof learning tasks. Our work provides a new perspective on the application of\noptimal transport flavored distances through kernel methods in machine learning\ntasks.", "journal": ""}
{"doi": "10.48550/arXiv.1511.03643", "date": "2015-11-11", "title": "Unifying distillation and privileged information", "authors": "David Lopez-Paz, L\u00e9on Bottou, Bernhard Sch\u00f6lkopf, Vladimir Vapnik", "abstract": "Distillation (Hinton et al., 2015) and privileged information (Vapnik &\nIzmailov, 2015) are two techniques that enable machines to learn from other\nmachines. This paper unifies these two techniques into generalized\ndistillation, a framework to learn from multiple machines and data\nrepresentations. We provide theoretical and causal insight about the inner\nworkings of generalized distillation, extend it to unsupervised, semisupervised\nand multitask learning scenarios, and illustrate its efficacy on a variety of\nnumerical simulations on both synthetic and real-world data.", "journal": "Proceedings of the International Conference on Learning\n  Representations (2016) 1-10"}
{"doi": "10.48550/arXiv.1909.13316", "date": "2019-09-29", "title": "Machine Learning vs Statistical Methods for Time Series Forecasting: Size Matters", "authors": "Vitor Cerqueira, Luis Torgo, Carlos Soares", "abstract": "Time series forecasting is one of the most active research topics. Machine\nlearning methods have been increasingly adopted to solve these predictive\ntasks. However, in a recent work, these were shown to systematically present a\nlower predictive performance relative to simple statistical methods. In this\nwork, we counter these results. We show that these are only valid under an\nextremely low sample size. Using a learning curve method, our results suggest\nthat machine learning methods improve their relative predictive performance as\nthe sample size grows. The code to reproduce the experiments is available at\nhttps://github.com/vcerqueira/MLforForecasting.", "journal": ""}
{"doi": "10.48550/arXiv.2001.04601", "date": "2020-01-14", "title": "For2For: Learning to forecast from forecasts", "authors": "Shi Zhao, Ying Feng", "abstract": "This paper presents a time series forecasting framework which combines\nstandard forecasting methods and a machine learning model. The inputs to the\nmachine learning model are not lagged values or regular time series features,\nbut instead forecasts produced by standard methods. The machine learning model\ncan be either a convolutional neural network model or a recurrent neural\nnetwork model. The intuition behind this approach is that forecasts of a time\nseries are themselves good features characterizing the series, especially when\nthe modelling purpose is forecasting. It can also be viewed as a weighted\nensemble method. Tested on the M4 competition dataset, this approach\noutperforms all submissions for quarterly series, and is more accurate than all\nbut the winning algorithm for monthly series.", "journal": ""}
{"doi": "10.48550/arXiv.2005.14139", "date": "2020-05-28", "title": "Machine learning and excited-state molecular dynamics", "authors": "Julia Westermayr, Philipp Marquetand", "abstract": "Machine learning is employed at an increasing rate in the research field of\nquantum chemistry. While the majority of approaches target the investigation of\nchemical systems in their electronic ground state, the inclusion of light into\nthe processes leads to electronically excited states and gives rise to several\nnew challenges. Here, we survey recent advances for excited-state dynamics\nbased on machine learning. In doing so, we highlight successes, pitfalls,\nchallenges and future avenues for machine learning approaches for light-induced\nmolecular processes.", "journal": "Mach. Learn.: Sci. Technol., 1, 043001 (2020)"}
{"doi": "10.48550/arXiv.2011.04890", "date": "2020-11-10", "title": "Quantum reservoir computing: a reservoir approach toward quantum machine learning on near-term quantum devices", "authors": "Keisuke Fujii, Kohei Nakajima", "abstract": "Quantum systems have an exponentially large degree of freedom in the number\nof particles and hence provide a rich dynamics that could not be simulated on\nconventional computers. Quantum reservoir computing is an approach to use such\na complex and rich dynamics on the quantum systems as it is for temporal\nmachine learning. In this chapter, we explain quantum reservoir computing and\nrelated approaches, quantum extreme learning machine and quantum circuit\nlearning, starting from a pedagogical introduction to quantum mechanics and\nmachine learning. All these quantum machine learning approaches are\nexperimentally feasible and effective on the state-of-the-art quantum devices.", "journal": ""}
{"doi": "10.48550/arXiv.2106.05466", "date": "2021-06-10", "title": "Adaptive machine learning for protein engineering", "authors": "Brian L. Hie, Kevin K. Yang", "abstract": "Machine-learning models that learn from data to predict how protein sequence\nencodes function are emerging as a useful protein engineering tool. However,\nwhen using these models to suggest new protein designs, one must deal with the\nvast combinatorial complexity of protein sequences. Here, we review how to use\na sequence-to-function machine-learning surrogate model to select sequences for\nexperimental measurement. First, we discuss how to select sequences through a\nsingle round of machine-learning optimization. Then, we discuss sequential\noptimization, where the goal is to discover optimized sequences and improve the\nmodel across multiple rounds of training, optimization, and experimental\nmeasurement.", "journal": ""}
{"doi": "10.48550/arXiv.2306.04748", "date": "2023-06-07", "title": "Analysis, Identification and Prediction of Parkinson Disease Sub-Types and Progression through Machine Learning", "authors": "Ashwin Ram", "abstract": "This paper represents a groundbreaking advancement in Parkinson disease (PD)\nresearch by employing a novel machine learning framework to categorize PD into\ndistinct subtypes and predict its progression. Utilizing a comprehensive\ndataset encompassing both clinical and neurological parameters, the research\napplies advanced supervised and unsupervised learning techniques. This\ninnovative approach enables the identification of subtle, yet critical,\npatterns in PD manifestation, which traditional methodologies often miss.\nSignificantly, this research offers a path toward personalized treatment\nstrategies, marking a major stride in the precision medicine domain and\nshowcasing the transformative potential of integrating machine learning into\nmedical research.", "journal": ""}
{"doi": "10.48550/arXiv.2306.09624", "date": "2023-06-16", "title": "Power-law Dynamic arising from machine learning", "authors": "Wei Chen, Weitao Du, Zhi-Ming Ma, Qi Meng", "abstract": "We study a kind of new SDE that was arisen from the research on optimization\nin machine learning, we call it power-law dynamic because its stationary\ndistribution cannot have sub-Gaussian tail and obeys power-law. We prove that\nthe power-law dynamic is ergodic with unique stationary distribution, provided\nthe learning rate is small enough. We investigate its first exist time. In\nparticular, we compare the exit times of the (continuous) power-law dynamic and\nits discretization. The comparison can help guide machine learning algorithm.", "journal": ""}
{"doi": "10.48550/arXiv.2309.02532", "date": "2023-09-05", "title": "Design of Oscillatory Neural Networks by Machine Learning", "authors": "Tamas Rudner, Wolfgang Porod, Gyorgy Csaba", "abstract": "We demonstrate the utility of machine learning algorithms for the design of\nOscillatory Neural Networks (ONNs). After constructing a circuit model of the\noscillators in a machine-learning-enabled simulator and performing\nBackpropagation through time (BPTT) for determining the coupling resistances\nbetween the ring oscillators, we show the design of associative memories and\nmulti-layered ONN classifiers. The machine-learning-designed ONNs show superior\nperformance compared to other design methods (such as Hebbian learning) and\nthey also enable significant simplifications in the circuit topology. We\ndemonstrate the design of multi-layered ONNs that show superior performance\ncompared to single-layer ones. We argue Machine learning can unlock the true\ncomputing potential of ONNs hardware.", "journal": ""}
{"doi": "10.48550/arXiv.2403.10175", "date": "2024-03-15", "title": "A Short Survey on Importance Weighting for Machine Learning", "authors": "Masanari Kimura, Hideitsu Hino", "abstract": "Importance weighting is a fundamental procedure in statistics and machine\nlearning that weights the objective function or probability distribution based\non the importance of the instance in some sense. The simplicity and usefulness\nof the idea has led to many applications of importance weighting. For example,\nit is known that supervised learning under an assumption about the difference\nbetween the training and test distributions, called distribution shift, can\nguarantee statistically desirable properties through importance weighting by\ntheir density ratio. This survey summarizes the broad applications of\nimportance weighting in machine learning and related research.", "journal": ""}
{"doi": "10.48550/arXiv.2405.20620", "date": "2024-05-31", "title": "\"Forgetting\" in Machine Learning and Beyond: A Survey", "authors": "Alyssa Shuang Sha, Bernardo Pereira Nunes, Armin Haller", "abstract": "This survey investigates the multifaceted nature of forgetting in machine\nlearning, drawing insights from neuroscientific research that posits forgetting\nas an adaptive function rather than a defect, enhancing the learning process\nand preventing overfitting. This survey focuses on the benefits of forgetting\nand its applications across various machine learning sub-fields that can help\nimprove model performance and enhance data privacy. Moreover, the paper\ndiscusses current challenges, future directions, and ethical considerations\nregarding the integration of forgetting mechanisms into machine learning\nmodels.", "journal": ""}
{"doi": "10.48550/arXiv.2409.09537", "date": "2024-09-14", "title": "Deep Fast Machine Learning Utils: A Python Library for Streamlined Machine Learning Prototyping", "authors": "Fabi Prezja", "abstract": "Machine learning (ML) research and application often involve time-consuming\nsteps such as model architecture prototyping, feature selection, and dataset\npreparation. To support these tasks, we introduce the Deep Fast Machine\nLearning Utils (DFMLU) library, which provides tools designed to automate and\nenhance aspects of these processes. Compatible with frameworks like TensorFlow,\nKeras, and Scikit-learn, DFMLU offers functionalities that support model\ndevelopment and data handling. The library includes methods for dense neural\nnetwork search, advanced feature selection, and utilities for data management\nand visualization of training outcomes. This manuscript presents an overview of\nDFMLU's functionalities, providing Python examples for each tool.", "journal": ""}
{"doi": "10.48550/arXiv.2411.15945", "date": "2024-11-24", "title": "Understanding Machine Learning Paradigms through the Lens of Statistical Thermodynamics: A tutorial", "authors": "Star, Liu", "abstract": "This tutorial investigates the convergence of statistical mechanics and\nlearning theory, elucidating the potential enhancements in machine learning\nmethodologies through the integration of foundational principles from physics.\nThe tutorial delves into advanced techniques like entropy, free energy, and\nvariational inference which are utilized in machine learning, illustrating\ntheir significant contributions to model efficiency and robustness. By bridging\nthese scientific disciplines, we aspire to inspire newer methodologies in\nresearches, demonstrating how an in-depth comprehension of physical systems'\nbehavior can yield more effective and dependable machine learning models,\nparticularly in contexts characterized by uncertainty.", "journal": ""}
{"doi": "10.48550/arXiv.2412.13276", "date": "2024-12-17", "title": "GPgym: A Remote Service Platform with Gaussian Process Regression for Online Learning", "authors": "Xiaobing Dai, Zewen Yang", "abstract": "Machine learning is now widely applied across various domains, including\nindustry, engineering, and research. While numerous mature machine learning\nmodels have been open-sourced on platforms like GitHub, their deployment often\nrequires writing scripts in specific programming languages, such as Python,\nC++, or MATLAB. This dependency on particular languages creates a barrier for\nprofessionals outside the field of machine learning, making it challenging to\nintegrate these algorithms into their workflows. To address this limitation, we\npropose GPgym, a remote service node based on Gaussian process regression.\nGPgym enables experts from diverse fields to seamlessly and flexibly\nincorporate machine learning techniques into their existing specialized\nsoftware, without needing to write or manage complex script code.", "journal": ""}
{"doi": "10.48550/arXiv.2412.18529", "date": "2024-12-24", "title": "Accelerating process control and optimization via machine learning: A review", "authors": "Ilias Mitrai, Prodromos Daoutidis", "abstract": "Process control and optimization have been widely used to solve\ndecision-making problems in chemical engineering applications. However,\nidentifying and tuning the best solution algorithm is challenging and\ntime-consuming. Machine learning tools can be used to automate these steps by\nlearning the behavior of a numerical solver from data. In this paper, we\ndiscuss recent advances in (i) the representation of decision-making problems\nfor machine learning tasks, (ii) algorithm selection, and (iii) algorithm\nconfiguration for monolithic and decomposition-based algorithms. Finally, we\ndiscuss open problems related to the application of machine learning for\naccelerating process optimization and control.", "journal": ""}
{"doi": "10.48550/arXiv.1904.05061", "date": "2019-04-10", "title": "A review on Neural Turing Machine", "authors": "Soroor Malekmohammadi Faradonbeh, Faramarz Safi-Esfahani", "abstract": "One of the major objectives of Artificial Intelligence is to design learning\nalgorithms that are executed on a general purposes computational machines such\nas human brain. Neural Turing Machine (NTM) is a step towards realizing such a\ncomputational machine. The attempt is made here to run a systematic review on\nNeural Turing Machine. First, the mind-map and taxonomy of machine learning,\nneural networks, and Turing machine are introduced. Next, NTM is inspected in\nterms of concepts, structure, variety of versions, implemented tasks,\ncomparisons, etc. Finally, the paper discusses on issues and ends up with\nseveral future works.", "journal": ""}
{"doi": "10.48550/arXiv.2504.21296", "date": "2025-04-30", "title": "Fairness in Graph Learning Augmented with Machine Learning: A Survey", "authors": "Renqiang Luo, Ziqi Xu, Xikun Zhang, Qing Qing, Huafei Huang, Enyan Dai, Zhe Wang, Bo Yang", "abstract": "Augmenting specialised machine learning techniques into traditional graph\nlearning models has achieved notable success across various domains, including\nfederated graph learning, dynamic graph learning, and graph transformers.\nHowever, the intricate mechanisms of these specialised techniques introduce\nsignificant challenges in maintaining model fairness, potentially resulting in\ndiscriminatory outcomes in high-stakes applications such as recommendation\nsystems, disaster response, criminal justice, and loan approval. This paper\nsystematically examines the unique fairness challenges posed by Graph Learning\naugmented with Machine Learning (GL-ML). It highlights the complex interplay\nbetween graph learning mechanisms and machine learning techniques, emphasising\nhow the augmentation of machine learning both enhances and complicates\nfairness. Additionally, we explore four critical techniques frequently employed\nto improve fairness in GL-ML methods. By thoroughly investigating the root\ncauses and broader implications of fairness challenges in this rapidly evolving\nfield, this work establishes a robust foundation for future research and\ninnovation in GL-ML fairness.", "journal": ""}
{"doi": "10.48550/arXiv.2107.11921", "date": "2021-07-26", "title": "Compensation Learning", "authors": "Rujing Yao, Ou Wu", "abstract": "Weighting strategy prevails in machine learning. For example, a common\napproach in robust machine learning is to exert lower weights on samples which\nare likely to be noisy or quite hard. This study reveals another undiscovered\nstrategy, namely, compensating. Various incarnations of compensating have been\nutilized but it has not been explicitly revealed. Learning with compensating is\ncalled compensation learning and a systematic taxonomy is constructed for it in\nthis study. In our taxonomy, compensation learning is divided on the basis of\nthe compensation targets, directions, inference manners, and granularity\nlevels. Many existing learning algorithms including some classical ones can be\nviewed or understood at least partially as compensation techniques.\nFurthermore, a family of new learning algorithms can be obtained by plugging\nthe compensation learning into existing learning algorithms. Specifically, two\nconcrete new learning algorithms are proposed for robust machine learning.\nExtensive experiments on image classification and text sentiment analysis\nverify the effectiveness of the two new algorithms. Compensation learning can\nalso be used in other various learning scenarios, such as imbalance learning,\nclustering, regression, and so on.", "journal": ""}
{"doi": "10.48550/arXiv.2404.19370", "date": "2024-04-30", "title": "Numeric Reward Machines", "authors": "Kristina Levina, Nikolaos Pappas, Athanasios Karapantelakis, Aneta Vulgarakis Feljan, Jendrik Seipp", "abstract": "Reward machines inform reinforcement learning agents about the reward\nstructure of the environment and often drastically speed up the learning\nprocess. However, reward machines only accept Boolean features such as\nrobot-reached-gold. Consequently, many inherently numeric tasks cannot profit\nfrom the guidance offered by reward machines. To address this gap, we aim to\nextend reward machines with numeric features such as distance-to-gold. For\nthis, we present two types of reward machines: numeric-Boolean and numeric. In\na numeric-Boolean reward machine, distance-to-gold is emulated by two Boolean\nfeatures distance-to-gold-decreased and robot-reached-gold. In a numeric reward\nmachine, distance-to-gold is used directly alongside the Boolean feature\nrobot-reached-gold. We compare our new approaches to a baseline reward machine\nin the Craft domain, where the numeric feature is the agent-to-target distance.\nWe use cross-product Q-learning, Q-learning with counter-factual experiences,\nand the options framework for learning. Our experimental results show that our\nnew approaches significantly outperform the baseline approach. Extending reward\nmachines with numeric features opens up new possibilities of using reward\nmachines in inherently numeric tasks.", "journal": ""}
{"doi": "10.48550/arXiv.1711.02038", "date": "2017-11-06", "title": "An efficient quantum algorithm for generative machine learning", "authors": "Xun Gao, Zhengyu Zhang, Luming Duan", "abstract": "A central task in the field of quantum computing is to find applications\nwhere quantum computer could provide exponential speedup over any classical\ncomputer. Machine learning represents an important field with broad\napplications where quantum computer may offer significant speedup. Several\nquantum algorithms for discriminative machine learning have been found based on\nefficient solving of linear algebraic problems, with potential exponential\nspeedup in runtime under the assumption of effective input from a quantum\nrandom access memory. In machine learning, generative models represent another\nlarge class which is widely used for both supervised and unsupervised learning.\nHere, we propose an efficient quantum algorithm for machine learning based on a\nquantum generative model. We prove that our proposed model is exponentially\nmore powerful to represent probability distributions compared with classical\ngenerative models and has exponential speedup in training and inference at\nleast for some instances under a reasonable assumption in computational\ncomplexity theory. Our result opens a new direction for quantum machine\nlearning and offers a remarkable example in which a quantum algorithm shows\nexponential improvement over any classical algorithm in an important\napplication field.", "journal": ""}
{"doi": "10.48550/arXiv.1802.05351", "date": "2018-02-14", "title": "Stealing Hyperparameters in Machine Learning", "authors": "Binghui Wang, Neil Zhenqiang Gong", "abstract": "Hyperparameters are critical in machine learning, as different\nhyperparameters often result in models with significantly different\nperformance. Hyperparameters may be deemed confidential because of their\ncommercial value and the confidentiality of the proprietary algorithms that the\nlearner uses to learn them. In this work, we propose attacks on stealing the\nhyperparameters that are learned by a learner. We call our attacks\nhyperparameter stealing attacks. Our attacks are applicable to a variety of\npopular machine learning algorithms such as ridge regression, logistic\nregression, support vector machine, and neural network. We evaluate the\neffectiveness of our attacks both theoretically and empirically. For instance,\nwe evaluate our attacks on Amazon Machine Learning. Our results demonstrate\nthat our attacks can accurately steal hyperparameters. We also study\ncountermeasures. Our results highlight the need for new defenses against our\nhyperparameter stealing attacks for certain machine learning algorithms.", "journal": ""}
{"doi": "10.48550/arXiv.1812.03057", "date": "2018-12-07", "title": "Open Problems in Engineering and Quality Assurance of Safety Critical Machine Learning Systems", "authors": "Hiroshi Kuwajima, Hirotoshi Yasuoka, Toshihiro Nakae", "abstract": "Fatal accidents are a major issue hindering the wide acceptance of\nsafety-critical systems using machine-learning and deep-learning models, such\nas automated-driving vehicles. Quality assurance frameworks are required for\nsuch machine learning systems, but there are no widely accepted and established\nquality-assurance concepts and techniques. At the same time, open problems and\nthe relevant technical fields are not organized. To establish standard quality\nassurance frameworks, it is necessary to visualize and organize these open\nproblems in an interdisciplinary way, so that the experts from many different\ntechnical fields may discuss these problems in depth and develop solutions. In\nthe present study, we identify, classify, and explore the open problems in\nquality assurance of safety-critical machine-learning systems, and their\nrelevant corresponding industry and technological trends, using\nautomated-driving vehicles as an example. Our results show that addressing\nthese open problems requires incorporating knowledge from several different\ntechnological and industrial fields, including the automobile industry,\nstatistics, software engineering, and machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.2006.09271", "date": "2020-06-15", "title": "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification", "authors": "Edward Raff, Charles Nicholas", "abstract": "Malware classification is a difficult problem, to which machine learning\nmethods have been applied for decades. Yet progress has often been slow, in\npart due to a number of unique difficulties with the task that occur through\nall stages of the developing a machine learning system: data collection,\nlabeling, feature creation and selection, model selection, and evaluation. In\nthis survey we will review a number of the current methods and challenges\nrelated to malware classification, including data collection, feature\nextraction, and model construction, and evaluation. Our discussion will include\nthoughts on the constraints that must be considered for machine learning based\nsolutions in this domain, and yet to be tackled problems for which machine\nlearning could also provide a solution. This survey aims to be useful both to\ncybersecurity practitioners who wish to learn more about how machine learning\ncan be applied to the malware problem, and to give data scientists the\nnecessary background into the challenges in this uniquely complicated space.", "journal": ""}
{"doi": "10.48550/arXiv.2006.16789", "date": "2020-06-27", "title": "Causality Learning: A New Perspective for Interpretable Machine Learning", "authors": "Guandong Xu, Tri Dung Duong, Qian Li, Shaowu Liu, Xianzhi Wang", "abstract": "Recent years have witnessed the rapid growth of machine learning in a wide\nrange of fields such as image recognition, text classification, credit scoring\nprediction, recommendation system, etc. In spite of their great performance in\ndifferent sectors, researchers still concern about the mechanism under any\nmachine learning (ML) techniques that are inherently black-box and becoming\nmore complex to achieve higher accuracy. Therefore, interpreting machine\nlearning model is currently a mainstream topic in the research community.\nHowever, the traditional interpretable machine learning focuses on the\nassociation instead of the causality. This paper provides an overview of causal\nanalysis with the fundamental background and key concepts, and then summarizes\nmost recent causal approaches for interpretable machine learning. The\nevaluation techniques for assessing method quality, and open problems in causal\ninterpretability are also discussed in this paper.", "journal": ""}
{"doi": "10.48550/arXiv.1805.05409", "date": "2018-05-11", "title": "Machine Learning for Public Administration Research, with Application to Organizational Reputation", "authors": "L. Jason Anastasopoulos, Andrew B. Whitford", "abstract": "Machine learning methods have gained a great deal of popularity in recent\nyears among public administration scholars and practitioners. These techniques\nopen the door to the analysis of text, image and other types of data that allow\nus to test foundational theories of public administration and to develop new\ntheories. Despite the excitement surrounding machine learning methods, clarity\nregarding their proper use and potential pitfalls is lacking. This paper\nattempts to fill this gap in the literature through providing a machine\nlearning \"guide to practice\" for public administration scholars and\npractitioners. Here, we take a foundational view of machine learning and\ndescribe how these methods can enrich public administration research and\npractice through their ability develop new measures, tap into new sources of\ndata and conduct statistical inference and causal inference in a principled\nmanner. We then turn our attention to the pitfalls of using these methods such\nas unvalidated measures and lack of interpretability. Finally, we demonstrate\nhow machine learning techniques can help us learn about organizational\nreputation in federal agencies through an illustrated example using tweets from\n13 executive federal agencies.", "journal": ""}
{"doi": "10.48550/arXiv.1904.05961", "date": "2019-04-11", "title": "Robust Coreset Construction for Distributed Machine Learning", "authors": "Hanlin Lu, Ming-Ju Li, Ting He, Shiqiang Wang, Vijaykrishnan Narayanan, Kevin S Chan", "abstract": "Coreset, which is a summary of the original dataset in the form of a small\nweighted set in the same sample space, provides a promising approach to enable\nmachine learning over distributed data. Although viewed as a proxy of the\noriginal dataset, each coreset is only designed to approximate the cost\nfunction of a specific machine learning problem, and thus different coresets\nare often required to solve different machine learning problems, increasing the\ncommunication overhead. We resolve this dilemma by developing robust coreset\nconstruction algorithms that can support a variety of machine learning\nproblems. Motivated by empirical evidence that suitably-weighted k-clustering\ncenters provide a robust coreset, we harden the observation by establishing\ntheoretical conditions under which the coreset provides a guaranteed\napproximation for a broad range of machine learning problems, and developing\nboth centralized and distributed algorithms to generate coresets satisfying the\nconditions. The robustness of the proposed algorithms is verified through\nextensive experiments on diverse datasets with respect to both supervised and\nunsupervised learning problems.", "journal": ""}
{"doi": "10.48550/arXiv.1907.00678", "date": "2019-07-01", "title": "Two-stage Optimization for Machine Learning Workflow", "authors": "Alexandre Quemy", "abstract": "Machines learning techniques plays a preponderant role in dealing with\nmassive amount of data and are employed in almost every possible domain.\nBuilding a high quality machine learning model to be deployed in production is\na challenging task, from both, the subject matter experts and the machine\nlearning practitioners.\n  For a broader adoption and scalability of machine learning systems, the\nconstruction and configuration of machine learning workflow need to gain in\nautomation. In the last few years, several techniques have been developed in\nthis direction, known as autoML.\n  In this paper, we present a two-stage optimization process to build data\npipelines and configure machine learning algorithms. First, we study the impact\nof data pipelines compared to algorithm configuration in order to show the\nimportance of data preprocessing over hyperparameter tuning. The second part\npresents policies to efficiently allocate search time between data pipeline\nconstruction and algorithm configuration. Those policies are agnostic from the\nmetaoptimizer. Last, we present a metric to determine if a data pipeline is\nspecific or independent from the algorithm, enabling fine-grain pipeline\npruning and meta-learning for the coldstart problem.", "journal": ""}
{"doi": "10.48550/arXiv.1911.03886", "date": "2019-11-10", "title": "Performance Analysis on Machine Learning-Based Channel Estimation", "authors": "Kai Mei, Jun Liu, Xiaochen Zhang, Nandana Rajatheva, Jibo Wei", "abstract": "Recently, machine learning-based channel estimation has attracted much\nattention. The performance of machine learning-based estimation has been\nvalidated by simulation experiments. However, little attention has been paid to\nthe theoretical performance analysis. In this paper, we investigate the mean\nsquare error (MSE) performance of machine learning-based estimation. Hypothesis\ntesting is employed to analyze its MSE upper bound. Furthermore, we build a\nstatistical model for hypothesis testing, which holds when the linear learning\nmodule with a low input dimension is used in machine learning-based channel\nestimation, and derive a clear analytical relation between the size of the\ntraining data and performance. Then, we simulate the machine learning-based\nchannel estimation in orthogonal frequency division multiplexing (OFDM) systems\nto verify our analysis results. Finally, the design considerations for the\nsituation where only limited training data is available are discussed. In this\nsituation, our analysis results can be applied to assess the performance and\nsupport the design of machine learning-based channel estimation.", "journal": ""}
{"doi": "10.48550/arXiv.2009.04661", "date": "2020-09-10", "title": "A Framework for Fairer Machine Learning in Organizations", "authors": "Lily Morse, Mike H. M. Teodorescu, Yazeed Awwad, Gerald Kane", "abstract": "With the increase in adoption of machine learning tools by organizations\nrisks of unfairness abound, especially when human decision processes in\noutcomes of socio-economic importance such as hiring, housing, lending, and\nadmissions are automated. We reveal sources of unfair machine learning, review\nfairness criteria, and provide a framework which, if implemented, would enable\nan organization to both avoid implementing an unfair machine learning model,\nbut also to avoid the common situation that as an algorithm learns with more\ndata it can become unfair over time. Issues of behavioral ethics in machine\nlearning implementations by organizations have not been thoroughly addressed in\nthe literature, because many of the necessary concepts are dispersed across\nthree literatures: ethics, machine learning, and management. Further, tradeoffs\nbetween fairness criteria in machine learning have not been addressed with\nregards to organizations. We advance the research by introducing an organizing\nframework for selecting and implementing fair algorithms in organizations.", "journal": ""}
{"doi": "10.48550/arXiv.2112.01998", "date": "2021-12-03", "title": "Application of Machine Learning in understanding plant virus pathogenesis: Trends and perspectives on emergence, diagnosis, host-virus interplay and management", "authors": "Dibyendu Ghosh, Srija Chakraborty, Hariprasad Kodamana, Supriya Chakraborty", "abstract": "Inclusion of high throughput technologies in the field of biology has\ngenerated massive amounts of biological data in the recent years. Now,\ntransforming these huge volumes of data into knowledge is the primary challenge\nin computational biology. The traditional methods of data analysis have failed\nto carry out the task. Hence, researchers are turning to machine learning based\napproaches for the analysis of high-dimensional big data. In machine learning,\nonce a model is trained with a training dataset, it can be applied on a testing\ndataset which is independent. In current times, deep learning algorithms\nfurther promote the application of machine learning in several field of biology\nincluding plant virology. Considering a significant progress in the application\nof machine learning in understanding plant virology, this review highlights an\nintroductory note on machine learning and comprehensively discusses the trends\nand prospects of machine learning in diagnosis of viral diseases, understanding\nhost-virus interplay and emergence of plant viruses.", "journal": ""}
{"doi": "10.48550/arXiv.2211.10708", "date": "2022-11-19", "title": "A Survey on Differential Privacy with Machine Learning and Future Outlook", "authors": "Samah Baraheem, Zhongmei Yao", "abstract": "Nowadays, machine learning models and applications have become increasingly\npervasive. With this rapid increase in the development and employment of\nmachine learning models, a concern regarding privacy has risen. Thus, there is\na legitimate need to protect the data from leaking and from any attacks. One of\nthe strongest and most prevalent privacy models that can be used to protect\nmachine learning models from any attacks and vulnerabilities is differential\nprivacy (DP). DP is strict and rigid definition of privacy, where it can\nguarantee that an adversary is not capable to reliably predict if a specific\nparticipant is included in the dataset or not. It works by injecting a noise to\nthe data whether to the inputs, the outputs, the ground truth labels, the\nobjective functions, or even to the gradients to alleviate the privacy issue\nand protect the data. To this end, this survey paper presents different\ndifferentially private machine learning algorithms categorized into two main\ncategories (traditional machine learning models vs. deep learning models).\nMoreover, future research directions for differential privacy with machine\nlearning algorithms are outlined.", "journal": ""}
{"doi": "10.48550/arXiv.2302.02926", "date": "2023-02-06", "title": "Curriculum Graph Machine Learning: A Survey", "authors": "Haoyang Li, Xin Wang, Wenwu Zhu", "abstract": "Graph machine learning has been extensively studied in both academia and\nindustry. However, in the literature, most existing graph machine learning\nmodels are designed to conduct training with data samples in a random order,\nwhich may suffer from suboptimal performance due to ignoring the importance of\ndifferent graph data samples and their training orders for the model\noptimization status. To tackle this critical problem, curriculum graph machine\nlearning (Graph CL), which integrates the strength of graph machine learning\nand curriculum learning, arises and attracts an increasing amount of attention\nfrom the research community. Therefore, in this paper, we comprehensively\noverview approaches on Graph CL and present a detailed survey of recent\nadvances in this direction. Specifically, we first discuss the key challenges\nof Graph CL and provide its formal problem definition. Then, we categorize and\nsummarize existing methods into three classes based on three kinds of graph\nmachine learning tasks, i.e., node-level, link-level, and graph-level tasks.\nFinally, we share our thoughts on future research directions. To the best of\nour knowledge, this paper is the first survey for curriculum graph machine\nlearning.", "journal": ""}
{"doi": "10.48550/arXiv.2306.04646", "date": "2023-06-01", "title": "Improve State-Level Wheat Yield Forecasts in Kazakhstan on GEOGLAM's EO Data by Leveraging A Simple Spatial-Aware Technique", "authors": "Anh Nhat Nhu, Ritvik Sahajpal, Christina Justice, Inbal Becker-Reshef", "abstract": "Accurate yield forecasting is essential for making informed policies and\nlong-term decisions for food security. Earth Observation (EO) data and machine\nlearning algorithms play a key role in providing a comprehensive and timely\nview of crop conditions from field to national scales. However, machine\nlearning algorithms' prediction accuracy is often harmed by spatial\nheterogeneity caused by exogenous factors not reflected in remote sensing data,\nsuch as differences in crop management strategies. In this paper, we propose\nand investigate a simple technique called state-wise additive bias to\nexplicitly address the cross-region yield heterogeneity in Kazakhstan. Compared\nto baseline machine learning models (Random Forest, CatBoost, XGBoost), our\nmethod reduces the overall RMSE by 8.9\\% and the highest state-wise RMSE by\n28.37\\%. The effectiveness of state-wise additive bias indicates machine\nlearning's performance can be significantly improved by explicitly addressing\nthe spatial heterogeneity, motivating future work on spatial-aware machine\nlearning algorithms for yield forecasts as well as for general geospatial\nforecasting problems.", "journal": "International Conference on Learning Representation (ICLR), First\n  Workshop on Machine Learning for Remote Sensing, 2023"}
{"doi": "10.48550/arXiv.2402.14694", "date": "2024-02-22", "title": "A Quick Introduction to Quantum Machine Learning for Non-Practitioners", "authors": "Ethan N. Evans, Dominic Byrne, Matthew G. Cook", "abstract": "This paper provides an introduction to quantum machine learning, exploring\nthe potential benefits of using quantum computing principles and algorithms\nthat may improve upon classical machine learning approaches. Quantum computing\nutilizes particles governed by quantum mechanics for computational purposes,\nleveraging properties like superposition and entanglement for information\nrepresentation and manipulation. Quantum machine learning applies these\nprinciples to enhance classical machine learning models, potentially reducing\nnetwork size and training time on quantum hardware. The paper covers basic\nquantum mechanics principles, including superposition, phase space, and\nentanglement, and introduces the concept of quantum gates that exploit these\nproperties. It also reviews classical deep learning concepts, such as\nartificial neural networks, gradient descent, and backpropagation, before\ndelving into trainable quantum circuits as neural networks. An example problem\ndemonstrates the potential advantages of quantum neural networks, and the\nappendices provide detailed derivations. The paper aims to help researchers new\nto quantum mechanics and machine learning develop their expertise more\nefficiently.", "journal": ""}
{"doi": "10.48550/arXiv.1711.04708", "date": "2017-11-13", "title": "Machine Learning for the Geosciences: Challenges and Opportunities", "authors": "Anuj Karpatne, Imme Ebert-Uphoff, Sai Ravela, Hassan Ali Babaie, Vipin Kumar", "abstract": "Geosciences is a field of great societal relevance that requires solutions to\nseveral urgent problems facing our humanity and the planet. As geosciences\nenters the era of big data, machine learning (ML) -- that has been widely\nsuccessful in commercial domains -- offers immense potential to contribute to\nproblems in geosciences. However, problems in geosciences have several unique\nchallenges that are seldom found in traditional applications, requiring novel\nproblem formulations and methodologies in machine learning. This article\nintroduces researchers in the machine learning (ML) community to these\nchallenges offered by geoscience problems and the opportunities that exist for\nadvancing both machine learning and geosciences. We first highlight typical\nsources of geoscience data and describe their properties that make it\nchallenging to use traditional machine learning techniques. We then describe\nsome of the common categories of geoscience problems where machine learning can\nplay a role, and discuss some of the existing efforts and promising directions\nfor methodological development in machine learning. We conclude by discussing\nsome of the emerging research themes in machine learning that are applicable\nacross all problems in the geosciences, and the importance of a deep\ncollaboration between machine learning and geosciences for synergistic\nadvancements in both disciplines.", "journal": ""}
{"doi": "10.48550/arXiv.2006.13311", "date": "2020-06-16", "title": "70 years of machine learning in geoscience in review", "authors": "Jesper S\u00f6ren Dramsch", "abstract": "This review gives an overview of the development of machine learning in\ngeoscience. A thorough analysis of the co-developments of machine learning\napplications throughout the last 70 years relates the recent enthusiasm for\nmachine learning to developments in geoscience. I explore the shift of kriging\ntowards a mainstream machine learning method and the historic application of\nneural networks in geoscience, following the general trend of machine learning\nenthusiasm through the decades. Furthermore, this chapter explores the shift\nfrom mathematical fundamentals and knowledge in software development towards\nskills in model validation, applied statistics, and integrated subject matter\nexpertise. The review is interspersed with code examples to complement the\ntheoretical foundations and illustrate model validation and machine learning\nexplainability for science. The scope of this review includes various shallow\nmachine learning methods, e.g. Decision Trees, Random Forests, Support-Vector\nMachines, and Gaussian Processes, as well as, deep neural networks, including\nfeed-forward neural networks, convolutional neural networks, recurrent neural\nnetworks and generative adversarial networks. Regarding geoscience, the review\nhas a bias towards geophysics but aims to strike a balance with geochemistry,\ngeostatistics, and geology, however excludes remote sensing, as this would\nexceed the scope. In general, I aim to provide context for the recent\nenthusiasm surrounding deep learning with respect to research, hardware, and\nsoftware developments that enable successful application of shallow and deep\nmachine learning in all disciplines of Earth science.", "journal": ""}
{"doi": "10.48550/arXiv.1811.01315", "date": "2018-11-04", "title": "Modeling Stated Preference for Mobility-on-Demand Transit: A Comparison of Machine Learning and Logit Models", "authors": "Xilei Zhao, Xiang Yan, Alan Yu, Pascal Van Hentenryck", "abstract": "Logit models are usually applied when studying individual travel behavior,\ni.e., to predict travel mode choice and to gain behavioral insights on traveler\npreferences. Recently, some studies have applied machine learning to model\ntravel mode choice and reported higher out-of-sample predictive accuracy than\ntraditional logit models (e.g., multinomial logit). However, little research\nfocuses on comparing the interpretability of machine learning with logit\nmodels. In other words, how to draw behavioral insights from the\nhigh-performance \"black-box\" machine-learning models remains largely unsolved\nin the field of travel behavior modeling.\n  This paper aims at providing a comprehensive comparison between the two\napproaches by examining the key similarities and differences in model\ndevelopment, evaluation, and behavioral interpretation between logit and\nmachine-learning models for travel mode choice modeling. To complement the\ntheoretical discussions, the paper also empirically evaluates the two\napproaches on the stated-preference survey data for a new type of transit\nsystem integrating high-frequency fixed-route services and ridesourcing. The\nresults show that machine learning can produce significantly higher predictive\naccuracy than logit models. Moreover, machine learning and logit models largely\nagree on many aspects of behavioral interpretations. In addition, machine\nlearning can automatically capture the nonlinear relationship between the input\nfeatures and choice outcomes. The paper concludes that there is great potential\nin merging ideas from machine learning and conventional statistical methods to\ndevelop refined models for travel behavior research and suggests some new\nresearch directions.", "journal": ""}
{"doi": "10.48550/arXiv.1911.02621", "date": "2019-11-06", "title": "The Threat of Adversarial Attacks on Machine Learning in Network Security -- A Survey", "authors": "Olakunle Ibitoye, Rana Abou-Khamis, Mohamed el Shehaby, Ashraf Matrawy, M. Omair Shafiq", "abstract": "Machine learning models have made many decision support systems to be faster,\nmore accurate, and more efficient. However, applications of machine learning in\nnetwork security face a more disproportionate threat of active adversarial\nattacks compared to other domains. This is because machine learning\napplications in network security such as malware detection, intrusion\ndetection, and spam filtering are by themselves adversarial in nature. In what\ncould be considered an arm's race between attackers and defenders, adversaries\nconstantly probe machine learning systems with inputs that are explicitly\ndesigned to bypass the system and induce a wrong prediction. In this survey, we\nfirst provide a taxonomy of machine learning techniques, tasks, and depth. We\nthen introduce a classification of machine learning in network security\napplications. Next, we examine various adversarial attacks against machine\nlearning in network security and introduce two classification approaches for\nadversarial attacks in network security. First, we classify adversarial attacks\nin network security based on a taxonomy of network security applications.\nSecondly, we categorize adversarial attacks in network security into a problem\nspace vs feature space dimensional classification model. We then analyze the\nvarious defenses against adversarial attacks on machine learning-based network\nsecurity applications. We conclude by introducing an adversarial risk grid map\nand evaluating several existing adversarial attacks against machine learning in\nnetwork security using the risk grid map. We also identify where each attack\nclassification resides within the adversarial risk grid map.", "journal": ""}
{"doi": "10.48550/arXiv.2007.15745", "date": "2020-07-30", "title": "On Hyperparameter Optimization of Machine Learning Algorithms: Theory and Practice", "authors": "Li Yang, Abdallah Shami", "abstract": "Machine learning algorithms have been used widely in various applications and\nareas. To fit a machine learning model into different problems, its\nhyper-parameters must be tuned. Selecting the best hyper-parameter\nconfiguration for machine learning models has a direct impact on the model's\nperformance. It often requires deep knowledge of machine learning algorithms\nand appropriate hyper-parameter optimization techniques. Although several\nautomatic optimization techniques exist, they have different strengths and\ndrawbacks when applied to different types of problems. In this paper,\noptimizing the hyper-parameters of common machine learning models is studied.\nWe introduce several state-of-the-art optimization techniques and discuss how\nto apply them to machine learning algorithms. Many available libraries and\nframeworks developed for hyper-parameter optimization problems are provided,\nand some open challenges of hyper-parameter optimization research are also\ndiscussed in this paper. Moreover, experiments are conducted on benchmark\ndatasets to compare the performance of different optimization methods and\nprovide practical examples of hyper-parameter optimization. This survey paper\nwill help industrial users, data analysts, and researchers to better develop\nmachine learning models by identifying the proper hyper-parameter\nconfigurations effectively.", "journal": ""}
{"doi": "10.48550/arXiv.2101.11948", "date": "2021-01-28", "title": "Choice modelling in the age of machine learning -- discussion paper", "authors": "S. Van Cranenburgh, S. Wang, A. Vij, F. Pereira, J. Walker", "abstract": "Since its inception, the choice modelling field has been dominated by\ntheory-driven modelling approaches. Machine learning offers an alternative\ndata-driven approach for modelling choice behaviour and is increasingly drawing\ninterest in our field. Cross-pollination of machine learning models, techniques\nand practices could help overcome problems and limitations encountered in the\ncurrent theory-driven modelling paradigm, such as subjective labour-intensive\nsearch processes for model selection, and the inability to work with text and\nimage data. However, despite the potential benefits of using the advances of\nmachine learning to improve choice modelling practices, the choice modelling\nfield has been hesitant to embrace machine learning. This discussion paper aims\nto consolidate knowledge on the use of machine learning models, techniques and\npractices for choice modelling, and discuss their potential. Thereby, we hope\nnot only to make the case that further integration of machine learning in\nchoice modelling is beneficial, but also to further facilitate it. To this end,\nwe clarify the similarities and differences between the two modelling\nparadigms; we review the use of machine learning for choice modelling; and we\nexplore areas of opportunities for embracing machine learning models and\ntechniques to improve our practices. To conclude this discussion paper, we put\nforward a set of research questions which must be addressed to better\nunderstand if and how machine learning can benefit choice modelling.", "journal": "Journal of Choice Modelling 42 (2022): 100340"}
{"doi": "10.48550/arXiv.2107.01238", "date": "2021-07-02", "title": "Solving Machine Learning Problems", "authors": "Sunny Tran, Pranav Krishna, Ishan Pakuwal, Prabhakar Kafle, Nikhil Singh, Jayson Lynch, Iddo Drori", "abstract": "Can a machine learn Machine Learning? This work trains a machine learning\nmodel to solve machine learning problems from a University undergraduate level\ncourse. We generate a new training set of questions and answers consisting of\ncourse exercises, homework, and quiz questions from MIT's 6.036 Introduction to\nMachine Learning course and train a machine learning model to answer these\nquestions. Our system demonstrates an overall accuracy of 96% for open-response\nquestions and 97% for multiple-choice questions, compared with MIT students'\naverage of 93%, achieving grade A performance in the course, all in real-time.\nQuestions cover all 12 topics taught in the course, excluding coding questions\nor questions with images. Topics include: (i) basic machine learning\nprinciples; (ii) perceptrons; (iii) feature extraction and selection; (iv)\nlogistic regression; (v) regression; (vi) neural networks; (vii) advanced\nneural networks; (viii) convolutional neural networks; (ix) recurrent neural\nnetworks; (x) state machines and MDPs; (xi) reinforcement learning; and (xii)\ndecision trees. Our system uses Transformer models within an encoder-decoder\narchitecture with graph and tree representations. An important aspect of our\napproach is a data-augmentation scheme for generating new example problems. We\nalso train a machine learning model to generate problem hints. Thus, our system\nautomatically generates new questions across topics, answers both open-response\nquestions and multiple-choice questions, classifies problems, and generates\nproblem hints, pushing the envelope of AI for STEM education.", "journal": ""}
{"doi": "10.48550/arXiv.2208.02030", "date": "2022-08-02", "title": "BPMN4sML: A BPMN Extension for Serverless Machine Learning. Technology Independent and Interoperable Modeling of Machine Learning Workflows and their Serverless Deployment Orchestration", "authors": "Laurens Martin Tetzlaff", "abstract": "Machine learning (ML) continues to permeate all layers of academia, industry\nand society. Despite its successes, mental frameworks to capture and represent\nmachine learning workflows in a consistent and coherent manner are lacking. For\ninstance, the de facto process modeling standard, Business Process Model and\nNotation (BPMN), managed by the Object Management Group, is widely accepted and\napplied. However, it is short of specific support to represent machine learning\nworkflows. Further, the number of heterogeneous tools for deployment of machine\nlearning solutions can easily overwhelm practitioners. Research is needed to\nalign the process from modeling to deploying ML workflows.\n  We analyze requirements for standard based conceptual modeling for machine\nlearning workflows and their serverless deployment. Confronting the\nshortcomings with respect to consistent and coherent modeling of ML workflows\nin a technology independent and interoperable manner, we extend BPMN's\nMeta-Object Facility (MOF) metamodel and the corresponding notation and\nintroduce BPMN4sML (BPMN for serverless machine learning). Our extension\nBPMN4sML follows the same outline referenced by the Object Management Group\n(OMG) for BPMN. We further address the heterogeneity in deployment by proposing\na conceptual mapping to convert BPMN4sML models to corresponding deployment\nmodels using TOSCA.\n  BPMN4sML allows technology-independent and interoperable modeling of machine\nlearning workflows of various granularity and complexity across the entire\nmachine learning lifecycle. It aids in arriving at a shared and standardized\nlanguage to communicate ML solutions. Moreover, it takes the first steps toward\nenabling conversion of ML workflow model diagrams to corresponding deployment\nmodels for serverless deployment via TOSCA.", "journal": ""}
{"doi": "10.48550/arXiv.1910.07012", "date": "2019-10-15", "title": "Transfer Learning for Algorithm Recommendation", "authors": "Gean Trindade Pereira, Mois\u00e9s dos Santos, Edesio Alcoba\u00e7a, Rafael Mantovani, Andr\u00e9 Carvalho", "abstract": "Meta-Learning is a subarea of Machine Learning that aims to take advantage of\nprior knowledge to learn faster and with fewer data [1]. There are different\nscenarios where meta-learning can be applied, and one of the most common is\nalgorithm recommendation, where previous experience on applying machine\nlearning algorithms for several datasets can be used to learn which algorithm,\nfrom a set of options, would be more suitable for a new dataset [2]. Perhaps\nthe most popular form of meta-learning is transfer learning, which consists of\ntransferring knowledge acquired by a machine learning algorithm in a previous\nlearning task to increase its performance faster in another and similar task\n[3]. Transfer Learning has been widely applied in a variety of complex tasks\nsuch as image classification, machine translation and, speech recognition,\nachieving remarkable results [4,5,6,7,8]. Although transfer learning is very\nused in traditional or base-learning, it is still unknown if it is useful in a\nmeta-learning setup. For that purpose, in this paper, we investigate the\neffects of transferring knowledge in the meta-level instead of base-level.\nThus, we train a neural network on meta-datasets related to algorithm\nrecommendation, and then using transfer learning, we reuse the knowledge\nlearned by the neural network in other similar datasets from the same domain,\nto verify how transferable is the acquired meta-knowledge.", "journal": ""}
{"doi": "10.48550/arXiv.2004.11694", "date": "2020-04-18", "title": "Identifying Semantically Duplicate Questions Using Data Science Approach: A Quora Case Study", "authors": "Navedanjum Ansari, Rajesh Sharma", "abstract": "Identifying semantically identical questions on, Question and Answering\nsocial media platforms like Quora is exceptionally significant to ensure that\nthe quality and the quantity of content are presented to users, based on the\nintent of the question and thus enriching overall user experience. Detecting\nduplicate questions is a challenging problem because natural language is very\nexpressive, and a unique intent can be conveyed using different words, phrases,\nand sentence structuring. Machine learning and deep learning methods are known\nto have accomplished superior results over traditional natural language\nprocessing techniques in identifying similar texts. In this paper, taking Quora\nfor our case study, we explored and applied different machine learning and deep\nlearning techniques on the task of identifying duplicate questions on Quora's\ndataset. By using feature engineering, feature importance techniques, and\nexperimenting with seven selected machine learning classifiers, we demonstrated\nthat our models outperformed previous studies on this task. Xgboost model with\ncharacter level term frequency and inverse term frequency is our best machine\nlearning model that has also outperformed a few of the Deep learning baseline\nmodels. We applied deep learning techniques to model four different deep neural\nnetworks of multiple layers consisting of Glove embeddings, Long Short Term\nMemory, Convolution, Max pooling, Dense, Batch Normalization, Activation\nfunctions, and model merge. Our deep learning models achieved better accuracy\nthan machine learning models. Three out of four proposed architectures\noutperformed the accuracy from previous machine learning and deep learning\nresearch work, two out of four models outperformed accuracy from previous deep\nlearning study on Quora's question pair dataset, and our best model achieved\naccuracy of 85.82% which is close to Quora state of the art accuracy.", "journal": ""}
{"doi": "10.48550/arXiv.2107.02378", "date": "2021-07-06", "title": "Learning an Explicit Hyperparameter Prediction Function Conditioned on Tasks", "authors": "Jun Shu, Deyu Meng, Zongben Xu", "abstract": "Meta learning has attracted much attention recently in machine learning\ncommunity. Contrary to conventional machine learning aiming to learn inherent\nprediction rules to predict labels for new query data, meta learning aims to\nlearn the learning methodology for machine learning from observed tasks, so as\nto generalize to new query tasks by leveraging the meta-learned learning\nmethodology. In this study, we interpret such learning methodology as learning\nan explicit hyper-parameter prediction function shared by all training tasks.\nSpecifically, this function is represented as a parameterized function called\nmeta-learner, mapping from a training/test task to its suitable hyper-parameter\nsetting, extracted from a pre-specified function set called meta learning\nmachine. Such setting guarantees that the meta-learned learning methodology is\nable to flexibly fit diverse query tasks, instead of only obtaining fixed\nhyper-parameters by many current meta learning methods, with less adaptability\nto query task's variations. Such understanding of meta learning also makes it\neasily succeed from traditional learning theory for analyzing its\ngeneralization bounds with general losses/tasks/models. The theory naturally\nleads to some feasible controlling strategies for ameliorating the quality of\nthe extracted meta-learner, verified to be able to finely ameliorate its\ngeneralization capability in some typical meta learning applications, including\nfew-shot regression, few-shot classification and domain generalization.", "journal": ""}
{"doi": "10.48550/arXiv.1903.12394", "date": "2019-03-29", "title": "Informed Machine Learning -- A Taxonomy and Survey of Integrating Knowledge into Learning Systems", "authors": "Laura von Rueden, Sebastian Mayer, Katharina Beckh, Bogdan Georgiev, Sven Giesselbach, Raoul Heese, Birgit Kirsch, Julius Pfrommer, Annika Pick, Rajkumar Ramamurthy, Michal Walczak, Jochen Garcke, Christian Bauckhage, Jannis Schuecker", "abstract": "Despite its great success, machine learning can have its limits when dealing\nwith insufficient training data. A potential solution is the additional\nintegration of prior knowledge into the training process which leads to the\nnotion of informed machine learning. In this paper, we present a structured\noverview of various approaches in this field. We provide a definition and\npropose a concept for informed machine learning which illustrates its building\nblocks and distinguishes it from conventional machine learning. We introduce a\ntaxonomy that serves as a classification framework for informed machine\nlearning approaches. It considers the source of knowledge, its representation,\nand its integration into the machine learning pipeline. Based on this taxonomy,\nwe survey related research and describe how different knowledge representations\nsuch as algebraic equations, logic rules, or simulation results can be used in\nlearning systems. This evaluation of numerous papers on the basis of our\ntaxonomy uncovers key methods in the field of informed machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.2401.16407", "date": "2024-01-29", "title": "Is K-fold cross validation the best model selection method for Machine Learning?", "authors": "Juan M Gorriz, R. Martin Clemente, F Segovia, J Ramirez, A Ortiz, J. Suckling", "abstract": "As a technique that can compactly represent complex patterns, machine\nlearning has significant potential for predictive inference. K-fold\ncross-validation (CV) is the most common approach to ascertaining the\nlikelihood that a machine learning outcome is generated by chance, and it\nfrequently outperforms conventional hypothesis testing. This improvement uses\nmeasures directly obtained from machine learning classifications, such as\naccuracy, that do not have a parametric description. To approach a frequentist\nanalysis within machine learning pipelines, a permutation test or simple\nstatistics from data partitions (i.e., folds) can be added to estimate\nconfidence intervals. Unfortunately, neither parametric nor non-parametric\ntests solve the inherent problems of partitioning small sample-size datasets\nand learning from heterogeneous data sources. The fact that machine learning\nstrongly depends on the learning parameters and the distribution of data across\nfolds recapitulates familiar difficulties around excess false positives and\nreplication. A novel statistical test based on K-fold CV and the Upper Bound of\nthe actual risk (K-fold CUBV) is proposed, where uncertain predictions of\nmachine learning with CV are bounded by the worst case through the evaluation\nof concentration inequalities. Probably Approximately Correct-Bayesian upper\nbounds for linear classifiers in combination with K-fold CV are derived and\nused to estimate the actual risk. The performance with simulated and\nneuroimaging datasets suggests that K-fold CUBV is a robust criterion for\ndetecting effects and validating accuracy values obtained from machine learning\nand classical CV schemes, while avoiding excess false positives.", "journal": ""}
{"doi": "10.48550/arXiv.1607.01354", "date": "2016-03-22", "title": "Learning Discriminative Features using Encoder-Decoder type Deep Neural Nets", "authors": "Vishwajeet Singh, Killamsetti Ravi Kumar, K Eswaran", "abstract": "As machine learning is applied to an increasing variety of complex problems,\nwhich are defined by high dimensional and complex data sets, the necessity for\ntask oriented feature learning grows in importance. With the advancement of\nDeep Learning algorithms, various successful feature learning techniques have\nevolved. In this paper, we present a novel way of learning discriminative\nfeatures by training Deep Neural Nets which have Encoder or Decoder type\narchitecture similar to an Autoencoder. We demonstrate that our approach can\nlearn discriminative features which can perform better at pattern\nclassification tasks when the number of training samples is relatively small in\nsize.", "journal": ""}
{"doi": "10.48550/arXiv.1802.08250", "date": "2018-02-22", "title": "SeNA-CNN: Overcoming Catastrophic Forgetting in Convolutional Neural Networks by Selective Network Augmentation", "authors": "Abel S. Zacarias, Lu\u00eds A. Alexandre", "abstract": "Lifelong learning aims to develop machine learning systems that can learn new\ntasks while preserving the performance on previous learned tasks. In this paper\nwe present a method to overcome catastrophic forgetting on convolutional neural\nnetworks, that learns new tasks and preserves the performance on old tasks\nwithout accessing the data of the original model, by selective network\naugmentation. The experiment results showed that SeNA-CNN, in some scenarios,\noutperforms the state-of-art Learning without Forgetting algorithm. Results\nalso showed that in some situations it is better to use SeNA-CNN instead of\ntraining a neural network using isolated learning.", "journal": ""}
{"doi": "10.48550/arXiv.2111.12867", "date": "2021-11-25", "title": "Back to Reality for Imitation Learning", "authors": "Edward Johns", "abstract": "Imitation learning, and robot learning in general, emerged due to\nbreakthroughs in machine learning, rather than breakthroughs in robotics. As\nsuch, evaluation metrics for robot learning are deeply rooted in those for\nmachine learning, and focus primarily on data efficiency. We believe that a\nbetter metric for real-world robot learning is time efficiency, which better\nmodels the true cost to humans. This is a call to arms to the robot learning\ncommunity to develop our own evaluation metrics, tailored towards the long-term\ngoals of real-world robotics.", "journal": ""}
{"doi": "10.48550/arXiv.1801.07883", "date": "2018-01-24", "title": "Deep Learning for Sentiment Analysis : A Survey", "authors": "Lei Zhang, Shuai Wang, Bing Liu", "abstract": "Deep learning has emerged as a powerful machine learning technique that\nlearns multiple layers of representations or features of the data and produces\nstate-of-the-art prediction results. Along with the success of deep learning in\nmany other application domains, deep learning is also popularly used in\nsentiment analysis in recent years. This paper first gives an overview of deep\nlearning and then provides a comprehensive survey of its current applications\nin sentiment analysis.", "journal": ""}
{"doi": "10.48550/arXiv.1809.02591", "date": "2018-09-07", "title": "Learning Invariances for Policy Generalization", "authors": "Remi Tachet, Philip Bachman, Harm van Seijen", "abstract": "While recent progress has spawned very powerful machine learning systems,\nthose agents remain extremely specialized and fail to transfer the knowledge\nthey gain to similar yet unseen tasks. In this paper, we study a simple\nreinforcement learning problem and focus on learning policies that encode the\nproper invariances for generalization to different settings. We evaluate three\npotential methods for policy generalization: data augmentation, meta-learning\nand adversarial training. We find our data augmentation method to be effective,\nand study the potential of meta-learning and adversarial learning as\nalternative task-agnostic approaches.", "journal": ""}
{"doi": "10.48550/arXiv.2202.03070", "date": "2022-02-07", "title": "Addressing modern and practical challenges in machine learning: A survey of online federated and transfer learning", "authors": "Shuang Dai, Fanlin Meng", "abstract": "Online federated learning (OFL) and online transfer learning (OTL) are two\ncollaborative paradigms for overcoming modern machine learning challenges such\nas data silos, streaming data, and data security. This survey explored OFL and\nOTL throughout their major evolutionary routes to enhance understanding of\nonline federated and transfer learning. Besides, practical aspects of popular\ndatasets and cutting-edge applications for online federated and transfer\nlearning are highlighted in this work. Furthermore, this survey provides\ninsight into potential future research areas and aims to serve as a resource\nfor professionals developing online federated and transfer learning frameworks.", "journal": ""}
{"doi": "10.48550/arXiv.2002.10619", "date": "2020-02-25", "title": "Three Approaches for Personalization with Applications to Federated Learning", "authors": "Yishay Mansour, Mehryar Mohri, Jae Ro, Ananda Theertha Suresh", "abstract": "The standard objective in machine learning is to train a single model for all\nusers. However, in many learning scenarios, such as cloud computing and\nfederated learning, it is possible to learn a personalized model per user. In\nthis work, we present a systematic learning-theoretic study of personalization.\nWe propose and analyze three approaches: user clustering, data interpolation,\nand model interpolation. For all three approaches, we provide\nlearning-theoretic guarantees and efficient algorithms for which we also\ndemonstrate the performance empirically. All of our algorithms are\nmodel-agnostic and work for any hypothesis class.", "journal": ""}
{"doi": "10.48550/arXiv.1705.02908", "date": "2017-05-08", "title": "Machine Learning with World Knowledge: The Position and Survey", "authors": "Yangqiu Song, Dan Roth", "abstract": "Machine learning has become pervasive in multiple domains, impacting a wide\nvariety of applications, such as knowledge discovery and data mining, natural\nlanguage processing, information retrieval, computer vision, social and health\ninformatics, ubiquitous computing, etc. Two essential problems of machine\nlearning are how to generate features and how to acquire labels for machines to\nlearn. Particularly, labeling large amount of data for each domain-specific\nproblem can be very time consuming and costly. It has become a key obstacle in\nmaking learning protocols realistic in applications. In this paper, we will\ndiscuss how to use the existing general-purpose world knowledge to enhance\nmachine learning processes, by enriching the features or reducing the labeling\nwork. We start from the comparison of world knowledge with domain-specific\nknowledge, and then introduce three key problems in using world knowledge in\nlearning processes, i.e., explicit and implicit feature representation,\ninference for knowledge linking and disambiguation, and learning with direct or\nindirect supervision. Finally we discuss the future directions of this research\ntopic.", "journal": ""}
{"doi": "10.48550/arXiv.1804.00709", "date": "2018-04-02", "title": "Generative Adversarial Learning for Spectrum Sensing", "authors": "Kemal Davaslioglu, Yalin E. Sagduyu", "abstract": "A novel approach of training data augmentation and domain adaptation is\npresented to support machine learning applications for cognitive radio. Machine\nlearning provides effective tools to automate cognitive radio functionalities\nby reliably extracting and learning intrinsic spectrum dynamics. However, there\nare two important challenges to overcome, in order to fully utilize the machine\nlearning benefits with cognitive radios. First, machine learning requires\nsignificant amount of truthed data to capture complex channel and emitter\ncharacteristics, and train the underlying algorithm (e.g., a classifier).\nSecond, the training data that has been identified for one spectrum environment\ncannot be used for another one (e.g., after channel and emitter conditions\nchange). To address these challenges, a generative adversarial network (GAN)\nwith deep learning structures is used to 1)~generate additional synthetic\ntraining data to improve classifier accuracy, and 2) adapt training data to\nspectrum dynamics. This approach is applied to spectrum sensing by assuming\nonly limited training data without knowledge of spectrum statistics. Machine\nlearning classifiers are trained with limited, augmented and adapted training\ndata to detect signals. Results show that training data augmentation increases\nthe classifier accuracy significantly and this increase is sustained with\ndomain adaptation as spectrum conditions change.", "journal": ""}
{"doi": "10.48550/arXiv.2010.04430", "date": "2020-10-09", "title": "Large-scale randomized experiment reveals machine learning helps people learn and remember more effectively", "authors": "Utkarsh Upadhyay, Graham Lancashire, Christoph Moser, Manuel Gomez-Rodriguez", "abstract": "Machine learning has typically focused on developing models and algorithms\nthat would ultimately replace humans at tasks where intelligence is required.\nIn this work, rather than replacing humans, we focus on unveiling the potential\nof machine learning to improve how people learn and remember factual material.\nTo this end, we perform a large-scale randomized controlled trial with\nthousands of learners from a popular learning app in the area of mobility.\nAfter controlling for the length and frequency of study, we find that learners\nwhose study sessions are optimized using machine learning remember the content\nover $\\sim$67% longer than those whose study sessions are generated using two\nalternative heuristics. Our randomized controlled trial also reveals that the\nlearners whose study sessions are optimized using machine learning are\n$\\sim$50% more likely to return to the app within 4-7 days.", "journal": ""}
{"doi": "10.48550/arXiv.2307.05232", "date": "2023-07-11", "title": "A Survey From Distributed Machine Learning to Distributed Deep Learning", "authors": "Mohammad Dehghani, Zahra Yazdanparast", "abstract": "Artificial intelligence has made remarkable progress in handling complex\ntasks, thanks to advances in hardware acceleration and machine learning\nalgorithms. However, to acquire more accurate outcomes and solve more complex\nissues, algorithms should be trained with more data. Processing this huge\namount of data could be time-consuming and require a great deal of computation.\nTo address these issues, distributed machine learning has been proposed, which\ninvolves distributing the data and algorithm across several machines. There has\nbeen considerable effort put into developing distributed machine learning\nalgorithms, and different methods have been proposed so far. We divide these\nalgorithms in classification and clustering (traditional machine learning),\ndeep learning and deep reinforcement learning groups. Distributed deep learning\nhas gained more attention in recent years and most of the studies have focused\non this approach. Therefore, we mostly concentrate on this category. Based on\nthe investigation of the mentioned algorithms, we highlighted the limitations\nthat should be addressed in future research.", "journal": ""}
{"doi": "10.48550/arXiv.2204.11897", "date": "2022-04-25", "title": "Reinforcement Teaching", "authors": "Calarina Muslimani, Alex Lewandowski, Dale Schuurmans, Matthew E. Taylor, Jun Luo", "abstract": "Machine learning algorithms learn to solve a task, but are unable to improve\ntheir ability to learn. Meta-learning methods learn about machine learning\nalgorithms and improve them so that they learn more quickly. However, existing\nmeta-learning methods are either hand-crafted to improve one specific component\nof an algorithm or only work with differentiable algorithms. We develop a\nunifying meta-learning framework, called Reinforcement Teaching, to improve the\nlearning process of \\emph{any} algorithm. Under Reinforcement Teaching, a\nteaching policy is learned, through reinforcement, to improve a student's\nlearning algorithm. To learn an effective teaching policy, we introduce the\nparametric-behavior embedder that learns a representation of the student's\nlearnable parameters from its input/output behavior. We further use learning\nprogress to shape the teacher's reward, allowing it to more quickly maximize\nthe student's performance. To demonstrate the generality of Reinforcement\nTeaching, we conduct experiments in which a teacher learns to significantly\nimprove both reinforcement and supervised learning algorithms. Reinforcement\nTeaching outperforms previous work using heuristic reward functions and state\nrepresentations, as well as other parameter representations.", "journal": ""}
{"doi": "10.48550/arXiv.1707.06742", "date": "2017-07-21", "title": "Machine Teaching: A New Paradigm for Building Machine Learning Systems", "authors": "Patrice Y. Simard, Saleema Amershi, David M. Chickering, Alicia Edelman Pelton, Soroush Ghorashi, Christopher Meek, Gonzalo Ramos, Jina Suh, Johan Verwey, Mo Wang, John Wernsing", "abstract": "The current processes for building machine learning systems require\npractitioners with deep knowledge of machine learning. This significantly\nlimits the number of machine learning systems that can be created and has led\nto a mismatch between the demand for machine learning systems and the ability\nfor organizations to build them. We believe that in order to meet this growing\ndemand for machine learning systems we must significantly increase the number\nof individuals that can teach machines. We postulate that we can achieve this\ngoal by making the process of teaching machines easy, fast and above all,\nuniversally accessible.\n  While machine learning focuses on creating new algorithms and improving the\naccuracy of \"learners\", the machine teaching discipline focuses on the efficacy\nof the \"teachers\". Machine teaching as a discipline is a paradigm shift that\nfollows and extends principles of software engineering and programming\nlanguages. We put a strong emphasis on the teacher and the teacher's\ninteraction with data, as well as crucial components such as techniques and\ndesign principles of interaction and visualization.\n  In this paper, we present our position regarding the discipline of machine\nteaching and articulate fundamental machine teaching principles. We also\ndescribe how, by decoupling knowledge about machine learning algorithms from\nthe process of teaching, we can accelerate innovation and empower millions of\nnew uses for machine learning models.", "journal": ""}
{"doi": "10.48550/arXiv.1409.4044", "date": "2014-09-14", "title": "A new approach in machine learning", "authors": "Alain Tapp", "abstract": "In this technical report we presented a novel approach to machine learning.\nOnce the new framework is presented, we will provide a simple and yet very\npowerful learning algorithm which will be benchmark on various dataset.\n  The framework we proposed is based on booleen circuits; more specifically the\nclassifier produced by our algorithm have that form. Using bits and boolean\ngates instead of real numbers and multiplication enable the the learning\nalgorithm and classifier to use very efficient boolean vector operations. This\nenable both the learning algorithm and classifier to be extremely efficient.\nThe accuracy of the classifier we obtain with our framework compares very\nfavorably those produced by conventional techniques, both in terms of\nefficiency and accuracy.", "journal": ""}
{"doi": "10.48550/arXiv.1903.05202", "date": "2019-03-12", "title": "Continual Learning in Practice", "authors": "Tom Diethe, Tom Borchert, Eno Thereska, Borja Balle, Neil Lawrence", "abstract": "This paper describes a reference architecture for self-maintaining systems\nthat can learn continually, as data arrives. In environments where data\nevolves, we need architectures that manage Machine Learning (ML) models in\nproduction, adapt to shifting data distributions, cope with outliers, retrain\nwhen necessary, and adapt to new tasks. This represents continual AutoML or\nAutomatically Adaptive Machine Learning. We describe the challenges and\nproposes a reference architecture.", "journal": ""}
{"doi": "10.48550/arXiv.1909.13340", "date": "2019-09-29", "title": "Learning Everywhere: A Taxonomy for the Integration of Machine Learning and Simulations", "authors": "Geoffrey Fox, Shantenu Jha", "abstract": "We present a taxonomy of research on Machine Learning (ML) applied to enhance\nsimulations together with a catalog of some activities. We cover eight patterns\nfor the link of ML to the simulations or systems plus three algorithmic areas:\nparticle dynamics, agent-based models and partial differential equations. The\npatterns are further divided into three action areas: Improving simulation with\nConfigurations and Integration of Data, Learn Structure, Theory and Model for\nSimulation, and Learn to make Surrogates.", "journal": ""}
{"doi": "10.48550/arXiv.1210.8353", "date": "2012-10-31", "title": "Temporal Autoencoding Restricted Boltzmann Machine", "authors": "Chris H\u00e4usler, Alex Susemihl", "abstract": "Much work has been done refining and characterizing the receptive fields\nlearned by deep learning algorithms. A lot of this work has focused on the\ndevelopment of Gabor-like filters learned when enforcing sparsity constraints\non a natural image dataset. Little work however has investigated how these\nfilters might expand to the temporal domain, namely through training on natural\nmovies. Here we investigate exactly this problem in established temporal deep\nlearning algorithms as well as a new learning paradigm suggested here, the\nTemporal Autoencoding Restricted Boltzmann Machine (TARBM).", "journal": ""}
{"doi": "10.48550/arXiv.1801.06275", "date": "2018-01-19", "title": "IoT Security Techniques Based on Machine Learning", "authors": "Liang Xiao, Xiaoyue Wan, Xiaozhen Lu, Yanyong Zhang, Di Wu", "abstract": "Internet of things (IoT) that integrate a variety of devices into networks to\nprovide advanced and intelligent services have to protect user privacy and\naddress attacks such as spoofing attacks, denial of service attacks, jamming\nand eavesdropping. In this article, we investigate the attack model for IoT\nsystems, and review the IoT security solutions based on machine learning\ntechniques including supervised learning, unsupervised learning and\nreinforcement learning. We focus on the machine learning based IoT\nauthentication, access control, secure offloading and malware detection schemes\nto protect data privacy. In this article, we discuss the challenges that need\nto be addressed to implement these machine learning based security schemes in\npractical IoT systems.", "journal": ""}
{"doi": "10.48550/arXiv.1910.01612", "date": "2019-10-03", "title": "Partial differential equation regularization for supervised machine learning", "authors": "Adam M Oberman", "abstract": "This article is an overview of supervised machine learning problems for\nregression and classification. Topics include: kernel methods, training by\nstochastic gradient descent, deep learning architecture, losses for\nclassification, statistical learning theory, and dimension independent\ngeneralization bounds. Implicit regularization in deep learning examples are\npresented, including data augmentation, adversarial training, and additive\nnoise. These methods are reframed as explicit gradient regularization.", "journal": ""}
{"doi": "10.48550/arXiv.2010.01040", "date": "2020-10-02", "title": "Attention-Based Clustering: Learning a Kernel from Context", "authors": "Samuel Coward, Erik Visse-Martindale, Chithrupa Ramesh", "abstract": "In machine learning, no data point stands alone. We believe that context is\nan underappreciated concept in many machine learning methods. We propose\nAttention-Based Clustering (ABC), a neural architecture based on the attention\nmechanism, which is designed to learn latent representations that adapt to\ncontext within an input set, and which is inherently agnostic to input sizes\nand number of clusters. By learning a similarity kernel, our method directly\ncombines with any out-of-the-box kernel-based clustering approach. We present\ncompetitive results for clustering Omniglot characters and include analytical\nevidence of the effectiveness of an attention-based approach for clustering.", "journal": ""}
{"doi": "10.48550/arXiv.2104.05569", "date": "2021-04-12", "title": "Deep Learning for IoT", "authors": "Tao Lin", "abstract": "Deep learning and other machine learning approaches are deployed to many\nsystems related to Internet of Things or IoT. However, it faces challenges that\nadversaries can take loopholes to hack these systems through tampering history\ndata. This paper first presents overall points of adversarial machine learning.\nThen, we illustrate traditional methods, such as Petri Net cannot solve this\nnew question efficiently. To help IoT data analysis more efficient, we propose\na retrieval method based on deep learning (recurrent neural network). Besides,\nthis paper presents a research on data retrieval solution to avoid hacking by\nadversaries in the fields of adversary machine leaning. It further directs the\nnew approaches in terms of how to implementing this framework in IoT settings\nbased on adversarial deep learning.", "journal": ""}
{"doi": "10.48550/arXiv.2211.04254", "date": "2022-11-07", "title": "FedGrad: Optimisation in Decentralised Machine Learning", "authors": "Mann Patel", "abstract": "Federated Learning is a machine learning paradigm where we aim to train\nmachine learning models in a distributed fashion. Many clients/edge devices\ncollaborate with each other to train a single model on the central. Clients do\nnot share their own datasets with each other, decoupling computation and data\non the same device. In this paper, we propose yet another adaptive federated\noptimization method and some other ideas in the field of federated learning. We\nalso perform experiments using these methods and showcase the improvement in\nthe overall performance of federated learning.", "journal": ""}
{"doi": "10.48550/arXiv.2305.07801", "date": "2023-05-12", "title": "Quantum learning machines", "authors": "G J Milburn", "abstract": "Physical learning machines, be they classical or quantum, are necessarily\ndissipative systems. The rate of energy dissipation decreases as the learning\nerror rate decreases linking thermodynamic efficiency and learning efficiency.\nIn the classical case the energy is dissipated as heat. We give an example\nbased on a quantum optical perceptron where the energy is dissipated as\nspontaneous emission. At optical frequencies the temperature is effectively\nzero so this perceptron is as efficient as it is possible to get. The example\nillustrates a general point: In a classical learning machine, measurement is\ntaken to reveal objective facts about the world. In quantum learning machines\nwhat is learned is defined by the nature of the measurement itself.", "journal": ""}
{"doi": "10.48550/arXiv.2409.12100", "date": "2024-09-18", "title": "Symmetry-Enriched Learning: A Category-Theoretic Framework for Robust Machine Learning Models", "authors": "Ronald Katende", "abstract": "This manuscript presents a novel framework that integrates higher-order\nsymmetries and category theory into machine learning. We introduce new\nmathematical constructs, including hyper-symmetry categories and functorial\nrepresentations, to model complex transformations within learning algorithms.\nOur contributions include the design of symmetry-enriched learning models, the\ndevelopment of advanced optimization techniques leveraging categorical\nsymmetries, and the theoretical analysis of their implications for model\nrobustness, generalization, and convergence. Through rigorous proofs and\npractical applications, we demonstrate that incorporating higher-dimensional\ncategorical structures enhances both the theoretical foundations and practical\ncapabilities of modern machine learning algorithms, opening new directions for\nresearch and innovation.", "journal": ""}
{"doi": "10.48550/arXiv.1811.03392", "date": "2018-11-08", "title": "Transformative Machine Learning", "authors": "Ivan Olier, Oghenejokpeme I. Orhobor, Joaquin Vanschoren, Ross D. King", "abstract": "The key to success in machine learning (ML) is the use of effective data\nrepresentations. Traditionally, data representations were hand-crafted.\nRecently it has been demonstrated that, given sufficient data, deep neural\nnetworks can learn effective implicit representations from simple input\nrepresentations. However, for most scientific problems, the use of deep\nlearning is not appropriate as the amount of available data is limited, and/or\nthe output models must be explainable. Nevertheless, many scientific problems\ndo have significant amounts of data available on related tasks, which makes\nthem amenable to multi-task learning, i.e. learning many related problems\nsimultaneously. Here we propose a novel and general representation learning\napproach for multi-task learning that works successfully with small amounts of\ndata. The fundamental new idea is to transform an input intrinsic data\nrepresentation (i.e., handcrafted features), to an extrinsic representation\nbased on what a pre-trained set of models predict about the examples. This\ntransformation has the dual advantages of producing significantly more accurate\npredictions, and providing explainable models. To demonstrate the utility of\nthis transformative learning approach, we have applied it to three real-world\nscientific problems: drug-design (quantitative structure activity relationship\nlearning), predicting human gene expression (across different tissue types and\ndrug treatments), and meta-learning for machine learning (predicting which\nmachine learning methods work best for a given problem). In all three problems,\ntransformative machine learning significantly outperforms the best intrinsic\nrepresentation.", "journal": ""}
{"doi": "10.48550/arXiv.2010.05113", "date": "2020-10-10", "title": "Contrastive Representation Learning: A Framework and Review", "authors": "Phuc H. Le-Khac, Graham Healy, Alan F. Smeaton", "abstract": "Contrastive Learning has recently received interest due to its success in\nself-supervised representation learning in the computer vision domain. However,\nthe origins of Contrastive Learning date as far back as the 1990s and its\ndevelopment has spanned across many fields and domains including Metric\nLearning and natural language processing. In this paper we provide a\ncomprehensive literature review and we propose a general Contrastive\nRepresentation Learning framework that simplifies and unifies many different\ncontrastive learning methods. We also provide a taxonomy for each of the\ncomponents of contrastive learning in order to summarise it and distinguish it\nfrom other forms of machine learning. We then discuss the inductive biases\nwhich are present in any contrastive learning system and we analyse our\nframework under different views from various sub-fields of Machine Learning.\nExamples of how contrastive learning has been applied in computer vision,\nnatural language processing, audio processing, and others, as well as in\nReinforcement Learning are also presented. Finally, we discuss the challenges\nand some of the most promising future research directions ahead.", "journal": ""}
{"doi": "10.48550/arXiv.2012.04863", "date": "2020-12-09", "title": "Skillearn: Machine Learning Inspired by Humans' Learning Skills", "authors": "Pengtao Xie, Xuefeng Du, Hao Ban", "abstract": "Humans, as the most powerful learners on the planet, have accumulated a lot\nof learning skills, such as learning through tests, interleaving learning,\nself-explanation, active recalling, to name a few. These learning skills and\nmethodologies enable humans to learn new topics more effectively and\nefficiently. We are interested in investigating whether humans' learning skills\ncan be borrowed to help machines to learn better. Specifically, we aim to\nformalize these skills and leverage them to train better machine learning (ML)\nmodels. To achieve this goal, we develop a general framework -- Skillearn,\nwhich provides a principled way to represent humans' learning skills\nmathematically and use the formally-represented skills to improve the training\nof ML models. In two case studies, we apply Skillearn to formalize two learning\nskills of humans: learning by passing tests and interleaving learning, and use\nthe formalized skills to improve neural architecture search. Experiments on\nvarious datasets show that trained using the skills formalized by Skillearn, ML\nmodels achieve significantly better performance.", "journal": ""}
{"doi": "10.48550/arXiv.1806.02865", "date": "2018-06-07", "title": "Kernel Machines With Missing Responses", "authors": "Tiantian Liu, Yair Goldberg", "abstract": "Missing responses is a missing data format in which outcomes are not always\nobserved. In this work we develop kernel machines that can handle missing\nresponses. First, we propose a kernel machine family that uses mainly the\ncomplete cases. For the quadratic loss, we then propose a family of\ndoubly-robust kernel machines. The proposed kernel-machine estimators can be\napplied to both regression and classification problems. We prove oracle\ninequalities for the finite-sample differences between the kernel machine risk\nand Bayes risk. We use these oracle inequalities to prove consistency and to\ncalculate convergence rates. We demonstrate the performance of the two proposed\nkernel machine families using both a simulation study and a real-world data\nanalysis.", "journal": ""}
{"doi": "10.48550/arXiv.1802.01034", "date": "2018-02-03", "title": "Multi-task Learning for Continuous Control", "authors": "Himani Arora, Rajath Kumar, Jason Krone, Chong Li", "abstract": "Reliable and effective multi-task learning is a prerequisite for the\ndevelopment of robotic agents that can quickly learn to accomplish related,\neveryday tasks. However, in the reinforcement learning domain, multi-task\nlearning has not exhibited the same level of success as in other domains, such\nas computer vision. In addition, most reinforcement learning research on\nmulti-task learning has been focused on discrete action spaces, which are not\nused for robotic control in the real-world. In this work, we apply multi-task\nlearning methods to continuous action spaces and benchmark their performance on\na series of simulated continuous control tasks. Most notably, we show that\nmulti-task learning outperforms our baselines and alternative knowledge sharing\nmethods.", "journal": ""}
{"doi": "10.48550/arXiv.2002.05518", "date": "2020-02-08", "title": "Learning State Abstractions for Transfer in Continuous Control", "authors": "Kavosh Asadi, David Abel, Michael L. Littman", "abstract": "Can simple algorithms with a good representation solve challenging\nreinforcement learning problems? In this work, we answer this question in the\naffirmative, where we take \"simple learning algorithm\" to be tabular\nQ-Learning, the \"good representations\" to be a learned state abstraction, and\n\"challenging problems\" to be continuous control tasks. Our main contribution is\na learning algorithm that abstracts a continuous state-space into a discrete\none. We transfer this learned representation to unseen problems to enable\neffective learning. We provide theory showing that learned abstractions\nmaintain a bounded value loss, and we report experiments showing that the\nabstractions empower tabular Q-Learning to learn efficiently in unseen tasks.", "journal": ""}
{"doi": "10.48550/arXiv.1908.10714", "date": "2019-08-22", "title": "Automated Architecture Design for Deep Neural Networks", "authors": "Steven Abreu", "abstract": "Machine learning has made tremendous progress in recent years and received\nlarge amounts of public attention. Though we are still far from designing a\nfull artificially intelligent agent, machine learning has brought us many\napplications in which computers solve human learning tasks remarkably well.\nMuch of this progress comes from a recent trend within machine learning, called\ndeep learning. Deep learning models are responsible for many state-of-the-art\napplications of machine learning. Despite their success, deep learning models\nare hard to train, very difficult to understand, and often times so complex\nthat training is only possible on very large GPU clusters. Lots of work has\nbeen done on enabling neural networks to learn efficiently. However, the design\nand architecture of such neural networks is often done manually through trial\nand error and expert knowledge. This thesis inspects different approaches,\nexisting and novel, to automate the design of deep feedforward neural networks\nin an attempt to create less complex models with good performance that take\naway the burden of deciding on an architecture and make it more efficient to\ndesign and train such deep networks.", "journal": ""}
{"doi": "10.48550/arXiv.1402.3382", "date": "2014-02-14", "title": "Machine Learning of Phonologically Conditioned Noun Declensions For Tamil Morphological Generators", "authors": "K. Rajan, Dr. V. Ramalingam, Dr. M. Ganesan", "abstract": "This paper presents machine learning solutions to a practical problem of\nNatural Language Generation (NLG), particularly the word formation in\nagglutinative languages like Tamil, in a supervised manner. The morphological\ngenerator is an important component of Natural Language Processing in\nArtificial Intelligence. It generates word forms given a root and affixes. The\nmorphophonemic changes like addition, deletion, alternation etc., occur when\ntwo or more morphemes or words joined together. The Sandhi rules should be\nexplicitly specified in the rule based morphological analyzers and generators.\nIn machine learning framework, these rules can be learned automatically by the\nsystem from the training samples and subsequently be applied for new inputs. In\nthis paper we proposed the machine learning models which learn the\nmorphophonemic rules for noun declensions from the given training data. These\nmodels are trained to learn sandhi rules using various learning algorithms and\nthe performance of those algorithms are presented. From this we conclude that\nmachine learning of morphological processing such as word form generation can\nbe successfully learned in a supervised manner, without explicit description of\nrules. The performance of Decision trees and Bayesian machine learning\nalgorithms on noun declensions are discussed.", "journal": ""}
{"doi": "10.48550/arXiv.2112.01088", "date": "2021-12-02", "title": "Constrained Machine Learning: The Bagel Framework", "authors": "Guillaume Perez, Sebastian Ament, Carla Gomes, Arnaud Lallouet", "abstract": "Machine learning models are widely used for real-world applications, such as\ndocument analysis and vision. Constrained machine learning problems are\nproblems where learned models have to both be accurate and respect constraints.\nFor continuous convex constraints, many works have been proposed, but learning\nunder combinatorial constraints is still a hard problem. The goal of this paper\nis to broaden the modeling capacity of constrained machine learning problems by\nincorporating existing work from combinatorial optimization. We propose first a\ngeneral framework called BaGeL (Branch, Generate and Learn) which applies\nBranch and Bound to constrained learning problems where a learning problem is\ngenerated and trained at each node until only valid models are obtained.\nBecause machine learning has specific requirements, we also propose an extended\ntable constraint to split the space of hypotheses. We validate the approach on\ntwo examples: a linear regression under configuration constraints and a\nnon-negative matrix factorization with prior knowledge for latent semantics\nanalysis.", "journal": ""}
{"doi": "10.48550/arXiv.2303.16310", "date": "2023-03-28", "title": "Crime Prediction Using Machine Learning and Deep Learning: A Systematic Review and Future Directions", "authors": "Varun Mandalapu, Lavanya Elluri, Piyush Vyas, Nirmalya Roy", "abstract": "Predicting crime using machine learning and deep learning techniques has\ngained considerable attention from researchers in recent years, focusing on\nidentifying patterns and trends in crime occurrences. This review paper\nexamines over 150 articles to explore the various machine learning and deep\nlearning algorithms applied to predict crime. The study provides access to the\ndatasets used for crime prediction by researchers and analyzes prominent\napproaches applied in machine learning and deep learning algorithms to predict\ncrime, offering insights into different trends and factors related to criminal\nactivities. Additionally, the paper highlights potential gaps and future\ndirections that can enhance the accuracy of crime prediction. Finally, the\ncomprehensive overview of research discussed in this paper on crime prediction\nusing machine learning and deep learning approaches serves as a valuable\nreference for researchers in this field. By gaining a deeper understanding of\ncrime prediction techniques, law enforcement agencies can develop strategies to\nprevent and respond to criminal activities more effectively.", "journal": ""}
{"doi": "10.48550/arXiv.1912.09789", "date": "2019-12-20", "title": "A Survey on Distributed Machine Learning", "authors": "Joost Verbraeken, Matthijs Wolting, Jonathan Katzy, Jeroen Kloppenburg, Tim Verbelen, Jan S. Rellermeyer", "abstract": "The demand for artificial intelligence has grown significantly over the last\ndecade and this growth has been fueled by advances in machine learning\ntechniques and the ability to leverage hardware acceleration. However, in order\nto increase the quality of predictions and render machine learning solutions\nfeasible for more complex applications, a substantial amount of training data\nis required. Although small machine learning models can be trained with modest\namounts of data, the input for training larger models such as neural networks\ngrows exponentially with the number of parameters. Since the demand for\nprocessing training data has outpaced the increase in computation power of\ncomputing machinery, there is a need for distributing the machine learning\nworkload across multiple machines, and turning the centralized into a\ndistributed system. These distributed systems present new challenges, first and\nforemost the efficient parallelization of the training process and the creation\nof a coherent model. This article provides an extensive overview of the current\nstate-of-the-art in the field by outlining the challenges and opportunities of\ndistributed machine learning over conventional (centralized) machine learning,\ndiscussing the techniques used for distributed machine learning, and providing\nan overview of the systems that are available.", "journal": ""}
{"doi": "10.48550/arXiv.2008.02369", "date": "2020-08-05", "title": "QUBO Formulations for Training Machine Learning Models", "authors": "Prasanna Date, Davis Arthur, Lauren Pusey-Nazzaro", "abstract": "Training machine learning models on classical computers is usually a time and\ncompute intensive process. With Moore's law coming to an end and ever\nincreasing demand for large-scale data analysis using machine learning, we must\nleverage non-conventional computing paradigms like quantum computing to train\nmachine learning models efficiently. Adiabatic quantum computers like the\nD-Wave 2000Q can approximately solve NP-hard optimization problems, such as the\nquadratic unconstrained binary optimization (QUBO), faster than classical\ncomputers. Since many machine learning problems are also NP-hard, we believe\nadiabatic quantum computers might be instrumental in training machine learning\nmodels efficiently in the post Moore's law era. In order to solve a problem on\nadiabatic quantum computers, it must be formulated as a QUBO problem, which is\na challenging task in itself. In this paper, we formulate the training problems\nof three machine learning models---linear regression, support vector machine\n(SVM) and equal-sized k-means clustering---as QUBO problems so that they can be\ntrained on adiabatic quantum computers efficiently. We also analyze the time\nand space complexities of our formulations and compare them to the\nstate-of-the-art classical algorithms for training these machine learning\nmodels. We show that the time and space complexities of our formulations are\nbetter (in the case of SVM and equal-sized k-means clustering) or equivalent\n(in case of linear regression) to their classical counterparts.", "journal": ""}
{"doi": "10.48550/arXiv.2012.03661", "date": "2020-11-30", "title": "Human vs. supervised machine learning: Who learns patterns faster?", "authors": "Niklas K\u00fchl, Marc Goutier, Lucas Baier, Clemens Wolff, Dominik Martin", "abstract": "The capabilities of supervised machine learning (SML), especially compared to\nhuman abilities, are being discussed in scientific research and in the usage of\nSML. This study provides an answer to how learning performance differs between\nhumans and machines when there is limited training data. We have designed an\nexperiment in which 44 humans and three different machine learning algorithms\nidentify patterns in labeled training data and have to label instances\naccording to the patterns they find. The results show a high dependency between\nperformance and the underlying patterns of the task. Whereas humans perform\nrelatively similarly across all patterns, machines show large performance\ndifferences for the various patterns in our experiment. After seeing 20\ninstances in the experiment, human performance does not improve anymore, which\nwe relate to theories of cognitive overload. Machines learn slower but can\nreach the same level or may even outperform humans in 2 of the 4 of used\npatterns. However, machines need more instances compared to humans for the same\nresults. The performance of machines is comparably lower for the other 2\npatterns due to the difficulty of combining input features.", "journal": ""}
{"doi": "10.48550/arXiv.2009.12783", "date": "2020-09-27", "title": "Machine Learning in Event-Triggered Control: Recent Advances and Open Issues", "authors": "Leila Sedghi, Zohaib Ijaz, Md. Noor-A-Rahim, Kritchai Witheephanich, Dirk Pesch", "abstract": "Networked control systems have gained considerable attention over the last\ndecade as a result of the trend towards decentralised control applications and\nthe emergence of cyber-physical system applications. However, real-world\nwireless networked control systems suffer from limited communication\nbandwidths, reliability issues, and a lack of awareness of network dynamics due\nto the complex nature of wireless networks. Combining machine learning and\nevent-triggered control has the potential to alleviate some of these issues.\nFor example, machine learning can be used to overcome the problem of a lack of\nnetwork models by learning system behavior or adapting to dynamically changing\nmodels by continuously learning model dynamics. Event-triggered control can\nhelp to conserve communication bandwidth by transmitting control information\nonly when necessary or when resources are available. The purpose of this\narticle is to conduct a review of the literature on the use of machine learning\nin combination with event-triggered control. Machine learning techniques such\nas statistical learning, neural networks, and reinforcement learning-based\napproaches such as deep reinforcement learning are being investigated in\ncombination with event-triggered control. We discuss how these learning\nalgorithms can be used for different applications depending on the purpose of\nthe machine learning use. Following the review and discussion of the\nliterature, we highlight open research questions and challenges associated with\nmachine learning-based event-triggered control and suggest potential solutions.", "journal": ""}
{"doi": "10.48550/arXiv.2409.07632", "date": "2024-09-11", "title": "Learning Robust Observable to Address Noise in Quantum Machine Learning", "authors": "Bikram Khanal, Pablo Rivas", "abstract": "Quantum Machine Learning (QML) has emerged as a promising field that combines\nthe power of quantum computing with the principles of machine learning. One of\nthe significant challenges in QML is dealing with noise in quantum systems,\nespecially in the Noisy Intermediate-Scale Quantum (NISQ) era. Noise in quantum\nsystems can introduce errors in quantum computations and degrade the\nperformance of quantum algorithms. In this paper, we propose a framework for\nlearning observables that are robust against noisy channels in quantum systems.\nWe demonstrate that it is possible to learn observables that remain invariant\nunder the effects of noise and show that this can be achieved through a\nmachine-learning approach. We present a toy example using a Bell state under a\ndepolarization channel to illustrate the concept of robust observables. We then\ndescribe a machine-learning framework for learning such observables across six\ntwo-qubit quantum circuits and five noisy channels. Our results show that it is\npossible to learn observables that are more robust to noise than conventional\nobservables. We discuss the implications of this finding for quantum machine\nlearning, including potential applications in enhancing the stability of QML\nmodels in noisy environments. By developing techniques for learning robust\nobservables, we can improve the performance and reliability of quantum machine\nlearning models in the presence of noise, contributing to the advancement of\npractical QML applications in the NISQ era.", "journal": ""}
{"doi": "10.48550/arXiv.1301.1575", "date": "2013-01-06", "title": "BigDB: Automatic Machine Learning Optimizer", "authors": "Anna Pyayt, Michael Gubanov", "abstract": "In this short vision paper, we introduce a machine learning optimizer for\ndata management and describe its architecture and main functionality.", "journal": ""}
{"doi": "10.48550/arXiv.1301.5088", "date": "2013-01-22", "title": "Piecewise Linear Multilayer Perceptrons and Dropout", "authors": "Ian J. Goodfellow", "abstract": "We propose a new type of hidden layer for a multilayer perceptron, and\ndemonstrate that it obtains the best reported performance for an MLP on the\nMNIST dataset.", "journal": ""}
{"doi": "10.48550/arXiv.1310.5738", "date": "2013-10-21", "title": "A Kernel for Hierarchical Parameter Spaces", "authors": "Frank Hutter, Michael A. Osborne", "abstract": "We define a family of kernels for mixed continuous/discrete hierarchical\nparameter spaces and show that they are positive definite.", "journal": ""}
{"doi": "10.48550/arXiv.1408.4072", "date": "2014-08-15", "title": "Indexing Cost Sensitive Prediction", "authors": "Leilani Battle, Edward Benson, Aditya Parameswaran, Eugene Wu", "abstract": "Predictive models are often used for real-time decision making. However,\ntypical machine learning techniques ignore feature evaluation cost, and focus\nsolely on the accuracy of the machine learning models obtained utilizing all\nthe features available. We develop algorithms and indexes to support\ncost-sensitive prediction, i.e., making decisions using machine learning models\ntaking feature evaluation cost into account. Given an item and a online\ncomputation cost (i.e., time) budget, we present two approaches to return an\nappropriately chosen machine learning model that will run within the specified\ntime on the given item. The first approach returns the optimal machine learning\nmodel, i.e., one with the highest accuracy, that runs within the specified\ntime, but requires significant up-front precomputation time. The second\napproach returns a possibly sub- optimal machine learning model, but requires\nlittle up-front precomputation time. We study these two algorithms in detail\nand characterize the scenarios (using real and synthetic data) in which each\nperforms well. Unlike prior work that focuses on a narrow domain or a specific\nalgorithm, our techniques are very general: they apply to any cost-sensitive\nprediction scenario on any machine learning algorithm.", "journal": ""}
{"doi": "10.48550/arXiv.1607.08878", "date": "2016-07-29", "title": "Identifying and Harnessing the Building Blocks of Machine Learning Pipelines for Sensible Initialization of a Data Science Automation Tool", "authors": "Randal S. Olson, Jason H. Moore", "abstract": "As data science continues to grow in popularity, there will be an increasing\nneed to make data science tools more scalable, flexible, and accessible. In\nparticular, automated machine learning (AutoML) systems seek to automate the\nprocess of designing and optimizing machine learning pipelines. In this\nchapter, we present a genetic programming-based AutoML system called TPOT that\noptimizes a series of feature preprocessors and machine learning models with\nthe goal of maximizing classification accuracy on a supervised classification\nproblem. Further, we analyze a large database of pipelines that were previously\nused to solve various supervised classification problems and identify 100 short\nseries of machine learning operations that appear the most frequently, which we\ncall the building blocks of machine learning pipelines. We harness these\nbuilding blocks to initialize TPOT with promising solutions, and find that this\nsensible initialization method significantly improves TPOT's performance on one\nbenchmark at no cost of significantly degrading performance on the others.\nThus, sensible initialization with machine learning pipeline building blocks\nshows promise for GP-based AutoML systems, and should be further refined in\nfuture work.", "journal": ""}
{"doi": "10.48550/arXiv.1807.00297", "date": "2018-07-01", "title": "Exponential Convergence of the Deep Neural Network Approximation for Analytic Functions", "authors": "Weinan E, Qingcan Wang", "abstract": "We prove that for analytic functions in low dimension, the convergence rate\nof the deep neural network approximation is exponential.", "journal": ""}
{"doi": "10.48550/arXiv.1807.06228", "date": "2018-07-17", "title": "RuleMatrix: Visualizing and Understanding Classifiers with Rules", "authors": "Yao Ming, Huamin Qu, Enrico Bertini", "abstract": "With the growing adoption of machine learning techniques, there is a surge of\nresearch interest towards making machine learning systems more transparent and\ninterpretable. Various visualizations have been developed to help model\ndevelopers understand, diagnose, and refine machine learning models. However, a\nlarge number of potential but neglected users are the domain experts with\nlittle knowledge of machine learning but are expected to work with machine\nlearning systems. In this paper, we present an interactive visualization\ntechnique to help users with little expertise in machine learning to\nunderstand, explore and validate predictive models. By viewing the model as a\nblack box, we extract a standardized rule-based knowledge representation from\nits input-output behavior. We design RuleMatrix, a matrix-based visualization\nof rules to help users navigate and verify the rules and the black-box model.\nWe evaluate the effectiveness of RuleMatrix via two use cases and a usability\nstudy.", "journal": ""}
{"doi": "10.48550/arXiv.1808.09856", "date": "2018-08-29", "title": "Application of Machine Learning in Rock Facies Classification with Physics-Motivated Feature Augmentation", "authors": "Jie Chen, Yu Zeng", "abstract": "With recent progress in algorithms and the availability of massive amounts of\ncomputation power, application of machine learning techniques is becoming a hot\ntopic in the oil and gas industry. One of the most promising aspects to apply\nmachine learning to the upstream field is the rock facies classification in\nreservoir characterization, which is crucial in determining the net pay\nthickness of reservoirs, thus a definitive factor in drilling decision making\nprocess. For complex machine learning tasks like facies classification, feature\nengineering is often critical. This paper shows the inclusion of\nphysics-motivated feature interaction in feature augmentation can further\nimprove the capability of machine learning in rock facies classification. We\ndemonstrate this approach with the SEG 2016 machine learning contest dataset\nand the top winning algorithms. The improvement is roboust and can be $\\sim5\\%$\nbetter than current existing best F-1 score, where F-1 is an evaluation metric\nused to quantify average prediction accuracy.", "journal": ""}
{"doi": "10.48550/arXiv.1903.07167", "date": "2019-03-17", "title": "Machine Learning: A Dark Side of Cancer Computing", "authors": "Ripon Patgiri, Sabuzima Nayak, Tanya Akutota, Bishal Paul", "abstract": "Cancer analysis and prediction is the utmost important research field for\nwell-being of humankind. The Cancer data are analyzed and predicted using\nmachine learning algorithms. Most of the researcher claims the accuracy of the\npredicted results within 99%. However, we show that machine learning algorithms\ncan easily predict with an accuracy of 100% on Wisconsin Diagnostic Breast\nCancer dataset. We show that the method of gaining accuracy is an unethical\napproach that we can easily mislead the algorithms. In this paper, we exploit\nthe weakness of Machine Learning algorithms. We perform extensive experiments\nfor the correctness of our results to exploit the weakness of machine learning\nalgorithms. The methods are rigorously evaluated to validate our claim. In\naddition, this paper focuses on correctness of accuracy. This paper report\nthree key outcomes of the experiments, namely, correctness of accuracies,\nsignificance of minimum accuracy, and correctness of machine learning\nalgorithms.", "journal": "Proceedings of the 2018 International Conference on Bioinformatics\n  and Computational Biology, pp. 92-98, 2018"}
{"doi": "10.48550/arXiv.1903.09731", "date": "2019-03-22", "title": "Expert-Augmented Machine Learning", "authors": "E. D. Gennatas, J. H. Friedman, L. H. Ungar, R. Pirracchio, E. Eaton, L. Reichman, Y. Interian, C. B. Simone, A. Auerbach, E. Delgado, M. J. Van der Laan, T. D. Solberg, G. Valdes", "abstract": "Machine Learning is proving invaluable across disciplines. However, its\nsuccess is often limited by the quality and quantity of available data, while\nits adoption by the level of trust that models afford users. Human vs. machine\nperformance is commonly compared empirically to decide whether a certain task\nshould be performed by a computer or an expert. In reality, the optimal\nlearning strategy may involve combining the complementary strengths of man and\nmachine. Here we present Expert-Augmented Machine Learning (EAML), an automated\nmethod that guides the extraction of expert knowledge and its integration into\nmachine-learned models. We use a large dataset of intensive care patient data\nto predict mortality and show that we can extract expert knowledge using an\nonline platform, help reveal hidden confounders, improve generalizability on a\ndifferent population and learn using less data. EAML presents a novel framework\nfor high performance and dependable machine learning in critical applications.", "journal": ""}
{"doi": "10.48550/arXiv.1905.08883", "date": "2019-05-21", "title": "Explainable Machine Learning for Scientific Insights and Discoveries", "authors": "Ribana Roscher, Bastian Bohn, Marco F. Duarte, Jochen Garcke", "abstract": "Machine learning methods have been remarkably successful for a wide range of\napplication areas in the extraction of essential information from data. An\nexciting and relatively recent development is the uptake of machine learning in\nthe natural sciences, where the major goal is to obtain novel scientific\ninsights and discoveries from observational or simulated data. A prerequisite\nfor obtaining a scientific outcome is domain knowledge, which is needed to gain\nexplainability, but also to enhance scientific consistency. In this article we\nreview explainable machine learning in view of applications in the natural\nsciences and discuss three core elements which we identified as relevant in\nthis context: transparency, interpretability, and explainability. With respect\nto these core elements, we provide a survey of recent scientific works that\nincorporate machine learning and the way that explainable machine learning is\nused in combination with domain knowledge from the application areas.", "journal": "IEEE Access, vol. 8, pp. 42200-42216, 2020"}
{"doi": "10.48550/arXiv.1905.11075", "date": "2019-05-27", "title": "Machine Learning for Fluid Mechanics", "authors": "Steven Brunton, Bernd Noack, Petros Koumoutsakos", "abstract": "The field of fluid mechanics is rapidly advancing, driven by unprecedented\nvolumes of data from field measurements, experiments and large-scale\nsimulations at multiple spatiotemporal scales. Machine learning offers a wealth\nof techniques to extract information from data that could be translated into\nknowledge about the underlying fluid mechanics. Moreover, machine learning\nalgorithms can augment domain knowledge and automate tasks related to flow\ncontrol and optimization. This article presents an overview of past history,\ncurrent developments, and emerging opportunities of machine learning for fluid\nmechanics. It outlines fundamental machine learning methodologies and discusses\ntheir uses for understanding, modeling, optimizing, and controlling fluid\nflows. The strengths and limitations of these methods are addressed from the\nperspective of scientific inquiry that considers data as an inherent part of\nmodeling, experimentation, and simulation. Machine learning provides a powerful\ninformation processing framework that can enrich, and possibly even transform,\ncurrent lines of fluid mechanics research and industrial applications.", "journal": ""}
{"doi": "10.48550/arXiv.2006.13488", "date": "2020-06-24", "title": "Distributionally-Robust Machine Learning Using Locally Differentially-Private Data", "authors": "Farhad Farokhi", "abstract": "We consider machine learning, particularly regression, using\nlocally-differentially private datasets. The Wasserstein distance is used to\ndefine an ambiguity set centered at the empirical distribution of the dataset\ncorrupted by local differential privacy noise. The ambiguity set is shown to\ncontain the probability distribution of unperturbed, clean data. The radius of\nthe ambiguity set is a function of the privacy budget, spread of the data, and\nthe size of the problem. Hence, machine learning with locally-differentially\nprivate datasets can be rewritten as a distributionally-robust optimization.\nFor general distributions, the distributionally-robust optimization problem can\nrelaxed as a regularized machine learning problem with the Lipschitz constant\nof the machine learning model as a regularizer. For linear and logistic\nregression, this regularizer is the dual norm of the model parameters. For\nGaussian data, the distributionally-robust optimization problem can be solved\nexactly to find an optimal regularizer. This approach results in an entirely\nnew regularizer for training linear regression models. Training with this novel\nregularizer can be posed as a semi-definite program. Finally, the performance\nof the proposed distributionally-robust machine learning training is\ndemonstrated on practical datasets.", "journal": ""}
{"doi": "10.48550/arXiv.2006.16189", "date": "2020-06-25", "title": "DOME: Recommendations for supervised machine learning validation in biology", "authors": "Ian Walsh, Dmytro Fishman, Dario Garcia-Gasulla, Tiina Titma, Gianluca Pollastri, The ELIXIR Machine Learning focus group, Jen Harrow, Fotis E. Psomopoulos, Silvio C. E. Tosatto", "abstract": "Modern biology frequently relies on machine learning to provide predictions\nand improve decision processes. There have been recent calls for more scrutiny\non machine learning performance and possible limitations. Here we present a set\nof community-wide recommendations aiming to help establish standards of\nsupervised machine learning validation in biology. Adopting a structured\nmethods description for machine learning based on data, optimization, model,\nevaluation (DOME) will aim to help both reviewers and readers to better\nunderstand and assess the performance and limitations of a method or outcome.\nThe recommendations are formulated as questions to anyone wishing to pursue\nimplementation of a machine learning algorithm. Answers to these questions can\nbe easily included in the supplementary material of published papers.", "journal": ""}
{"doi": "10.48550/arXiv.1904.12054", "date": "2019-04-26", "title": "Benchmark and Survey of Automated Machine Learning Frameworks", "authors": "Marc-Andr\u00e9 Z\u00f6ller, Marco F. Huber", "abstract": "Machine learning (ML) has become a vital part in many aspects of our daily\nlife. However, building well performing machine learning applications requires\nhighly specialized data scientists and domain experts. Automated machine\nlearning (AutoML) aims to reduce the demand for data scientists by enabling\ndomain experts to build machine learning applications automatically without\nextensive knowledge of statistics and machine learning. This paper is a\ncombination of a survey on current AutoML methods and a benchmark of popular\nAutoML frameworks on real data sets. Driven by the selected frameworks for\nevaluation, we summarize and review important AutoML techniques and methods\nconcerning every step in building an ML pipeline. The selected AutoML\nframeworks are evaluated on 137 data sets from established AutoML benchmark\nsuits.", "journal": "Journal of Artificial Intelligence Research 70 (2021) 409-472"}
{"doi": "10.48550/arXiv.1910.09457", "date": "2019-10-21", "title": "Aleatoric and Epistemic Uncertainty in Machine Learning: An Introduction to Concepts and Methods", "authors": "Eyke H\u00fcllermeier, Willem Waegeman", "abstract": "The notion of uncertainty is of major importance in machine learning and\nconstitutes a key element of machine learning methodology. In line with the\nstatistical tradition, uncertainty has long been perceived as almost synonymous\nwith standard probability and probabilistic predictions. Yet, due to the\nsteadily increasing relevance of machine learning for practical applications\nand related issues such as safety requirements, new problems and challenges\nhave recently been identified by machine learning scholars, and these problems\nmay call for new methodological developments. In particular, this includes the\nimportance of distinguishing between (at least) two different types of\nuncertainty, often referred to as aleatoric and epistemic. In this paper, we\nprovide an introduction to the topic of uncertainty in machine learning as well\nas an overview of attempts so far at handling uncertainty in general and\nformalizing this distinction in particular.", "journal": ""}
{"doi": "10.48550/arXiv.2003.06795", "date": "2020-03-15", "title": "Towards automated kernel selection in machine learning systems: A SYCL case study", "authors": "John Lawson", "abstract": "Automated tuning of compute kernels is a popular area of research, mainly\nfocused on finding optimal kernel parameters for a problem with fixed input\nsizes. This approach is good for deploying machine learning models, where the\nnetwork topology is constant, but machine learning research often involves\nchanging network topologies and hyperparameters. Traditional kernel auto-tuning\nhas limited impact in this case; a more general selection of kernels is\nrequired for libraries to accelerate machine learning research.\n  In this paper we present initial results using machine learning to select\nkernels in a case study deploying high performance SYCL kernels in libraries\nthat target a range of heterogeneous devices from desktop GPUs to embedded\naccelerators. The techniques investigated apply more generally and could\nsimilarly be integrated with other heterogeneous programming systems. By\ncombining auto-tuning and machine learning these kernel selection processes can\nbe deployed with little developer effort to achieve high performance on new\nhardware.", "journal": ""}
{"doi": "10.48550/arXiv.2201.05216", "date": "2022-01-13", "title": "The Fairness Field Guide: Perspectives from Social and Formal Sciences", "authors": "Alycia N. Carey, Xintao Wu", "abstract": "Over the past several years, a slew of different methods to measure the\nfairness of a machine learning model have been proposed. However, despite the\ngrowing number of publications and implementations, there is still a critical\nlack of literature that explains the interplay of fair machine learning with\nthe social sciences of philosophy, sociology, and law. We hope to remedy this\nissue by accumulating and expounding upon the thoughts and discussions of fair\nmachine learning produced by both social and formal (specifically machine\nlearning and statistics) sciences in this field guide. Specifically, in\naddition to giving the mathematical and algorithmic backgrounds of several\npopular statistical and causal-based fair machine learning methods, we explain\nthe underlying philosophical and legal thoughts that support them. Further, we\nexplore several criticisms of the current approaches to fair machine learning\nfrom sociological and philosophical viewpoints. It is our hope that this field\nguide will help fair machine learning practitioners better understand how their\nalgorithms align with important humanistic values (such as fairness) and how we\ncan, as a field, design methods and metrics to better serve oppressed and\nmarginalized populaces.", "journal": ""}
{"doi": "10.48550/arXiv.1804.00403", "date": "2018-04-02", "title": "A Note on Kaldi's PLDA Implementation", "authors": "Ke Ding", "abstract": "Some explanations to Kaldi's PLDA implementation to make formula derivation\neasier to catch.", "journal": ""}
{"doi": "10.48550/arXiv.1804.02969", "date": "2018-04-09", "title": "A review of possible effects of cognitive biases on the interpretation of rule-based machine learning models", "authors": "Tom\u00e1\u0161 Kliegr, \u0160t\u011bp\u00e1n Bahn\u00edk, Johannes F\u00fcrnkranz", "abstract": "While the interpretability of machine learning models is often equated with\ntheir mere syntactic comprehensibility, we think that interpretability goes\nbeyond that, and that human interpretability should also be investigated from\nthe point of view of cognitive science. The goal of this paper is to discuss to\nwhat extent cognitive biases may affect human understanding of interpretable\nmachine learning models, in particular of logical rules discovered from data.\nTwenty cognitive biases are covered, as are possible debiasing techniques that\ncan be adopted by designers of machine learning algorithms and software. Our\nreview transfers results obtained in cognitive psychology to the domain of\nmachine learning, aiming to bridge the current gap between these two areas. It\nneeds to be followed by empirical studies specifically focused on the machine\nlearning domain.", "journal": "Artificial Intelligence (2021): 103458"}
{"doi": "10.48550/arXiv.1811.05266", "date": "2018-11-13", "title": "A conjugate prior for the Dirichlet distribution", "authors": "Jean-Marc Andreoli", "abstract": "This note investigates a conjugate class for the Dirichlet distribution class\nin the exponential family.", "journal": ""}
{"doi": "10.48550/arXiv.1811.10455", "date": "2018-11-26", "title": "A Framework for Implementing Machine Learning on Omics Data", "authors": "Geoffroy Dubourg-Felonneau, Timothy Cannings, Fergal Cotter, Hannah Thompson, Nirmesh Patel, John W Cassidy, Harry W Clifford", "abstract": "The potential benefits of applying machine learning methods to -omics data\nare becoming increasingly apparent, especially in clinical settings. However,\nthe unique characteristics of these data are not always well suited to machine\nlearning techniques. These data are often generated across different\ntechnologies in different labs, and frequently with high dimensionality. In\nthis paper we present a framework for combining -omics data sets, and for\nhandling high dimensional data, making -omics research more accessible to\nmachine learning applications. We demonstrate the success of this framework\nthrough integration and analysis of multi-analyte data for a set of 3,533\nbreast cancers. We then use this data-set to predict breast cancer patient\nsurvival for individuals at risk of an impending event, with higher accuracy\nand lower variance than methods trained on individual data-sets. We hope that\nour pipelines for data-set generation and transformation will open up -omics\ndata to machine learning researchers. We have made these freely available for\nnoncommercial use at www.ccg.ai.", "journal": ""}
{"doi": "10.48550/arXiv.1902.02322", "date": "2019-02-06", "title": "Is AmI (Attacks Meet Interpretability) Robust to Adversarial Examples?", "authors": "Nicholas Carlini", "abstract": "No.", "journal": ""}
{"doi": "10.48550/arXiv.1911.08603", "date": "2019-11-19", "title": "Forbidden knowledge in machine learning -- Reflections on the limits of research and publication", "authors": "Thilo Hagendorff", "abstract": "Certain research strands can yield \"forbidden knowledge\". This term refers to\nknowledge that is considered too sensitive, dangerous or taboo to be produced\nor shared. Discourses about such publication restrictions are already\nentrenched in scientific fields like IT security, synthetic biology or nuclear\nphysics research. This paper makes the case for transferring this discourse to\nmachine learning research. Some machine learning applications can very easily\nbe misused and unfold harmful consequences, for instance with regard to\ngenerative video or text synthesis, personality analysis, behavior\nmanipulation, software vulnerability detection and the like. Up to now, the\nmachine learning research community embraces the idea of open access. However,\nthis is opposed to precautionary efforts to prevent the malicious use of\nmachine learning applications. Information about or from such applications may,\nif improperly disclosed, cause harm to people, organizations or whole\nsocieties. Hence, the goal of this work is to outline norms that can help to\ndecide whether and when the dissemination of such information should be\nprevented. It proposes review parameters for the machine learning community to\nestablish an ethical framework on how to deal with forbidden knowledge and\ndual-use applications.", "journal": ""}
{"doi": "10.48550/arXiv.1911.11920", "date": "2019-11-27", "title": "Warning Signs in Communicating the Machine Learning Detection Results of Misinformation with Individuals", "authors": "Limeng Cui", "abstract": "With the prevalence of misinformation online, researchers have focused on\ndeveloping various machine learning algorithms to detect fake news. However,\nusers' perception of machine learning outcomes and related behaviors have been\nwidely ignored. Hence, this paper proposed to bridge this gap by studying how\nto pass the detection results of machine learning to the users, and aid their\ndecisions in handling misinformation. An online experiment was conducted, to\nevaluate the effect of the proposed machine learning warning sign against a\ncontrol condition. We examined participants' detection and sharing of news. The\ndata showed that warning sign's effects on participants' trust toward the fake\nnews were not significant. However, we found that people's uncertainty about\nthe authenticity of the news dropped with the presence of the machine learning\nwarning sign. We also found that social media experience had effects on users'\ntrust toward the fake news, and age and social media experience had effects on\nusers' sharing decision. Therefore, the results indicate that there are many\nfactors worth studying that affect people's trust in the news. Moreover, the\nwarning sign in communicating machine learning detection results is different\nfrom ordinary warnings and needs more detailed research and design. These\nfindings hold important implications for the design of machine learning\nwarnings.", "journal": ""}
{"doi": "10.48550/arXiv.2002.05193", "date": "2020-02-12", "title": "A Hierarchy of Limitations in Machine Learning", "authors": "Momin M. Malik", "abstract": "\"All models are wrong, but some are useful\", wrote George E. P. Box (1979).\nMachine learning has focused on the usefulness of probability models for\nprediction in social systems, but is only now coming to grips with the ways in\nwhich these models are wrong---and the consequences of those shortcomings. This\npaper attempts a comprehensive, structured overview of the specific conceptual,\nprocedural, and statistical limitations of models in machine learning when\napplied to society. Machine learning modelers themselves can use the described\nhierarchy to identify possible failure points and think through how to address\nthem, and consumers of machine learning models can know what to question when\nconfronted with the decision about if, where, and how to apply machine\nlearning. The limitations go from commitments inherent in quantification\nitself, through to showing how unmodeled dependencies can lead to\ncross-validation being overly optimistic as a way of assessing model\nperformance.", "journal": ""}
{"doi": "10.48550/arXiv.2002.05432", "date": "2020-02-13", "title": "The PHOTON Wizard -- Towards Educational Machine Learning Code Generators", "authors": "Ramona Leenings, Nils Ralf Winter, Kelvin Sarink, Jan Ernsting, Xiaoyi Jiang, Udo Dannlowski, Tim Hahn", "abstract": "Despite the tremendous efforts to democratize machine learning, especially in\napplied-science, the application is still often hampered by the lack of coding\nskills. As we consider programmatic understanding key to building effective and\nefficient machine learning solutions, we argue for a novel educational approach\nthat builds upon the accessibility and acceptance of graphical user interfaces\nto convey programming skills to an applied-science target group. We outline a\nproof-of-concept, open-source web application, the PHOTON Wizard, which\ndynamically translates GUI interactions into valid source code for the Python\nmachine learning framework PHOTON. Thereby, users possessing theoretical\nmachine learning knowledge gain key insights into the model development\nworkflow as well as an intuitive understanding of custom implementations.\nSpecifically, the PHOTON Wizard integrates the concept of Educational Machine\nLearning Code Generators to teach users how to write code for designing,\ntraining, optimizing and evaluating custom machine learning pipelines.", "journal": ""}
{"doi": "10.48550/arXiv.2005.08946", "date": "2020-05-16", "title": "Arabic Offensive Language Detection Using Machine Learning and Ensemble Machine Learning Approaches", "authors": "Fatemah Husain", "abstract": "This study aims at investigating the effect of applying single learner\nmachine learning approach and ensemble machine learning approach for offensive\nlanguage detection on Arabic language. Classifying Arabic social media text is\na very challenging task due to the ambiguity and informality of the written\nformat of the text. Arabic language has multiple dialects with diverse\nvocabularies and structures, which increase the complexity of obtaining high\nclassification performance. Our study shows significant impact for applying\nensemble machine learning approach over the single learner machine learning\napproach. Among the trained ensemble machine learning classifiers, bagging\nperforms the best in offensive language detection with F1 score of 88%, which\nexceeds the score obtained by the best single learner classifier by 6%. Our\nfindings highlight the great opportunities of investing more efforts in\npromoting the ensemble machine learning approach solutions for offensive\nlanguage detection models.", "journal": ""}
{"doi": "10.48550/arXiv.2104.10201", "date": "2021-04-20", "title": "Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020", "authors": "Ryan Turner, David Eriksson, Michael McCourt, Juha Kiili, Eero Laaksonen, Zhen Xu, Isabelle Guyon", "abstract": "This paper presents the results and insights from the black-box optimization\n(BBO) challenge at NeurIPS 2020 which ran from July-October, 2020. The\nchallenge emphasized the importance of evaluating derivative-free optimizers\nfor tuning the hyperparameters of machine learning models. This was the first\nblack-box optimization challenge with a machine learning emphasis. It was based\non tuning (validation set) performance of standard machine learning models on\nreal datasets. This competition has widespread impact as black-box optimization\n(e.g., Bayesian optimization) is relevant for hyperparameter tuning in almost\nevery machine learning project as well as many applications outside of machine\nlearning. The final leaderboard was determined using the optimization\nperformance on held-out (hidden) objective functions, where the optimizers ran\nwithout human intervention. Baselines were set using the default settings of\nseveral open-source black-box optimization packages as well as random search.", "journal": ""}
{"doi": "10.48550/arXiv.2106.02964", "date": "2021-06-05", "title": "A Review of Machine Learning Classification Using Quantum Annealing for Real-world Applications", "authors": "Rajdeep Kumar Nath, Himanshu Thapliyal, Travis S. Humble", "abstract": "Optimizing the training of a machine learning pipeline helps in reducing\ntraining costs and improving model performance. One such optimizing strategy is\nquantum annealing, which is an emerging computing paradigm that has shown\npotential in optimizing the training of a machine learning model. The\nimplementation of a physical quantum annealer has been realized by D-Wave\nsystems and is available to the research community for experiments. Recent\nexperimental results on a variety of machine learning applications using\nquantum annealing have shown interesting results where the performance of\nclassical machine learning techniques is limited by limited training data and\nhigh dimensional features. This article explores the application of D-Wave's\nquantum annealer for optimizing machine learning pipelines for real-world\nclassification problems. We review the application domains on which a physical\nquantum annealer has been used to train machine learning classifiers. We\ndiscuss and analyze the experiments performed on the D-Wave quantum annealer\nfor applications such as image recognition, remote sensing imagery,\ncomputational biology, and particle physics. We discuss the possible advantages\nand the problems for which quantum annealing is likely to be advantageous over\nclassical computation.", "journal": "Springer Nature Computer Science (SNCS), 2021"}
{"doi": "10.48550/arXiv.2106.12974", "date": "2021-06-24", "title": "Tensor networks for unsupervised machine learning", "authors": "Jing Liu, Sujie Li, Jiang Zhang, Pan Zhang", "abstract": "Modeling the joint distribution of high-dimensional data is a central task in\nunsupervised machine learning. In recent years, many interests have been\nattracted to developing learning models based on tensor networks, which have\nthe advantages of a principle understanding of the expressive power using\nentanglement properties, and as a bridge connecting classical computation and\nquantum computation. Despite the great potential, however, existing tensor\nnetwork models for unsupervised machine learning only work as a proof of\nprinciple, as their performance is much worse than the standard models such as\nrestricted Boltzmann machines and neural networks. In this Letter, we present\nautoregressive matrix product states (AMPS), a tensor network model combining\nmatrix product states from quantum many-body physics and autoregressive\nmodeling from machine learning. Our model enjoys the exact calculation of\nnormalized probability and unbiased sampling. We demonstrate the performance of\nour model using two applications, generative modeling on synthetic and\nreal-world data, and reinforcement learning in statistical physics. Using\nextensive numerical experiments, we show that the proposed model significantly\noutperforms the existing tensor network models and the restricted Boltzmann\nmachines, and is competitive with state-of-the-art neural network models.", "journal": ""}
{"doi": "10.48550/arXiv.2107.04851", "date": "2021-07-10", "title": "Machine Learning for Financial Forecasting, Planning and Analysis: Recent Developments and Pitfalls", "authors": "Helmut Wasserbacher, Martin Spindler", "abstract": "This article is an introduction to machine learning for financial\nforecasting, planning and analysis (FP\\&A). Machine learning appears well\nsuited to support FP\\&A with the highly automated extraction of information\nfrom large amounts of data. However, because most traditional machine learning\ntechniques focus on forecasting (prediction), we discuss the particular care\nthat must be taken to avoid the pitfalls of using them for planning and\nresource allocation (causal inference). While the naive application of machine\nlearning usually fails in this context, the recently developed double machine\nlearning framework can address causal questions of interest. We review the\ncurrent literature on machine learning in FP\\&A and illustrate in a simulation\nstudy how machine learning can be used for both forecasting and planning. We\nalso investigate how forecasting and planning improve as the number of data\npoints increases.", "journal": ""}
{"doi": "10.48550/arXiv.2203.16569", "date": "2022-03-30", "title": "Generating Scientific Articles with Machine Learning", "authors": "Eliot H. Ayache, Conor M. B. Omand", "abstract": "In recent years, the field of machine learning has seen rapid growth, with\napplications in a variety of domains, including image recognition, natural\nlanguage processing, and predictive modeling. In this paper, we explore the\napplication of machine learning to the generation of scientific articles. We\npresent a method for using machine learning to generate scientific articles\nbased on a data set of scientific papers. The method uses a machine-learning\nalgorithm to learn the structure of a scientific article and a set of training\ndata consisting of scientific papers. The machine-learning algorithm is used to\ngenerate a scientific article based on the data set of scientific papers. We\nevaluate the performance of the method by comparing the generated article to a\nset of manually written articles. The results show that the machine-generated\narticle is of similar quality to the manually written articles.", "journal": ""}
{"doi": "10.48550/arXiv.2205.05910", "date": "2022-05-12", "title": "Comments on: \"Hybrid Semiparametric Bayesian Networks\"", "authors": "Marco Scutari", "abstract": "Invited discussion on the paper \"Hybrid Semiparametric Bayesian Networks\" by\nDavid Atienza, Pedro Larranaga and Concha Bielza (TEST, 2022).", "journal": "TEST (2022), 30, 328-330"}
{"doi": "10.48550/arXiv.2209.09362", "date": "2022-09-19", "title": "Analyzing Machine Learning Models for Credit Scoring with Explainable AI and Optimizing Investment Decisions", "authors": "Swati Tyagi", "abstract": "This paper examines two different yet related questions related to\nexplainable AI (XAI) practices. Machine learning (ML) is increasingly important\nin financial services, such as pre-approval, credit underwriting, investments,\nand various front-end and back-end activities. Machine Learning can\nautomatically detect non-linearities and interactions in training data,\nfacilitating faster and more accurate credit decisions. However, machine\nlearning models are opaque and hard to explain, which are critical elements\nneeded for establishing a reliable technology. The study compares various\nmachine learning models, including single classifiers (logistic regression,\ndecision trees, LDA, QDA), heterogeneous ensembles (AdaBoost, Random Forest),\nand sequential neural networks. The results indicate that ensemble classifiers\nand neural networks outperform. In addition, two advanced post-hoc model\nagnostic explainability techniques - LIME and SHAP are utilized to assess\nML-based credit scoring models using the open-access datasets offered by\nUS-based P2P Lending Platform, Lending Club. For this study, we are also using\nmachine learning algorithms to develop new investment models and explore\nportfolio strategies that can maximize profitability while minimizing risk.", "journal": "American International Journal of Business Management\n  (AIJBM).2022;5(01)"}
{"doi": "10.48550/arXiv.2306.08933", "date": "2023-06-15", "title": "Towards Interpretability in Audio and Visual Affective Machine Learning: A Review", "authors": "David S. Johnson, Olya Hakobyan, Hanna Drimalla", "abstract": "Machine learning is frequently used in affective computing, but presents\nchallenges due the opacity of state-of-the-art machine learning methods.\nBecause of the impact affective machine learning systems may have on an\nindividual's life, it is important that models be made transparent to detect\nand mitigate biased decision making. In this regard, affective machine learning\ncould benefit from the recent advancements in explainable artificial\nintelligence (XAI) research. We perform a structured literature review to\nexamine the use of interpretability in the context of affective machine\nlearning. We focus on studies using audio, visual, or audiovisual data for\nmodel training and identified 29 research articles. Our findings show an\nemergence of the use of interpretability methods in the last five years.\nHowever, their use is currently limited regarding the range of methods used,\nthe depth of evaluations, and the consideration of use-cases. We outline the\nmain gaps in the research and provide recommendations for researchers that aim\nto implement interpretable methods for affective machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.2311.07126", "date": "2023-11-13", "title": "How to Do Machine Learning with Small Data? -- A Review from an Industrial Perspective", "authors": "Ivan Kraljevski, Yong Chul Ju, Dmitrij Ivanov, Constanze Tsch\u00f6pe, Matthias Wolff", "abstract": "Artificial intelligence experienced a technological breakthrough in science,\nindustry, and everyday life in the recent few decades. The advancements can be\ncredited to the ever-increasing availability and miniaturization of\ncomputational resources that resulted in exponential data growth. However,\nbecause of the insufficient amount of data in some cases, employing machine\nlearning in solving complex tasks is not straightforward or even possible. As a\nresult, machine learning with small data experiences rising importance in data\nscience and application in several fields. The authors focus on interpreting\nthe general term of \"small data\" and their engineering and industrial\napplication role. They give a brief overview of the most important industrial\napplications of machine learning and small data. Small data is defined in terms\nof various characteristics compared to big data, and a machine learning\nformalism was introduced. Five critical challenges of machine learning with\nsmall data in industrial applications are presented: unlabeled data, imbalanced\ndata, missing data, insufficient data, and rare events. Based on those\ndefinitions, an overview of the considerations in domain representation and\ndata acquisition is given along with a taxonomy of machine learning approaches\nin the context of small data.", "journal": ""}
{"doi": "10.48550/arXiv.2405.15950", "date": "2024-05-24", "title": "A Systematic Bias of Machine Learning Regression Models and Its Correction: an Application to Imaging-based Brain Age Prediction", "authors": "Hwiyoung Lee, Shuo Chen", "abstract": "Machine learning models for continuous outcomes often yield systematically\nbiased predictions, particularly for values that largely deviate from the mean.\nSpecifically, predictions for large-valued outcomes tend to be negatively\nbiased (underestimating actual values), while those for small-valued outcomes\nare positively biased (overestimating actual values). We refer to this linear\ncentral tendency warped bias as the \"systematic bias of machine learning\nregression\". In this paper, we first demonstrate that this systematic\nprediction bias persists across various machine learning regression models, and\nthen delve into its theoretical underpinnings. To address this issue, we\npropose a general constrained optimization approach designed to correct this\nbias and develop computationally efficient implementation algorithms.\nSimulation results indicate that our correction method effectively eliminates\nthe bias from the predicted outcomes. We apply the proposed approach to the\nprediction of brain age using neuroimaging data. In comparison to competing\nmachine learning regression models, our method effectively addresses the\nlongstanding issue of \"systematic bias of machine learning regression\" in\nneuroimaging-based brain age calculation, yielding unbiased predictions of\nbrain age.", "journal": ""}
{"doi": "10.48550/arXiv.2407.03595", "date": "2024-07-04", "title": "Machine Learning for Economic Forecasting: An Application to China's GDP Growth", "authors": "Yanqing Yang, Xingcheng Xu, Jinfeng Ge, Yan Xu", "abstract": "This paper aims to explore the application of machine learning in forecasting\nChinese macroeconomic variables. Specifically, it employs various machine\nlearning models to predict the quarterly real GDP growth of China, and analyzes\nthe factors contributing to the performance differences among these models. Our\nfindings indicate that the average forecast errors of machine learning models\nare generally lower than those of traditional econometric models or expert\nforecasts, particularly in periods of economic stability. However, during\ncertain inflection points, although machine learning models still outperform\ntraditional econometric models, expert forecasts may exhibit greater accuracy\nin some instances due to experts' more comprehensive understanding of the\nmacroeconomic environment and real-time economic variables. In addition to\nmacroeconomic forecasting, this paper employs interpretable machine learning\nmethods to identify the key attributive variables from different machine\nlearning models, aiming to enhance the understanding and evaluation of their\ncontributions to macroeconomic fluctuations.", "journal": ""}
{"doi": "10.48550/arXiv.2407.18735", "date": "2024-07-26", "title": "AutoRDF2GML: Facilitating RDF Integration in Graph Machine Learning", "authors": "Michael F\u00e4rber, David Lamprecht, Yuni Susanti", "abstract": "In this paper, we introduce AutoRDF2GML, a framework designed to convert RDF\ndata into data representations tailored for graph machine learning tasks.\nAutoRDF2GML enables, for the first time, the creation of both content-based\nfeatures -- i.e., features based on RDF datatype properties -- and\ntopology-based features -- i.e., features based on RDF object properties.\nCharacterized by automated feature extraction, AutoRDF2GML makes it possible\neven for users less familiar with RDF and SPARQL to generate data\nrepresentations ready for graph machine learning tasks, such as link\nprediction, node classification, and graph classification. Furthermore, we\npresent four new benchmark datasets for graph machine learning, created from\nlarge RDF knowledge graphs using our framework. These datasets serve as\nvaluable resources for evaluating graph machine learning approaches, such as\ngraph neural networks. Overall, our framework effectively bridges the gap\nbetween the Graph Machine Learning and Semantic Web communities, paving the way\nfor RDF-based machine learning applications.", "journal": ""}
{"doi": "10.48550/arXiv.2408.13556", "date": "2024-08-24", "title": "What if? Causal Machine Learning in Supply Chain Risk Management", "authors": "Mateusz Wyrembek, George Baryannis, Alexandra Brintrup", "abstract": "The penultimate goal for developing machine learning models in supply chain\nmanagement is to make optimal interventions. However, most machine learning\nmodels identify correlations in data rather than inferring causation, making it\ndifficult to systematically plan for better outcomes. In this article, we\npropose and evaluate the use of causal machine learning for developing supply\nchain risk intervention models, and demonstrate its use with a case study in\nsupply chain risk management in the maritime engineering sector. Our findings\nhighlight that causal machine learning enhances decision-making processes by\nidentifying changes that can be achieved under different supply chain\ninterventions, allowing \"what-if\" scenario planning. We therefore propose\ndifferent machine learning developmental pathways for for predicting risk, and\nplanning for interventions to minimise risk and outline key steps for supply\nchain researchers to explore causal machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.2409.04365", "date": "2024-09-06", "title": "Leveraging Machine Learning for Official Statistics: A Statistical Manifesto", "authors": "Marco Puts, David Salgado, Piet Daas", "abstract": "It is important for official statistics production to apply ML with\nstatistical rigor, as it presents both opportunities and challenges. Although\nmachine learning has enjoyed rapid technological advances in recent years, its\napplication does not possess the methodological robustness necessary to produce\nhigh quality statistical results. In order to account for all sources of error\nin machine learning models, the Total Machine Learning Error (TMLE) is\npresented as a framework analogous to the Total Survey Error Model used in\nsurvey methodology. As a means of ensuring that ML models are both internally\nvalid as well as externally valid, the TMLE model addresses issues such as\nrepresentativeness and measurement errors. There are several case studies\npresented, illustrating the importance of applying more rigor to the\napplication of machine learning in official statistics.", "journal": ""}
{"doi": "10.48550/arXiv.2409.06938", "date": "2024-09-11", "title": "k-MLE, k-Bregman, k-VARs: Theory, Convergence, Computation", "authors": "Zuogong Yue, Victor Solo", "abstract": "We develop hard clustering based on likelihood rather than distance and prove\nconvergence. We also provide simulations and real data examples.", "journal": ""}
{"doi": "10.48550/arXiv.2411.09403", "date": "2024-11-14", "title": "Quantum Machine Learning: An Interplay Between Quantum Computing and Machine Learning", "authors": "Jun Qi, Chao-Han Yang, Samuel Yen-Chi Chen, Pin-Yu Chen", "abstract": "Quantum machine learning (QML) is a rapidly growing field that combines\nquantum computing principles with traditional machine learning. It seeks to\nrevolutionize machine learning by harnessing the unique capabilities of quantum\nmechanics and employs machine learning techniques to advance quantum computing\nresearch. This paper introduces quantum computing for the machine learning\nparadigm, where variational quantum circuits (VQC) are used to develop QML\narchitectures on noisy intermediate-scale quantum (NISQ) devices. We discuss\nmachine learning for the quantum computing paradigm, showcasing our recent\ntheoretical and empirical findings. In particular, we delve into future\ndirections for studying QML, exploring the potential industrial impacts of QML\nresearch.", "journal": ""}
{"doi": "10.48550/arXiv.2502.12323", "date": "2025-02-17", "title": "Adversarial Debiasing for Unbiased Parameter Recovery", "authors": "Luke C Sanford, Megan Ayers, Matthew Gordon, Eliana Stone", "abstract": "Advances in machine learning and the increasing availability of\nhigh-dimensional data have led to the proliferation of social science research\nthat uses the predictions of machine learning models as proxies for measures of\nhuman activity or environmental outcomes. However, prediction errors from\nmachine learning models can lead to bias in the estimates of regression\ncoefficients. In this paper, we show how this bias can arise, propose a test\nfor detecting bias, and demonstrate the use of an adversarial machine learning\nalgorithm in order to de-bias predictions. These methods are applicable to any\nsetting where machine-learned predictions are the dependent variable in a\nregression. We conduct simulations and empirical exercises using ground truth\nand satellite data on forest cover in Africa. Using the predictions from a\nnaive machine learning model leads to biased parameter estimates, while the\npredictions from the adversarial model recover the true coefficients.", "journal": ""}
{"doi": "10.48550/arXiv.2502.17993", "date": "2025-02-25", "title": "A Perspective on Symbolic Machine Learning in Physical Sciences", "authors": "Nour Makke, Sanjay Chawla", "abstract": "Machine learning is rapidly making its pathway across all of the natural\nsciences, including physical sciences. The rate at which ML is impacting\nnon-scientific disciplines is incomparable to that in the physical sciences.\nThis is partly due to the uninterpretable nature of deep neural networks.\nSymbolic machine learning stands as an equal and complementary partner to\nnumerical machine learning in speeding up scientific discovery in physics. This\nperspective discusses the main differences between the ML and scientific\napproaches. It stresses the need to develop and apply symbolic machine learning\nto physics problems equally, in parallel to numerical machine learning, because\nof the dual nature of physics research.", "journal": ""}
{"doi": "10.48550/arXiv.2105.03684", "date": "2021-05-08", "title": "Quantum Machine Learning For Classical Data", "authors": "Leonard Wossnig", "abstract": "In this dissertation, we study the intersection of quantum computing and\nsupervised machine learning algorithms, which means that we investigate quantum\nalgorithms for supervised machine learning that operate on classical data. This\narea of research falls under the umbrella of quantum machine learning, a\nresearch area of computer science which has recently received wide attention.\nIn particular, we investigate to what extent quantum computers can be used to\naccelerate supervised machine learning algorithms. The aim of this is to\ndevelop a clear understanding of the promises and limitations of the current\nstate of the art of quantum algorithms for supervised machine learning, but\nalso to define directions for future research in this exciting field. We start\nby looking at supervised quantum machine learning (QML) algorithms through the\nlens of statistical learning theory. In this framework, we derive novel bounds\non the computational complexities of a large set of supervised QML algorithms\nunder the requirement of optimal learning rates. Next, we give a new bound for\nHamiltonian simulation of dense Hamiltonians, a major subroutine of most known\nsupervised QML algorithms, and then derive a classical algorithm with nearly\nthe same complexity. We then draw the parallels to recent \"quantum-inspired\"\nresults, and will explain the implications of these results for quantum machine\nlearning applications. Looking for areas which might bear larger advantages for\nQML algorithms, we finally propose a novel algorithm for Quantum Boltzmann\nmachines, and argue that quantum algorithms for quantum data are one of the\nmost promising applications for QML with potentially exponential advantage over\nclassical approaches.", "journal": ""}
{"doi": "10.48550/arXiv.1803.06401", "date": "2018-03-16", "title": "Evaluating Conditional Cash Transfer Policies with Machine Learning Methods", "authors": "Tzai-Shuen Chen", "abstract": "This paper presents an out-of-sample prediction comparison between major\nmachine learning models and the structural econometric model. Over the past\ndecade, machine learning has established itself as a powerful tool in many\nprediction applications, but this approach is still not widely adopted in\nempirical economic studies. To evaluate the benefits of this approach, I use\nthe most common machine learning algorithms, CART, C4.5, LASSO, random forest,\nand adaboost, to construct prediction models for a cash transfer experiment\nconducted by the Progresa program in Mexico, and I compare the prediction\nresults with those of a previous structural econometric study. Two prediction\ntasks are performed in this paper: the out-of-sample forecast and the long-term\nwithin-sample simulation. For the out-of-sample forecast, both the mean\nabsolute error and the root mean square error of the school attendance rates\nfound by all machine learning models are smaller than those found by the\nstructural model. Random forest and adaboost have the highest accuracy for the\nindividual outcomes of all subgroups. For the long-term within-sample\nsimulation, the structural model has better performance than do all of the\nmachine learning models. The poor within-sample fitness of the machine learning\nmodel results from the inaccuracy of the income and pregnancy prediction\nmodels. The result shows that the machine learning model performs better than\ndoes the structural model when there are many data to learn; however, when the\ndata are limited, the structural model offers a more sensible prediction. The\nfindings of this paper show promise for adopting machine learning in economic\npolicy analyses in the era of big data.", "journal": ""}
{"doi": "10.48550/arXiv.0508073", "date": "2005-08-16", "title": "Universal Learning of Repeated Matrix Games", "authors": "Jan Poland, Marcus Hutter", "abstract": "We study and compare the learning dynamics of two universal learning\nalgorithms, one based on Bayesian learning and the other on prediction with\nexpert advice. Both approaches have strong asymptotic performance guarantees.\nWhen confronted with the task of finding good long-term strategies in repeated\n2x2 matrix games, they behave quite differently.", "journal": "Proc. 15th Annual Machine Learning Conf. of Belgium and The\n  Netherlands (Benelearn 2006) pages 7-14"}
{"doi": "10.48550/arXiv.1905.07187", "date": "2019-05-17", "title": "An Essay on Optimization Mystery of Deep Learning", "authors": "Eugene Golikov", "abstract": "Despite the huge empirical success of deep learning, theoretical\nunderstanding of neural networks learning process is still lacking. This is the\nreason, why some of its features seem \"mysterious\". We emphasize two mysteries\nof deep learning: generalization mystery, and optimization mystery. In this\nessay we review and draw connections between several selected works concerning\nthe latter.", "journal": ""}
{"doi": "10.48550/arXiv.1204.4294", "date": "2012-04-19", "title": "Learning in Riemannian Orbifolds", "authors": "Brijnesh J. Jain, Klaus Obermayer", "abstract": "Learning in Riemannian orbifolds is motivated by existing machine learning\nalgorithms that directly operate on finite combinatorial structures such as\npoint patterns, trees, and graphs. These methods, however, lack statistical\njustification. This contribution derives consistency results for learning\nproblems in structured domains and thereby generalizes learning in vector\nspaces and manifolds.", "journal": ""}
{"doi": "10.48550/arXiv.1707.00797", "date": "2017-07-04", "title": "Learning Deep Energy Models: Contrastive Divergence vs. Amortized MLE", "authors": "Qiang Liu, Dilin Wang", "abstract": "We propose a number of new algorithms for learning deep energy models and\ndemonstrate their properties. We show that our SteinCD performs well in term of\ntest likelihood, while SteinGAN performs well in terms of generating realistic\nlooking images. Our results suggest promising directions for learning better\nmodels by combining GAN-style methods with traditional energy-based learning.", "journal": ""}
{"doi": "10.48550/arXiv.1906.10025", "date": "2019-06-24", "title": "Modern Deep Reinforcement Learning Algorithms", "authors": "Sergey Ivanov, Alexander D'yakonov", "abstract": "Recent advances in Reinforcement Learning, grounded on combining classical\ntheoretical results with Deep Learning paradigm, led to breakthroughs in many\nartificial intelligence tasks and gave birth to Deep Reinforcement Learning\n(DRL) as a field of research. In this work latest DRL algorithms are reviewed\nwith a focus on their theoretical justification, practical limitations and\nobserved empirical properties.", "journal": ""}
{"doi": "10.48550/arXiv.2204.07697", "date": "2022-04-16", "title": "Theory of Graph Neural Networks: Representation and Learning", "authors": "Stefanie Jegelka", "abstract": "Graph Neural Networks (GNNs), neural network architectures targeted to\nlearning representations of graphs, have become a popular learning model for\nprediction tasks on nodes, graphs and configurations of points, with wide\nsuccess in practice. This article summarizes a selection of the emerging\ntheoretical results on approximation and learning properties of widely used\nmessage passing GNNs and higher-order GNNs, focusing on representation,\ngeneralization and extrapolation. Along the way, it summarizes mathematical\nconnections.", "journal": ""}
{"doi": "10.48550/arXiv.2412.02969", "date": "2024-12-04", "title": "Unified Inductive Logic: From Formal Learning to Statistical Inference to Supervised Learning", "authors": "Hanti Lin", "abstract": "While the traditional conception of inductive logic is Carnapian, I develop a\nPeircean alternative and use it to unify formal learning theory, statistics,\nand a significant part of machine learning: supervised learning. Some crucial\nstandards for evaluating non-deductive inferences have been assumed separately\nin those areas, but can actually be justified by a unifying principle.", "journal": ""}
{"doi": "10.48550/arXiv.2105.04130", "date": "2021-05-10", "title": "Boltzmann machines as two-dimensional tensor networks", "authors": "Sujie Li, Feng Pan, Pengfei Zhou, Pan Zhang", "abstract": "Restricted Boltzmann machines (RBM) and deep Boltzmann machines (DBM) are\nimportant models in machine learning, and recently found numerous applications\nin quantum many-body physics. We show that there are fundamental connections\nbetween them and tensor networks. In particular, we demonstrate that any RBM\nand DBM can be exactly represented as a two-dimensional tensor network. This\nrepresentation gives an understanding of the expressive power of RBM and DBM\nusing entanglement structures of the tensor networks, also provides an\nefficient tensor network contraction algorithm for the computing partition\nfunction of RBM and DBM. Using numerical experiments, we demonstrate that the\nproposed algorithm is much more accurate than the state-of-the-art machine\nlearning methods in estimating the partition function of restricted Boltzmann\nmachines and deep Boltzmann machines, and have potential applications in\ntraining deep Boltzmann machines for general machine learning tasks.", "journal": "Phys. Rev. B 104, 075154 (2021)"}
{"doi": "10.48550/arXiv.1709.03854", "date": "2017-09-12", "title": "Meta-QSAR: a large-scale application of meta-learning to drug design and discovery", "authors": "Ivan Olier, Noureddin Sadawi, G. Richard Bickerton, Joaquin Vanschoren, Crina Grosan, Larisa Soldatova, Ross D. King", "abstract": "We investigate the learning of quantitative structure activity relationships\n(QSARs) as a case-study of meta-learning. This application area is of the\nhighest societal importance, as it is a key step in the development of new\nmedicines. The standard QSAR learning problem is: given a target (usually a\nprotein) and a set of chemical compounds (small molecules) with associated\nbioactivities (e.g. inhibition of the target), learn a predictive mapping from\nmolecular representation to activity. Although almost every type of machine\nlearning method has been applied to QSAR learning there is no agreed single\nbest way of learning QSARs, and therefore the problem area is well-suited to\nmeta-learning. We first carried out the most comprehensive ever comparison of\nmachine learning methods for QSAR learning: 18 regression methods, 6 molecular\nrepresentations, applied to more than 2,700 QSAR problems. (These results have\nbeen made publicly available on OpenML and represent a valuable resource for\ntesting novel meta-learning methods.) We then investigated the utility of\nalgorithm selection for QSAR problems. We found that this meta-learning\napproach outperformed the best individual QSAR learning method (random forests\nusing a molecular fingerprint representation) by up to 13%, on average. We\nconclude that meta-learning outperforms base-learning methods for QSAR\nlearning, and as this investigation is one of the most extensive ever\ncomparisons of base and meta-learning methods ever made, it provides evidence\nfor the general effectiveness of meta-learning over base-learning.", "journal": ""}
{"doi": "10.48550/arXiv.1703.02910", "date": "2017-03-08", "title": "Deep Bayesian Active Learning with Image Data", "authors": "Yarin Gal, Riashat Islam, Zoubin Ghahramani", "abstract": "Even though active learning forms an important pillar of machine learning,\ndeep learning tools are not prevalent within it. Deep learning poses several\ndifficulties when used in an active learning setting. First, active learning\n(AL) methods generally rely on being able to learn and update models from small\namounts of data. Recent advances in deep learning, on the other hand, are\nnotorious for their dependence on large amounts of data. Second, many AL\nacquisition functions rely on model uncertainty, yet deep learning methods\nrarely represent such model uncertainty. In this paper we combine recent\nadvances in Bayesian deep learning into the active learning framework in a\npractical way. We develop an active learning framework for high dimensional\ndata, a task which has been extremely challenging so far, with very sparse\nexisting literature. Taking advantage of specialised models such as Bayesian\nconvolutional neural networks, we demonstrate our active learning techniques\nwith image data, obtaining a significant improvement on existing active\nlearning approaches. We demonstrate this on both the MNIST dataset, as well as\nfor skin cancer diagnosis from lesion images (ISIC2016 task).", "journal": ""}
{"doi": "10.48550/arXiv.2002.09571", "date": "2020-02-21", "title": "Learning to Continually Learn", "authors": "Shawn Beaulieu, Lapo Frati, Thomas Miconi, Joel Lehman, Kenneth O. Stanley, Jeff Clune, Nick Cheney", "abstract": "Continual lifelong learning requires an agent or model to learn many\nsequentially ordered tasks, building on previous knowledge without\ncatastrophically forgetting it. Much work has gone towards preventing the\ndefault tendency of machine learning models to catastrophically forget, yet\nvirtually all such work involves manually-designed solutions to the problem. We\ninstead advocate meta-learning a solution to catastrophic forgetting, allowing\nAI to learn to continually learn. Inspired by neuromodulatory processes in the\nbrain, we propose A Neuromodulated Meta-Learning Algorithm (ANML). It\ndifferentiates through a sequential learning process to meta-learn an\nactivation-gating function that enables context-dependent selective activation\nwithin a deep neural network. Specifically, a neuromodulatory (NM) neural\nnetwork gates the forward pass of another (otherwise normal) neural network\ncalled the prediction learning network (PLN). The NM network also thus\nindirectly controls selective plasticity (i.e. the backward pass of) the PLN.\nANML enables continual learning without catastrophic forgetting at scale: it\nproduces state-of-the-art continual learning performance, sequentially learning\nas many as 600 classes (over 9,000 SGD updates).", "journal": ""}
{"doi": "10.48550/arXiv.1310.8320", "date": "2013-10-30", "title": "Safe and Efficient Screening For Sparse Support Vector Machine", "authors": "Zheng Zhao, Jun Liu", "abstract": "Screening is an effective technique for speeding up the training process of a\nsparse learning model by removing the features that are guaranteed to be\ninactive the process. In this paper, we present a efficient screening technique\nfor sparse support vector machine based on variational inequality. The\ntechnique is both efficient and safe.", "journal": ""}
{"doi": "10.48550/arXiv.1406.3726", "date": "2014-06-14", "title": "Evaluation of Machine Learning Techniques for Green Energy Prediction", "authors": "Ankur Sahai", "abstract": "We evaluate the following Machine Learning techniques for Green Energy (Wind,\nSolar) Prediction: Bayesian Inference, Neural Networks, Support Vector\nMachines, Clustering techniques (PCA). Our objective is to predict green energy\nusing weather forecasts, predict deviations from forecast green energy, find\ncorrelation amongst different weather parameters and green energy availability,\nrecover lost or missing energy (/ weather) data. We use historical weather data\nand weather forecasts for the same.", "journal": ""}
{"doi": "10.48550/arXiv.2106.12417", "date": "2021-06-23", "title": "False perfection in machine prediction: Detecting and assessing circularity problems in machine learning", "authors": "Michael Hagmann, Stefan Riezler", "abstract": "This paper is an excerpt of an early version of Chapter 2 of the book\n\"Validity, Reliability, and Significance. Empirical Methods for NLP and Data\nScience\", by Stefan Riezler and Michael Hagmann, published in December 2021 by\nMorgan & Claypool. Please see the book's homepage at\nhttps://www.morganclaypoolpublishers.com/catalog_Orig/product_info.php?products_id=1688\nfor a more recent and comprehensive discussion.", "journal": ""}
{"doi": "10.48550/arXiv.2301.11257", "date": "2023-01-26", "title": "A Benchmark Study by using various Machine Learning Models for Predicting Covid-19 trends", "authors": "D. Kamelesun, R. Saranya, P. Kathiravan", "abstract": "Machine learning and deep learning play vital roles in predicting diseases in\nthe medical field. Machine learning algorithms are widely classified as\nsupervised, unsupervised, and reinforcement learning. This paper contains a\ndetailed description of our experimental research work in that we used a\nsupervised machine-learning algorithm to build our model for outbreaks of the\nnovel Coronavirus that has spread over the whole world and caused many deaths,\nwhich is one of the most disastrous Pandemics in the history of the world. The\npeople suffered physically and economically to survive in this lockdown. This\nwork aims to understand better how machine learning, ensemble, and deep\nlearning models work and are implemented in the real dataset. In our work, we\nare going to analyze the current trend or pattern of the coronavirus and then\npredict the further future of the covid-19 confirmed cases or new cases by\ntraining the past Covid-19 dataset by using the machine learning algorithm such\nas Linear Regression, Polynomial Regression, K-nearest neighbor, Decision Tree,\nSupport Vector Machine and Random forest algorithm are used to train the model.\nThe decision tree and the Random Forest algorithm perform better than SVR in\nthis work. The performance of SVR and lasso regression are low in all\nprediction areas Because the SVR is challenging to separate the data using the\nhyperplane for this type of problem. So SVR mostly gives a lower performance in\nthis problem. Ensemble (Voting, Bagging, and Stacking) and deep learning\nmodels(ANN) also predict well. After the prediction, we evaluated the model\nusing MAE, MSE, RMSE, and MAPE. This work aims to find the trend/pattern of the\ncovid-19.", "journal": ""}
{"doi": "10.48550/arXiv.2307.09862", "date": "2023-07-19", "title": "Towards a population-informed approach to the definition of data-driven models for structural dynamics", "authors": "G. Tsialiamanis, N. Dervilis, D. J. Wagg, K. Worden", "abstract": "Machine learning has affected the way in which many phenomena for various\ndomains are modelled, one of these domains being that of structural dynamics.\nHowever, because machine-learning algorithms are problem-specific, they often\nfail to perform efficiently in cases of data scarcity. To deal with such\nissues, combination of physics-based approaches and machine learning algorithms\nhave been developed. Although such methods are effective, they also require the\nanalyser's understanding of the underlying physics of the problem. The current\nwork is aimed at motivating the use of models which learn such relationships\nfrom a population of phenomena, whose underlying physics are similar. The\ndevelopment of such models is motivated by the way that physics-based models,\nand more specifically finite element models, work. Such models are considered\ntransferrable, explainable and trustworthy, attributes which are not trivially\nimposed or achieved for machine-learning models. For this reason,\nmachine-learning approaches are less trusted by industry and often considered\nmore difficult to form validated models. To achieve such data-driven models, a\npopulation-based scheme is followed here and two different machine-learning\nalgorithms from the meta-learning domain are used. The two algorithms are the\nmodel-agnostic meta-learning (MAML) algorithm and the conditional neural\nprocesses (CNP) model. The algorithms seem to perform as intended and\noutperform a traditional machine-learning algorithm at approximating the\nquantities of interest. Moreover, they exhibit behaviour similar to traditional\nmachine learning algorithms (e.g. neural networks or Gaussian processes),\nconcerning their performance as a function of the available structures in the\ntraining population.", "journal": "Mechanical Systems and Signal Processing, Volume 200, 1 October\n  2023, 110581"}
{"doi": "10.48550/arXiv.2506.12226", "date": "2025-06-13", "title": "Learning Causality for Modern Machine Learning", "authors": "Yongqiang Chen", "abstract": "In the past decades, machine learning with Empirical Risk Minimization (ERM)\nhas demonstrated great capability in learning and exploiting the statistical\npatterns from data, or even surpassing humans. Despite the success, ERM avoids\nthe modeling of causality the way of understanding and handling changes, which\nis fundamental to human intelligence. When deploying models beyond the training\nenvironment, distribution shifts are everywhere. For example, an autopilot\nsystem often needs to deal with new weather conditions that have not been seen\nduring training, An Al-aided drug discovery system needs to predict the\nbiochemical properties of molecules with respect to new viruses such as\nCOVID-19. It renders the problem of Out-of-Distribution (OOD) generalization\nchallenging to conventional machine learning.\n  In this thesis, we investigate how to incorporate and realize the causality\nfor broader tasks in modern machine learning. In particular, we exploit the\ninvariance implied by the principle of independent causal mechanisms (ICM),\nthat is, the causal mechanisms generating the effects from causes do not inform\nor influence each other. Therefore, the conditional distribution between the\ntarget variable given its causes is invariant under distribution shifts. With\nthe causal invariance principle, we first instantiate it to graphs -- a general\ndata structure ubiquitous in many real-world industry and scientific\napplications, such as financial networks and molecules. Then, we shall see how\nlearning the causality benefits many of the desirable properties of modern\nmachine learning, in terms of (i) OOD generalization capability; (ii)\ninterpretability; and (iii) robustness to adversarial attacks.\n  Realizing the causality in machine learning, on the other hand, raises a\ndilemma for optimization in conventional machine learning, as it often\ncontradicts the objective of ERM...", "journal": ""}
{"doi": "10.48550/arXiv.2202.02896", "date": "2022-02-07", "title": "Evaluation Methods and Measures for Causal Learning Algorithms", "authors": "Lu Cheng, Ruocheng Guo, Raha Moraffah, Paras Sheth, K. Selcuk Candan, Huan Liu", "abstract": "The convenient access to copious multi-faceted data has encouraged machine\nlearning researchers to reconsider correlation-based learning and embrace the\nopportunity of causality-based learning, i.e., causal machine learning (causal\nlearning). Recent years have therefore witnessed great effort in developing\ncausal learning algorithms aiming to help AI achieve human-level intelligence.\nDue to the lack-of ground-truth data, one of the biggest challenges in current\ncausal learning research is algorithm evaluations. This largely impedes the\ncross-pollination of AI and causal inference, and hinders the two fields to\nbenefit from the advances of the other. To bridge from conventional causal\ninference (i.e., based on statistical methods) to causal learning with big data\n(i.e., the intersection of causal inference and machine learning), in this\nsurvey, we review commonly-used datasets, evaluation methods, and measures for\ncausal learning using an evaluation pipeline similar to conventional machine\nlearning. We focus on the two fundamental causal-inference tasks and\ncausality-aware machine learning tasks. Limitations of current evaluation\nprocedures are also discussed. We then examine popular causal inference\ntools/packages and conclude with primary challenges and opportunities for\nbenchmarking causal learning algorithms in the era of big data. The survey\nseeks to bring to the forefront the urgency of developing publicly available\nbenchmarks and consensus-building standards for causal learning evaluation with\nobservational data. In doing so, we hope to broaden the discussions and\nfacilitate collaboration to advance the innovation and application of causal\nlearning.", "journal": ""}
{"doi": "10.48550/arXiv.1308.3750", "date": "2013-08-17", "title": "Comment on \"robustness and regularization of support vector machines\" by H. Xu, et al., (Journal of Machine Learning Research, vol. 10, pp. 1485-1510, 2009, arXiv:0803.3490)", "authors": "Yahya Forghani, Hadi Sadoghi Yazdi", "abstract": "This paper comments on the published work dealing with robustness and\nregularization of support vector machines (Journal of Machine Learning\nResearch, vol. 10, pp. 1485-1510, 2009) [arXiv:0803.3490] by H. Xu, etc. They\nproposed a theorem to show that it is possible to relate robustness in the\nfeature space and robustness in the sample space directly. In this paper, we\npropose a counter example that rejects their theorem.", "journal": ""}
{"doi": "10.48550/arXiv.2208.04365", "date": "2022-08-08", "title": "Gradient Flows for L2 Support Vector Machine Training", "authors": "Christian Bauckhage, Helen Schneider, Benjamin Wulff, Rafet Sifa", "abstract": "We explore the merits of training of support vector machines for binary\nclassification by means of solving systems of ordinary differential equations.\nWe thus assume a continuous time perspective on a machine learning problem\nwhich may be of interest for implementations on (re)emerging hardware platforms\nsuch as analog- or quantum computers.", "journal": ""}
{"doi": "10.48550/arXiv.2209.13963", "date": "2022-09-28", "title": "Machine Beats Machine: Machine Learning Models to Defend Against Adversarial Attacks", "authors": "Jo\u017ee M. Ro\u017eanec, Dimitrios Papamartzivanos, Entso Veliou, Theodora Anastasiou, Jelle Keizer, Bla\u017e Fortuna, Dunja Mladeni\u0107", "abstract": "We propose using a two-layered deployment of machine learning models to\nprevent adversarial attacks. The first layer determines whether the data was\ntampered, while the second layer solves a domain-specific problem. We explore\nthree sets of features and three dataset variations to train machine learning\nmodels. Our results show clustering algorithms achieved promising results. In\nparticular, we consider the best results were obtained by applying the DBSCAN\nalgorithm to the structured structural similarity index measure computed\nbetween the images and a white reference image.", "journal": ""}
{"doi": "10.48550/arXiv.2408.16620", "date": "2024-08-29", "title": "Hyperdimensional Vector Tsetlin Machines with Applications to Sequence Learning and Generation", "authors": "Christian D. Blakely", "abstract": "We construct a two-layered model for learning and generating sequential data\nthat is both computationally fast and competitive with vanilla Tsetlin\nmachines, adding numerous advantages. Through the use of hyperdimensional\nvector computing (HVC) algebras and Tsetlin machine clause structures, we\ndemonstrate that the combination of both inherits the generality of data\nencoding and decoding of HVC with the fast interpretable nature of Tsetlin\nmachines to yield a powerful machine learning model. We apply the approach in\ntwo areas, namely in forecasting, generating new sequences, and classification.\nFor the latter, we derive results for the entire UCR Time Series Archive and\ncompare with the standard benchmarks to see how well the method competes in\ntime series classification.", "journal": ""}
{"doi": "10.48550/arXiv.1611.07567", "date": "2016-11-22", "title": "Feature Importance Measure for Non-linear Learning Algorithms", "authors": "Marina M. -C. Vidovic, Nico G\u00f6rnitz, Klaus-Robert M\u00fcller, Marius Kloft", "abstract": "Complex problems may require sophisticated, non-linear learning methods such\nas kernel machines or deep neural networks to achieve state of the art\nprediction accuracies. However, high prediction accuracies are not the only\nobjective to consider when solving problems using machine learning. Instead,\nparticular scientific applications require some explanation of the learned\nprediction function. Unfortunately, most methods do not come with out of the\nbox straight forward interpretation. Even linear prediction functions are not\nstraight forward to explain if features exhibit complex correlation structure.\n  In this paper, we propose the Measure of Feature Importance (MFI). MFI is\ngeneral and can be applied to any arbitrary learning machine (including kernel\nmachines and deep learning). MFI is intrinsically non-linear and can detect\nfeatures that by itself are inconspicuous and only impact the prediction\nfunction through their interaction with other features. Lastly, MFI can be used\nfor both --- model-based feature importance and instance-based feature\nimportance (i.e, measuring the importance of a feature for a particular data\npoint).", "journal": ""}
{"doi": "10.48550/arXiv.2105.13448", "date": "2021-05-27", "title": "Open-world Machine Learning: Applications, Challenges, and Opportunities", "authors": "Jitendra Parmar, Satyendra Singh Chouhan, Vaskar Raychoudhury, Santosh Singh Rathore", "abstract": "Traditional machine learning mainly supervised learning, follows the\nassumptions of closed-world learning, i.e., for each testing class, a training\nclass is available. However, such machine learning models fail to identify the\nclasses which were not available during training time. These classes can be\nreferred to as unseen classes. Whereas open-world machine learning (OWML) deals\nwith unseen classes. In this paper, first, we present an overview of OWML with\nimportance to the real-world context. Next, different dimensions of open-world\nmachine learning are explored and discussed. The area of OWML gained the\nattention of the research community in the last decade only. We have searched\nthrough different online digital libraries and scrutinized the work done in the\nlast decade. This paper presents a systematic review of various techniques for\nOWML. It also presents the research gaps, challenges, and future directions in\nopen-world machine learning. This paper will help researchers understand the\ncomprehensive developments of OWML and the likelihood of extending the research\nin suitable areas. It will also help to select applicable methodologies and\ndatasets to explore this further.", "journal": ""}
{"doi": "10.48550/arXiv.1609.02664", "date": "2016-09-09", "title": "Machine Learning with Guarantees using Descriptive Complexity and SMT Solvers", "authors": "Charles Jordan, \u0141ukasz Kaiser", "abstract": "Machine learning is a thriving part of computer science. There are many\nefficient approaches to machine learning that do not provide strong theoretical\nguarantees, and a beautiful general learning theory. Unfortunately, machine\nlearning approaches that give strong theoretical guarantees have not been\nefficient enough to be applicable. In this paper we introduce a logical\napproach to machine learning. Models are represented by tuples of logical\nformulas and inputs and outputs are logical structures. We present our\nframework together with several applications where we evaluate it using SAT and\nSMT solvers. We argue that this approach to machine learning is particularly\nsuited to bridge the gap between efficiency and theoretical soundness. We\nexploit results from descriptive complexity theory to prove strong theoretical\nguarantees for our approach. To show its applicability, we present experimental\nresults including learning complexity-theoretic reductions rules for board\ngames. We also explain how neural networks fit into our framework, although the\ncurrent implementation does not scale to provide guarantees for real-world\nneural networks.", "journal": ""}
{"doi": "10.48550/arXiv.1911.00108", "date": "2019-10-31", "title": "RankML: a Meta Learning-Based Approach for Pre-Ranking Machine Learning Pipelines", "authors": "Doron Laadan, Roman Vainshtein, Yarden Curiel, Gilad Katz, Lior Rokach", "abstract": "The explosion of digital data has created multiple opportunities for\norganizations and individuals to leverage machine learning (ML) to transform\nthe way they operate. However, the shortage of experts in the field of machine\nlearning -- data scientists -- is often a setback to the use of ML. In an\nattempt to alleviate this shortage, multiple approaches for the automation of\nmachine learning have been proposed in recent years. While these approaches are\neffective, they often require a great deal of time and computing resources. In\nthis study, we propose RankML, a meta-learning based approach for predicting\nthe performance of whole machine learning pipelines. Given a previously-unseen\ndataset, a performance metric, and a set of candidate pipelines, RankML\nimmediately produces a ranked list of all pipelines based on their predicted\nperformance. Extensive evaluation on 244 datasets, both in regression and\nclassification tasks, shows that our approach either outperforms or is\ncomparable to state-of-the-art, computationally heavy approaches while\nrequiring a fraction of the time and computational cost.", "journal": ""}
{"doi": "10.48550/arXiv.2009.09723", "date": "2020-09-21", "title": "Machine Guides, Human Supervises: Interactive Learning with Global Explanations", "authors": "Teodora Popordanoska, Mohit Kumar, Stefano Teso", "abstract": "We introduce explanatory guided learning (XGL), a novel interactive learning\nstrategy in which a machine guides a human supervisor toward selecting\ninformative examples for a classifier. The guidance is provided by means of\nglobal explanations, which summarize the classifier's behavior on different\nregions of the instance space and expose its flaws. Compared to other\nexplanatory interactive learning strategies, which are machine-initiated and\nrely on local explanations, XGL is designed to be robust against cases in which\nthe explanations supplied by the machine oversell the classifier's quality.\nMoreover, XGL leverages global explanations to open up the black-box of\nhuman-initiated interaction, enabling supervisors to select informative\nexamples that challenge the learned model. By drawing a link to interactive\nmachine teaching, we show theoretically that global explanations are a viable\napproach for guiding supervisors. Our simulations show that explanatory guided\nlearning avoids overselling the model's quality and performs comparably or\nbetter than machine- and human-initiated interactive learning strategies in\nterms of model quality.", "journal": ""}
{"doi": "10.48550/arXiv.2204.13625", "date": "2022-04-28", "title": "Standardized Evaluation of Machine Learning Methods for Evolving Data Streams", "authors": "Johannes Haug, Effi Tramountani, Gjergji Kasneci", "abstract": "Due to the unspecified and dynamic nature of data streams, online machine\nlearning requires powerful and flexible solutions. However, evaluating online\nmachine learning methods under realistic conditions is difficult. Existing work\ntherefore often draws on different heuristics and simulations that do not\nnecessarily produce meaningful and reliable results. Indeed, in the absence of\ncommon evaluation standards, it often remains unclear how online learning\nmethods will perform in practice or in comparison to similar work. In this\npaper, we propose a comprehensive set of properties for high-quality machine\nlearning in evolving data streams. In particular, we discuss sensible\nperformance measures and evaluation strategies for online predictive modelling,\nonline feature selection and concept drift detection. As one of the first\nworks, we also look at the interpretability of online learning methods. The\nproposed evaluation standards are provided in a new Python framework called\nfloat. Float is completely modular and allows the simultaneous integration of\ncommon libraries, such as scikit-multiflow or river, with custom code. Float is\nopen-sourced and can be accessed at https://github.com/haugjo/float. In this\nsense, we hope that our work will contribute to more standardized, reliable and\nrealistic testing and comparison of online machine learning methods.", "journal": ""}
{"doi": "10.48550/arXiv.2206.00423", "date": "2022-06-01", "title": "Open-environment Machine Learning", "authors": "Zhi-Hua Zhou", "abstract": "Conventional machine learning studies generally assume close-environment\nscenarios where important factors of the learning process hold invariant. With\nthe great success of machine learning, nowadays, more and more practical tasks,\nparticularly those involving open-environment scenarios where important factors\nare subject to change, called open-environment machine learning (Open ML) in\nthis article, are present to the community. Evidently it is a grand challenge\nfor machine learning turning from close environment to open environment. It\nbecomes even more challenging since, in various big data tasks, data are\nusually accumulated with time, like streams, while it is hard to train the\nmachine learning model after collecting all data as in conventional studies.\nThis article briefly introduces some advances in this line of research,\nfocusing on techniques concerning emerging new classes, decremental/incremental\nfeatures, changing data distributions, varied learning objectives, and\ndiscusses some theoretical issues.", "journal": ""}
{"doi": "10.48550/arXiv.2208.07017", "date": "2022-08-15", "title": "Prospects of federated machine learning in fluid dynamics", "authors": "Omer San, Suraj Pawar, Adil Rasheed", "abstract": "Physics-based models have been mainstream in fluid dynamics for developing\npredictive models. In recent years, machine learning has offered a renaissance\nto the fluid community due to the rapid developments in data science,\nprocessing units, neural network based technologies, and sensor adaptations. So\nfar in many applications in fluid dynamics, machine learning approaches have\nbeen mostly focused on a standard process that requires centralizing the\ntraining data on a designated machine or in a data center. In this letter, we\npresent a federated machine learning approach that enables localized clients to\ncollaboratively learn an aggregated and shared predictive model while keeping\nall the training data on each edge device. We demonstrate the feasibility and\nprospects of such decentralized learning approach with an effort to forge a\ndeep learning surrogate model for reconstructing spatiotemporal fields. Our\nresults indicate that federated machine learning might be a viable tool for\ndesigning highly accurate predictive decentralized digital twins relevant to\nfluid dynamics.", "journal": ""}
{"doi": "10.48550/arXiv.2301.03595", "date": "2022-12-15", "title": "White-box Inference Attacks against Centralized Machine Learning and Federated Learning", "authors": "Jingyi Ge", "abstract": "With the development of information science and technology, various\nindustries have generated massive amounts of data, and machine learning is\nwidely used in the analysis of big data. However, if the privacy of machine\nlearning applications' customers cannot be guaranteed, it will cause security\nthreats and losses to users' personal privacy information and service\nproviders. Therefore, the issue of privacy protection of machine learning has\nreceived wide attention. For centralized machine learning models, we evaluate\nthe impact of different neural network layers, gradient, gradient norm, and\nfine-tuned models on member inference attack performance with prior knowledge;\nFor the federated learning model, we discuss the location of the attacker in\nthe target model and its attack mode. The results show that the centralized\nmachine learning model shows more serious member information leakage in all\naspects, and the accuracy of the attacker in the central parameter server is\nsignificantly higher than the local Inference attacks as participants.", "journal": ""}
{"doi": "10.48550/arXiv.2307.01390", "date": "2023-07-03", "title": "Adversarial Learning in Real-World Fraud Detection: Challenges and Perspectives", "authors": "Danele Lunghi, Alkis Simitsis, Olivier Caelen, Gianluca Bontempi", "abstract": "Data economy relies on data-driven systems and complex machine learning\napplications are fueled by them. Unfortunately, however, machine learning\nmodels are exposed to fraudulent activities and adversarial attacks, which\nthreaten their security and trustworthiness. In the last decade or so, the\nresearch interest on adversarial machine learning has grown significantly,\nrevealing how learning applications could be severely impacted by effective\nattacks. Although early results of adversarial machine learning indicate the\nhuge potential of the approach to specific domains such as image processing,\nstill there is a gap in both the research literature and practice regarding how\nto generalize adversarial techniques in other domains and applications. Fraud\ndetection is a critical defense mechanism for data economy, as it is for other\napplications as well, which poses several challenges for machine learning. In\nthis work, we describe how attacks against fraud detection systems differ from\nother applications of adversarial machine learning, and propose a number of\ninteresting directions to bridge this gap.", "journal": ""}
{"doi": "10.48550/arXiv.2311.04372", "date": "2023-11-07", "title": "Enhancing Malware Detection by Integrating Machine Learning with Cuckoo Sandbox", "authors": "Amaal F. Alshmarni, Mohammed A. Alliheedi", "abstract": "In the modern era, malware is experiencing a significant increase in both its\nvariety and quantity, aligning with the widespread adoption of the digital\nworld. This surge in malware has emerged as a critical challenge in the realm\nof cybersecurity, prompting numerous research endeavors and contributions to\naddress the issue. Machine learning algorithms have been leveraged for malware\ndetection due to their ability to uncover concealed patterns within vast\ndatasets. However, deep learning algorithms, characterized by their\nmulti-layered structure, surpass the limitations of traditional machine\nlearning approaches. By employing deep learning techniques such as CNN\n(Convolutional Neural Network) and RNN (Recurrent Neural Network), this study\naims to classify and identify malware extracted from a dataset containing API\ncall sequences. The performance of these algorithms is compared with that of\nconventional machine learning methods, including SVM (Support Vector Machine),\nRF (Random Forest), KNN (K-Nearest Neighbors), XGB (Extreme Gradient Boosting),\nand GBC (Gradient Boosting Classifier), all using the same dataset. The\noutcomes of this research demonstrate that both deep learning and machine\nlearning algorithms achieve remarkably high levels of accuracy, reaching up to\n99% in certain cases.", "journal": "JISCR, vol. 7, no. 1, pp. 85-92, Jun. 2024"}
{"doi": "10.48550/arXiv.2402.02637", "date": "2024-02-04", "title": "$C^*$-Algebraic Machine Learning: Moving in a New Direction", "authors": "Yuka Hashimoto, Masahiro Ikeda, Hachem Kadri", "abstract": "Machine learning has a long collaborative tradition with several fields of\nmathematics, such as statistics, probability and linear algebra. We propose a\nnew direction for machine learning research: $C^*$-algebraic ML $-$ a\ncross-fertilization between $C^*$-algebra and machine learning. The\nmathematical concept of $C^*$-algebra is a natural generalization of the space\nof complex numbers. It enables us to unify existing learning strategies, and\nconstruct a new framework for more diverse and information-rich data models. We\nexplain why and how to use $C^*$-algebras in machine learning, and provide\ntechnical considerations that go into the design of $C^*$-algebraic learning\nmodels in the contexts of kernel methods and neural networks. Furthermore, we\ndiscuss open questions and challenges in $C^*$-algebraic ML and give our\nthoughts for future development and applications.", "journal": "ICML 2024"}
{"doi": "10.48550/arXiv.2410.20281", "date": "2024-10-26", "title": "Proactive Fraud Defense: Machine Learning's Evolving Role in Protecting Against Online Fraud", "authors": "Md Kamrul Hasan Chy", "abstract": "As online fraud becomes more sophisticated and pervasive, traditional fraud\ndetection methods are struggling to keep pace with the evolving tactics\nemployed by fraudsters. This paper explores the transformative role of machine\nlearning in addressing these challenges by offering more advanced, scalable,\nand adaptable solutions for fraud detection and prevention. By analyzing key\nmodels such as Random Forest, Neural Networks, and Gradient Boosting, this\npaper highlights the strengths of machine learning in processing vast datasets,\nidentifying intricate fraud patterns, and providing real-time predictions that\nenable a proactive approach to fraud prevention. Unlike rule-based systems that\nreact after fraud has occurred, machine learning models continuously learn from\nnew data, adapting to emerging fraud schemes and reducing false positives,\nwhich ultimately minimizes financial losses. This research emphasizes the\npotential of machine learning to revolutionize fraud detection frameworks by\nmaking them more dynamic, efficient, and capable of handling the growing\ncomplexity of fraud across various industries. Future developments in machine\nlearning, including deep learning and hybrid models, are expected to further\nenhance the predictive accuracy and applicability of these systems, ensuring\nthat organizations remain resilient in the face of new and emerging fraud\ntactics.", "journal": ""}
{"doi": "10.48550/arXiv.2412.01393", "date": "2024-12-02", "title": "Machine Learning Analysis of Anomalous Diffusion", "authors": "Wenjie Cai, Yi Hu, Xiang Qu, Hui Zhao, Gongyi Wang, Jing Li, Zihan Huang", "abstract": "The rapid advancements in machine learning have made its application to\nanomalous diffusion analysis both essential and inevitable. This review\nsystematically introduces the integration of machine learning techniques for\nenhanced analysis of anomalous diffusion, focusing on two pivotal aspects:\nsingle trajectory characterization via machine learning and representation\nlearning of anomalous diffusion. We extensively compare various machine\nlearning methods, including both classical machine learning and deep learning,\nused for the inference of diffusion parameters and trajectory segmentation.\nAdditionally, platforms such as the Anomalous Diffusion Challenge that serve as\nbenchmarks for evaluating these methods are highlighted. On the other hand, we\noutline three primary strategies for representing anomalous diffusion: the\ncombination of predefined features, the feature vector from the penultimate\nlayer of neural network, and the latent representation from the autoencoder,\nanalyzing their applicability across various scenarios. This investigation\npaves the way for future research, offering valuable perspectives that can\nfurther enrich the study of anomalous diffusion and advance the application of\nartificial intelligence in statistical physics and biophysics.", "journal": "European Physical Journal Plus, 2025, 140, 183"}
{"doi": "10.48550/arXiv.2412.14753", "date": "2024-12-19", "title": "Opportunities and limitations of explaining quantum machine learning", "authors": "Elies Gil-Fuster, Jonas R. Naujoks, Gr\u00e9goire Montavon, Thomas Wiegand, Wojciech Samek, Jens Eisert", "abstract": "A common trait of many machine learning models is that it is often difficult\nto understand and explain what caused the model to produce the given output.\nWhile the explainability of neural networks has been an active field of\nresearch in the last years, comparably little is known for quantum machine\nlearning models. Despite a few recent works analyzing some specific aspects of\nexplainability, as of now there is no clear big picture perspective as to what\ncan be expected from quantum learning models in terms of explainability. In\nthis work, we address this issue by identifying promising research avenues in\nthis direction and lining out the expected future results. We additionally\npropose two explanation methods designed specifically for quantum machine\nlearning models, as first of their kind to the best of our knowledge. Next to\nour pre-view of the field, we compare both existing and novel methods to\nexplain the predictions of quantum learning models. By studying explainability\nin quantum machine learning, we can contribute to the sustainable development\nof the field, preventing trust issues in the future.", "journal": ""}
{"doi": "10.48550/arXiv.1909.07245", "date": "2019-09-16", "title": "BMVC 2019: Workshop on Interpretable and Explainable Machine Vision", "authors": "Alun Preece", "abstract": "Proceedings of the BMVC 2019 Workshop on Interpretable and Explainable\nMachine Vision, Cardiff, UK, September 12, 2019.", "journal": ""}
{"doi": "10.48550/arXiv.0904.3667", "date": "2009-04-23", "title": "Considerations upon the Machine Learning Technologies", "authors": "Alin Munteanu, Cristina Ofelia Sofran", "abstract": "Artificial intelligence offers superior techniques and methods by which\nproblems from diverse domains may find an optimal solution. The Machine\nLearning technologies refer to the domain of artificial intelligence aiming to\ndevelop the techniques allowing the computers to \"learn\". Some systems based on\nMachine Learning technologies tend to eliminate the necessity of the human\nintelligence while the others adopt a man-machine collaborative approach.", "journal": "Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 133-138"}
{"doi": "10.48550/arXiv.0911.1386", "date": "2009-11-07", "title": "Machine Learning: When and Where the Horses Went Astray?", "authors": "Emanuel Diamant", "abstract": "Machine Learning is usually defined as a subfield of AI, which is busy with\ninformation extraction from raw data sets. Despite of its common acceptance and\nwidespread recognition, this definition is wrong and groundless. Meaningful\ninformation does not belong to the data that bear it. It belongs to the\nobservers of the data and it is a shared agreement and a convention among them.\nTherefore, this private information cannot be extracted from the data by any\nmeans. Therefore, all further attempts of Machine Learning apologists to\njustify their funny business are inappropriate.", "journal": ""}
{"doi": "10.48550/arXiv.1202.6548", "date": "2012-02-29", "title": "mlpy: Machine Learning Python", "authors": "Davide Albanese, Roberto Visintainer, Stefano Merler, Samantha Riccadonna, Giuseppe Jurman, Cesare Furlanello", "abstract": "mlpy is a Python Open Source Machine Learning library built on top of\nNumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of\nstate-of-the-art machine learning methods for supervised and unsupervised\nproblems and it is aimed at finding a reasonable compromise among modularity,\nmaintainability, reproducibility, usability and efficiency. mlpy is\nmultiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at\nthe website http://mlpy.fbk.eu.", "journal": ""}
{"doi": "10.48550/arXiv.1206.4656", "date": "2012-06-18", "title": "Machine Learning that Matters", "authors": "Kiri Wagstaff", "abstract": "Much of current machine learning (ML) research has lost its connection to\nproblems of import to the larger world of science and society. From this\nperspective, there exist glaring limitations in the data sets we investigate,\nthe metrics we employ for evaluation, and the degree to which results are\ncommunicated back to their originating domains. What changes are needed to how\nwe conduct research to increase the impact that ML has? We present six Impact\nChallenges to explicitly focus the field?s energy and attention, and we discuss\nexisting obstacles that must be addressed. We aim to inspire ongoing discussion\nand focus on ML that matters.", "journal": "Proceedings of the Twenty-Ninth International Conference on\n  Machine Learning (ICML), p. 529-536"}
{"doi": "10.48550/arXiv.1308.4214", "date": "2013-08-20", "title": "Pylearn2: a machine learning research library", "authors": "Ian J. Goodfellow, David Warde-Farley, Pascal Lamblin, Vincent Dumoulin, Mehdi Mirza, Razvan Pascanu, James Bergstra, Fr\u00e9d\u00e9ric Bastien, Yoshua Bengio", "abstract": "Pylearn2 is a machine learning research library. This does not just mean that\nit is a collection of machine learning algorithms that share a common API; it\nmeans that it has been designed for flexibility and extensibility in order to\nfacilitate research projects that involve new or unusual use cases. In this\npaper we give a brief history of the library, an overview of its basic\nphilosophy, a summary of the library's architecture, and a description of how\nthe Pylearn2 community functions socially.", "journal": ""}
{"doi": "10.48550/arXiv.1403.0745", "date": "2014-03-04", "title": "EnsembleSVM: A Library for Ensemble Learning Using Support Vector Machines", "authors": "Marc Claesen, Frank De Smet, Johan Suykens, Bart De Moor", "abstract": "EnsembleSVM is a free software package containing efficient routines to\nperform ensemble learning with support vector machine (SVM) base models. It\ncurrently offers ensemble methods based on binary SVM models. Our\nimplementation avoids duplicate storage and evaluation of support vectors which\nare shared between constituent models. Experimental results show that using\nensemble approaches can drastically reduce training complexity while\nmaintaining high predictive accuracy. The EnsembleSVM software package is\nfreely available online at http://esat.kuleuven.be/stadius/ensemblesvm.", "journal": "Journal of Machine Learning Research. 15 (2014) 141-145"}
{"doi": "10.48550/arXiv.1506.04776", "date": "2015-06-15", "title": "Encog: Library of Interchangeable Machine Learning Models for Java and C#", "authors": "Jeff Heaton", "abstract": "This paper introduces the Encog library for Java and C#, a scalable,\nadaptable, multiplatform machine learning framework that was 1st released in\n2008. Encog allows a variety of machine learning models to be applied to\ndatasets using regression, classification, and clustering. Various supported\nmachine learning models can be used interchangeably with minimal recoding.\nEncog uses efficient multithreaded code to reduce training time by exploiting\nmodern multicore processors. The current version of Encog can be downloaded\nfrom http://www.encog.org.", "journal": ""}
{"doi": "10.48550/arXiv.1601.03642", "date": "2016-01-12", "title": "Creativity in Machine Learning", "authors": "Martin Thoma", "abstract": "Recent machine learning techniques can be modified to produce creative\nresults. Those results did not exist before; it is not a trivial combination of\nthe data which was fed into the machine learning system. The obtained results\ncome in multiple forms: As images, as text and as audio.\n  This paper gives a high level overview of how they are created and gives some\nexamples. It is meant to be a summary of the current work and give people who\nare new to machine learning some starting points.", "journal": ""}
{"doi": "10.48550/arXiv.1606.01042", "date": "2016-06-03", "title": "Machine Learning for E-mail Spam Filtering: Review,Techniques and Trends", "authors": "Alexy Bhowmick, Shyamanta M. Hazarika", "abstract": "We present a comprehensive review of the most effective content-based e-mail\nspam filtering techniques. We focus primarily on Machine Learning-based spam\nfilters and their variants, and report on a broad review ranging from surveying\nthe relevant ideas, efforts, effectiveness, and the current progress. The\ninitial exposition of the background examines the basics of e-mail spam\nfiltering, the evolving nature of spam, spammers playing cat-and-mouse with\ne-mail service providers (ESPs), and the Machine Learning front in fighting\nspam. We conclude by measuring the impact of Machine Learning-based filters and\nexplore the promising offshoots of latest developments.", "journal": ""}
{"doi": "10.48550/arXiv.1606.05685", "date": "2016-06-17", "title": "Using Visual Analytics to Interpret Predictive Machine Learning Models", "authors": "Josua Krause, Adam Perer, Enrico Bertini", "abstract": "It is commonly believed that increasing the interpretability of a machine\nlearning model may decrease its predictive power. However, inspecting\ninput-output relationships of those models using visual analytics, while\ntreating them as black-box, can help to understand the reasoning behind\noutcomes without sacrificing predictive quality. We identify a space of\npossible solutions and provide two examples of where such techniques have been\nsuccessfully used in practice.", "journal": ""}
{"doi": "10.48550/arXiv.1612.05740", "date": "2016-12-17", "title": "Machine Learning, Linear and Bayesian Models for Logistic Regression in Failure Detection Problems", "authors": "B. Pavlyshenko", "abstract": "In this work, we study the use of logistic regression in manufacturing\nfailures detection. As a data set for the analysis, we used the data from\nKaggle competition Bosch Production Line Performance. We considered the use of\nmachine learning, linear and Bayesian models. For machine learning approach, we\nanalyzed XGBoost tree based classifier to obtain high scored classification.\nUsing the generalized linear model for logistic regression makes it possible to\nanalyze the influence of the factors under study. The Bayesian approach for\nlogistic regression gives the statistical distribution for the parameters of\nthe model. It can be useful in the probabilistic analysis, e.g. risk\nassessment.", "journal": ""}
{"doi": "10.48550/arXiv.1710.08464", "date": "2017-10-23", "title": "Interpretable Machine Learning for Privacy-Preserving Pervasive Systems", "authors": "Benjamin Baron, Mirco Musolesi", "abstract": "Our everyday interactions with pervasive systems generate traces that capture\nvarious aspects of human behavior and enable machine learning algorithms to\nextract latent information about users. In this paper, we propose a machine\nlearning interpretability framework that enables users to understand how these\ngenerated traces violate their privacy.", "journal": "IEEE Pervasive Computing, 2019"}
{"doi": "10.48550/arXiv.1711.00001", "date": "2017-10-30", "title": "Gene Ontology (GO) Prediction using Machine Learning Methods", "authors": "Haoze Wu, Yangyu Zhou", "abstract": "We applied machine learning to predict whether a gene is involved in axon\nregeneration. We extracted 31 features from different databases and trained\nfive machine learning models. Our optimal model, a Random Forest Classifier\nwith 50 submodels, yielded a test score of 85.71%, which is 4.1% higher than\nthe baseline score. We concluded that our models have some predictive\ncapability. Similar methodology and features could be applied to predict other\nGene Ontology (GO) terms.", "journal": ""}
{"doi": "10.48550/arXiv.1802.03532", "date": "2018-02-10", "title": "Bayesian Optimization Using Monotonicity Information and Its Application in Machine Learning Hyperparameter", "authors": "Wenyi Wang, William J. Welch", "abstract": "We propose an algorithm for a family of optimization problems where the\nobjective can be decomposed as a sum of functions with monotonicity properties.\nThe motivating problem is optimization of hyperparameters of machine learning\nalgorithms, where we argue that the objective, validation error, can be\ndecomposed as monotonic functions of the hyperparameters. Our proposed\nalgorithm adapts Bayesian optimization methods to incorporate the monotonicity\nconstraints. We illustrate the advantages of exploiting monotonicity using\nillustrative examples and demonstrate the improvements in optimization\nefficiency for some machine learning hyperparameter tuning applications.", "journal": ""}
{"doi": "10.48550/arXiv.1807.03200", "date": "2018-07-06", "title": "The CodRep Machine Learning on Source Code Competition", "authors": "Zimin Chen, Martin Monperrus", "abstract": "CodRep is a machine learning competition on source code data. It is carefully\ndesigned so that anybody can enter the competition, whether professional\nresearchers, students or independent scholars, without specific knowledge in\nmachine learning or program analysis. In particular, it aims at being a common\nplayground on which the machine learning and the software engineering research\ncommunities can interact. The competition has started on April 14th 2018 and\nhas ended on October 14th 2018. The CodRep data is hosted at\nhttps://github.com/KTH/CodRep-competition/.", "journal": ""}
{"doi": "10.48550/arXiv.1807.06574", "date": "2018-07-17", "title": "Jensen: An Easily-Extensible C++ Toolkit for Production-Level Machine Learning and Convex Optimization", "authors": "Rishabh Iyer, John T. Halloran, Kai Wei", "abstract": "This paper introduces Jensen, an easily extensible and scalable toolkit for\nproduction-level machine learning and convex optimization. Jensen implements a\nframework of convex (or loss) functions, convex optimization algorithms\n(including Gradient Descent, L-BFGS, Stochastic Gradient Descent, Conjugate\nGradient, etc.), and a family of machine learning classifiers and regressors\n(Logistic Regression, SVMs, Least Square Regression, etc.). This framework\nmakes it possible to deploy and train models with a few lines of code, and also\nextend and build upon this by integrating new loss functions and optimization\nalgorithms.", "journal": ""}
{"doi": "10.48550/arXiv.1807.08655", "date": "2018-06-29", "title": "Training Humans and Machines", "authors": "Aki Nikolaidis", "abstract": "For many years, researchers in psychology, education, statistics, and machine\nlearning have been developing practical methods to improve learning speed,\nretention, and generalizability, and this work has been successful. Many of\nthese methods are rooted in common underlying principles that seem to drive\nlearning and overlearning in both humans and machines. I present a review of a\nsmall part of this work to point to potentially novel applications in both\nmachine and human learning that may be worth exploring.", "journal": ""}
{"doi": "10.48550/arXiv.1810.04491", "date": "2018-10-10", "title": "Multi-class Classification Model Inspired by Quantum Detection Theory", "authors": "Prayag Tiwari, Massimo Melucci", "abstract": "Machine Learning has become very famous currently which assist in identifying\nthe patterns from the raw data. Technological advancement has led to\nsubstantial improvement in Machine Learning which, thus helping to improve\nprediction. Current Machine Learning models are based on Classical Theory,\nwhich can be replaced by Quantum Theory to improve the effectiveness of the\nmodel. In the previous work, we developed binary classifier inspired by Quantum\nDetection Theory. In this extended abstract, our main goal is to develop\nmulti-class classifier. We generally use the terminology multinomial\nclassification or multi-class classification when we have a classification\nproblem for classifying observations or instances into one of three or more\nclasses.", "journal": ""}
{"doi": "10.48550/arXiv.1903.08356", "date": "2019-03-20", "title": "Machine Learning for Data-Driven Movement Generation: a Review of the State of the Art", "authors": "Omid Alemi, Philippe Pasquier", "abstract": "The rise of non-linear and interactive media such as video games has\nincreased the need for automatic movement animation generation. In this survey,\nwe review and analyze different aspects of building automatic movement\ngeneration systems using machine learning techniques and motion capture data.\nWe cover topics such as high-level movement characterization, training data,\nfeatures representation, machine learning models, and evaluation methods. We\nconclude by presenting a discussion of the reviewed literature and outlining\nthe research gaps and remaining challenges for future work.", "journal": ""}
{"doi": "10.48550/arXiv.1905.01330", "date": "2019-05-03", "title": "TensorNetwork: A Library for Physics and Machine Learning", "authors": "Chase Roberts, Ashley Milsted, Martin Ganahl, Adam Zalcman, Bruce Fontaine, Yijian Zou, Jack Hidary, Guifre Vidal, Stefan Leichenauer", "abstract": "TensorNetwork is an open source library for implementing tensor network\nalgorithms. Tensor networks are sparse data structures originally designed for\nsimulating quantum many-body physics, but are currently also applied in a\nnumber of other research areas, including machine learning. We demonstrate the\nuse of the API with applications both physics and machine learning, with\ndetails appearing in companion papers.", "journal": ""}
{"doi": "10.48550/arXiv.2006.14755", "date": "2020-06-26", "title": "DeltaGrad: Rapid retraining of machine learning models", "authors": "Yinjun Wu, Edgar Dobriban, Susan B. Davidson", "abstract": "Machine learning models are not static and may need to be retrained on\nslightly changed datasets, for instance, with the addition or deletion of a set\nof data points. This has many applications, including privacy, robustness, bias\nreduction, and uncertainty quantifcation. However, it is expensive to retrain\nmodels from scratch. To address this problem, we propose the DeltaGrad\nalgorithm for rapid retraining machine learning models based on information\ncached during the training phase. We provide both theoretical and empirical\nsupport for the effectiveness of DeltaGrad, and show that it compares favorably\nto the state of the art.", "journal": "published in ICML 2020"}
{"doi": "10.48550/arXiv.1805.03441", "date": "2018-05-09", "title": "Machine Learning in Compiler Optimisation", "authors": "Zheng Wang, Michael O'Boyle", "abstract": "In the last decade, machine learning based compilation has moved from an an\nobscure research niche to a mainstream activity. In this article, we describe\nthe relationship between machine learning and compiler optimisation and\nintroduce the main concepts of features, models, training and deployment. We\nthen provide a comprehensive survey and provide a road map for the wide variety\nof different research areas. We conclude with a discussion on open issues in\nthe area and potential research directions. This paper provides both an\naccessible introduction to the fast moving area of machine learning based\ncompilation and a detailed bibliography of its main achievements.", "journal": ""}
{"doi": "10.48550/arXiv.1805.08239", "date": "2018-05-21", "title": "The Roles of Supervised Machine Learning in Systems Neuroscience", "authors": "Joshua I. Glaser, Ari S. Benjamin, Roozbeh Farhoodi, Konrad P. Kording", "abstract": "Over the last several years, the use of machine learning (ML) in neuroscience\nhas been rapidly increasing. Here, we review ML's contributions, both realized\nand potential, across several areas of systems neuroscience. We describe four\nprimary roles of ML within neuroscience: 1) creating solutions to engineering\nproblems, 2) identifying predictive variables, 3) setting benchmarks for simple\nmodels of the brain, and 4) serving itself as a model for the brain. The\nbreadth and ease of its applicability suggests that machine learning should be\nin the toolbox of most systems neuroscientists.", "journal": ""}
{"doi": "10.48550/arXiv.1901.09323", "date": "2019-01-27", "title": "Prediction of Silicate Glasses' Stiffness by High-Throughput Molecular Dynamics Simulations and Machine Learning", "authors": "Kai Yang, Xinyi Xu, Benjamin Yang, Brian Cook, Herbert Ramos, Mathieu Bauchy", "abstract": "The development by machine learning of models predicting materials'\nproperties usually requires the use of a large number of consistent data for\ntraining. However, quality experimental datasets are not always available or\nself-consistent. Here, as an alternative route, we combine machine learning\nwith high-throughput molecular dynamics simulations to predict the Young's\nmodulus of silicate glasses. We demonstrate that this combined approach offers\nexcellent predictions over the entire compositional domain. By comparing the\nperformance of select machine learning algorithms, we discuss the nature of the\nbalance between accuracy, simplicity, and interpretability in machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.1910.08842", "date": "2019-10-19", "title": "Machine Learning for AC Optimal Power Flow", "authors": "Neel Guha, Zhecheng Wang, Matt Wytock, Arun Majumdar", "abstract": "We explore machine learning methods for AC Optimal Powerflow (ACOPF) - the\ntask of optimizing power generation in a transmission network according while\nrespecting physical and engineering constraints. We present two formulations of\nACOPF as a machine learning problem: 1) an end-to-end prediction task where we\ndirectly predict the optimal generator settings, and 2) a constraint prediction\ntask where we predict the set of active constraints in the optimal solution. We\nvalidate these approaches on two benchmark grids.", "journal": ""}
{"doi": "10.48550/arXiv.1910.13376", "date": "2019-10-29", "title": "How Much Can We See? A Note on Quantifying Explainability of Machine Learning Models", "authors": "Gero Szepannek", "abstract": "One of the most popular approaches to understanding feature effects of modern\nblack box machine learning models are partial dependence plots (PDP). These\nplots are easy to understand but only able to visualize low order dependencies.\nThe paper is about the question 'How much can we see?': A framework is\ndeveloped to quantify the explainability of arbitrary machine learning models,\ni.e. up to what degree the visualization as given by a PDP is able to explain\nthe predictions of the model. The result allows for a judgement whether an\nattempt to explain a black box model is sufficient or not.", "journal": ""}
{"doi": "10.48550/arXiv.1910.13827", "date": "2019-10-29", "title": "Predicting Rainfall using Machine Learning Techniques", "authors": "Nikhil Oswal", "abstract": "Rainfall prediction is one of the challenging and uncertain tasks which has a\nsignificant impact on human society. Timely and accurate predictions can help\nto proactively reduce human and financial loss. This study presents a set of\nexperiments which involve the use of prevalent machine learning techniques to\nbuild models to predict whether it is going to rain tomorrow or not based on\nweather data for that particular day in major cities of Australia. This\ncomparative study is conducted concentrating on three aspects: modeling inputs,\nmodeling methods, and pre-processing techniques. The results provide a\ncomparison of various evaluation metrics of these machine learning techniques\nand their reliability to predict the rainfall by analyzing the weather data.", "journal": ""}
{"doi": "10.48550/arXiv.2105.01407", "date": "2021-05-04", "title": "A Review on Oracle Issues in Machine Learning", "authors": "Diogo Seca", "abstract": "Machine learning contrasts with traditional software development in that the\noracle is the data, and the data is not always a correct representation of the\nproblem that machine learning tries to model. We present a survey of the oracle\nissues found in machine learning and state-of-the-art solutions for dealing\nwith these issues. These include lines of research for differential testing,\nmetamorphic testing, and test coverage. We also review some recent improvements\nto robustness during modeling that reduce the impact of oracle issues, as well\nas tools and frameworks for assisting in testing and discovering issues\nspecific to the dataset.", "journal": ""}
{"doi": "10.48550/arXiv.2105.06314", "date": "2021-05-13", "title": "Explainable Machine Learning for Fraud Detection", "authors": "Ismini Psychoula, Andreas Gutmann, Pradip Mainali, S. H. Lee, Paul Dunphy, Fabien A. P. Petitcolas", "abstract": "The application of machine learning to support the processing of large\ndatasets holds promise in many industries, including financial services.\nHowever, practical issues for the full adoption of machine learning remain with\nthe focus being on understanding and being able to explain the decisions and\npredictions made by complex models. In this paper, we explore explainability\nmethods in the domain of real-time fraud detection by investigating the\nselection of appropriate background datasets and runtime trade-offs on both\nsupervised and unsupervised models.", "journal": ""}
{"doi": "10.48550/arXiv.2202.02414", "date": "2022-02-04", "title": "OMLT: Optimization & Machine Learning Toolkit", "authors": "Francesco Ceccon, Jordan Jalving, Joshua Haddad, Alexander Thebelt, Calvin Tsay, Carl D. Laird, Ruth Misener", "abstract": "The optimization and machine learning toolkit (OMLT) is an open-source\nsoftware package incorporating neural network and gradient-boosted tree\nsurrogate models, which have been trained using machine learning, into larger\noptimization problems. We discuss the advances in optimization technology that\nmade OMLT possible and show how OMLT seamlessly integrates with the algebraic\nmodeling language Pyomo. We demonstrate how to use OMLT for solving\ndecision-making problems in both computer science and engineering.", "journal": ""}
{"doi": "10.48550/arXiv.1708.04680", "date": "2017-08-11", "title": "Augmentor: An Image Augmentation Library for Machine Learning", "authors": "Marcus D. Bloice, Christof Stocker, Andreas Holzinger", "abstract": "The generation of artificial data based on existing observations, known as\ndata augmentation, is a technique used in machine learning to improve model\naccuracy, generalisation, and to control overfitting. Augmentor is a software\npackage, available in both Python and Julia versions, that provides a high\nlevel API for the expansion of image data using a stochastic, pipeline-based\napproach which effectively allows for images to be sampled from a distribution\nof augmented images at runtime. Augmentor provides methods for most standard\naugmentation practices as well as several advanced features such as\nlabel-preserving, randomised elastic distortions, and provides many helper\nfunctions for typical augmentation tasks used in machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.1708.08022", "date": "2017-08-26", "title": "On the Protection of Private Information in Machine Learning Systems: Two Recent Approaches", "authors": "Mart\u00edn Abadi, \u00dalfar Erlingsson, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Nicolas Papernot, Kunal Talwar, Li Zhang", "abstract": "The recent, remarkable growth of machine learning has led to intense interest\nin the privacy of the data on which machine learning relies, and to new\ntechniques for preserving privacy. However, older ideas about privacy may well\nremain valid and useful. This note reviews two recent works on privacy in the\nlight of the wisdom of some of the early literature, in particular the\nprinciples distilled by Saltzer and Schroeder in the 1970s.", "journal": "IEEE 30th Computer Security Foundations Symposium (CSF), pages\n  1--6, 2017"}
{"doi": "10.48550/arXiv.1803.04193", "date": "2018-03-12", "title": "Extreme Learning Machine for Graph Signal Processing", "authors": "Arun Venkitaraman, Saikat Chatterjee, Peter H\u00e4ndel", "abstract": "In this article, we improve extreme learning machines for regression tasks\nusing a graph signal processing based regularization. We assume that the target\nsignal for prediction or regression is a graph signal. With this assumption, we\nuse the regularization to enforce that the output of an extreme learning\nmachine is smooth over a given graph. Simulation results with real data confirm\nthat such regularization helps significantly when the available training data\nis limited in size and corrupted by noise.", "journal": ""}
{"doi": "10.48550/arXiv.1804.01382", "date": "2018-04-03", "title": "Vanlearning: A Machine Learning SaaS Application for People Without Programming Backgrounds", "authors": "Chaochen Wu", "abstract": "Although we have tons of machine learning tools to analyze data, most of them\nrequire users have some programming backgrounds. Here we introduce a SaaS\napplication which allows users analyze their data without any coding and even\nwithout any knowledge of machine learning. Users can upload, train, predict and\ndownload their data by simply clicks their mouses. Our system uses data\npre-processor and validator to relieve the computational cost of our server.\nThe simple architecture of Vanlearning helps developers can easily maintain and\nextend it.", "journal": ""}
{"doi": "10.48550/arXiv.1811.04548", "date": "2018-11-12", "title": "Recent Research Advances on Interactive Machine Learning", "authors": "Liu Jiang, Shixia Liu, Changjian Chen", "abstract": "Interactive Machine Learning (IML) is an iterative learning process that\ntightly couples a human with a machine learner, which is widely used by\nresearchers and practitioners to effectively solve a wide variety of real-world\napplication problems. Although recent years have witnessed the proliferation of\nIML in the field of visual analytics, most recent surveys either focus on a\nspecific area of IML or aim to summarize a visualization field that is too\ngeneric for IML. In this paper, we systematically review the recent literature\non IML and classify them into a task-oriented taxonomy built by us. We conclude\nthe survey with a discussion of open challenges and research opportunities that\nwe believe are inspiring for future work in IML.", "journal": ""}
{"doi": "10.48550/arXiv.1906.01279", "date": "2019-06-04", "title": "Graduated Optimization of Black-Box Functions", "authors": "Weijia Shao, Christian Gei\u00dfler, Fikret Sivrikaya", "abstract": "Motivated by the problem of tuning hyperparameters in machine learning, we\npresent a new approach for gradually and adaptively optimizing an unknown\nfunction using estimated gradients. We validate the empirical performance of\nthe proposed idea on both low and high dimensional problems. The experimental\nresults demonstrate the advantages of our approach for tuning high dimensional\nhyperparameters in machine learning.", "journal": ""}
{"doi": "10.48550/arXiv.1906.10742", "date": "2019-06-19", "title": "Machine Learning Testing: Survey, Landscapes and Horizons", "authors": "Jie M. Zhang, Mark Harman, Lei Ma, Yang Liu", "abstract": "This paper provides a comprehensive survey of Machine Learning Testing (ML\ntesting) research. It covers 144 papers on testing properties (e.g.,\ncorrectness, robustness, and fairness), testing components (e.g., the data,\nlearning program, and framework), testing workflow (e.g., test generation and\ntest evaluation), and application scenarios (e.g., autonomous driving, machine\ntranslation). The paper also analyses trends concerning datasets, research\ntrends, and research focus, concluding with research challenges and promising\nresearch directions in ML testing.", "journal": ""}
{"doi": "10.48550/arXiv.1906.11899", "date": "2019-06-12", "title": "Lidar based Detection and Classification of Pedestrians and Vehicles Using Machine Learning Methods", "authors": "Farzad Shafiei Dizaji", "abstract": "The goal of this paper is to classify objects mapped by LiDAR sensor into\ndifferent classes such as vehicles, pedestrians and bikers. Utilizing a\nLiDAR-based object detector and Neural Networks-based classifier, a novel\nreal-time object detection is presented essentially with respect to aid\nself-driving vehicles in recognizing and classifying other objects encountered\nin the course of driving and proceed accordingly. We discuss our work using\nmachine learning methods to tackle a common high-level problem found in machine\nlearning applications for self-driving cars: the classification of pointcloud\ndata obtained from a 3D LiDAR sensor.", "journal": ""}
{"doi": "10.48550/arXiv.1907.05297", "date": "2019-07-11", "title": "Beyond Imitation: Generative and Variational Choreography via Machine Learning", "authors": "Mariel Pettee, Chase Shimmin, Douglas Duhaime, Ilya Vidrin", "abstract": "Our team of dance artists, physicists, and machine learning researchers has\ncollectively developed several original, configurable machine-learning tools to\ngenerate novel sequences of choreography as well as tunable variations on input\nchoreographic sequences. We use recurrent neural network and autoencoder\narchitectures from a training dataset of movements captured as 53\nthree-dimensional points at each timestep. Sample animations of generated\nsequences and an interactive version of our model can be found at http:\n//www.beyondimitation.com.", "journal": ""}
{"doi": "10.48550/arXiv.1907.09764", "date": "2019-07-23", "title": "Trees and Islands -- Machine learning approach to nuclear physics", "authors": "Nishchal R. Dwivedi", "abstract": "We implement machine learning algorithms to nuclear data. These algorithms\nare purely data driven and generate models that are capable to capture\nintricate trends. Gradient boosted trees algorithm is employed to generate a\ntrained model from existing nuclear data, which is used for prediction for data\nof damping parameter, shell correction energies, quadrupole deformation,\npairing gaps, level densities and giant dipole resonance for large number of\nnuclei. We, in particular, predict level density parameter for superheavy\nelements which is of great current interest. The predictions made by the\nmachine learning algorithm is found to have standard deviation from 0.00035 to\n0.73.", "journal": ""}
{"doi": "10.48550/arXiv.1911.02455", "date": "2019-11-06", "title": "Unfairness towards subjective opinions in Machine Learning", "authors": "Agathe Balayn, Alessandro Bozzon, Zoltan Szlavik", "abstract": "Despite the high interest for Machine Learning (ML) in academia and industry,\nmany issues related to the application of ML to real-life problems are yet to\nbe addressed. Here we put forward one limitation which arises from a lack of\nadaptation of ML models and datasets to specific applications. We formalise a\nnew notion of unfairness as exclusion of opinions. We propose ways to quantify\nthis unfairness, and aid understanding its causes through visualisation. These\ninsights into the functioning of ML-based systems hint at methods to mitigate\nunfairness.", "journal": ""}
{"doi": "10.48550/arXiv.1911.04787", "date": "2019-11-12", "title": "Effects of data ambiguity and cognitive biases on the interpretability of machine learning models in humanitarian decision making", "authors": "David Paulus, Gerdien de Vries, Bartel Van de Walle", "abstract": "The effectiveness of machine learning algorithms depends on the quality and\namount of data and the operationalization and interpretation by the human\nanalyst. In humanitarian response, data is often lacking or overburdening, thus\nambiguous, and the time-scarce, volatile, insecure environments of humanitarian\nactivities are likely to inflict cognitive biases. This paper proposes to\nresearch the effects of data ambiguity and cognitive biases on the\ninterpretability of machine learning algorithms in humanitarian decision\nmaking.", "journal": ""}
{"doi": "10.48550/arXiv.1911.10500", "date": "2019-11-24", "title": "Causality for Machine Learning", "authors": "Bernhard Sch\u00f6lkopf", "abstract": "Graphical causal inference as pioneered by Judea Pearl arose from research on\nartificial intelligence (AI), and for a long time had little connection to the\nfield of machine learning.\n  This article discusses where links have been and should be established,\nintroducing key concepts along the way. It argues that the hard open problems\nof machine learning and AI are intrinsically related to causality, and explains\nhow the field is beginning to understand them.", "journal": "pp 765-804 in H. Geffner et al. (eds): Probabilistic and Causal\n  Inference: The Works of Judea Pearl, ACM, 2022"}
{"doi": "10.48550/arXiv.2001.06597", "date": "2020-01-18", "title": "Machine Learning in Quantitative PET Imaging", "authors": "Tonghe Wang, Yang Lei, Yabo Fu, Walter J. Curran, Tian Liu, Xiaofeng Yang", "abstract": "This paper reviewed the machine learning-based studies for quantitative\npositron emission tomography (PET). Specifically, we summarized the recent\ndevelopments of machine learning-based methods in PET attenuation correction\nand low-count PET reconstruction by listing and comparing the proposed methods,\nstudy designs and reported performances of the current published studies with\nbrief discussion on representative studies. The contributions and challenges\namong the reviewed studies were summarized and highlighted in the discussion\npart followed by.", "journal": ""}
{"doi": "10.48550/arXiv.2002.11631", "date": "2020-02-25", "title": "CausalML: Python Package for Causal Machine Learning", "authors": "Huigang Chen, Totte Harinen, Jeong-Yoon Lee, Mike Yung, Zhenyu Zhao", "abstract": "CausalML is a Python implementation of algorithms related to causal inference\nand machine learning. Algorithms combining causal inference and machine\nlearning have been a trending topic in recent years. This package tries to\nbridge the gap between theoretical work on methodology and practical\napplications by making a collection of methods in this field available in\nPython. This paper introduces the key concepts, scope, and use cases of this\npackage.", "journal": ""}
{"doi": "10.48550/arXiv.2004.04686", "date": "2020-03-27", "title": "Machine Learning in Artificial Intelligence: Towards a Common Understanding", "authors": "Niklas K\u00fchl, Marc Goutier, Robin Hirt, Gerhard Satzger", "abstract": "The application of \"machine learning\" and \"artificial intelligence\" has\nbecome popular within the last decade. Both terms are frequently used in\nscience and media, sometimes interchangeably, sometimes with different\nmeanings. In this work, we aim to clarify the relationship between these terms\nand, in particular, to specify the contribution of machine learning to\nartificial intelligence. We review relevant literature and present a conceptual\nframework which clarifies the role of machine learning to build (artificial)\nintelligent agents. Hence, we seek to provide more terminological clarity and a\nstarting point for (interdisciplinary) discussions and future research.", "journal": ""}
{"doi": "10.48550/arXiv.2005.02649", "date": "2020-05-06", "title": "Testing the Robustness of AutoML Systems", "authors": "Tuomas Halvari, Jukka K. Nurminen, Tommi Mikkonen", "abstract": "Automated machine learning (AutoML) systems aim at finding the best machine\nlearning (ML) pipeline that automatically matches the task and data at hand. We\ninvestigate the robustness of machine learning pipelines generated with three\nAutoML systems, TPOT, H2O, and AutoKeras. In particular, we study the influence\nof dirty data on accuracy, and consider how using dirty training data may help\ncreate more robust solutions. Furthermore, we also analyze how the structure of\nthe generated pipelines differs in different cases.", "journal": "EPTCS 319, 2020, pp. 103-116"}
{"doi": "10.48550/arXiv.2005.07534", "date": "2020-05-15", "title": "Machine Learning as a Catalyst for Value-Based Health Care", "authors": "Matthew G. Crowson, Timothy C. Y. Chan", "abstract": "In this manuscript, we present an argument that machine learning, a subfield\nof artificial intelligence, can drive improvement in value-based health care\nthrough reducing error in clinical decision making. Much of what has been\npreviously published on machine learning in medicine represent single-use or\nproof-of-concept cases, as well as broad reviews of the advantages and\nlimitations of machine learning. It is timely to look at the broader strategy\nfor artificial intelligence implementation in medicine and emphasize how\nmachine learning can positively influence value-based care.", "journal": ""}
{"doi": "10.48550/arXiv.2005.11313", "date": "2020-05-22", "title": "Comparative Study of Machine Learning Models and BERT on SQuAD", "authors": "Devshree Patel, Param Raval, Ratnam Parikh, Yesha Shastri", "abstract": "This study aims to provide a comparative analysis of performance of certain\nmodels popular in machine learning and the BERT model on the Stanford Question\nAnswering Dataset (SQuAD). The analysis shows that the BERT model, which was\nonce state-of-the-art on SQuAD, gives higher accuracy in comparison to other\nmodels. However, BERT requires a greater execution time even when only 100\nsamples are used. This shows that with increasing accuracy more amount of time\nis invested in training the data. Whereas in case of preliminary machine\nlearning models, execution time for full data is lower but accuracy is\ncompromised.", "journal": ""}
{"doi": "10.48550/arXiv.2007.04911", "date": "2020-07-09", "title": "GAMA: a General Automated Machine learning Assistant", "authors": "Pieter Gijsbers, Joaquin Vanschoren", "abstract": "The General Automated Machine learning Assistant (GAMA) is a modular AutoML\nsystem developed to empower users to track and control how AutoML algorithms\nsearch for optimal machine learning pipelines, and facilitate AutoML research\nitself. In contrast to current, often black-box systems, GAMA allows users to\nplug in different AutoML and post-processing techniques, logs and visualizes\nthe search process, and supports easy benchmarking. It currently features three\nAutoML search algorithms, two model post-processing steps, and is designed to\nallow for more components to be added.", "journal": "Lecture Notes in Computer Science, vol 12461 (2021). p560-564"}
{"doi": "10.48550/arXiv.2007.06299", "date": "2020-07-13", "title": "Monitoring and explainability of models in production", "authors": "Janis Klaise, Arnaud Van Looveren, Clive Cox, Giovanni Vacanti, Alexandru Coca", "abstract": "The machine learning lifecycle extends beyond the deployment stage.\nMonitoring deployed models is crucial for continued provision of high quality\nmachine learning enabled services. Key areas include model performance and data\nmonitoring, detecting outliers and data drift using statistical techniques, and\nproviding explanations of historic predictions. We discuss the challenges to\nsuccessful implementation of solutions in each of these areas with some recent\nexamples of production ready solutions using open source tools.", "journal": ""}
{"doi": "10.48550/arXiv.2008.05906", "date": "2020-08-11", "title": "So You Need Datasets for Your COVID-19 Detection Research Using Machine Learning?", "authors": "Md Fahimuzzman Sohan", "abstract": "Millions of people are infected by the coronavirus disease 2019 (COVID19)\naround the world. Machine Learning (ML) techniques are being used for COVID19\ndetection research from the beginning of the epidemic. This article represents\nthe detailed information on frequently used datasets in COVID19 detection using\nMachine Learning (ML). We investigated 96 papers on COVID19 detection between\nJanuary 2020 and June 2020. We extracted the information about used datasets\nfrom the articles and represented them here simultaneously. This investigation\nwill help future researchers to find the COVID19 datasets without difficulty.", "journal": ""}
{"doi": "10.48550/arXiv.2008.07278", "date": "2020-07-21", "title": "Machine Learning in Population and Public Health", "authors": "Vishwali Mhasawade, Yuan Zhao, Rumi Chunara", "abstract": "Research in population and public health focuses on the mechanisms between\ndifferent cultural, social, and environmental factors and their effect on the\nhealth, of not just individuals, but communities as a whole. We present here a\nvery brief introduction into research in these fields, as well as connections\nto existing machine learning work to help activate the machine learning\ncommunity on such topics and highlight specific opportunities where machine\nlearning, public and population health may synergize to better achieve health\nequity.", "journal": ""}
{"doi": "10.48550/arXiv.2012.05940", "date": "2020-12-10", "title": "A Simplistic Machine Learning Approach to Contact Tracing", "authors": "Carlos G\u00f3mez, Niamh Belton, Boi Quach, Jack Nicholls, Devanshu Anand", "abstract": "This report is based on the modified NIST challenge, Too Close For Too Long,\nprovided by the SFI Centre for Machine Learning (ML-Labs). The modified\nchallenge excludes the time calculation (too long) aspect. By handcrafting\nfeatures from phone instrumental data we develop two machine learning models, a\nGBM and an MLP, to estimate distance between two phones. Our method is able to\noutperform the leading NIST challenge result by the Hong Kong University of\nScience and Technology (HKUST) by a significant margin.", "journal": ""}
{"doi": "10.48550/arXiv.2101.06986", "date": "2021-01-18", "title": "Interactive slice visualization for exploring machine learning models", "authors": "Catherine B. Hurley, Mark O'Connell, Katarina Domijan", "abstract": "Machine learning models fit complex algorithms to arbitrarily large datasets.\nThese algorithms are well-known to be high on performance and low on\ninterpretability. We use interactive visualization of slices of predictor space\nto address the interpretability deficit; in effect opening up the black-box of\nmachine learning algorithms, for the purpose of interrogating, explaining,\nvalidating and comparing model fits. Slices are specified directly through\ninteraction, or using various touring algorithms designed to visit\nhigh-occupancy sections or regions where the model fits have interesting\nproperties. The methods presented here are implemented in the R package\n\\pkg{condvis2}.", "journal": ""}
{"doi": "10.48550/arXiv.2101.08119", "date": "2021-01-20", "title": "Review of Machine Learning Applications in Wireless Communications", "authors": "Apoorva Bajaj", "abstract": "This paper looks at various aspects of Machine Learning (ML) applications in\nwireless communication technologies, focusing mainly on fifth-generation (5G)\nand millimeter wave (mmWave) technologies. This paper includes the summaries of\n3 papers on machine learning applications in wireless communication technology.\nThe paper deals with the need for integration of machine learning in wireless\ncommunication, types of machine learning techniques used in wireless\ncommunication, advantages and potential of ML in wireless communication, and\nimplementation parameters of ML in wireless communication, as well as a study\non RSS-Based Classification of usage in indoor millimeter-wave wireless\nnetworks.", "journal": ""}
{"doi": "10.48550/arXiv.2107.05598", "date": "2021-07-12", "title": "Nonlinear Least Squares for Large-Scale Machine Learning using Stochastic Jacobian Estimates", "authors": "Johannes J. Brust", "abstract": "For large nonlinear least squares loss functions in machine learning we\nexploit the property that the number of model parameters typically exceeds the\ndata in one batch. This implies a low-rank structure in the Hessian of the\nloss, which enables effective means to compute search directions. Using this\nproperty, we develop two algorithms that estimate Jacobian matrices and perform\nwell when compared to state-of-the-art methods.", "journal": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139, 2021"}
{"doi": "10.48550/arXiv.2107.12156", "date": "2021-07-21", "title": "Brain Inspired Computing Approach for the Optimization of the Thin Film Thickness of Polystyrene on the Glass Substrates", "authors": "Akshansh Mishra, Devarrishi Dixit", "abstract": "Advent in machine learning is leaving a deep impact on various sectors\nincluding the material science domain. The present paper highlights the\napplication of various supervised machine learning regression algorithms such\nas polynomial regression, decision tree regression algorithm, random forest\nalgorithm, support vector regression algorithm, and artificial neural network\nalgorithm to determine the thin film thickness of Polystyrene on the glass\nsubstrates. The results showed that the polynomial regression machine learning\nalgorithm outperforms all other machine learning models by yielding the\ncoefficient of determination of 0.96 approximately and mean square error of\n0.04 respectively.", "journal": ""}
{"doi": "10.48550/arXiv.2109.02496", "date": "2021-09-06", "title": "Statistical Privacy Guarantees of Machine Learning Preprocessing Techniques", "authors": "Ashly Lau, Jonathan Passerat-Palmbach", "abstract": "Differential privacy provides strong privacy guarantees for machine learning\napplications. Much recent work has been focused on developing differentially\nprivate models, however there has been a gap in other stages of the machine\nlearning pipeline, in particular during the preprocessing phase. Our\ncontributions are twofold: we adapt a privacy violation detection framework\nbased on statistical methods to empirically measure privacy levels of machine\nlearning pipelines, and apply the newly created framework to show that\nresampling techniques used when dealing with imbalanced datasets cause the\nresultant model to leak more privacy. These results highlight the need for\ndeveloping private preprocessing techniques.", "journal": ""}
{"doi": "10.48550/arXiv.2109.14376", "date": "2021-09-29", "title": "Fairness-Driven Private Collaborative Machine Learning", "authors": "Dana Pessach, Tamir Tassa, Erez Shmueli", "abstract": "The performance of machine learning algorithms can be considerably improved\nwhen trained over larger datasets. In many domains, such as medicine and\nfinance, larger datasets can be obtained if several parties, each having access\nto limited amounts of data, collaborate and share their data. However, such\ndata sharing introduces significant privacy challenges. While multiple recent\nstudies have investigated methods for private collaborative machine learning,\nthe fairness of such collaborative algorithms was overlooked. In this work we\nsuggest a feasible privacy-preserving pre-process mechanism for enhancing\nfairness of collaborative machine learning algorithms. Our experimentation with\nthe proposed method shows that it is able to enhance fairness considerably with\nonly a minor compromise in accuracy.", "journal": ""}
{"doi": "10.48550/arXiv.2112.04807", "date": "2021-12-09", "title": "Effective dimension of machine learning models", "authors": "Amira Abbas, David Sutter, Alessio Figalli, Stefan Woerner", "abstract": "Making statements about the performance of trained models on tasks involving\nnew data is one of the primary goals of machine learning, i.e., to understand\nthe generalization power of a model. Various capacity measures try to capture\nthis ability, but usually fall short in explaining important characteristics of\nmodels that we observe in practice. In this study, we propose the local\neffective dimension as a capacity measure which seems to correlate well with\ngeneralization error on standard data sets. Importantly, we prove that the\nlocal effective dimension bounds the generalization error and discuss the\naptness of this capacity measure for machine learning models.", "journal": ""}
{"doi": "10.48550/arXiv.2112.05554", "date": "2021-12-04", "title": "Using Machine Learning to Find New Density Functionals", "authors": "Bhupalee Kalita, Kieron Burke", "abstract": "Machine learning has now become an integral part of research and innovation.\nThe field of machine learning density functional theory has continuously\nexpanded over the years while making several noticeable advances. We briefly\ndiscuss the status of this field and point out some current and future\nchallenges. We also talk about how state-of-the-art science and technology\ntools can help overcome these challenges. This draft is a part of the \"Roadmap\non Machine Learning in Electronic Structure\" to be published in Electronic\nStructure (EST).", "journal": ""}
{"doi": "10.48550/arXiv.2205.05279", "date": "2022-05-11", "title": "Unsupervised machine learning for physical concepts", "authors": "Ruyu Yang", "abstract": "In recent years, machine learning methods have been used to assist scientists\nin scientific research. Human scientific theories are based on a series of\nconcepts. How machine learns the concepts from experimental data will be an\nimportant first step. We propose a hybrid method to extract interpretable\nphysical concepts through unsupervised machine learning. This method consists\nof two stages. At first, we need to find the Betti numbers of experimental\ndata. Secondly, given the Betti numbers, we use a variational autoencoder\nnetwork to extract meaningful physical variables. We test our protocol on toy\nmodels and show how it works.", "journal": ""}
